  0%|          | 0/67994 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/train_mem_ft.py", line 17, in <module>
    train()
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/train_eseg.py", line 1346, in train
    trainer.train()
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/transformers/trainer.py", line 2122, in train
    return inner_training_loop(
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/transformers/trainer.py", line 2426, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches)
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/transformers/trainer.py", line 5038, in get_batch_samples
    batch_samples += [next(epoch_iterator)]
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 493, in __getitem__
    ret_dicts = [self._build_conversation_dict(instance, index, i) for index in indices]
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 493, in <listcomp>
    ret_dicts = [self._build_conversation_dict(instance, index, i) for index in indices]
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 703, in _build_conversation_dict
    extra_replacement = list([self.build_query(x, instance) for x in replacement]) # list[tuple[str, Any]]:  e.g. ('image-encode, data)
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 703, in <listcomp>
    extra_replacement = list([self.build_query(x, instance) for x in replacement]) # list[tuple[str, Any]]:  e.g. ('image-encode, data)
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 420, in build_query
    data, tgt_mask_id = self.get_bitmask_decode(image_path, gt_mask, ref_mask)
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 340, in get_bitmask_decode
    data = processor(np.array(Image.open(image_path).convert('RGB')), masks=masks)
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/model/segmentator/hipie_utils.py", line 104, in __call__
    masks = [self.transform.apply_image(mask) for mask in masks]
  File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/model/segmentator/hipie_utils.py", line 104, in <listcomp>
    masks = [self.transform.apply_image(mask) for mask in masks]
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/segment_anything/utils/transforms.py", line 31, in apply_image
    return np.array(resize(to_pil_image(image), target_size))
  File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 322, in to_pil_image
    raise TypeError(f"Input type {npimg.dtype} is not supported")
TypeError: Input type bool is not supported
[rank0]: Traceback (most recent call last):
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/train_mem_ft.py", line 17, in <module>
[rank0]:     train()
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/train_eseg.py", line 1346, in train
[rank0]:     trainer.train()
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/transformers/trainer.py", line 2122, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/transformers/trainer.py", line 2426, in _inner_training_loop
[rank0]:     batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches)
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/transformers/trainer.py", line 5038, in get_batch_samples
[rank0]:     batch_samples += [next(epoch_iterator)]
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
[rank0]:     return self._process_data(data)
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
[rank0]:     raise exception
[rank0]: TypeError: Caught TypeError in DataLoader worker process 0.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 493, in __getitem__
[rank0]:     ret_dicts = [self._build_conversation_dict(instance, index, i) for index in indices]
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 493, in <listcomp>
[rank0]:     ret_dicts = [self._build_conversation_dict(instance, index, i) for index in indices]
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 703, in _build_conversation_dict
[rank0]:     extra_replacement = list([self.build_query(x, instance) for x in replacement]) # list[tuple[str, Any]]:  e.g. ('image-encode, data)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 703, in <listcomp>
[rank0]:     extra_replacement = list([self.build_query(x, instance) for x in replacement]) # list[tuple[str, Any]]:  e.g. ('image-encode, data)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 420, in build_query
[rank0]:     data, tgt_mask_id = self.get_bitmask_decode(image_path, gt_mask, ref_mask)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/train/explanatory_seg_dataset_adapter.py", line 340, in get_bitmask_decode
[rank0]:     data = processor(np.array(Image.open(image_path).convert('RGB')), masks=masks)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/model/segmentator/hipie_utils.py", line 104, in __call__
[rank0]:     masks = [self.transform.apply_image(mask) for mask in masks]
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/segllm/llava/model/segmentator/hipie_utils.py", line 104, in <listcomp>
[rank0]:     masks = [self.transform.apply_image(mask) for mask in masks]
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/segment_anything/utils/transforms.py", line 31, in apply_image
[rank0]:     return np.array(resize(to_pil_image(image), target_size))
[rank0]:   File "/shared/nas2/blume5/lib/conda/miniconda3/envs/segllm/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 322, in to_pil_image
[rank0]:     raise TypeError(f"Input type {npimg.dtype} is not supported")
[rank0]: TypeError: Input type bool is not supported