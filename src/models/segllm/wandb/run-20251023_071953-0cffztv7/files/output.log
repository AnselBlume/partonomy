
  0%|                                                                                                                                                                                                                                                                                                                                                                          | 0/1000 [00:00<?, ?it/s]/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'global_step': 0, 'loss_lang': 2.1875, 'segm_loss_loss_ce': 14.054627418518066, 'segm_loss_loss_bbox': 5.533013343811035, 'segm_loss_loss_giou': 3.450713634490967, 'segm_loss_loss_mask': 3.4547929763793945, 'segm_loss_loss_dice': 9.669384002685547, 'segm_loss_loss_ce_0': 16.490894317626953, 'segm_loss_loss_bbox_0': 6.31319522857666, 'segm_loss_loss_giou_0': 3.961642026901245, 'segm_loss_loss_boxiou_0': 1.7400462627410889, 'segm_loss_loss_mask_0': 2.922380208969116, 'segm_loss_loss_dice_0': 9.754318237304688, 'segm_loss_loss_ce_1': 16.565359115600586, 'segm_loss_loss_bbox_1': 4.489312171936035, 'segm_loss_loss_giou_1': 3.450028419494629, 'segm_loss_loss_boxiou_1': 1.6567423343658447, 'segm_loss_loss_mask_1': 2.1388344764709473, 'segm_loss_loss_dice_1': 9.49887466430664, 'segm_loss_loss_ce_2': 14.274514198303223, 'segm_loss_loss_bbox_2': 5.218669891357422, 'segm_loss_loss_giou_2': 3.439918041229248, 'segm_loss_loss_boxiou_2': 2.0737438201904297, 'segm_loss_loss_mask_2': 2.7920565605163574, 'segm_loss_loss_dice_2': 9.695405960083008, 'segm_loss_loss_ce_3': 14.394160270690918, 'segm_loss_loss_bbox_3': 5.554248809814453, 'segm_loss_loss_giou_3': 3.4563004970550537, 'segm_loss_loss_boxiou_3': 2.4609146118164062, 'segm_loss_loss_mask_3': 3.2320680618286133, 'segm_loss_loss_dice_3': 9.654223442077637, 'segm_loss_loss_ce_4': 13.763544082641602, 'segm_loss_loss_bbox_4': 5.529097557067871, 'segm_loss_loss_giou_4': 3.451554775238037, 'segm_loss_loss_boxiou_4': 2.5244710445404053, 'segm_loss_loss_mask_4': 3.6026997566223145, 'segm_loss_loss_dice_4': 9.666735649108887, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 3.321928024291992, 'segm_loss_loss_bbox_enc': 0.33220601081848145, 'segm_loss_loss_giou_enc': 1.7052218914031982, 'segm_loss_total_loss': 235.28797912597656, 'segm_loss_iou_train': 0.0031593656167387962}
{'global_step': 0, 'loss_lang': 2.375, 'segm_loss_loss_ce': 22.723148345947266, 'segm_loss_loss_bbox': 1.381021499633789, 'segm_loss_loss_giou': 1.9430198669433594, 'segm_loss_loss_mask': 1.5732362270355225, 'segm_loss_loss_dice': 7.471351623535156, 'segm_loss_loss_ce_0': 23.68415641784668, 'segm_loss_loss_bbox_0': 1.3072961568832397, 'segm_loss_loss_giou_0': 1.956357479095459, 'segm_loss_loss_boxiou_0': 1.2125952243804932, 'segm_loss_loss_mask_0': 1.7109519243240356, 'segm_loss_loss_dice_0': 7.8452324867248535, 'segm_loss_loss_ce_1': 22.07172203063965, 'segm_loss_loss_bbox_1': 1.56626296043396, 'segm_loss_loss_giou_1': 1.955336570739746, 'segm_loss_loss_boxiou_1': 1.2707003355026245, 'segm_loss_loss_mask_1': 1.4782848358154297, 'segm_loss_loss_dice_1': 8.001985549926758, 'segm_loss_loss_ce_2': 22.105627059936523, 'segm_loss_loss_bbox_2': 1.5282177925109863, 'segm_loss_loss_giou_2': 1.855499505996704, 'segm_loss_loss_boxiou_2': 1.1003977060317993, 'segm_loss_loss_mask_2': 1.1263455152511597, 'segm_loss_loss_dice_2': 7.513539791107178, 'segm_loss_loss_ce_3': 22.932289123535156, 'segm_loss_loss_bbox_3': 1.4828481674194336, 'segm_loss_loss_giou_3': 1.9093289375305176, 'segm_loss_loss_boxiou_3': 1.0811313390731812, 'segm_loss_loss_mask_3': 1.3131691217422485, 'segm_loss_loss_dice_3': 7.7468461990356445, 'segm_loss_loss_ce_4': 23.11495590209961, 'segm_loss_loss_bbox_4': 1.40665602684021, 'segm_loss_loss_giou_4': 1.9864416122436523, 'segm_loss_loss_boxiou_4': 1.1944265365600586, 'segm_loss_loss_mask_4': 1.5826036930084229, 'segm_loss_loss_dice_4': 7.472448348999023, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 1.9944868087768555, 'segm_loss_loss_bbox_enc': 0.3628532290458679, 'segm_loss_loss_giou_enc': 0.4645933210849762, 'segm_loss_total_loss': 220.4275360107422, 'segm_loss_iou_train': 0.675000011920929}
{'global_step': 0, 'loss_lang': 1.546875, 'segm_loss_loss_ce': 23.49435043334961, 'segm_loss_loss_bbox': 0.9831738471984863, 'segm_loss_loss_giou': 1.2476770877838135, 'segm_loss_loss_mask': 1.0598756074905396, 'segm_loss_loss_dice': 5.214749336242676, 'segm_loss_loss_ce_0': 24.87833023071289, 'segm_loss_loss_bbox_0': 0.8376458883285522, 'segm_loss_loss_giou_0': 1.1643614768981934, 'segm_loss_loss_boxiou_0': 0.5382132530212402, 'segm_loss_loss_mask_0': 0.7105140686035156, 'segm_loss_loss_dice_0': 5.415292263031006, 'segm_loss_loss_ce_1': 23.318628311157227, 'segm_loss_loss_bbox_1': 0.8825677037239075, 'segm_loss_loss_giou_1': 1.1895239353179932, 'segm_loss_loss_boxiou_1': 0.4662157893180847, 'segm_loss_loss_mask_1': 1.4339674711227417, 'segm_loss_loss_dice_1': 5.387692451477051, 'segm_loss_loss_ce_2': 22.06385040283203, 'segm_loss_loss_bbox_2': 0.8569329977035522, 'segm_loss_loss_giou_2': 1.1318721771240234, 'segm_loss_loss_boxiou_2': 0.40642690658569336, 'segm_loss_loss_mask_2': 1.1801378726959229, 'segm_loss_loss_dice_2': 5.228970050811768, 'segm_loss_loss_ce_3': 22.064678192138672, 'segm_loss_loss_bbox_3': 0.8483880758285522, 'segm_loss_loss_giou_3': 1.1098767518997192, 'segm_loss_loss_boxiou_3': 0.42055216431617737, 'segm_loss_loss_mask_3': 1.234647512435913, 'segm_loss_loss_dice_3': 5.264915943145752, 'segm_loss_loss_ce_4': 22.278602600097656, 'segm_loss_loss_bbox_4': 1.01511549949646, 'segm_loss_loss_giou_4': 1.2761383056640625, 'segm_loss_loss_boxiou_4': 0.4087396264076233, 'segm_loss_loss_mask_4': 1.0331625938415527, 'segm_loss_loss_dice_4': 5.3029680252075195, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 0.9819455742835999, 'segm_loss_loss_bbox_enc': 0.1194535568356514, 'segm_loss_loss_giou_enc': 0.28918883204460144, 'segm_loss_total_loss': 192.73951721191406, 'segm_loss_iou_train': 0.9390722513198853}
{'global_step': 0, 'loss_lang': 3.171875, 'segm_loss_loss_ce': 21.149824142456055, 'segm_loss_loss_bbox': 0.567219614982605, 'segm_loss_loss_giou': 1.6220779418945312, 'segm_loss_loss_mask': 0.163507342338562, 'segm_loss_loss_dice': 5.339499473571777, 'segm_loss_loss_ce_0': 25.13771629333496, 'segm_loss_loss_bbox_0': 0.42495691776275635, 'segm_loss_loss_giou_0': 1.305006504058838, 'segm_loss_loss_boxiou_0': 0.5485123991966248, 'segm_loss_loss_mask_0': 0.11533033847808838, 'segm_loss_loss_dice_0': 5.5481648445129395, 'segm_loss_loss_ce_1': 22.079872131347656, 'segm_loss_loss_bbox_1': 0.5635066032409668, 'segm_loss_loss_giou_1': 1.53106689453125, 'segm_loss_loss_boxiou_1': 0.5746323466300964, 'segm_loss_loss_mask_1': 0.10649338364601135, 'segm_loss_loss_dice_1': 5.339749336242676, 'segm_loss_loss_ce_2': 20.4936466217041, 'segm_loss_loss_bbox_2': 0.5441279411315918, 'segm_loss_loss_giou_2': 1.5708353519439697, 'segm_loss_loss_boxiou_2': 0.5679933428764343, 'segm_loss_loss_mask_2': 0.16998203098773956, 'segm_loss_loss_dice_2': 5.39471435546875, 'segm_loss_loss_ce_3': 20.650617599487305, 'segm_loss_loss_bbox_3': 0.5288692116737366, 'segm_loss_loss_giou_3': 1.5397987365722656, 'segm_loss_loss_boxiou_3': 0.571079671382904, 'segm_loss_loss_mask_3': 0.09962679445743561, 'segm_loss_loss_dice_3': 5.265203475952148, 'segm_loss_loss_ce_4': 21.572193145751953, 'segm_loss_loss_bbox_4': 0.5589799284934998, 'segm_loss_loss_giou_4': 1.6055846214294434, 'segm_loss_loss_boxiou_4': 0.6275131106376648, 'segm_loss_loss_mask_4': 0.11310844123363495, 'segm_loss_loss_dice_4': 5.229917526245117, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 1.84047532081604, 'segm_loss_loss_bbox_enc': 0.07251203805208206, 'segm_loss_loss_giou_enc': 0.3262985348701477, 'segm_loss_total_loss': 181.46034240722656, 'segm_loss_iou_train': 0.7720997929573059}
{'global_step': 0, 'loss_lang': 2.234375, 'segm_loss_loss_ce': 20.617361068725586, 'segm_loss_loss_bbox': 2.0343265533447266, 'segm_loss_loss_giou': 4.1420488357543945, 'segm_loss_loss_mask': 0.47314557433128357, 'segm_loss_loss_dice': 9.773421287536621, 'segm_loss_loss_ce_0': 23.069822311401367, 'segm_loss_loss_bbox_0': 2.1462242603302, 'segm_loss_loss_giou_0': 3.9070568084716797, 'segm_loss_loss_boxiou_0': 1.4645394086837769, 'segm_loss_loss_mask_0': 0.3571488857269287, 'segm_loss_loss_dice_0': 9.85362720489502, 'segm_loss_loss_ce_1': 20.479677200317383, 'segm_loss_loss_bbox_1': 2.150674819946289, 'segm_loss_loss_giou_1': 4.075100898742676, 'segm_loss_loss_boxiou_1': 1.6161493062973022, 'segm_loss_loss_mask_1': 0.3780679404735565, 'segm_loss_loss_dice_1': 9.786028861999512, 'segm_loss_loss_ce_2': 20.494159698486328, 'segm_loss_loss_bbox_2': 2.170511245727539, 'segm_loss_loss_giou_2': 4.118973255157471, 'segm_loss_loss_boxiou_2': 1.5065184831619263, 'segm_loss_loss_mask_2': 0.4626363515853882, 'segm_loss_loss_dice_2': 9.77107048034668, 'segm_loss_loss_ce_3': 20.563739776611328, 'segm_loss_loss_bbox_3': 2.831674098968506, 'segm_loss_loss_giou_3': 3.8526740074157715, 'segm_loss_loss_boxiou_3': 1.2527176141738892, 'segm_loss_loss_mask_3': 0.35234534740448, 'segm_loss_loss_dice_3': 9.805200576782227, 'segm_loss_loss_ce_4': 20.36489486694336, 'segm_loss_loss_bbox_4': 2.0522301197052, 'segm_loss_loss_giou_4': 4.140871524810791, 'segm_loss_loss_boxiou_4': 1.5096198320388794, 'segm_loss_loss_mask_4': 0.4272903501987457, 'segm_loss_loss_dice_4': 9.72546100616455, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 2.6128005981445312, 'segm_loss_loss_bbox_enc': 0.32681548595428467, 'segm_loss_loss_giou_enc': 1.548586130142212, 'segm_loss_total_loss': 236.21536254882812, 'segm_loss_iou_train': 0.0}
{'global_step': 0, 'loss_lang': 2.078125, 'segm_loss_loss_ce': 19.143808364868164, 'segm_loss_loss_bbox': 9.282072067260742, 'segm_loss_loss_giou': 4.138329982757568, 'segm_loss_loss_mask': 2.414431571960449, 'segm_loss_loss_dice': 9.939262390136719, 'segm_loss_loss_ce_0': 21.88079071044922, 'segm_loss_loss_bbox_0': 8.561590194702148, 'segm_loss_loss_giou_0': 3.749831199645996, 'segm_loss_loss_boxiou_0': 1.8684196472167969, 'segm_loss_loss_mask_0': 1.4739620685577393, 'segm_loss_loss_dice_0': 9.904725074768066, 'segm_loss_loss_ce_1': 20.46833038330078, 'segm_loss_loss_bbox_1': 9.02931022644043, 'segm_loss_loss_giou_1': 4.114899635314941, 'segm_loss_loss_boxiou_1': 2.4830431938171387, 'segm_loss_loss_mask_1': 3.388739824295044, 'segm_loss_loss_dice_1': 9.950035095214844, 'segm_loss_loss_ce_2': 19.75069808959961, 'segm_loss_loss_bbox_2': 9.179304122924805, 'segm_loss_loss_giou_2': 4.102299690246582, 'segm_loss_loss_boxiou_2': 2.5384933948516846, 'segm_loss_loss_mask_2': 2.7123260498046875, 'segm_loss_loss_dice_2': 9.948650360107422, 'segm_loss_loss_ce_3': 18.941497802734375, 'segm_loss_loss_bbox_3': 9.246061325073242, 'segm_loss_loss_giou_3': 4.134103298187256, 'segm_loss_loss_boxiou_3': 2.500234603881836, 'segm_loss_loss_mask_3': 2.466604471206665, 'segm_loss_loss_dice_3': 9.925105094909668, 'segm_loss_loss_ce_4': 19.119590759277344, 'segm_loss_loss_bbox_4': 9.277875900268555, 'segm_loss_loss_giou_4': 4.132017135620117, 'segm_loss_loss_boxiou_4': 2.4134368896484375, 'segm_loss_loss_mask_4': 2.4912185668945312, 'segm_loss_loss_dice_4': 9.856689453125, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 2.6070709228515625, 'segm_loss_loss_bbox_enc': 0.5321526527404785, 'segm_loss_loss_giou_enc': 1.415218472480774, 'segm_loss_total_loss': 289.0823669433594, 'segm_loss_iou_train': 0.0019166389247402549}
{'global_step': 0, 'loss_lang': 2.578125, 'segm_loss_loss_ce': 22.321298599243164, 'segm_loss_loss_bbox': 1.4044177532196045, 'segm_loss_loss_giou': 3.6426730155944824, 'segm_loss_loss_mask': 0.4770536720752716, 'segm_loss_loss_dice': 8.955592155456543, 'segm_loss_loss_ce_0': 24.900272369384766, 'segm_loss_loss_bbox_0': 1.091460108757019, 'segm_loss_loss_giou_0': 5.027663230895996, 'segm_loss_loss_boxiou_0': 1.3572639226913452, 'segm_loss_loss_mask_0': 0.5228022336959839, 'segm_loss_loss_dice_0': 9.422357559204102, 'segm_loss_loss_ce_1': 22.543922424316406, 'segm_loss_loss_bbox_1': 1.6552720069885254, 'segm_loss_loss_giou_1': 4.3431220054626465, 'segm_loss_loss_boxiou_1': 1.3232296705245972, 'segm_loss_loss_mask_1': 0.40583163499832153, 'segm_loss_loss_dice_1': 9.056412696838379, 'segm_loss_loss_ce_2': 22.560440063476562, 'segm_loss_loss_bbox_2': 1.47384512424469, 'segm_loss_loss_giou_2': 3.9263486862182617, 'segm_loss_loss_boxiou_2': 1.3746987581253052, 'segm_loss_loss_mask_2': 0.40100568532943726, 'segm_loss_loss_dice_2': 9.18220329284668, 'segm_loss_loss_ce_3': 22.397993087768555, 'segm_loss_loss_bbox_3': 1.4068591594696045, 'segm_loss_loss_giou_3': 3.6302433013916016, 'segm_loss_loss_boxiou_3': 1.4341164827346802, 'segm_loss_loss_mask_3': 0.46566691994667053, 'segm_loss_loss_dice_3': 9.019954681396484, 'segm_loss_loss_ce_4': 22.437664031982422, 'segm_loss_loss_bbox_4': 1.3540637493133545, 'segm_loss_loss_giou_4': 3.624357223510742, 'segm_loss_loss_boxiou_4': 1.5184298753738403, 'segm_loss_loss_mask_4': 0.49253249168395996, 'segm_loss_loss_dice_4': 8.971065521240234, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 2.2646195888519287, 'segm_loss_loss_bbox_enc': 0.6217854619026184, 'segm_loss_loss_giou_enc': 1.7896885871887207, 'segm_loss_total_loss': 238.7983856201172, 'segm_loss_iou_train': 0.10605302453041077}
{'global_step': 0, 'loss_lang': 2.6875, 'segm_loss_loss_ce': 16.671899795532227, 'segm_loss_loss_bbox': 2.2219700813293457, 'segm_loss_loss_giou': 2.8448822498321533, 'segm_loss_loss_mask': 0.6004536151885986, 'segm_loss_loss_dice': 8.867402076721191, 'segm_loss_loss_ce_0': 19.196884155273438, 'segm_loss_loss_bbox_0': 2.8222460746765137, 'segm_loss_loss_giou_0': 3.5171303749084473, 'segm_loss_loss_boxiou_0': 1.5474990606307983, 'segm_loss_loss_mask_0': 0.6439816951751709, 'segm_loss_loss_dice_0': 9.443832397460938, 'segm_loss_loss_ce_1': 16.87850570678711, 'segm_loss_loss_bbox_1': 2.477745532989502, 'segm_loss_loss_giou_1': 2.994711399078369, 'segm_loss_loss_boxiou_1': 1.9106621742248535, 'segm_loss_loss_mask_1': 0.6499463319778442, 'segm_loss_loss_dice_1': 8.967900276184082, 'segm_loss_loss_ce_2': 15.513927459716797, 'segm_loss_loss_bbox_2': 2.333259105682373, 'segm_loss_loss_giou_2': 2.8094239234924316, 'segm_loss_loss_boxiou_2': 1.8503295183181763, 'segm_loss_loss_mask_2': 0.5269951820373535, 'segm_loss_loss_dice_2': 9.177705764770508, 'segm_loss_loss_ce_3': 16.32744026184082, 'segm_loss_loss_bbox_3': 2.239570140838623, 'segm_loss_loss_giou_3': 2.82344388961792, 'segm_loss_loss_boxiou_3': 1.8748763799667358, 'segm_loss_loss_mask_3': 0.5749672651290894, 'segm_loss_loss_dice_3': 9.084460258483887, 'segm_loss_loss_ce_4': 16.6234130859375, 'segm_loss_loss_bbox_4': 2.2007222175598145, 'segm_loss_loss_giou_4': 2.839585304260254, 'segm_loss_loss_boxiou_4': 1.863511562347412, 'segm_loss_loss_mask_4': 0.6322649717330933, 'segm_loss_loss_dice_4': 8.972620010375977, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 1.969348430633545, 'segm_loss_loss_bbox_enc': 1.2810258865356445, 'segm_loss_loss_giou_enc': 1.9219086170196533, 'segm_loss_total_loss': 205.69857788085938, 'segm_loss_iou_train': 0.0}
{'global_step': 0, 'loss_lang': 1.9609375, 'segm_loss_loss_ce': 21.840591430664062, 'segm_loss_loss_bbox': 0.8441154956817627, 'segm_loss_loss_giou': 2.0687339305877686, 'segm_loss_loss_mask': 0.4260444939136505, 'segm_loss_loss_dice': 7.159333229064941, 'segm_loss_loss_ce_0': 23.104087829589844, 'segm_loss_loss_bbox_0': 0.6744378209114075, 'segm_loss_loss_giou_0': 1.8329359292984009, 'segm_loss_loss_boxiou_0': 1.0615313053131104, 'segm_loss_loss_mask_0': 0.9016482830047607, 'segm_loss_loss_dice_0': 7.460156440734863, 'segm_loss_loss_ce_1': 22.045488357543945, 'segm_loss_loss_bbox_1': 0.8712761402130127, 'segm_loss_loss_giou_1': 2.133934497833252, 'segm_loss_loss_boxiou_1': 0.9726316928863525, 'segm_loss_loss_mask_1': 0.38121286034584045, 'segm_loss_loss_dice_1': 7.399580001831055, 'segm_loss_loss_ce_2': 22.92586898803711, 'segm_loss_loss_bbox_2': 0.8554069995880127, 'segm_loss_loss_giou_2': 2.1045079231262207, 'segm_loss_loss_boxiou_2': 1.0014108419418335, 'segm_loss_loss_mask_2': 0.456874817609787, 'segm_loss_loss_dice_2': 7.2934112548828125, 'segm_loss_loss_ce_3': 22.017059326171875, 'segm_loss_loss_bbox_3': 0.8584586381912231, 'segm_loss_loss_giou_3': 2.0952091217041016, 'segm_loss_loss_boxiou_3': 0.9634263515472412, 'segm_loss_loss_mask_3': 0.40359094738960266, 'segm_loss_loss_dice_3': 7.324581146240234, 'segm_loss_loss_ce_4': 21.326534271240234, 'segm_loss_loss_bbox_4': 0.8471672534942627, 'segm_loss_loss_giou_4': 2.0716354846954346, 'segm_loss_loss_boxiou_4': 0.9924688935279846, 'segm_loss_loss_mask_4': 0.41512471437454224, 'segm_loss_loss_dice_4': 6.986993789672852, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 1.6369858980178833, 'segm_loss_loss_bbox_enc': 0.4268436133861542, 'segm_loss_loss_giou_enc': 1.0578677654266357, 'segm_loss_total_loss': 205.2393341064453, 'segm_loss_iou_train': 0.3264737129211426}
{'global_step': 0, 'loss_lang': 2.203125, 'segm_loss_loss_ce': 24.377573013305664, 'segm_loss_loss_bbox': 2.2917168140411377, 'segm_loss_loss_giou': 3.238985061645508, 'segm_loss_loss_mask': 0.16006895899772644, 'segm_loss_loss_dice': 8.150662422180176, 'segm_loss_loss_ce_0': 23.818195343017578, 'segm_loss_loss_bbox_0': 2.755380630493164, 'segm_loss_loss_giou_0': 3.020660161972046, 'segm_loss_loss_boxiou_0': 0.9217938184738159, 'segm_loss_loss_mask_0': 0.1594950258731842, 'segm_loss_loss_dice_0': 9.60389518737793, 'segm_loss_loss_ce_1': 20.672374725341797, 'segm_loss_loss_bbox_1': 1.9401544332504272, 'segm_loss_loss_giou_1': 3.0937931537628174, 'segm_loss_loss_boxiou_1': 1.0866371393203735, 'segm_loss_loss_mask_1': 0.24360708892345428, 'segm_loss_loss_dice_1': 8.178838729858398, 'segm_loss_loss_ce_2': 21.32207679748535, 'segm_loss_loss_bbox_2': 1.6313166618347168, 'segm_loss_loss_giou_2': 3.2022194862365723, 'segm_loss_loss_boxiou_2': 1.4124778509140015, 'segm_loss_loss_mask_2': 0.3879961669445038, 'segm_loss_loss_dice_2': 8.732158660888672, 'segm_loss_loss_ce_3': 21.5245418548584, 'segm_loss_loss_bbox_3': 2.5775644779205322, 'segm_loss_loss_giou_3': 3.2861440181732178, 'segm_loss_loss_boxiou_3': 0.8821894526481628, 'segm_loss_loss_mask_3': 0.31720641255378723, 'segm_loss_loss_dice_3': 8.77434253692627, 'segm_loss_loss_ce_4': 22.877241134643555, 'segm_loss_loss_bbox_4': 2.2404470443725586, 'segm_loss_loss_giou_4': 3.218249559402466, 'segm_loss_loss_boxiou_4': 1.0642802715301514, 'segm_loss_loss_mask_4': 0.2922120690345764, 'segm_loss_loss_dice_4': 7.333003044128418, 'segm_loss_loss_bbox_dn': 0.0, 'segm_loss_loss_giou_dn': 0.0, 'segm_loss_loss_class_dn': 0.0, 'segm_loss_loss_bbox_dn_0': 0.0, 'segm_loss_loss_giou_dn_0': 0.0, 'segm_loss_loss_class_dn_0': 0.0, 'segm_loss_loss_bbox_dn_1': 0.0, 'segm_loss_loss_giou_dn_1': 0.0, 'segm_loss_loss_class_dn_1': 0.0, 'segm_loss_loss_bbox_dn_2': 0.0, 'segm_loss_loss_giou_dn_2': 0.0, 'segm_loss_loss_class_dn_2': 0.0, 'segm_loss_loss_bbox_dn_3': 0.0, 'segm_loss_loss_giou_dn_3': 0.0, 'segm_loss_loss_class_dn_3': 0.0, 'segm_loss_loss_bbox_dn_4': 0.0, 'segm_loss_loss_giou_dn_4': 0.0, 'segm_loss_loss_class_dn_4': 0.0, 'segm_loss_loss_ce_enc': 2.5390262603759766, 'segm_loss_loss_bbox_enc': 0.23629051446914673, 'segm_loss_loss_giou_enc': 1.3525713682174683, 'segm_loss_total_loss': 228.91754150390625, 'segm_loss_iou_train': 0.014251255430281162}
{'loss': 228.1562, 'grad_norm': 2087.498046875, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.0}
  0%|▎                                                                                                                                                                                                                                                                                                                                                               | 1/1000 [00:23<6:27:17, 23.26s/it]/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 4096}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.
  warnings.warn(
/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 223.2188, 'grad_norm': 4279.888671875, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.0}
  0%|▋                                                                                                                                                                                                                                                                                                                                                              | 2/1000 [01:15<11:13:04, 40.46s/it]/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/scratch/blume5/envs/segllm2/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 226.4062, 'grad_norm': 2581.19970703125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
