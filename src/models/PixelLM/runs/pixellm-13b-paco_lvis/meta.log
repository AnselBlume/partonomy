2025-05-14 02:31:48,153 - INFO - Namespace(device='cuda', local_rank=0, vis_save_path='./vis_output', image_size=1024, model_max_length=512, val_dataset='ExplanatorySeg', val_batch_size=1, workers=1, precision='bf16', version='./runs/PixelLM-13B/hf_model', vision_tower='openai/clip-vit-large-patch14', vision_pretrained='/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/weights/sam_vit_h_4b8939.pth', eval_only=True, dataset_dir='/shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors', dataset_path='paco_lvis/paco_lvis_qa_pairs_val.json', output_generation_prompt_in_dataset=False, log_base_dir='./runs', exp_name='pixellm-13b-paco_lvis', use_mm_start_end=True, train_mask_decoder=True, out_dim=256, ce_loss_weight=1.0, dice_loss_weight=0.5, bce_loss_weight=2.0, seg_token_num=1, image_feature_scale_num=2, separate_mm_projector=True, use_expand_question_list=False, masks_process_with_clip=False, preprocessor_config='./configs/preprocessor_448.json', resize_vision_tower=True, resize_vision_tower_size=448, vision_tower_for_mask=True, pad_val_clip_images=True, conv_type='llava_v1', limit_batches=None, question_type=<QuestionType.WHOLE_TO_PART: 'whole_to_part'>, test_with_gt_object=False, output_predictions=True, predictions_path='/shared/nas2/jk100/partonomy_private/results/pixellm-13b/paco_lvis/2025_05_14-02_14_51-predictions/whole_to_part_seg_token_num_1_feature_scale_num_2.json', metrics=Namespace(iou_evaluator_config=Namespace(matching_strategy=<MatchingStrategy.ALL: 'all'>, reduction=<Reduction.MICRO: 'micro'>), part_text_evaluator_config=Namespace(match_method=<MatchingStrategy.EXACT: 'exact'>, embedding_model='google-bert/bert-base-uncased', cosine_threshold=0.75, embedding_device='cuda', embedding_matching_algorithm='hungarian', llm_model='microsoft/Phi-4-mini-instruct', llm_temperature=0, max_tokens=100, vllm_gpu_memory_utilization=1.0)))
2025-05-14 02:31:48,504 - INFO - --------build_sam_decoder--------
2025-05-14 02:31:48,504 - INFO - --------sam decoder image size 448--------
2025-05-14 02:31:48,522 - INFO - --------mm_projector requires grad--------
2025-05-14 02:32:02,529 - INFO - --------build_sam_decoder--------
2025-05-14 02:32:02,530 - INFO - --------sam decoder image size 448--------
2025-05-14 03:22:29,201 - INFO - Namespace(device='cuda', local_rank=0, vis_save_path='./vis_output', image_size=1024, model_max_length=512, val_dataset='ExplanatorySeg', val_batch_size=1, workers=1, precision='bf16', version='./runs/PixelLM-13B/hf_model', vision_tower='openai/clip-vit-large-patch14', vision_pretrained='/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/weights/sam_vit_h_4b8939.pth', eval_only=True, dataset_dir='/shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors', dataset_path='pascal_part/pascal_part_qa_pairs_val.json', output_generation_prompt_in_dataset=False, log_base_dir='./runs', exp_name='pixellm-13b-pascal_part', use_mm_start_end=True, train_mask_decoder=True, out_dim=256, ce_loss_weight=1.0, dice_loss_weight=0.5, bce_loss_weight=2.0, seg_token_num=1, image_feature_scale_num=2, separate_mm_projector=True, use_expand_question_list=False, masks_process_with_clip=False, preprocessor_config='./configs/preprocessor_448.json', resize_vision_tower=True, resize_vision_tower_size=448, vision_tower_for_mask=True, pad_val_clip_images=True, conv_type='llava_v1', limit_batches=None, question_type=<QuestionType.WHOLE_TO_PART: 'whole_to_part'>, test_with_gt_object=False, output_predictions=True, predictions_path='/shared/nas2/jk100/partonomy_private/results/pixellm-13b/pascal_part/2025_05_14-02_14_51-predictions/whole_to_part_seg_token_num_1_feature_scale_num_2.json', metrics=Namespace(iou_evaluator_config=Namespace(matching_strategy=<MatchingStrategy.ALL: 'all'>, reduction=<Reduction.MICRO: 'micro'>), part_text_evaluator_config=Namespace(match_method=<MatchingStrategy.EXACT: 'exact'>, embedding_model='google-bert/bert-base-uncased', cosine_threshold=0.75, embedding_device='cuda', embedding_matching_algorithm='hungarian', llm_model='microsoft/Phi-4-mini-instruct', llm_temperature=0, max_tokens=100, vllm_gpu_memory_utilization=1.0)))
2025-05-14 03:22:29,565 - INFO - --------build_sam_decoder--------
2025-05-14 03:22:29,565 - INFO - --------sam decoder image size 448--------
2025-05-14 03:22:29,582 - INFO - --------mm_projector requires grad--------
2025-05-14 03:22:43,091 - INFO - --------build_sam_decoder--------
2025-05-14 03:22:43,091 - INFO - --------sam decoder image size 448--------
