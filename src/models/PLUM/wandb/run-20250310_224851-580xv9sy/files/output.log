You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565



Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [05:07<00:00, 102.59s/it]
trainable params: 6,553,600 || all params: 14,025,701,683 || trainable%: 0.0467256480147682
n:  base_model.model.model.embed_tokens.weight p.shape:  torch.Size([32002, 5120])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.q_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.q_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.k_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.k_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.v_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.v_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.out_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm1.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm2.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin1.weight p.shape:  torch.Size([2048, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin1.bias p.shape:  torch.Size([2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin2.weight p.shape:  torch.Size([256, 2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm3.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm3.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm4.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm4.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.q_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.q_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.k_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.k_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.v_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.v_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.out_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm1.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm2.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin1.weight p.shape:  torch.Size([2048, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin1.bias p.shape:  torch.Size([2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin2.weight p.shape:  torch.Size([256, 2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm3.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm3.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm4.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm4.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.norm_final_attn.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.norm_final_attn.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_token.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.mask_decoder.mask_tokens.weight p.shape:  torch.Size([4, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.0.weight p.shape:  torch.Size([256, 64, 2, 2])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.0.bias p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.1.weight p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.1.bias p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.3.weight p.shape:  torch.Size([64, 32, 2, 2])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.3.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.2.weight p.shape:  torch.Size([4, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.2.bias p.shape:  torch.Size([4])
n:  base_model.model.model.text_hidden_fcs.0.0.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.model.text_hidden_fcs.0.0.bias p.shape:  torch.Size([5120])
n:  base_model.model.model.text_hidden_fcs.0.2.weight p.shape:  torch.Size([256, 5120])
n:  base_model.model.model.text_hidden_fcs.0.2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.token_to_mask_fcs.0.0.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.model.token_to_mask_fcs.0.0.bias p.shape:  torch.Size([5120])
n:  base_model.model.model.token_to_mask_fcs.0.2.weight p.shape:  torch.Size([3, 5120])
n:  base_model.model.model.token_to_mask_fcs.0.2.bias p.shape:  torch.Size([3])
n:  base_model.model.lm_head.weight p.shape:  torch.Size([32002, 5120])
>> (PLUM.py) Initializing teacher LLM...
>> (PLUM.py) Teacher LLM initialized.
ade20k:  20210
cocostuff:  118287
loading annotations into memory...
Done (t=1.76s)
creating index...
index created!
pascal_part:  4366
loading annotations into memory...
Done (t=14.32s)
creating index...
index created!
paco_lvis:  45790
mapillary:  18000
loading dataset refclef into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refclef/refs(unc).p
creating index...
index created.
DONE (t=4.31s)
dataset refclef (refs unc) (train split) has 17978 images and 99523 annotations.
loading dataset refcoco into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcoco/refs(unc).p
creating index...
index created.
DONE (t=6.48s)
dataset refcoco (refs unc) (train split) has 16994 images and 196771 annotations.
loading dataset refcoco+ into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcoco+/refs(unc).p
creating index...
index created.
DONE (t=8.72s)
dataset refcoco+ (refs unc) (train split) has 16992 images and 196737 annotations.
loading dataset refcocog into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcocog/refs(umd).p
creating index...
index created.
DONE (t=9.30s)
dataset refcocog (refs umd) (train split) has 21899 images and 208960 annotations.
vqa_data:  157712
number of reason_seg samples:  239
len(self.img_to_explanation):  239
Training with 20000 examples and validating with 200 examples.
[2025-03-10 22:56:23,889] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5, git-hash=unknown, git-branch=unknown
[2025-03-10 22:56:23,889] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-03-10 22:56:23,889] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-03-10 22:56:23,889] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-10 22:56:48,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /shared/nas/data/m1/jk100/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /shared/nas/data/m1/jk100/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Time to load fused_adam op: 21.734489679336548 seconds
[2025-03-10 22:57:10,907] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-03-10 22:57:11,639] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-03-10 22:57:11,639] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2025-03-10 22:57:11,639] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-03-10 22:57:11,639] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500000000
[2025-03-10 22:57:11,639] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[2025-03-10 22:57:11,640] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2025-03-10 22:57:11,640] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Rank: 0 partition count [1] and sizes[(392077800, False)]
Loading extension module fused_adam...
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/tensor/python_tensor.cpp:78.)
  self._dummy_overflow_buf = get_accelerator().IntTensor([0])
[2025-03-10 22:57:16,891] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2025-03-10 22:57:16,893] [INFO] [utils.py:786:see_memory_usage] MA 53.81 GB         Max_MA 54.54 GB         CA 54.75 GB         Max_CA 55 GB
[2025-03-10 22:57:16,893] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 120.47 GB, percent = 12.0%
[2025-03-10 22:57:20,112] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2025-03-10 22:57:20,113] [INFO] [utils.py:786:see_memory_usage] MA 56.73 GB         Max_MA 58.19 GB         CA 59.13 GB         Max_CA 59 GB
[2025-03-10 22:57:20,113] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 120.48 GB, percent = 12.0%
[2025-03-10 22:57:20,114] [INFO] [stage_1_and_2.py:488:__init__] optimizer state initialized
[2025-03-10 22:57:26,032] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2025-03-10 22:57:26,034] [INFO] [utils.py:786:see_memory_usage] MA 56.73 GB         Max_MA 56.73 GB         CA 59.13 GB         Max_CA 59 GB
[2025-03-10 22:57:26,034] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 120.48 GB, percent = 12.0%
[2025-03-10 22:57:26,042] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-03-10 22:57:26,042] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR
[2025-03-10 22:57:26,042] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x7fb701e6dc90>
[2025-03-10 22:57:26,042] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[(0.9, 0.95)]
[2025-03-10 22:57:26,049] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2025-03-10 22:57:26,050] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2025-03-10 22:57:26,050] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-03-10 22:57:26,050] [INFO] [config.py:964:print]   amp_enabled .................. False
[2025-03-10 22:57:26,050] [INFO] [config.py:964:print]   amp_params ................... False
[2025-03-10 22:57:26,050] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   bfloat16_enabled ............. True
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa4c97b1870>
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   communication_data_type ...... None
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-10 22:57:26,051] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   disable_allgather ............ False
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   dump_state ................... False
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2025-03-10 22:57:26,052] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   fp16_auto_cast ............... None
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   fp16_enabled ................. False
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2025-03-10 22:57:26,053] [INFO] [config.py:964:print]   global_rank .................. 0
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 10
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 1
[2025-03-10 22:57:26,054] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   loss_scale ................... 1.0
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2025-03-10 22:57:26,055] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   optimizer_name ............... adamw
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   optimizer_params ............. {'lr': 0.0003, 'weight_decay': 0.0, 'betas': (0.9, 0.95)}
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   pld_enabled .................. False
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   pld_params ................... False
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   scheduler_name ............... WarmupDecayLR
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   scheduler_params ............. {'total_num_steps': 25000, 'warmup_min_lr': 0, 'warmup_max_lr': 0.0003, 'warmup_num_steps': 100, 'warmup_type': 'linear'}
[2025-03-10 22:57:26,056] [INFO] [config.py:964:print]   sparse_attention ............. None
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   train_batch_size ............. 40
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  4
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2025-03-10 22:57:26,057] [INFO] [config.py:964:print]   world_size ................... 1
[2025-03-10 22:57:26,058] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[2025-03-10 22:57:26,058] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2025-03-10 22:57:26,058] [INFO] [config.py:964:print]   zero_enabled ................. True
[2025-03-10 22:57:26,058] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-10 22:57:26,058] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[2025-03-10 22:57:26,058] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4,
    "gradient_accumulation_steps": 10,
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 0.0003,
            "weight_decay": 0.0,
            "betas": [0.9, 0.95]
        }
    },
    "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "total_num_steps": 2.500000e+04,
            "warmup_min_lr": 0,
            "warmup_max_lr": 0.0003,
            "warmup_num_steps": 100,
            "warmup_type": "linear"
        }
    },
    "fp16": {
        "enabled": false
    },
    "bf16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "zero_optimization": {
        "stage": 2,
        "contiguous_gradients": true,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 5.000000e+08,
        "allgather_bucket_size": 5.000000e+08
    }
}
(train) >> AFTER DEEPSPEED
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)
  return F.conv2d(input, weight, bias, self.stride,
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch: [0][  1/500]	Time 58.554 (58.554)	Loss 0.8664 (0.7481)	CeLoss 0.3223 (0.2290)	SegCLSLoss 0.1240 (0.1049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1457 (0.1457)	MaskBCELoss 0.0505 (0.0580)	MaskDICELoss 0.0953 (0.0877)
Epoch: [0][  2/500]	Time 45.617 (45.617)	Loss 0.6924 (0.7059)	CeLoss 0.2324 (0.2135)	SegCLSLoss 0.1133 (0.1146)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1020 (0.1241)	MaskBCELoss 0.0023 (0.0305)	MaskDICELoss 0.0997 (0.0936)
Epoch: [0][  3/500]	Time 45.501 (45.501)	Loss 0.8015 (0.7410)	CeLoss 0.2832 (0.2822)	SegCLSLoss 0.1162 (0.1048)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1587 (0.1219)	MaskBCELoss 0.0871 (0.0404)	MaskDICELoss 0.0717 (0.0815)
Epoch: [0][  4/500]	Time 47.410 (47.410)	Loss 0.8080 (0.7164)	CeLoss 0.3320 (0.2554)	SegCLSLoss 0.1196 (0.1049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1090 (0.1156)	MaskBCELoss 0.0102 (0.0270)	MaskDICELoss 0.0989 (0.0887)
Epoch: [0][  5/500]	Time 45.432 (45.432)	Loss 0.7984 (0.7106)	CeLoss 0.2969 (0.2120)	SegCLSLoss 0.1172 (0.1137)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1285 (0.1298)	MaskBCELoss 0.0359 (0.0387)	MaskDICELoss 0.0926 (0.0911)
Epoch: [0][  6/500]	Time 43.514 (43.514)	Loss 0.6425 (0.7316)	CeLoss 0.1748 (0.2285)	SegCLSLoss 0.1123 (0.1148)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1056 (0.1280)	MaskBCELoss 0.0056 (0.0332)	MaskDICELoss 0.1000 (0.0947)
Epoch: [0][  7/500]	Time 43.707 (43.707)	Loss 0.7501 (0.7035)	CeLoss 0.2188 (0.2371)	SegCLSLoss 0.1104 (0.1156)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1487 (0.1195)	MaskBCELoss 0.0591 (0.0348)	MaskDICELoss 0.0896 (0.0847)
Epoch: [0][  8/500]	Time 52.838 (52.838)	Loss 0.8206 (0.7501)	CeLoss 0.3066 (0.2557)	SegCLSLoss 0.1196 (0.1047)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1275 (0.1413)	MaskBCELoss 0.0276 (0.0617)	MaskDICELoss 0.1000 (0.0796)
Epoch: [0][  9/500]	Time 48.485 (48.485)	Loss 0.8593 (0.8186)	CeLoss 0.1260 (0.2482)	SegCLSLoss 0.1147 (0.1165)	KLLoss 0.0000 (0.0000)	MaskLoss 0.2399 (0.1629)	MaskBCELoss 0.1415 (0.0699)	MaskDICELoss 0.0984 (0.0931)
Epoch: [0][ 10/500]	Time 46.984 (46.984)	Loss 0.6575 (0.7639)	CeLoss 0.1943 (0.2569)	SegCLSLoss 0.1104 (0.1150)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1041 (0.1301)	MaskBCELoss 0.0045 (0.0355)	MaskDICELoss 0.0996 (0.0945)
Epoch: [0][ 11/500]	Time 50.759 (50.759)	Loss 0.7808 (0.7722)	CeLoss 0.3242 (0.2571)	SegCLSLoss 0.0986 (0.0902)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1045 (0.1446)	MaskBCELoss 0.0046 (0.0540)	MaskDICELoss 0.0999 (0.0906)
Epoch: [0][ 12/500]	Time 48.494 (48.494)	Loss 0.5308 (0.7347)	CeLoss 0.0986 (0.2388)	SegCLSLoss 0.0850 (0.0889)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1140 (0.1358)	MaskBCELoss 0.0333 (0.0458)	MaskDICELoss 0.0807 (0.0900)
Epoch: [0][ 13/500]	Time 69.045 (69.045)	Loss 0.7763 (0.6981)	CeLoss 0.2139 (0.2583)	SegCLSLoss 0.0850 (0.0813)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1602 (0.1236)	MaskBCELoss 0.0603 (0.0477)	MaskDICELoss 0.0999 (0.0759)
Epoch: [0][ 14/500]	Time 83.065 (83.065)	Loss 0.6284 (0.7131)	CeLoss 0.1826 (0.2262)	SegCLSLoss 0.0830 (0.0839)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1027 (0.1321)	MaskBCELoss 0.0036 (0.0417)	MaskDICELoss 0.0990 (0.0904)
Epoch: [0][ 15/500]	Time 72.604 (72.604)	Loss 0.6987 (0.6508)	CeLoss 0.1816 (0.2167)	SegCLSLoss 0.0845 (0.0784)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1377 (0.1182)	MaskBCELoss 0.0385 (0.0390)	MaskDICELoss 0.0992 (0.0792)
Epoch: [0][ 16/500]	Time 72.592 (72.592)	Loss 0.6908 (0.7423)	CeLoss 0.1748 (0.2232)	SegCLSLoss 0.0820 (0.0786)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1378 (0.1532)	MaskBCELoss 0.0380 (0.0665)	MaskDICELoss 0.0998 (0.0867)
Epoch: [0][ 17/500]	Time 74.911 (74.911)	Loss 0.7689 (0.7872)	CeLoss 0.3184 (0.2808)	SegCLSLoss 0.0986 (0.0898)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1022 (0.1375)	MaskBCELoss 0.0044 (0.0442)	MaskDICELoss 0.0979 (0.0933)
Epoch: [0][ 18/500]	Time 76.123 (76.123)	Loss 0.6276 (0.7348)	CeLoss 0.1475 (0.2487)	SegCLSLoss 0.0874 (0.0904)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1343 (0.1286)	MaskBCELoss 0.0505 (0.0368)	MaskDICELoss 0.0838 (0.0918)
Epoch: [0][ 19/500]	Time 72.677 (72.677)	Loss 0.6749 (0.7839)	CeLoss 0.1543 (0.2537)	SegCLSLoss 0.0850 (0.0885)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1414 (0.1490)	MaskBCELoss 0.0439 (0.0550)	MaskDICELoss 0.0976 (0.0940)
Epoch: [0][ 20/500]	Time 78.334 (78.334)	Loss 0.7740 (0.6729)	CeLoss 0.2637 (0.2246)	SegCLSLoss 0.0859 (0.0798)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1339 (0.1238)	MaskBCELoss 0.0340 (0.0435)	MaskDICELoss 0.0999 (0.0803)
Epoch: [0][ 21/500]	Time 51.054 (51.054)	Loss 0.6661 (0.7394)	CeLoss 0.2441 (0.2399)	SegCLSLoss 0.0219 (0.0337)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1116 (0.1461)	MaskBCELoss 0.0174 (0.0510)	MaskDICELoss 0.0942 (0.0952)
Epoch: [0][ 22/500]	Time 69.177 (69.177)	Loss 0.6002 (0.6778)	CeLoss 0.1504 (0.2233)	SegCLSLoss 0.0260 (0.0312)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1185 (0.1245)	MaskBCELoss 0.0189 (0.0297)	MaskDICELoss 0.0996 (0.0948)
Epoch: [0][ 23/500]	Time 72.300 (72.300)	Loss 0.7065 (0.6958)	CeLoss 0.2285 (0.2264)	SegCLSLoss 0.0216 (0.0318)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1396 (0.1313)	MaskBCELoss 0.0455 (0.0358)	MaskDICELoss 0.0941 (0.0955)
Epoch: [0][ 24/500]	Time 44.495 (44.495)	Loss 0.7748 (0.6271)	CeLoss 0.3008 (0.2045)	SegCLSLoss 0.0386 (0.0296)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1299 (0.1135)	MaskBCELoss 0.0318 (0.0230)	MaskDICELoss 0.0981 (0.0905)
Epoch: [0][ 25/500]	Time 49.252 (49.252)	Loss 0.6320 (0.6056)	CeLoss 0.1465 (0.1974)	SegCLSLoss 0.0281 (0.0221)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1572 (0.1344)	MaskBCELoss 0.0788 (0.0702)	MaskDICELoss 0.0784 (0.0642)
Epoch: [0][ 26/500]	Time 41.097 (41.097)	Loss 0.8132 (0.7019)	CeLoss 0.3477 (0.2325)	SegCLSLoss 0.0432 (0.0346)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1272 (0.1286)	MaskBCELoss 0.0330 (0.0313)	MaskDICELoss 0.0942 (0.0974)
Epoch: [0][ 27/500]	Time 51.142 (51.142)	Loss 0.7044 (0.7039)	CeLoss 0.2812 (0.2402)	SegCLSLoss 0.0417 (0.0334)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1015 (0.1278)	MaskBCELoss 0.0015 (0.0320)	MaskDICELoss 0.1000 (0.0958)
Epoch: [0][ 28/500]	Time 66.424 (66.424)	Loss 0.8090 (0.6675)	CeLoss 0.3184 (0.2286)	SegCLSLoss 0.0420 (0.0291)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1356 (0.1260)	MaskBCELoss 0.0362 (0.0397)	MaskDICELoss 0.0994 (0.0863)
Epoch: [0][ 29/500]	Time 43.561 (43.561)	Loss 0.6224 (0.7364)	CeLoss 0.1250 (0.2614)	SegCLSLoss 0.0322 (0.0370)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1556 (0.1314)	MaskBCELoss 0.0708 (0.0348)	MaskDICELoss 0.0849 (0.0967)
Epoch: [0][ 30/500]	Time 50.087 (50.087)	Loss 0.7845 (0.6889)	CeLoss 0.3340 (0.2457)	SegCLSLoss 0.0430 (0.0352)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1164 (0.1141)	MaskBCELoss 0.0186 (0.0153)	MaskDICELoss 0.0978 (0.0987)
Epoch: [0][ 31/500]	Time 64.490 (64.490)	Loss 0.7521 (0.6124)	CeLoss 0.2754 (0.2011)	SegCLSLoss 0.0145 (0.0095)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1347 (0.1171)	MaskBCELoss 0.0347 (0.0309)	MaskDICELoss 0.1000 (0.0862)
Epoch: [0][ 32/500]	Time 48.183 (48.183)	Loss 0.6435 (0.6379)	CeLoss 0.2891 (0.2414)	SegCLSLoss 0.0133 (0.0092)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1192 (0.1163)	MaskBCELoss 0.0643 (0.0365)	MaskDICELoss 0.0549 (0.0798)
Epoch: [0][ 33/500]	Time 51.854 (51.854)	Loss 0.6358 (0.6620)	CeLoss 0.1777 (0.2093)	SegCLSLoss 0.0072 (0.0100)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1270 (0.1348)	MaskBCELoss 0.0271 (0.0459)	MaskDICELoss 0.0999 (0.0890)
Epoch: [0][ 34/500]	Time 45.446 (45.446)	Loss 0.6212 (0.6434)	CeLoss 0.2451 (0.2154)	SegCLSLoss 0.0064 (0.0086)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1148 (0.1297)	MaskBCELoss 0.0432 (0.0475)	MaskDICELoss 0.0716 (0.0822)
Epoch: [0][ 35/500]	Time 49.852 (49.852)	Loss 0.6439 (0.6157)	CeLoss 0.1621 (0.2081)	SegCLSLoss 0.0112 (0.0106)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1431 (0.1171)	MaskBCELoss 0.0482 (0.0329)	MaskDICELoss 0.0949 (0.0841)
Epoch: [0][ 36/500]	Time 47.929 (47.929)	Loss 0.6923 (0.6466)	CeLoss 0.2695 (0.2406)	SegCLSLoss 0.0121 (0.0095)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1219 (0.1158)	MaskBCELoss 0.0358 (0.0309)	MaskDICELoss 0.0860 (0.0849)
Epoch: [0][ 37/500]	Time 43.036 (43.036)	Loss 0.6045 (0.6648)	CeLoss 0.1465 (0.1991)	SegCLSLoss 0.0089 (0.0104)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1339 (0.1435)	MaskBCELoss 0.0413 (0.0568)	MaskDICELoss 0.0926 (0.0867)
Epoch: [0][ 38/500]	Time 47.667 (47.667)	Loss 0.6216 (0.7125)	CeLoss 0.1895 (0.2587)	SegCLSLoss 0.0075 (0.0115)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1157 (0.1321)	MaskBCELoss 0.0171 (0.0402)	MaskDICELoss 0.0986 (0.0919)
Epoch: [0][ 39/500]	Time 44.522 (44.522)	Loss 0.7440 (0.6541)	CeLoss 0.2734 (0.2300)	SegCLSLoss 0.0146 (0.0102)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1490 (0.1238)	MaskBCELoss 0.0666 (0.0380)	MaskDICELoss 0.0824 (0.0858)
Epoch: [0][ 40/500]	Time 47.177 (47.177)	Loss 0.5922 (0.6361)	CeLoss 0.1572 (0.2362)	SegCLSLoss 0.0090 (0.0101)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1306 (0.1178)	MaskBCELoss 0.0459 (0.0382)	MaskDICELoss 0.0847 (0.0796)
Epoch: [0][ 41/500]	Time 46.614 (46.614)	Loss 0.6487 (0.6381)	CeLoss 0.2539 (0.1925)	SegCLSLoss 0.0042 (0.0039)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1146 (0.1314)	MaskBCELoss 0.0322 (0.0410)	MaskDICELoss 0.0824 (0.0904)
Epoch: [0][ 42/500]	Time 49.955 (49.955)	Loss 0.3188 (0.5208)	CeLoss 0.1846 (0.1959)	SegCLSLoss 0.0016 (0.0027)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0429 (0.0985)	MaskBCELoss 0.0189 (0.0352)	MaskDICELoss 0.0240 (0.0633)
Epoch: [0][ 43/500]	Time 50.751 (50.751)	Loss 0.6669 (0.5743)	CeLoss 0.2139 (0.1978)	SegCLSLoss 0.0013 (0.0034)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1277 (0.1057)	MaskBCELoss 0.0289 (0.0239)	MaskDICELoss 0.0988 (0.0818)
Epoch: [0][ 44/500]	Time 50.219 (50.219)	Loss 0.6303 (0.5734)	CeLoss 0.1973 (0.1962)	SegCLSLoss 0.0020 (0.0033)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1294 (0.1089)	MaskBCELoss 0.0429 (0.0299)	MaskDICELoss 0.0865 (0.0790)
Epoch: [0][ 45/500]	Time 51.648 (51.648)	Loss 0.7290 (0.4692)	CeLoss 0.2773 (0.2062)	SegCLSLoss 0.0057 (0.0026)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1314 (0.0719)	MaskBCELoss 0.0381 (0.0129)	MaskDICELoss 0.0933 (0.0590)
Epoch: [0][ 46/500]	Time 46.543 (46.543)	Loss 0.6338 (0.6118)	CeLoss 0.2061 (0.1956)	SegCLSLoss 0.0047 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1166 (0.1224)	MaskBCELoss 0.0201 (0.0377)	MaskDICELoss 0.0964 (0.0848)
Epoch: [0][ 47/500]	Time 45.230 (45.230)	Loss 0.7313 (0.6513)	CeLoss 0.2617 (0.2313)	SegCLSLoss 0.0024 (0.0052)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1411 (0.1206)	MaskBCELoss 0.0478 (0.0325)	MaskDICELoss 0.0933 (0.0881)
Epoch: [0][ 48/500]	Time 45.535 (45.535)	Loss 0.6174 (0.6725)	CeLoss 0.1777 (0.2188)	SegCLSLoss 0.0025 (0.0031)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1195 (0.1356)	MaskBCELoss 0.0198 (0.0450)	MaskDICELoss 0.0997 (0.0906)
Epoch: [0][ 49/500]	Time 46.922 (46.922)	Loss 0.6059 (0.4986)	CeLoss 0.2236 (0.1957)	SegCLSLoss 0.0027 (0.0039)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1070 (0.0882)	MaskBCELoss 0.0236 (0.0260)	MaskDICELoss 0.0835 (0.0622)
Epoch: [0][ 50/500]	Time 43.848 (43.848)	Loss 0.7386 (0.6346)	CeLoss 0.3262 (0.2177)	SegCLSLoss 0.0042 (0.0049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1063 (0.1135)	MaskBCELoss 0.0074 (0.0198)	MaskDICELoss 0.0989 (0.0937)
Epoch: [0][ 51/500]	Time 47.255 (47.255)	Loss 0.8103 (0.5595)	CeLoss 0.2402 (0.1856)	SegCLSLoss 0.0026 (0.0041)	KLLoss 0.0001 (0.0000)	MaskLoss 0.1947 (0.1032)	MaskBCELoss 0.1054 (0.0204)	MaskDICELoss 0.0894 (0.0827)
Epoch: [0][ 52/500]	Time 42.771 (42.771)	Loss 0.5867 (0.6133)	CeLoss 0.1758 (0.1924)	SegCLSLoss 0.0064 (0.0043)	KLLoss 0.0000 (0.0001)	MaskLoss 0.1048 (0.1130)	MaskBCELoss 0.0057 (0.0166)	MaskDICELoss 0.0991 (0.0964)
Epoch: [0][ 53/500]	Time 48.270 (48.270)	Loss 0.5395 (0.5737)	CeLoss 0.1240 (0.1704)	SegCLSLoss 0.0016 (0.0034)	KLLoss 0.0001 (0.0000)	MaskLoss 0.1074 (0.1233)	MaskBCELoss 0.0075 (0.0458)	MaskDICELoss 0.0999 (0.0775)
Epoch: [0][ 54/500]	Time 47.978 (47.978)	Loss 0.5559 (0.5605)	CeLoss 0.1572 (0.1681)	SegCLSLoss 0.0035 (0.0045)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1173 (0.1147)	MaskBCELoss 0.0359 (0.0343)	MaskDICELoss 0.0814 (0.0804)
Epoch: [0][ 55/500]	Time 46.313 (46.313)	Loss 0.6152 (0.5675)	CeLoss 0.2012 (0.1957)	SegCLSLoss 0.0056 (0.0041)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1054 (0.1050)	MaskBCELoss 0.0055 (0.0253)	MaskDICELoss 0.0999 (0.0798)
Epoch: [0][ 56/500]	Time 50.532 (50.532)	Loss 0.5839 (0.5975)	CeLoss 0.1699 (0.1761)	SegCLSLoss 0.0029 (0.0049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1061 (0.1183)	MaskBCELoss 0.0061 (0.0271)	MaskDICELoss 0.0999 (0.0912)
Epoch: [0][ 57/500]	Time 44.566 (44.566)	Loss 0.5382 (0.5138)	CeLoss 0.1650 (0.1810)	SegCLSLoss 0.0036 (0.0023)	KLLoss 0.0000 (0.0001)	MaskLoss 0.1098 (0.0936)	MaskBCELoss 0.0338 (0.0214)	MaskDICELoss 0.0761 (0.0723)
Epoch: [0][ 58/500]	Time 51.019 (51.019)	Loss 0.6040 (0.5187)	CeLoss 0.1924 (0.1922)	SegCLSLoss 0.0047 (0.0027)	KLLoss 0.0000 (0.0001)	MaskLoss 0.1049 (0.0867)	MaskBCELoss 0.0050 (0.0109)	MaskDICELoss 0.0999 (0.0758)
Epoch: [0][ 59/500]	Time 45.684 (45.684)	Loss 0.7109 (0.6029)	CeLoss 0.2471 (0.1721)	SegCLSLoss 0.0023 (0.0032)	KLLoss 0.0001 (0.0000)	MaskLoss 0.1386 (0.1175)	MaskBCELoss 0.0460 (0.0205)	MaskDICELoss 0.0926 (0.0970)
Epoch: [0][ 60/500]	Time 45.692 (45.692)	Loss 0.6246 (0.4427)	CeLoss 0.1973 (0.1596)	SegCLSLoss 0.0058 (0.0025)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1239 (0.0773)	MaskBCELoss 0.0355 (0.0137)	MaskDICELoss 0.0884 (0.0636)
Epoch: [0][ 61/500]	Time 45.805 (45.805)	Loss 0.5447 (0.5806)	CeLoss 0.1299 (0.1572)	SegCLSLoss 0.0017 (0.0044)	KLLoss 0.0001 (0.0002)	MaskLoss 0.1071 (0.1222)	MaskBCELoss 0.0071 (0.0338)	MaskDICELoss 0.1000 (0.0884)
Epoch: [0][ 62/500]	Time 44.762 (44.762)	Loss 0.5083 (0.4762)	CeLoss 0.1738 (0.1432)	SegCLSLoss 0.0205 (0.0061)	KLLoss 0.0001 (0.0001)	MaskLoss 0.0969 (0.0891)	MaskBCELoss 0.0318 (0.0132)	MaskDICELoss 0.0651 (0.0759)
Epoch: [0][ 63/500]	Time 47.182 (47.182)	Loss 0.5891 (0.5444)	CeLoss 0.1514 (0.1471)	SegCLSLoss 0.0014 (0.0038)	KLLoss 0.0000 (0.0001)	MaskLoss 0.1199 (0.1162)	MaskBCELoss 0.0215 (0.0346)	MaskDICELoss 0.0984 (0.0815)
Epoch: [0][ 64/500]	Time 48.694 (48.694)	Loss 0.6045 (0.5314)	CeLoss 0.1934 (0.1467)	SegCLSLoss 0.0031 (0.0038)	KLLoss 0.0001 (0.0001)	MaskLoss 0.1053 (0.1063)	MaskBCELoss 0.0057 (0.0212)	MaskDICELoss 0.0997 (0.0851)
Epoch: [0][ 65/500]	Time 47.885 (47.885)	Loss 0.5591 (0.5688)	CeLoss 0.1348 (0.1530)	SegCLSLoss 0.0020 (0.0051)	KLLoss 0.0001 (0.0002)	MaskLoss 0.1135 (0.1116)	MaskBCELoss 0.0155 (0.0167)	MaskDICELoss 0.0980 (0.0949)
Epoch: [0][ 66/500]	Time 47.345 (47.345)	Loss 0.1344 (0.5675)	CeLoss 0.1348 (0.1683)	SegCLSLoss 0.0000 (0.0044)	KLLoss 0.0000 (0.0002)	MaskLoss 0.0000 (0.1187)	MaskBCELoss 0.0000 (0.0390)	MaskDICELoss 0.0000 (0.0797)
Epoch: [0][ 67/500]	Time 50.965 (50.965)	Loss 0.5894 (0.5532)	CeLoss 0.1748 (0.1623)	SegCLSLoss 0.0027 (0.0046)	KLLoss 0.0002 (0.0002)	MaskLoss 0.1078 (0.1097)	MaskBCELoss 0.0092 (0.0251)	MaskDICELoss 0.0986 (0.0845)
Epoch: [0][ 68/500]	Time 52.811 (52.811)	Loss 0.5407 (0.5669)	CeLoss 0.1416 (0.1357)	SegCLSLoss 0.0023 (0.0038)	KLLoss 0.0001 (0.0001)	MaskLoss 0.1128 (0.1226)	MaskBCELoss 0.0264 (0.0305)	MaskDICELoss 0.0864 (0.0921)
Epoch: [0][ 69/500]	Time 52.092 (52.092)	Loss 0.5038 (0.5282)	CeLoss 0.1338 (0.1468)	SegCLSLoss 0.0012 (0.0024)	KLLoss 0.0001 (0.0001)	MaskLoss 0.0991 (0.1082)	MaskBCELoss 0.0135 (0.0262)	MaskDICELoss 0.0856 (0.0819)
Epoch: [0][ 70/500]	Time 47.909 (47.909)	Loss 0.5816 (0.5595)	CeLoss 0.1699 (0.1581)	SegCLSLoss 0.0017 (0.0028)	KLLoss 0.0003 (0.0001)	MaskLoss 0.1059 (0.1072)	MaskBCELoss 0.0066 (0.0144)	MaskDICELoss 0.0993 (0.0928)
Epoch: [0][ 71/500]	Time 45.917 (45.917)	Loss 0.5170 (0.5202)	CeLoss 0.1406 (0.1323)	SegCLSLoss 0.0079 (0.0095)	KLLoss 0.0002 (0.0004)	MaskLoss 0.1009 (0.1094)	MaskBCELoss 0.0156 (0.0274)	MaskDICELoss 0.0853 (0.0820)
Epoch: [0][ 72/500]	Time 47.628 (47.628)	Loss 0.6392 (0.5446)	CeLoss 0.1504 (0.1250)	SegCLSLoss 0.0047 (0.0047)	KLLoss 0.0005 (0.0005)	MaskLoss 0.1527 (0.1201)	MaskBCELoss 0.0627 (0.0318)	MaskDICELoss 0.0900 (0.0883)
Epoch: [0][ 73/500]	Time 42.087 (42.087)	Loss 0.5359 (0.5475)	CeLoss 0.1582 (0.1388)	SegCLSLoss 0.0085 (0.0055)	KLLoss 0.0001 (0.0005)	MaskLoss 0.1035 (0.1199)	MaskBCELoss 0.0198 (0.0371)	MaskDICELoss 0.0836 (0.0828)
Epoch: [0][ 74/500]	Time 50.186 (50.186)	Loss 0.5483 (0.5250)	CeLoss 0.1211 (0.1304)	SegCLSLoss 0.0019 (0.0069)	KLLoss 0.0004 (0.0004)	MaskLoss 0.1128 (0.1083)	MaskBCELoss 0.0128 (0.0212)	MaskDICELoss 0.1000 (0.0871)
Epoch: [0][ 75/500]	Time 47.148 (47.148)	Loss 0.5333 (0.4500)	CeLoss 0.1094 (0.1167)	SegCLSLoss 0.0036 (0.0022)	KLLoss 0.0001 (0.0002)	MaskLoss 0.1117 (0.0912)	MaskBCELoss 0.0121 (0.0164)	MaskDICELoss 0.0995 (0.0748)
Epoch: [0][ 76/500]	Time 50.135 (50.135)	Loss 0.5636 (0.4479)	CeLoss 0.1426 (0.1250)	SegCLSLoss 0.0047 (0.0048)	KLLoss 0.0007 (0.0003)	MaskLoss 0.1109 (0.0872)	MaskBCELoss 0.0125 (0.0141)	MaskDICELoss 0.0983 (0.0730)
Epoch: [0][ 77/500]	Time 43.154 (43.154)	Loss 0.5545 (0.5350)	CeLoss 0.1045 (0.1307)	SegCLSLoss 0.0032 (0.0049)	KLLoss 0.0007 (0.0004)	MaskLoss 0.1345 (0.1157)	MaskBCELoss 0.0453 (0.0305)	MaskDICELoss 0.0892 (0.0851)
Epoch: [0][ 78/500]	Time 48.220 (48.220)	Loss 0.5609 (0.5283)	CeLoss 0.1406 (0.1262)	SegCLSLoss 0.0064 (0.0038)	KLLoss 0.0006 (0.0003)	MaskLoss 0.1179 (0.1161)	MaskBCELoss 0.0276 (0.0322)	MaskDICELoss 0.0903 (0.0839)
Epoch: [0][ 79/500]	Time 49.428 (49.428)	Loss 0.5547 (0.5410)	CeLoss 0.1147 (0.1293)	SegCLSLoss 0.0052 (0.0035)	KLLoss 0.0005 (0.0004)	MaskLoss 0.1186 (0.1171)	MaskBCELoss 0.0188 (0.0294)	MaskDICELoss 0.0998 (0.0877)
Epoch: [0][ 80/500]	Time 45.131 (45.131)	Loss 0.5733 (0.5545)	CeLoss 0.1543 (0.1300)	SegCLSLoss 0.0052 (0.0054)	KLLoss 0.0003 (0.0005)	MaskLoss 0.1120 (0.1176)	MaskBCELoss 0.0159 (0.0246)	MaskDICELoss 0.0961 (0.0930)
Epoch: [0][ 81/500]	Time 45.976 (45.976)	Loss 0.4964 (0.4590)	CeLoss 0.1094 (0.1087)	SegCLSLoss 0.0025 (0.0044)	KLLoss 0.0004 (0.0008)	MaskLoss 0.1248 (0.1034)	MaskBCELoss 0.0570 (0.0331)	MaskDICELoss 0.0679 (0.0703)
Epoch: [0][ 82/500]	Time 48.813 (48.813)	Loss 0.5509 (0.4850)	CeLoss 0.1270 (0.1092)	SegCLSLoss 0.0030 (0.0078)	KLLoss 0.0031 (0.0009)	MaskLoss 0.1390 (0.1114)	MaskBCELoss 0.0686 (0.0374)	MaskDICELoss 0.0704 (0.0740)
Epoch: [0][ 83/500]	Time 50.442 (50.442)	Loss 0.5379 (0.5397)	CeLoss 0.1172 (0.1171)	SegCLSLoss 0.0127 (0.0055)	KLLoss 0.0007 (0.0009)	MaskLoss 0.1106 (0.1190)	MaskBCELoss 0.0144 (0.0284)	MaskDICELoss 0.0962 (0.0906)
Epoch: [0][ 84/500]	Time 47.031 (47.031)	Loss 0.1008 (0.3679)	CeLoss 0.1006 (0.1065)	SegCLSLoss 0.0000 (0.0040)	KLLoss 0.0000 (0.0007)	MaskLoss 0.0000 (0.0757)	MaskBCELoss 0.0000 (0.0221)	MaskDICELoss 0.0000 (0.0536)
Epoch: [0][ 85/500]	Time 49.180 (49.180)	Loss 0.5665 (0.5054)	CeLoss 0.1289 (0.1154)	SegCLSLoss 0.0195 (0.0090)	KLLoss 0.0009 (0.0009)	MaskLoss 0.1134 (0.1108)	MaskBCELoss 0.0134 (0.0294)	MaskDICELoss 0.1000 (0.0815)
Epoch: [0][ 86/500]	Time 70.421 (70.421)	Loss 0.5650 (0.5017)	CeLoss 0.1162 (0.1139)	SegCLSLoss 0.0050 (0.0038)	KLLoss 0.0009 (0.0010)	MaskLoss 0.1508 (0.1100)	MaskBCELoss 0.0789 (0.0276)	MaskDICELoss 0.0719 (0.0824)
Epoch: [0][ 87/500]	Time 66.127 (66.127)	Loss 0.1495 (0.4898)	CeLoss 0.1162 (0.1071)	SegCLSLoss 0.0035 (0.0039)	KLLoss 0.0013 (0.0010)	MaskLoss 0.0083 (0.1040)	MaskBCELoss 0.0017 (0.0181)	MaskDICELoss 0.0066 (0.0859)
Epoch: [0][ 88/500]	Time 46.461 (46.461)	Loss 0.5785 (0.5837)	CeLoss 0.1094 (0.1161)	SegCLSLoss 0.0049 (0.0074)	KLLoss 0.0007 (0.0012)	MaskLoss 0.1333 (0.1405)	MaskBCELoss 0.0336 (0.0497)	MaskDICELoss 0.0997 (0.0908)
Epoch: [0][ 89/500]	Time 49.577 (49.577)	Loss 0.5409 (0.4880)	CeLoss 0.0957 (0.1140)	SegCLSLoss 0.0009 (0.0035)	KLLoss 0.0014 (0.0011)	MaskLoss 0.1242 (0.1046)	MaskBCELoss 0.0267 (0.0236)	MaskDICELoss 0.0974 (0.0810)
Epoch: [0][ 90/500]	Time 45.559 (45.559)	Loss 0.5292 (0.5438)	CeLoss 0.1045 (0.1180)	SegCLSLoss 0.0022 (0.0070)	KLLoss 0.0011 (0.0009)	MaskLoss 0.1115 (0.1238)	MaskBCELoss 0.0115 (0.0370)	MaskDICELoss 0.1000 (0.0868)
Epoch: [0][ 91/500]	Time 55.664 (55.664)	Loss 0.5133 (0.4651)	CeLoss 0.0923 (0.1039)	SegCLSLoss 0.0033 (0.0068)	KLLoss 0.0020 (0.0018)	MaskLoss 0.1176 (0.1016)	MaskBCELoss 0.0264 (0.0251)	MaskDICELoss 0.0912 (0.0765)
Epoch: [0][ 92/500]	Time 46.508 (46.508)	Loss 0.5219 (0.5129)	CeLoss 0.0947 (0.1090)	SegCLSLoss 0.0037 (0.0070)	KLLoss 0.0014 (0.0015)	MaskLoss 0.1166 (0.1096)	MaskBCELoss 0.0215 (0.0198)	MaskDICELoss 0.0951 (0.0898)
Epoch: [0][ 93/500]	Time 46.370 (46.370)	Loss 0.5464 (0.5178)	CeLoss 0.1182 (0.1103)	SegCLSLoss 0.0029 (0.0082)	KLLoss 0.0015 (0.0016)	MaskLoss 0.1127 (0.1120)	MaskBCELoss 0.0128 (0.0231)	MaskDICELoss 0.0999 (0.0890)
Epoch: [0][ 94/500]	Time 48.858 (48.858)	Loss 0.5289 (0.4720)	CeLoss 0.1016 (0.1034)	SegCLSLoss 0.0037 (0.0073)	KLLoss 0.0013 (0.0018)	MaskLoss 0.1127 (0.1061)	MaskBCELoss 0.0132 (0.0306)	MaskDICELoss 0.0995 (0.0755)
Epoch: [0][ 95/500]	Time 48.002 (48.002)	Loss 0.5323 (0.4600)	CeLoss 0.0830 (0.1048)	SegCLSLoss 0.0080 (0.0102)	KLLoss 0.0012 (0.0015)	MaskLoss 0.1224 (0.0991)	MaskBCELoss 0.0229 (0.0238)	MaskDICELoss 0.0996 (0.0752)
Epoch: [0][ 96/500]	Time 45.140 (45.140)	Loss 0.4942 (0.4358)	CeLoss 0.1016 (0.1076)	SegCLSLoss 0.0117 (0.0114)	KLLoss 0.0017 (0.0012)	MaskLoss 0.1065 (0.0904)	MaskBCELoss 0.0205 (0.0202)	MaskDICELoss 0.0860 (0.0702)
Epoch: [0][ 97/500]	Time 49.316 (49.316)	Loss 0.5287 (0.4481)	CeLoss 0.0801 (0.1006)	SegCLSLoss 0.0127 (0.0079)	KLLoss 0.0019 (0.0013)	MaskLoss 0.1329 (0.0966)	MaskBCELoss 0.0455 (0.0222)	MaskDICELoss 0.0873 (0.0745)
Epoch: [0][ 98/500]	Time 44.140 (44.140)	Loss 0.5267 (0.5109)	CeLoss 0.1064 (0.1062)	SegCLSLoss 0.0049 (0.0072)	KLLoss 0.0019 (0.0015)	MaskLoss 0.1093 (0.1110)	MaskBCELoss 0.0104 (0.0221)	MaskDICELoss 0.0989 (0.0889)
Epoch: [0][ 99/500]	Time 47.721 (47.721)	Loss 0.4806 (0.4496)	CeLoss 0.0869 (0.0990)	SegCLSLoss 0.0065 (0.0076)	KLLoss 0.0023 (0.0015)	MaskLoss 0.1162 (0.0970)	MaskBCELoss 0.0384 (0.0213)	MaskDICELoss 0.0778 (0.0757)
[2025-03-11 00:22:34,712] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.00029991566265060235], mom=[(0.9, 0.95)]
[2025-03-11 00:22:34,718] [INFO] [timer.py:215:stop] epoch=0/micro_step=100/global_step=10, RunningAvgSamplesPerSec=0.8198614200981612, CurrSamplesPerSec=0.8592357543342373, MemAllocated=60.39GB, MaxMemAllocated=73.08GB
Epoch: [0][100/500]	Time 49.787 (49.787)	Loss 0.5296 (0.4795)	CeLoss 0.1055 (0.1103)	SegCLSLoss 0.0027 (0.0060)	KLLoss 0.0011 (0.0014)	MaskLoss 0.1112 (0.1027)	MaskBCELoss 0.0115 (0.0229)	MaskDICELoss 0.0997 (0.0798)
Epoch: [0][101/500]	Time 49.465 (49.465)	Loss 0.4274 (0.4913)	CeLoss 0.1016 (0.0959)	SegCLSLoss 0.0095 (0.0092)	KLLoss 0.0013 (0.0019)	MaskLoss 0.0906 (0.1087)	MaskBCELoss 0.0214 (0.0230)	MaskDICELoss 0.0692 (0.0857)
Epoch: [0][102/500]	Time 46.999 (46.999)	Loss 0.0902 (0.4237)	CeLoss 0.0903 (0.0947)	SegCLSLoss 0.0000 (0.0074)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0879)	MaskBCELoss 0.0000 (0.0142)	MaskDICELoss 0.0000 (0.0737)
Epoch: [0][103/500]	Time 49.371 (49.371)	Loss 0.5123 (0.4751)	CeLoss 0.0918 (0.0962)	SegCLSLoss 0.0173 (0.0082)	KLLoss 0.0021 (0.0018)	MaskLoss 0.1046 (0.1006)	MaskBCELoss 0.0046 (0.0148)	MaskDICELoss 0.1000 (0.0858)
Epoch: [0][104/500]	Time 49.687 (49.687)	Loss 0.5204 (0.4935)	CeLoss 0.1250 (0.0929)	SegCLSLoss 0.0134 (0.0063)	KLLoss 0.0019 (0.0024)	MaskLoss 0.0992 (0.1089)	MaskBCELoss 0.0050 (0.0202)	MaskDICELoss 0.0942 (0.0887)
Epoch: [0][105/500]	Time 47.485 (47.485)	Loss 0.6661 (0.4170)	CeLoss 0.0889 (0.0982)	SegCLSLoss 0.0037 (0.0085)	KLLoss 0.0028 (0.0028)	MaskLoss 0.1948 (0.0901)	MaskBCELoss 0.1033 (0.0244)	MaskDICELoss 0.0915 (0.0657)
Epoch: [0][106/500]	Time 48.073 (48.073)	Loss 0.5480 (0.4243)	CeLoss 0.1387 (0.1033)	SegCLSLoss 0.0018 (0.0072)	KLLoss 0.0031 (0.0021)	MaskLoss 0.1250 (0.0903)	MaskBCELoss 0.0471 (0.0229)	MaskDICELoss 0.0779 (0.0675)
Epoch: [0][107/500]	Time 52.760 (52.760)	Loss 0.5168 (0.4726)	CeLoss 0.0986 (0.0934)	SegCLSLoss 0.0120 (0.0082)	KLLoss 0.0009 (0.0018)	MaskLoss 0.1133 (0.1059)	MaskBCELoss 0.0210 (0.0251)	MaskDICELoss 0.0923 (0.0808)
Epoch: [0][108/500]	Time 56.545 (56.545)	Loss 0.3819 (0.4618)	CeLoss 0.1108 (0.0947)	SegCLSLoss 0.0023 (0.0061)	KLLoss 0.0038 (0.0021)	MaskLoss 0.0744 (0.1054)	MaskBCELoss 0.0157 (0.0299)	MaskDICELoss 0.0587 (0.0756)
Epoch: [0][109/500]	Time 46.501 (46.501)	Loss 0.4711 (0.5501)	CeLoss 0.0679 (0.0920)	SegCLSLoss 0.0166 (0.0101)	KLLoss 0.0024 (0.0027)	MaskLoss 0.1027 (0.1281)	MaskBCELoss 0.0092 (0.0311)	MaskDICELoss 0.0936 (0.0971)
Epoch: [0][110/500]	Time 48.127 (48.127)	Loss 0.5216 (0.5191)	CeLoss 0.1030 (0.0966)	SegCLSLoss 0.0110 (0.0090)	KLLoss 0.0020 (0.0029)	MaskLoss 0.1054 (0.1181)	MaskBCELoss 0.0054 (0.0286)	MaskDICELoss 0.1000 (0.0895)
Epoch: [0][111/500]	Time 44.507 (44.507)	Loss 0.5807 (0.4006)	CeLoss 0.1436 (0.0948)	SegCLSLoss 0.0038 (0.0079)	KLLoss 0.0022 (0.0020)	MaskLoss 0.1197 (0.0822)	MaskBCELoss 0.0229 (0.0146)	MaskDICELoss 0.0968 (0.0676)
Epoch: [0][112/500]	Time 47.354 (47.354)	Loss 0.1133 (0.4668)	CeLoss 0.1133 (0.0945)	SegCLSLoss 0.0000 (0.0061)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.1097)	MaskBCELoss 0.0000 (0.0359)	MaskDICELoss 0.0000 (0.0738)
Epoch: [0][113/500]	Time 52.279 (52.279)	Loss 0.4944 (0.4577)	CeLoss 0.0693 (0.0923)	SegCLSLoss 0.0028 (0.0038)	KLLoss 0.0034 (0.0026)	MaskLoss 0.1110 (0.1088)	MaskBCELoss 0.0119 (0.0371)	MaskDICELoss 0.0991 (0.0717)
Epoch: [0][114/500]	Time 48.075 (48.075)	Loss 0.4931 (0.4794)	CeLoss 0.0732 (0.0873)	SegCLSLoss 0.0058 (0.0102)	KLLoss 0.0020 (0.0026)	MaskLoss 0.1088 (0.1109)	MaskBCELoss 0.0100 (0.0295)	MaskDICELoss 0.0989 (0.0814)
Epoch: [0][115/500]	Time 47.901 (47.901)	Loss 0.5509 (0.4722)	CeLoss 0.1289 (0.0953)	SegCLSLoss 0.0087 (0.0115)	KLLoss 0.0018 (0.0021)	MaskLoss 0.1307 (0.1028)	MaskBCELoss 0.0536 (0.0209)	MaskDICELoss 0.0771 (0.0818)
Epoch: [0][116/500]	Time 51.797 (51.797)	Loss 0.5619 (0.5147)	CeLoss 0.0811 (0.0867)	SegCLSLoss 0.0102 (0.0057)	KLLoss 0.0055 (0.0028)	MaskLoss 0.1375 (0.1208)	MaskBCELoss 0.0398 (0.0304)	MaskDICELoss 0.0977 (0.0904)
Epoch: [0][117/500]	Time 49.843 (49.843)	Loss 0.7633 (0.5058)	CeLoss 0.0845 (0.0946)	SegCLSLoss 0.0024 (0.0056)	KLLoss 0.0016 (0.0027)	MaskLoss 0.2388 (0.1174)	MaskBCELoss 0.1396 (0.0320)	MaskDICELoss 0.0993 (0.0854)
Epoch: [0][118/500]	Time 42.185 (42.185)	Loss 0.4669 (0.4511)	CeLoss 0.1299 (0.0856)	SegCLSLoss 0.0028 (0.0059)	KLLoss 0.0043 (0.0030)	MaskLoss 0.0942 (0.0975)	MaskBCELoss 0.0229 (0.0152)	MaskDICELoss 0.0713 (0.0823)
Epoch: [0][119/500]	Time 42.054 (42.054)	Loss 0.4922 (0.5475)	CeLoss 0.0767 (0.0944)	SegCLSLoss 0.0116 (0.0094)	KLLoss 0.0039 (0.0034)	MaskLoss 0.1040 (0.1281)	MaskBCELoss 0.0051 (0.0336)	MaskDICELoss 0.0989 (0.0945)
Epoch: [0][120/500]	Time 50.736 (50.736)	Loss 0.4667 (0.4225)	CeLoss 0.0996 (0.0978)	SegCLSLoss 0.0096 (0.0072)	KLLoss 0.0020 (0.0019)	MaskLoss 0.0950 (0.0884)	MaskBCELoss 0.0102 (0.0171)	MaskDICELoss 0.0848 (0.0712)
Epoch: [0][121/500]	Time 44.197 (44.197)	Loss 0.3886 (0.4293)	CeLoss 0.0747 (0.0905)	SegCLSLoss 0.0232 (0.0083)	KLLoss 0.0023 (0.0031)	MaskLoss 0.0880 (0.0943)	MaskBCELoss 0.0260 (0.0228)	MaskDICELoss 0.0620 (0.0715)
Epoch: [0][122/500]	Time 51.448 (51.448)	Loss 0.4118 (0.4772)	CeLoss 0.0820 (0.0783)	SegCLSLoss 0.0113 (0.0076)	KLLoss 0.0025 (0.0027)	MaskLoss 0.0951 (0.1124)	MaskBCELoss 0.0293 (0.0286)	MaskDICELoss 0.0659 (0.0838)
Epoch: [0][123/500]	Time 48.666 (48.666)	Loss 0.3878 (0.4774)	CeLoss 0.0879 (0.0817)	SegCLSLoss 0.0031 (0.0121)	KLLoss 0.0018 (0.0023)	MaskLoss 0.0833 (0.1129)	MaskBCELoss 0.0185 (0.0321)	MaskDICELoss 0.0648 (0.0808)
Epoch: [0][124/500]	Time 47.620 (47.620)	Loss 0.4968 (0.4874)	CeLoss 0.0728 (0.0921)	SegCLSLoss 0.0138 (0.0042)	KLLoss 0.0022 (0.0024)	MaskLoss 0.1245 (0.1207)	MaskBCELoss 0.0416 (0.0461)	MaskDICELoss 0.0829 (0.0747)
Epoch: [0][125/500]	Time 45.798 (45.798)	Loss 0.4907 (0.4663)	CeLoss 0.0693 (0.0953)	SegCLSLoss 0.0016 (0.0099)	KLLoss 0.0046 (0.0026)	MaskLoss 0.1084 (0.1078)	MaskBCELoss 0.0089 (0.0339)	MaskDICELoss 0.0995 (0.0739)
Epoch: [0][126/500]	Time 48.676 (48.676)	Loss 0.5228 (0.5651)	CeLoss 0.0742 (0.0864)	SegCLSLoss 0.0032 (0.0160)	KLLoss 0.0068 (0.0026)	MaskLoss 0.1228 (0.1458)	MaskBCELoss 0.0256 (0.0576)	MaskDICELoss 0.0972 (0.0882)
Epoch: [0][127/500]	Time 50.626 (50.626)	Loss 0.5002 (0.4605)	CeLoss 0.0947 (0.0948)	SegCLSLoss 0.0160 (0.0130)	KLLoss 0.0015 (0.0034)	MaskLoss 0.1173 (0.1046)	MaskBCELoss 0.0368 (0.0314)	MaskDICELoss 0.0805 (0.0732)
Epoch: [0][128/500]	Time 46.194 (46.194)	Loss 0.5884 (0.4717)	CeLoss 0.1270 (0.1023)	SegCLSLoss 0.0059 (0.0081)	KLLoss 0.0045 (0.0027)	MaskLoss 0.1274 (0.1051)	MaskBCELoss 0.0277 (0.0288)	MaskDICELoss 0.0997 (0.0762)
Epoch: [0][129/500]	Time 49.353 (49.353)	Loss 0.4243 (0.3826)	CeLoss 0.0928 (0.0915)	SegCLSLoss 0.0135 (0.0052)	KLLoss 0.0020 (0.0022)	MaskLoss 0.0989 (0.0825)	MaskBCELoss 0.0364 (0.0217)	MaskDICELoss 0.0625 (0.0607)
Epoch: [0][130/500]	Time 48.619 (48.619)	Loss 0.4709 (0.5175)	CeLoss 0.0850 (0.0866)	SegCLSLoss 0.0045 (0.0078)	KLLoss 0.0038 (0.0029)	MaskLoss 0.1082 (0.1201)	MaskBCELoss 0.0267 (0.0283)	MaskDICELoss 0.0815 (0.0919)
Epoch: [0][131/500]	Time 45.430 (45.430)	Loss 0.5770 (0.4814)	CeLoss 0.0610 (0.0834)	SegCLSLoss 0.0114 (0.0089)	KLLoss 0.0013 (0.0027)	MaskLoss 0.1550 (0.1220)	MaskBCELoss 0.0554 (0.0486)	MaskDICELoss 0.0997 (0.0734)
Epoch: [0][132/500]	Time 48.620 (48.620)	Loss 0.5319 (0.4943)	CeLoss 0.0928 (0.0864)	SegCLSLoss 0.0041 (0.0096)	KLLoss 0.0023 (0.0019)	MaskLoss 0.1187 (0.1233)	MaskBCELoss 0.0198 (0.0461)	MaskDICELoss 0.0989 (0.0773)
Epoch: [0][133/500]	Time 50.491 (50.491)	Loss 0.5224 (0.5189)	CeLoss 0.0713 (0.0944)	SegCLSLoss 0.0035 (0.0065)	KLLoss 0.0020 (0.0023)	MaskLoss 0.1316 (0.1281)	MaskBCELoss 0.0392 (0.0465)	MaskDICELoss 0.0924 (0.0815)
Epoch: [0][134/500]	Time 52.769 (52.769)	Loss 0.5036 (0.4709)	CeLoss 0.1030 (0.0834)	SegCLSLoss 0.0044 (0.0080)	KLLoss 0.0038 (0.0025)	MaskLoss 0.1114 (0.1140)	MaskBCELoss 0.0258 (0.0377)	MaskDICELoss 0.0856 (0.0764)
Epoch: [0][135/500]	Time 50.691 (50.691)	Loss 0.5745 (0.3591)	CeLoss 0.1108 (0.0882)	SegCLSLoss 0.0021 (0.0064)	KLLoss 0.0031 (0.0023)	MaskLoss 0.1344 (0.0802)	MaskBCELoss 0.0391 (0.0277)	MaskDICELoss 0.0954 (0.0525)
Epoch: [0][136/500]	Time 48.596 (48.596)	Loss 0.6021 (0.4912)	CeLoss 0.0986 (0.0799)	SegCLSLoss 0.0015 (0.0066)	KLLoss 0.0049 (0.0031)	MaskLoss 0.1515 (0.1239)	MaskBCELoss 0.0539 (0.0453)	MaskDICELoss 0.0976 (0.0786)
Epoch: [0][137/500]	Time 44.329 (44.329)	Loss 0.4675 (0.4670)	CeLoss 0.0713 (0.0841)	SegCLSLoss 0.0150 (0.0097)	KLLoss 0.0026 (0.0038)	MaskLoss 0.1186 (0.1170)	MaskBCELoss 0.0441 (0.0469)	MaskDICELoss 0.0745 (0.0701)
Epoch: [0][138/500]	Time 48.414 (48.414)	Loss 0.5733 (0.4032)	CeLoss 0.0947 (0.0758)	SegCLSLoss 0.0040 (0.0071)	KLLoss 0.0027 (0.0022)	MaskLoss 0.1473 (0.0988)	MaskBCELoss 0.0577 (0.0368)	MaskDICELoss 0.0896 (0.0620)
Epoch: [0][139/500]	Time 44.396 (44.396)	Loss 0.5161 (0.3727)	CeLoss 0.0645 (0.0828)	SegCLSLoss 0.0112 (0.0095)	KLLoss 0.0034 (0.0021)	MaskLoss 0.1219 (0.0851)	MaskBCELoss 0.0225 (0.0287)	MaskDICELoss 0.0994 (0.0565)
Epoch: [0][140/500]	Time 44.247 (44.247)	Loss 0.5679 (0.5147)	CeLoss 0.0889 (0.0783)	SegCLSLoss 0.0086 (0.0121)	KLLoss 0.0019 (0.0022)	MaskLoss 0.1387 (0.1282)	MaskBCELoss 0.0408 (0.0424)	MaskDICELoss 0.0978 (0.0858)
Epoch: [0][141/500]	Time 50.452 (50.452)	Loss 0.3995 (0.4942)	CeLoss 0.0991 (0.0805)	SegCLSLoss 0.0026 (0.0039)	KLLoss 0.0026 (0.0035)	MaskLoss 0.0982 (0.1207)	MaskBCELoss 0.0482 (0.0373)	MaskDICELoss 0.0500 (0.0834)
Epoch: [0][142/500]	Time 50.591 (50.591)	Loss 0.5730 (0.4980)	CeLoss 0.0554 (0.0769)	SegCLSLoss 0.0035 (0.0075)	KLLoss 0.0024 (0.0028)	MaskLoss 0.1581 (0.1229)	MaskBCELoss 0.0596 (0.0386)	MaskDICELoss 0.0985 (0.0844)
Epoch: [0][143/500]	Time 50.350 (50.350)	Loss 0.4876 (0.5052)	CeLoss 0.0547 (0.0856)	SegCLSLoss 0.0082 (0.0086)	KLLoss 0.0031 (0.0032)	MaskLoss 0.1347 (0.1225)	MaskBCELoss 0.0567 (0.0389)	MaskDICELoss 0.0780 (0.0836)
Epoch: [0][144/500]	Time 50.143 (50.143)	Loss 0.5343 (0.5168)	CeLoss 0.0593 (0.0709)	SegCLSLoss 0.0060 (0.0071)	KLLoss 0.0033 (0.0027)	MaskLoss 0.1349 (0.1286)	MaskBCELoss 0.0357 (0.0372)	MaskDICELoss 0.0992 (0.0913)
Epoch: [0][145/500]	Time 53.404 (53.404)	Loss 0.5156 (0.4386)	CeLoss 0.0679 (0.0762)	SegCLSLoss 0.0022 (0.0087)	KLLoss 0.0039 (0.0022)	MaskLoss 0.1334 (0.1070)	MaskBCELoss 0.0455 (0.0361)	MaskDICELoss 0.0879 (0.0709)
Epoch: [0][146/500]	Time 49.484 (49.484)	Loss 0.5504 (0.4259)	CeLoss 0.0967 (0.0808)	SegCLSLoss 0.0073 (0.0086)	KLLoss 0.0019 (0.0024)	MaskLoss 0.1333 (0.1028)	MaskBCELoss 0.0425 (0.0364)	MaskDICELoss 0.0907 (0.0664)
Epoch: [0][147/500]	Time 49.595 (49.595)	Loss 0.5552 (0.4832)	CeLoss 0.0913 (0.0780)	SegCLSLoss 0.0164 (0.0065)	KLLoss 0.0020 (0.0026)	MaskLoss 0.1315 (0.1192)	MaskBCELoss 0.0362 (0.0387)	MaskDICELoss 0.0953 (0.0805)
Epoch: [0][148/500]	Time 47.693 (47.693)	Loss 0.5869 (0.4992)	CeLoss 0.0903 (0.0869)	SegCLSLoss 0.0027 (0.0094)	KLLoss 0.0018 (0.0026)	MaskLoss 0.1503 (0.1209)	MaskBCELoss 0.0536 (0.0391)	MaskDICELoss 0.0967 (0.0818)
Epoch: [0][149/500]	Time 46.958 (46.958)	Loss 0.4934 (0.5263)	CeLoss 0.0598 (0.0795)	SegCLSLoss 0.0188 (0.0074)	KLLoss 0.0018 (0.0030)	MaskLoss 0.1268 (0.1333)	MaskBCELoss 0.0426 (0.0465)	MaskDICELoss 0.0843 (0.0868)
Epoch: [0][150/500]	Time 50.191 (50.191)	Loss 0.4361 (0.4934)	CeLoss 0.1079 (0.0831)	SegCLSLoss 0.0043 (0.0139)	KLLoss 0.0035 (0.0025)	MaskLoss 0.0996 (0.1184)	MaskBCELoss 0.0379 (0.0364)	MaskDICELoss 0.0618 (0.0820)
Epoch: [0][151/500]	Time 45.962 (45.962)	Loss 1.2070 (0.5522)	CeLoss 0.1172 (0.0793)	SegCLSLoss 0.0025 (0.0082)	KLLoss 0.0023 (0.0028)	MaskLoss 0.4467 (0.1480)	MaskBCELoss 0.3505 (0.0629)	MaskDICELoss 0.0962 (0.0851)
Epoch: [0][152/500]	Time 47.255 (47.255)	Loss 0.1042 (0.4135)	CeLoss 0.0811 (0.0693)	SegCLSLoss 0.0019 (0.0134)	KLLoss 0.0033 (0.0025)	MaskLoss 0.0069 (0.1038)	MaskBCELoss 0.0042 (0.0401)	MaskDICELoss 0.0027 (0.0637)
Epoch: [0][153/500]	Time 46.850 (46.850)	Loss 0.5105 (0.4990)	CeLoss 0.0728 (0.0815)	SegCLSLoss 0.0133 (0.0080)	KLLoss 0.0023 (0.0025)	MaskLoss 0.1147 (0.1188)	MaskBCELoss 0.0151 (0.0321)	MaskDICELoss 0.0997 (0.0867)
Epoch: [0][154/500]	Time 44.022 (44.022)	Loss 0.6605 (0.4738)	CeLoss 0.0498 (0.0750)	SegCLSLoss 0.0052 (0.0066)	KLLoss 0.0020 (0.0033)	MaskLoss 0.2171 (0.1181)	MaskBCELoss 0.1310 (0.0401)	MaskDICELoss 0.0860 (0.0780)
Epoch: [0][155/500]	Time 42.436 (42.436)	Loss 0.5362 (0.4860)	CeLoss 0.0562 (0.0743)	SegCLSLoss 0.0051 (0.0115)	KLLoss 0.0054 (0.0035)	MaskLoss 0.1359 (0.1196)	MaskBCELoss 0.0359 (0.0380)	MaskDICELoss 0.1000 (0.0816)
Epoch: [0][156/500]	Time 48.717 (48.717)	Loss 0.5153 (0.5032)	CeLoss 0.1123 (0.0709)	SegCLSLoss 0.0031 (0.0102)	KLLoss 0.0044 (0.0032)	MaskLoss 0.1113 (0.1205)	MaskBCELoss 0.0243 (0.0291)	MaskDICELoss 0.0870 (0.0914)
Epoch: [0][157/500]	Time 47.974 (47.974)	Loss 0.5185 (0.4477)	CeLoss 0.0500 (0.0761)	SegCLSLoss 0.0220 (0.0168)	KLLoss 0.0027 (0.0026)	MaskLoss 0.1280 (0.1113)	MaskBCELoss 0.0286 (0.0423)	MaskDICELoss 0.0994 (0.0690)
Epoch: [0][158/500]	Time 45.442 (45.442)	Loss 0.4342 (0.4095)	CeLoss 0.0752 (0.0711)	SegCLSLoss 0.0040 (0.0108)	KLLoss 0.0051 (0.0026)	MaskLoss 0.1041 (0.0951)	MaskBCELoss 0.0321 (0.0249)	MaskDICELoss 0.0720 (0.0702)
Epoch: [0][159/500]	Time 49.720 (49.720)	Loss 0.3927 (0.4611)	CeLoss 0.0918 (0.0788)	SegCLSLoss 0.0170 (0.0117)	KLLoss 0.0020 (0.0024)	MaskLoss 0.0903 (0.1071)	MaskBCELoss 0.0351 (0.0272)	MaskDICELoss 0.0552 (0.0799)
Epoch: [0][160/500]	Time 54.567 (54.567)	Loss 0.5376 (0.4226)	CeLoss 0.0747 (0.0773)	SegCLSLoss 0.0030 (0.0079)	KLLoss 0.0042 (0.0020)	MaskLoss 0.1312 (0.0974)	MaskBCELoss 0.0337 (0.0251)	MaskDICELoss 0.0974 (0.0723)
Epoch: [0][161/500]	Time 46.415 (46.415)	Loss 0.4741 (0.4890)	CeLoss 0.0500 (0.0706)	SegCLSLoss 0.0078 (0.0099)	KLLoss 0.0031 (0.0031)	MaskLoss 0.1088 (0.1179)	MaskBCELoss 0.0091 (0.0306)	MaskDICELoss 0.0997 (0.0873)
Epoch: [0][162/500]	Time 50.827 (50.827)	Loss 0.4459 (0.4201)	CeLoss 0.0513 (0.0708)	SegCLSLoss 0.0070 (0.0064)	KLLoss 0.0027 (0.0030)	MaskLoss 0.1083 (0.0936)	MaskBCELoss 0.0223 (0.0157)	MaskDICELoss 0.0860 (0.0779)
Epoch: [0][163/500]	Time 54.096 (54.096)	Loss 0.4832 (0.3876)	CeLoss 0.0474 (0.0712)	SegCLSLoss 0.0048 (0.0055)	KLLoss 0.0049 (0.0023)	MaskLoss 0.1145 (0.0866)	MaskBCELoss 0.0145 (0.0175)	MaskDICELoss 0.1000 (0.0691)
Epoch: [0][164/500]	Time 52.903 (52.903)	Loss 0.4879 (0.4052)	CeLoss 0.0439 (0.0585)	SegCLSLoss 0.0159 (0.0089)	KLLoss 0.0041 (0.0027)	MaskLoss 0.1164 (0.0941)	MaskBCELoss 0.0169 (0.0184)	MaskDICELoss 0.0995 (0.0757)
Epoch: [0][165/500]	Time 45.062 (45.062)	Loss 0.3557 (0.4241)	CeLoss 0.0574 (0.0615)	SegCLSLoss 0.0254 (0.0112)	KLLoss 0.0012 (0.0025)	MaskLoss 0.0752 (0.1008)	MaskBCELoss 0.0084 (0.0244)	MaskDICELoss 0.0669 (0.0764)
Epoch: [0][166/500]	Time 49.305 (49.305)	Loss 0.4856 (0.3697)	CeLoss 0.0474 (0.0717)	SegCLSLoss 0.0052 (0.0034)	KLLoss 0.0036 (0.0026)	MaskLoss 0.1162 (0.0843)	MaskBCELoss 0.0163 (0.0217)	MaskDICELoss 0.0999 (0.0626)
Epoch: [0][167/500]	Time 49.818 (49.818)	Loss 0.0559 (0.3951)	CeLoss 0.0559 (0.0701)	SegCLSLoss 0.0000 (0.0035)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0953)	MaskBCELoss 0.0000 (0.0302)	MaskDICELoss 0.0000 (0.0651)
Epoch: [0][168/500]	Time 50.788 (50.788)	Loss 0.5053 (0.4436)	CeLoss 0.0986 (0.0688)	SegCLSLoss 0.0130 (0.0098)	KLLoss 0.0047 (0.0027)	MaskLoss 0.1081 (0.1017)	MaskBCELoss 0.0183 (0.0197)	MaskDICELoss 0.0898 (0.0819)
Epoch: [0][169/500]	Time 50.101 (50.101)	Loss 0.4867 (0.4277)	CeLoss 0.0522 (0.0728)	SegCLSLoss 0.0081 (0.0049)	KLLoss 0.0024 (0.0027)	MaskLoss 0.1153 (0.1012)	MaskBCELoss 0.0165 (0.0274)	MaskDICELoss 0.0988 (0.0737)
Epoch: [0][170/500]	Time 47.104 (47.104)	Loss 0.5259 (0.4786)	CeLoss 0.0840 (0.0703)	SegCLSLoss 0.0148 (0.0075)	KLLoss 0.0022 (0.0032)	MaskLoss 0.1255 (0.1100)	MaskBCELoss 0.0349 (0.0193)	MaskDICELoss 0.0906 (0.0907)
Epoch: [0][171/500]	Time 43.375 (43.375)	Loss 0.5086 (0.4420)	CeLoss 0.1025 (0.0680)	SegCLSLoss 0.0031 (0.0061)	KLLoss 0.0040 (0.0028)	MaskLoss 0.1342 (0.1014)	MaskBCELoss 0.0681 (0.0187)	MaskDICELoss 0.0661 (0.0827)
Epoch: [0][172/500]	Time 49.019 (49.019)	Loss 0.4896 (0.4707)	CeLoss 0.0527 (0.0642)	SegCLSLoss 0.0113 (0.0124)	KLLoss 0.0017 (0.0027)	MaskLoss 0.1182 (0.1204)	MaskBCELoss 0.0214 (0.0419)	MaskDICELoss 0.0967 (0.0785)
Epoch: [0][173/500]	Time 44.785 (44.785)	Loss 0.4029 (0.3493)	CeLoss 0.0481 (0.0650)	SegCLSLoss 0.0164 (0.0083)	KLLoss 0.0033 (0.0023)	MaskLoss 0.0983 (0.0738)	MaskBCELoss 0.0249 (0.0087)	MaskDICELoss 0.0735 (0.0651)
Epoch: [0][174/500]	Time 51.227 (51.227)	Loss 0.4863 (0.4606)	CeLoss 0.0493 (0.0692)	SegCLSLoss 0.0058 (0.0049)	KLLoss 0.0062 (0.0039)	MaskLoss 0.1209 (0.1074)	MaskBCELoss 0.0277 (0.0223)	MaskDICELoss 0.0932 (0.0851)
Epoch: [0][175/500]	Time 50.726 (50.726)	Loss 0.4828 (0.4381)	CeLoss 0.0437 (0.0665)	SegCLSLoss 0.0101 (0.0136)	KLLoss 0.0058 (0.0034)	MaskLoss 0.1149 (0.1006)	MaskBCELoss 0.0157 (0.0205)	MaskDICELoss 0.0992 (0.0801)
Epoch: [0][176/500]	Time 51.186 (51.186)	Loss 0.5115 (0.4325)	CeLoss 0.0508 (0.0677)	SegCLSLoss 0.0386 (0.0109)	KLLoss 0.0029 (0.0030)	MaskLoss 0.1201 (0.0992)	MaskBCELoss 0.0210 (0.0202)	MaskDICELoss 0.0991 (0.0790)
Epoch: [0][177/500]	Time 46.305 (46.305)	Loss 0.3929 (0.4430)	CeLoss 0.0542 (0.0670)	SegCLSLoss 0.0099 (0.0124)	KLLoss 0.0027 (0.0029)	MaskLoss 0.0987 (0.1060)	MaskBCELoss 0.0320 (0.0286)	MaskDICELoss 0.0667 (0.0774)
Epoch: [0][178/500]	Time 45.659 (45.659)	Loss 0.4696 (0.4926)	CeLoss 0.0674 (0.0617)	SegCLSLoss 0.0028 (0.0120)	KLLoss 0.0056 (0.0036)	MaskLoss 0.1025 (0.1203)	MaskBCELoss 0.0075 (0.0299)	MaskDICELoss 0.0950 (0.0904)
Epoch: [0][179/500]	Time 42.589 (42.589)	Loss 0.5212 (0.4430)	CeLoss 0.0757 (0.0748)	SegCLSLoss 0.0139 (0.0094)	KLLoss 0.0026 (0.0036)	MaskLoss 0.1249 (0.0989)	MaskBCELoss 0.0319 (0.0178)	MaskDICELoss 0.0930 (0.0810)
Epoch: [0][180/500]	Time 46.495 (46.495)	Loss 0.4749 (0.3948)	CeLoss 0.0488 (0.0742)	SegCLSLoss 0.0203 (0.0102)	KLLoss 0.0038 (0.0027)	MaskLoss 0.1073 (0.0871)	MaskBCELoss 0.0085 (0.0178)	MaskDICELoss 0.0988 (0.0693)
Epoch: [0][181/500]	Time 49.445 (49.445)	Loss 0.5123 (0.4352)	CeLoss 0.0825 (0.0791)	SegCLSLoss 0.0031 (0.0077)	KLLoss 0.0067 (0.0031)	MaskLoss 0.1109 (0.0937)	MaskBCELoss 0.0109 (0.0128)	MaskDICELoss 0.0999 (0.0809)
Epoch: [0][182/500]	Time 44.299 (44.299)	Loss 0.4802 (0.5167)	CeLoss 0.0522 (0.0616)	SegCLSLoss 0.0089 (0.0090)	KLLoss 0.0053 (0.0045)	MaskLoss 0.1093 (0.1347)	MaskBCELoss 0.0097 (0.0463)	MaskDICELoss 0.0997 (0.0884)
Epoch: [0][183/500]	Time 50.201 (50.201)	Loss 0.5109 (0.4111)	CeLoss 0.0459 (0.0691)	SegCLSLoss 0.0110 (0.0061)	KLLoss 0.0023 (0.0037)	MaskLoss 0.1410 (0.0934)	MaskBCELoss 0.0535 (0.0192)	MaskDICELoss 0.0875 (0.0742)
Epoch: [0][184/500]	Time 49.241 (49.241)	Loss 0.6269 (0.5476)	CeLoss 0.0513 (0.0558)	SegCLSLoss 0.0034 (0.0076)	KLLoss 0.0037 (0.0045)	MaskLoss 0.1997 (0.1504)	MaskBCELoss 0.1142 (0.0591)	MaskDICELoss 0.0856 (0.0914)
Epoch: [0][185/500]	Time 46.729 (46.729)	Loss 0.5528 (0.5001)	CeLoss 0.0952 (0.0615)	SegCLSLoss 0.0022 (0.0138)	KLLoss 0.0047 (0.0039)	MaskLoss 0.1306 (0.1266)	MaskBCELoss 0.0357 (0.0393)	MaskDICELoss 0.0950 (0.0873)
Epoch: [0][186/500]	Time 48.925 (48.925)	Loss 0.0805 (0.4607)	CeLoss 0.0806 (0.0647)	SegCLSLoss 0.0000 (0.0132)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.1067)	MaskBCELoss 0.0000 (0.0203)	MaskDICELoss 0.0000 (0.0864)
Epoch: [0][187/500]	Time 51.645 (51.645)	Loss 0.4057 (0.3223)	CeLoss 0.0444 (0.0742)	SegCLSLoss 0.0204 (0.0055)	KLLoss 0.0031 (0.0018)	MaskLoss 0.0942 (0.0727)	MaskBCELoss 0.0144 (0.0236)	MaskDICELoss 0.0797 (0.0490)
Epoch: [0][188/500]	Time 45.498 (45.498)	Loss 0.4851 (0.3298)	CeLoss 0.0444 (0.0668)	SegCLSLoss 0.0125 (0.0060)	KLLoss 0.0049 (0.0026)	MaskLoss 0.1167 (0.0761)	MaskBCELoss 0.0185 (0.0234)	MaskDICELoss 0.0981 (0.0527)
Epoch: [0][189/500]	Time 54.499 (54.499)	Loss 0.4606 (0.3881)	CeLoss 0.0737 (0.0610)	SegCLSLoss 0.0115 (0.0095)	KLLoss 0.0020 (0.0035)	MaskLoss 0.0972 (0.0946)	MaskBCELoss 0.0050 (0.0298)	MaskDICELoss 0.0922 (0.0648)
Epoch: [0][190/500]	Time 50.492 (50.492)	Loss 0.4994 (0.4583)	CeLoss 0.0830 (0.0717)	SegCLSLoss 0.0082 (0.0067)	KLLoss 0.0030 (0.0037)	MaskLoss 0.1048 (0.1006)	MaskBCELoss 0.0052 (0.0115)	MaskDICELoss 0.0996 (0.0891)
Epoch: [0][191/500]	Time 49.476 (49.476)	Loss 0.3856 (0.4565)	CeLoss 0.0781 (0.0658)	SegCLSLoss 0.0072 (0.0045)	KLLoss 0.0021 (0.0029)	MaskLoss 0.0819 (0.1095)	MaskBCELoss 0.0127 (0.0263)	MaskDICELoss 0.0692 (0.0832)
Epoch: [0][192/500]	Time 46.885 (46.885)	Loss 0.4757 (0.4053)	CeLoss 0.0454 (0.0496)	SegCLSLoss 0.0099 (0.0066)	KLLoss 0.0031 (0.0032)	MaskLoss 0.1127 (0.1005)	MaskBCELoss 0.0143 (0.0263)	MaskDICELoss 0.0984 (0.0742)
Epoch: [0][193/500]	Time 50.888 (50.888)	Loss 0.4286 (0.4405)	CeLoss 0.0859 (0.0719)	SegCLSLoss 0.0046 (0.0048)	KLLoss 0.0035 (0.0050)	MaskLoss 0.0859 (0.1110)	MaskBCELoss 0.0034 (0.0415)	MaskDICELoss 0.0825 (0.0696)
Epoch: [0][194/500]	Time 52.667 (52.667)	Loss 0.4229 (0.3313)	CeLoss 0.0654 (0.0552)	SegCLSLoss 0.0084 (0.0114)	KLLoss 0.0053 (0.0030)	MaskLoss 0.0935 (0.0753)	MaskBCELoss 0.0130 (0.0170)	MaskDICELoss 0.0805 (0.0583)
Epoch: [0][195/500]	Time 47.678 (47.678)	Loss 0.4489 (0.4711)	CeLoss 0.0408 (0.0580)	SegCLSLoss 0.0337 (0.0139)	KLLoss 0.0028 (0.0036)	MaskLoss 0.1116 (0.1139)	MaskBCELoss 0.0290 (0.0265)	MaskDICELoss 0.0826 (0.0874)
Epoch: [0][196/500]	Time 51.010 (51.010)	Loss 0.4525 (0.5633)	CeLoss 0.0474 (0.0520)	SegCLSLoss 0.0034 (0.0152)	KLLoss 0.0022 (0.0043)	MaskLoss 0.1086 (0.1575)	MaskBCELoss 0.0166 (0.0654)	MaskDICELoss 0.0919 (0.0922)
Epoch: [0][197/500]	Time 47.607 (47.607)	Loss 0.4801 (0.4214)	CeLoss 0.0742 (0.0696)	SegCLSLoss 0.0047 (0.0083)	KLLoss 0.0028 (0.0032)	MaskLoss 0.1068 (0.0941)	MaskBCELoss 0.0132 (0.0159)	MaskDICELoss 0.0936 (0.0782)
Epoch: [0][198/500]	Time 47.249 (47.249)	Loss 0.5300 (0.4300)	CeLoss 0.1201 (0.0780)	SegCLSLoss 0.0041 (0.0051)	KLLoss 0.0037 (0.0032)	MaskLoss 0.1074 (0.1026)	MaskBCELoss 0.0130 (0.0320)	MaskDICELoss 0.0943 (0.0705)
Epoch: [0][199/500]	Time 47.271 (47.271)	Loss 0.4536 (0.4452)	CeLoss 0.0640 (0.0733)	SegCLSLoss 0.0168 (0.0105)	KLLoss 0.0034 (0.0038)	MaskLoss 0.1024 (0.1018)	MaskBCELoss 0.0161 (0.0222)	MaskDICELoss 0.0863 (0.0797)
[2025-03-11 01:43:27,064] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0002985903614457831], mom=[(0.9, 0.95)]
[2025-03-11 01:43:27,070] [INFO] [timer.py:215:stop] epoch=0/micro_step=200/global_step=20, RunningAvgSamplesPerSec=0.8345798241828206, CurrSamplesPerSec=0.9052904423248164, MemAllocated=59.58GB, MaxMemAllocated=73.59GB
Epoch: [0][200/500]	Time 50.129 (50.129)	Loss 0.4609 (0.5102)	CeLoss 0.0728 (0.0656)	SegCLSLoss 0.0037 (0.0078)	KLLoss 0.0050 (0.0041)	MaskLoss 0.1066 (0.1328)	MaskBCELoss 0.0225 (0.0473)	MaskDICELoss 0.0840 (0.0855)
Epoch: [0][201/500]	Time 52.118 (52.118)	Loss 0.1119 (0.4554)	CeLoss 0.0598 (0.0659)	SegCLSLoss 0.0020 (0.0080)	KLLoss 0.0079 (0.0045)	MaskLoss 0.0152 (0.1067)	MaskBCELoss 0.0088 (0.0229)	MaskDICELoss 0.0064 (0.0838)
Epoch: [0][202/500]	Time 45.885 (45.885)	Loss 0.4530 (0.4191)	CeLoss 0.0640 (0.0577)	SegCLSLoss 0.0031 (0.0098)	KLLoss 0.0036 (0.0041)	MaskLoss 0.1005 (0.0994)	MaskBCELoss 0.0090 (0.0226)	MaskDICELoss 0.0914 (0.0768)
Epoch: [0][203/500]	Time 46.546 (46.546)	Loss 0.3215 (0.4276)	CeLoss 0.0830 (0.0717)	SegCLSLoss 0.0162 (0.0189)	KLLoss 0.0029 (0.0037)	MaskLoss 0.0719 (0.0950)	MaskBCELoss 0.0299 (0.0186)	MaskDICELoss 0.0420 (0.0764)
Epoch: [0][204/500]	Time 52.759 (52.759)	Loss 0.3455 (0.3913)	CeLoss 0.0923 (0.0689)	SegCLSLoss 0.0026 (0.0036)	KLLoss 0.0041 (0.0040)	MaskLoss 0.0826 (0.0967)	MaskBCELoss 0.0414 (0.0351)	MaskDICELoss 0.0413 (0.0616)
Epoch: [0][205/500]	Time 47.963 (47.963)	Loss 0.4207 (0.4004)	CeLoss 0.0449 (0.0578)	SegCLSLoss 0.0047 (0.0090)	KLLoss 0.0054 (0.0051)	MaskLoss 0.1153 (0.0978)	MaskBCELoss 0.0466 (0.0291)	MaskDICELoss 0.0687 (0.0687)
Epoch: [0][206/500]	Time 45.908 (45.908)	Loss 0.4628 (0.4293)	CeLoss 0.0425 (0.0589)	SegCLSLoss 0.0083 (0.0072)	KLLoss 0.0042 (0.0044)	MaskLoss 0.1060 (0.1042)	MaskBCELoss 0.0061 (0.0272)	MaskDICELoss 0.1000 (0.0770)
Epoch: [0][207/500]	Time 46.332 (46.332)	Loss 0.3811 (0.3734)	CeLoss 0.0315 (0.0605)	SegCLSLoss 0.0447 (0.0146)	KLLoss 0.0027 (0.0036)	MaskLoss 0.0947 (0.0851)	MaskBCELoss 0.0271 (0.0193)	MaskDICELoss 0.0675 (0.0658)
Epoch: [0][208/500]	Time 47.046 (47.046)	Loss 0.4707 (0.3873)	CeLoss 0.0388 (0.0644)	SegCLSLoss 0.0023 (0.0056)	KLLoss 0.0052 (0.0041)	MaskLoss 0.1263 (0.0954)	MaskBCELoss 0.0397 (0.0328)	MaskDICELoss 0.0865 (0.0626)
Epoch: [0][209/500]	Time 49.874 (49.874)	Loss 0.5561 (0.4390)	CeLoss 0.0435 (0.0537)	SegCLSLoss 0.0157 (0.0141)	KLLoss 0.0049 (0.0047)	MaskLoss 0.1520 (0.1107)	MaskBCELoss 0.0539 (0.0346)	MaskDICELoss 0.0981 (0.0761)
Epoch: [0][210/500]	Time 49.462 (49.462)	Loss 0.5373 (0.4748)	CeLoss 0.0732 (0.0541)	SegCLSLoss 0.0214 (0.0154)	KLLoss 0.0039 (0.0039)	MaskLoss 0.1282 (0.1138)	MaskBCELoss 0.0315 (0.0230)	MaskDICELoss 0.0967 (0.0908)
Epoch: [0][211/500]	Time 41.499 (41.499)	Loss 0.5131 (0.4147)	CeLoss 0.0669 (0.0779)	SegCLSLoss 0.0079 (0.0084)	KLLoss 0.0030 (0.0034)	MaskLoss 0.1198 (0.0976)	MaskBCELoss 0.0200 (0.0305)	MaskDICELoss 0.0998 (0.0671)
Epoch: [0][212/500]	Time 44.590 (44.590)	Loss 0.4980 (0.4902)	CeLoss 0.0688 (0.0602)	SegCLSLoss 0.0125 (0.0135)	KLLoss 0.0042 (0.0037)	MaskLoss 0.1122 (0.1243)	MaskBCELoss 0.0150 (0.0387)	MaskDICELoss 0.0972 (0.0855)
Epoch: [0][213/500]	Time 53.324 (53.324)	Loss 0.0605 (0.4045)	CeLoss 0.0605 (0.0656)	SegCLSLoss 0.0000 (0.0109)	KLLoss 0.0000 (0.0039)	MaskLoss 0.0000 (0.1020)	MaskBCELoss 0.0000 (0.0393)	MaskDICELoss 0.0000 (0.0627)
Epoch: [0][214/500]	Time 45.527 (45.527)	Loss 0.5219 (0.4651)	CeLoss 0.0640 (0.0769)	SegCLSLoss 0.0044 (0.0070)	KLLoss 0.0044 (0.0035)	MaskLoss 0.1285 (0.1114)	MaskBCELoss 0.0314 (0.0321)	MaskDICELoss 0.0971 (0.0792)
Epoch: [0][215/500]	Time 49.505 (49.505)	Loss 0.5519 (0.4652)	CeLoss 0.0815 (0.0570)	SegCLSLoss 0.0099 (0.0175)	KLLoss 0.0035 (0.0038)	MaskLoss 0.1366 (0.1116)	MaskBCELoss 0.0423 (0.0253)	MaskDICELoss 0.0943 (0.0863)
Epoch: [0][216/500]	Time 48.745 (48.745)	Loss 0.4875 (0.4275)	CeLoss 0.0593 (0.0613)	SegCLSLoss 0.0070 (0.0117)	KLLoss 0.0020 (0.0034)	MaskLoss 0.1121 (0.1008)	MaskBCELoss 0.0129 (0.0231)	MaskDICELoss 0.0992 (0.0777)
Epoch: [0][217/500]	Time 47.632 (47.632)	Loss 0.3232 (0.4105)	CeLoss 0.0439 (0.0663)	SegCLSLoss 0.0189 (0.0101)	KLLoss 0.0034 (0.0040)	MaskLoss 0.0783 (0.0950)	MaskBCELoss 0.0236 (0.0223)	MaskDICELoss 0.0547 (0.0726)
Epoch: [0][218/500]	Time 44.120 (44.120)	Loss 0.4612 (0.5000)	CeLoss 0.0474 (0.0617)	SegCLSLoss 0.0032 (0.0127)	KLLoss 0.0054 (0.0046)	MaskLoss 0.1155 (0.1205)	MaskBCELoss 0.0276 (0.0273)	MaskDICELoss 0.0879 (0.0932)
Epoch: [0][219/500]	Time 44.207 (44.207)	Loss 0.5583 (0.4872)	CeLoss 0.0698 (0.0690)	SegCLSLoss 0.0162 (0.0104)	KLLoss 0.0045 (0.0042)	MaskLoss 0.1414 (0.1213)	MaskBCELoss 0.0448 (0.0383)	MaskDICELoss 0.0966 (0.0830)
Epoch: [0][220/500]	Time 51.315 (51.315)	Loss 0.5542 (0.4832)	CeLoss 0.0713 (0.0612)	SegCLSLoss 0.0025 (0.0068)	KLLoss 0.0063 (0.0038)	MaskLoss 0.1744 (0.1250)	MaskBCELoss 0.1111 (0.0425)	MaskDICELoss 0.0633 (0.0824)
Epoch: [0][221/500]	Time 43.265 (43.265)	Loss 0.4600 (0.5029)	CeLoss 0.0923 (0.0521)	SegCLSLoss 0.0225 (0.0135)	KLLoss 0.0051 (0.0034)	MaskLoss 0.1081 (0.1279)	MaskBCELoss 0.0401 (0.0355)	MaskDICELoss 0.0680 (0.0924)
Epoch: [0][222/500]	Time 51.760 (51.760)	Loss 0.5499 (0.4366)	CeLoss 0.0713 (0.0601)	SegCLSLoss 0.0327 (0.0092)	KLLoss 0.0042 (0.0035)	MaskLoss 0.1289 (0.1039)	MaskBCELoss 0.0289 (0.0237)	MaskDICELoss 0.1000 (0.0803)
Epoch: [0][223/500]	Time 44.373 (44.373)	Loss 0.4085 (0.4826)	CeLoss 0.0767 (0.0719)	SegCLSLoss 0.0076 (0.0089)	KLLoss 0.0036 (0.0040)	MaskLoss 0.0919 (0.1168)	MaskBCELoss 0.0216 (0.0324)	MaskDICELoss 0.0703 (0.0844)
Epoch: [0][224/500]	Time 47.197 (47.197)	Loss 0.0547 (0.3809)	CeLoss 0.0547 (0.0592)	SegCLSLoss 0.0000 (0.0085)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0910)	MaskBCELoss 0.0000 (0.0247)	MaskDICELoss 0.0000 (0.0663)
Epoch: [0][225/500]	Time 44.151 (44.151)	Loss 0.4723 (0.5083)	CeLoss 0.0376 (0.0767)	SegCLSLoss 0.0217 (0.0077)	KLLoss 0.0036 (0.0038)	MaskLoss 0.1110 (0.1202)	MaskBCELoss 0.0121 (0.0284)	MaskDICELoss 0.0990 (0.0918)
Epoch: [0][226/500]	Time 47.115 (47.115)	Loss 0.4990 (0.4150)	CeLoss 0.0554 (0.0493)	SegCLSLoss 0.0022 (0.0064)	KLLoss 0.0068 (0.0053)	MaskLoss 0.1179 (0.1033)	MaskBCELoss 0.0179 (0.0279)	MaskDICELoss 0.1000 (0.0754)
Epoch: [0][227/500]	Time 50.972 (50.972)	Loss 0.3726 (0.4609)	CeLoss 0.0359 (0.0484)	SegCLSLoss 0.0199 (0.0122)	KLLoss 0.0014 (0.0043)	MaskLoss 0.0939 (0.1135)	MaskBCELoss 0.0252 (0.0259)	MaskDICELoss 0.0687 (0.0876)
Epoch: [0][228/500]	Time 40.831 (40.831)	Loss 0.5022 (0.4972)	CeLoss 0.0859 (0.0676)	SegCLSLoss 0.0157 (0.0094)	KLLoss 0.0041 (0.0036)	MaskLoss 0.1179 (0.1242)	MaskBCELoss 0.0336 (0.0377)	MaskDICELoss 0.0843 (0.0865)
Epoch: [0][229/500]	Time 47.583 (47.583)	Loss 0.4909 (0.4490)	CeLoss 0.0618 (0.0520)	SegCLSLoss 0.0122 (0.0138)	KLLoss 0.0033 (0.0035)	MaskLoss 0.1099 (0.1084)	MaskBCELoss 0.0100 (0.0236)	MaskDICELoss 0.1000 (0.0848)
Epoch: [0][230/500]	Time 49.638 (49.638)	Loss 0.4925 (0.4750)	CeLoss 0.0425 (0.0428)	SegCLSLoss 0.0034 (0.0082)	KLLoss 0.0037 (0.0050)	MaskLoss 0.1233 (0.1288)	MaskBCELoss 0.0244 (0.0461)	MaskDICELoss 0.0989 (0.0828)
Epoch: [0][231/500]	Time 50.938 (50.938)	Loss 0.5777 (0.5140)	CeLoss 0.0811 (0.0577)	SegCLSLoss 0.0095 (0.0065)	KLLoss 0.0039 (0.0042)	MaskLoss 0.1442 (0.1363)	MaskBCELoss 0.0445 (0.0483)	MaskDICELoss 0.0997 (0.0881)
Epoch: [0][232/500]	Time 48.287 (48.287)	Loss 0.5319 (0.4350)	CeLoss 0.0679 (0.0543)	SegCLSLoss 0.0083 (0.0050)	KLLoss 0.0040 (0.0036)	MaskLoss 0.1373 (0.1049)	MaskBCELoss 0.0468 (0.0225)	MaskDICELoss 0.0905 (0.0824)
Epoch: [0][233/500]	Time 48.362 (48.362)	Loss 0.4363 (0.4282)	CeLoss 0.0654 (0.0618)	SegCLSLoss 0.0126 (0.0082)	KLLoss 0.0022 (0.0031)	MaskLoss 0.1090 (0.1014)	MaskBCELoss 0.0370 (0.0233)	MaskDICELoss 0.0720 (0.0782)
Epoch: [0][234/500]	Time 45.998 (45.998)	Loss 0.4953 (0.5076)	CeLoss 0.0610 (0.0649)	SegCLSLoss 0.0055 (0.0098)	KLLoss 0.0033 (0.0038)	MaskLoss 0.1157 (0.1234)	MaskBCELoss 0.0174 (0.0297)	MaskDICELoss 0.0983 (0.0937)
Epoch: [0][235/500]	Time 49.825 (49.825)	Loss 0.0430 (0.4636)	CeLoss 0.0430 (0.0620)	SegCLSLoss 0.0000 (0.0079)	KLLoss 0.0000 (0.0041)	MaskLoss 0.0000 (0.1129)	MaskBCELoss 0.0000 (0.0291)	MaskDICELoss 0.0000 (0.0838)
Epoch: [0][236/500]	Time 50.464 (50.464)	Loss 0.4811 (0.3704)	CeLoss 0.0376 (0.0719)	SegCLSLoss 0.0139 (0.0052)	KLLoss 0.0052 (0.0035)	MaskLoss 0.1158 (0.0827)	MaskBCELoss 0.0160 (0.0191)	MaskDICELoss 0.0998 (0.0636)
Epoch: [0][237/500]	Time 49.861 (49.861)	Loss 0.4707 (0.4216)	CeLoss 0.0613 (0.0581)	SegCLSLoss 0.0052 (0.0088)	KLLoss 0.0043 (0.0042)	MaskLoss 0.1119 (0.0995)	MaskBCELoss 0.0225 (0.0217)	MaskDICELoss 0.0893 (0.0778)
Epoch: [0][238/500]	Time 46.175 (46.175)	Loss 0.4778 (0.4752)	CeLoss 0.0376 (0.0673)	SegCLSLoss 0.0146 (0.0100)	KLLoss 0.0051 (0.0039)	MaskLoss 0.1183 (0.1133)	MaskBCELoss 0.0227 (0.0270)	MaskDICELoss 0.0956 (0.0863)
Epoch: [0][239/500]	Time 52.296 (52.296)	Loss 0.4950 (0.3762)	CeLoss 0.0320 (0.0604)	SegCLSLoss 0.0039 (0.0082)	KLLoss 0.0067 (0.0030)	MaskLoss 0.1305 (0.0879)	MaskBCELoss 0.0339 (0.0215)	MaskDICELoss 0.0967 (0.0665)
Epoch: [0][240/500]	Time 44.577 (44.577)	Loss 0.1088 (0.4530)	CeLoss 0.0698 (0.0586)	SegCLSLoss 0.0021 (0.0087)	KLLoss 0.0063 (0.0040)	MaskLoss 0.0126 (0.1108)	MaskBCELoss 0.0095 (0.0287)	MaskDICELoss 0.0031 (0.0821)
Epoch: [0][241/500]	Time 47.706 (47.706)	Loss 0.4888 (0.4583)	CeLoss 0.0654 (0.0601)	SegCLSLoss 0.0075 (0.0110)	KLLoss 0.0039 (0.0034)	MaskLoss 0.1079 (0.1077)	MaskBCELoss 0.0080 (0.0208)	MaskDICELoss 0.1000 (0.0869)
Epoch: [0][242/500]	Time 51.236 (51.236)	Loss 0.5321 (0.4700)	CeLoss 0.0352 (0.0474)	SegCLSLoss 0.0115 (0.0099)	KLLoss 0.0031 (0.0028)	MaskLoss 0.1444 (0.1185)	MaskBCELoss 0.0448 (0.0296)	MaskDICELoss 0.0996 (0.0889)
Epoch: [0][243/500]	Time 49.171 (49.171)	Loss 0.4769 (0.4085)	CeLoss 0.0581 (0.0503)	SegCLSLoss 0.0045 (0.0098)	KLLoss 0.0057 (0.0037)	MaskLoss 0.1053 (0.0941)	MaskBCELoss 0.0054 (0.0134)	MaskDICELoss 0.0999 (0.0807)
Epoch: [0][244/500]	Time 45.689 (45.689)	Loss 0.4669 (0.2852)	CeLoss 0.0449 (0.0569)	SegCLSLoss 0.0017 (0.0060)	KLLoss 0.0044 (0.0019)	MaskLoss 0.1313 (0.0642)	MaskBCELoss 0.0541 (0.0168)	MaskDICELoss 0.0772 (0.0475)
Epoch: [0][245/500]	Time 45.944 (45.944)	Loss 0.6038 (0.4216)	CeLoss 0.0369 (0.0558)	SegCLSLoss 0.0057 (0.0103)	KLLoss 0.0049 (0.0036)	MaskLoss 0.1863 (0.1038)	MaskBCELoss 0.0931 (0.0290)	MaskDICELoss 0.0932 (0.0748)
Epoch: [0][246/500]	Time 49.282 (49.282)	Loss 0.5410 (0.4601)	CeLoss 0.0884 (0.0633)	SegCLSLoss 0.0015 (0.0036)	KLLoss 0.0054 (0.0037)	MaskLoss 0.1239 (0.1085)	MaskBCELoss 0.0245 (0.0213)	MaskDICELoss 0.0993 (0.0872)
Epoch: [0][247/500]	Time 49.547 (49.547)	Loss 0.4611 (0.3395)	CeLoss 0.1118 (0.0569)	SegCLSLoss 0.0027 (0.0060)	KLLoss 0.0068 (0.0042)	MaskLoss 0.1194 (0.0812)	MaskBCELoss 0.0683 (0.0248)	MaskDICELoss 0.0510 (0.0565)
Epoch: [0][248/500]	Time 44.099 (44.099)	Loss 0.4738 (0.4112)	CeLoss 0.0339 (0.0487)	SegCLSLoss 0.0500 (0.0164)	KLLoss 0.0026 (0.0025)	MaskLoss 0.1077 (0.0944)	MaskBCELoss 0.0094 (0.0130)	MaskDICELoss 0.0983 (0.0814)
Epoch: [0][249/500]	Time 43.929 (43.929)	Loss 0.4770 (0.4857)	CeLoss 0.0540 (0.0557)	SegCLSLoss 0.0027 (0.0079)	KLLoss 0.0049 (0.0039)	MaskLoss 0.1168 (0.1195)	MaskBCELoss 0.0251 (0.0279)	MaskDICELoss 0.0916 (0.0916)
Epoch: [0][250/500]	Time 45.808 (45.808)	Loss 0.4977 (0.4188)	CeLoss 0.0781 (0.0543)	SegCLSLoss 0.0093 (0.0139)	KLLoss 0.0032 (0.0033)	MaskLoss 0.1182 (0.0993)	MaskBCELoss 0.0306 (0.0214)	MaskDICELoss 0.0877 (0.0779)
Epoch: [0][251/500]	Time 46.562 (46.562)	Loss 0.4555 (0.4436)	CeLoss 0.0422 (0.0477)	SegCLSLoss 0.0026 (0.0121)	KLLoss 0.0049 (0.0033)	MaskLoss 0.1040 (0.1054)	MaskBCELoss 0.0044 (0.0176)	MaskDICELoss 0.0996 (0.0879)
Epoch: [0][252/500]	Time 50.522 (50.522)	Loss 0.2546 (0.3968)	CeLoss 0.0527 (0.0572)	SegCLSLoss 0.0016 (0.0052)	KLLoss 0.0063 (0.0035)	MaskLoss 0.0519 (0.0910)	MaskBCELoss 0.0063 (0.0153)	MaskDICELoss 0.0456 (0.0757)
Epoch: [0][253/500]	Time 51.847 (51.847)	Loss 0.1040 (0.4598)	CeLoss 0.0322 (0.0667)	SegCLSLoss 0.0030 (0.0083)	KLLoss 0.0095 (0.0049)	MaskLoss 0.0246 (0.1087)	MaskBCELoss 0.0189 (0.0254)	MaskDICELoss 0.0057 (0.0833)
Epoch: [0][254/500]	Time 49.919 (49.919)	Loss 0.4077 (0.3929)	CeLoss 0.0708 (0.0579)	SegCLSLoss 0.0114 (0.0116)	KLLoss 0.0064 (0.0032)	MaskLoss 0.0855 (0.0909)	MaskBCELoss 0.0085 (0.0188)	MaskDICELoss 0.0770 (0.0721)
Epoch: [0][255/500]	Time 48.406 (48.406)	Loss 0.5019 (0.4194)	CeLoss 0.0811 (0.0626)	SegCLSLoss 0.0029 (0.0088)	KLLoss 0.0039 (0.0031)	MaskLoss 0.1087 (0.0930)	MaskBCELoss 0.0096 (0.0112)	MaskDICELoss 0.0991 (0.0818)
Epoch: [0][256/500]	Time 49.535 (49.535)	Loss 0.4885 (0.4695)	CeLoss 0.0566 (0.0519)	SegCLSLoss 0.0101 (0.0086)	KLLoss 0.0033 (0.0033)	MaskLoss 0.1190 (0.1137)	MaskBCELoss 0.0261 (0.0225)	MaskDICELoss 0.0928 (0.0913)
Epoch: [0][257/500]	Time 47.430 (47.430)	Loss 0.2568 (0.4013)	CeLoss 0.0520 (0.0513)	SegCLSLoss 0.0014 (0.0079)	KLLoss 0.0038 (0.0042)	MaskLoss 0.0716 (0.1009)	MaskBCELoss 0.0432 (0.0309)	MaskDICELoss 0.0285 (0.0700)
Epoch: [0][258/500]	Time 51.364 (51.364)	Loss 0.4978 (0.4032)	CeLoss 0.0713 (0.0596)	SegCLSLoss 0.0017 (0.0055)	KLLoss 0.0065 (0.0033)	MaskLoss 0.1094 (0.0949)	MaskBCELoss 0.0094 (0.0211)	MaskDICELoss 0.1000 (0.0739)
Epoch: [0][259/500]	Time 39.903 (39.903)	Loss 0.4645 (0.4518)	CeLoss 0.0859 (0.0526)	SegCLSLoss 0.0664 (0.0137)	KLLoss 0.0012 (0.0040)	MaskLoss 0.1016 (0.1090)	MaskBCELoss 0.0311 (0.0238)	MaskDICELoss 0.0705 (0.0852)
Epoch: [0][260/500]	Time 50.242 (50.242)	Loss 0.3668 (0.3657)	CeLoss 0.0312 (0.0470)	SegCLSLoss 0.0046 (0.0040)	KLLoss 0.0033 (0.0034)	MaskLoss 0.1011 (0.0952)	MaskBCELoss 0.0373 (0.0338)	MaskDICELoss 0.0638 (0.0614)
Epoch: [0][261/500]	Time 47.283 (47.283)	Loss 0.4874 (0.4451)	CeLoss 0.0356 (0.0584)	SegCLSLoss 0.0043 (0.0078)	KLLoss 0.0025 (0.0025)	MaskLoss 0.1425 (0.1099)	MaskBCELoss 0.0614 (0.0297)	MaskDICELoss 0.0811 (0.0803)
Epoch: [0][262/500]	Time 46.824 (46.824)	Loss 0.5189 (0.4101)	CeLoss 0.0854 (0.0498)	SegCLSLoss 0.0018 (0.0110)	KLLoss 0.0040 (0.0029)	MaskLoss 0.1146 (0.1012)	MaskBCELoss 0.0148 (0.0265)	MaskDICELoss 0.0998 (0.0747)
Epoch: [0][263/500]	Time 49.318 (49.318)	Loss 0.6286 (0.4885)	CeLoss 0.0481 (0.0469)	SegCLSLoss 0.0025 (0.0047)	KLLoss 0.0044 (0.0044)	MaskLoss 0.1981 (0.1264)	MaskBCELoss 0.1087 (0.0354)	MaskDICELoss 0.0894 (0.0910)
Epoch: [0][264/500]	Time 46.448 (46.448)	Loss 0.4091 (0.3668)	CeLoss 0.0299 (0.0445)	SegCLSLoss 0.0140 (0.0059)	KLLoss 0.0051 (0.0036)	MaskLoss 0.1014 (0.0906)	MaskBCELoss 0.0192 (0.0233)	MaskDICELoss 0.0822 (0.0673)
Epoch: [0][265/500]	Time 44.918 (44.918)	Loss 0.1459 (0.4084)	CeLoss 0.0986 (0.0637)	SegCLSLoss 0.0029 (0.0060)	KLLoss 0.0101 (0.0053)	MaskLoss 0.0141 (0.0936)	MaskBCELoss 0.0104 (0.0190)	MaskDICELoss 0.0038 (0.0746)
Epoch: [0][266/500]	Time 44.924 (44.924)	Loss 0.4542 (0.4541)	CeLoss 0.0640 (0.0458)	SegCLSLoss 0.0071 (0.0172)	KLLoss 0.0047 (0.0035)	MaskLoss 0.1018 (0.1070)	MaskBCELoss 0.0126 (0.0158)	MaskDICELoss 0.0892 (0.0911)
Epoch: [0][267/500]	Time 50.029 (50.029)	Loss 0.4740 (0.3759)	CeLoss 0.0571 (0.0543)	SegCLSLoss 0.0019 (0.0037)	KLLoss 0.0025 (0.0031)	MaskLoss 0.1069 (0.0881)	MaskBCELoss 0.0069 (0.0178)	MaskDICELoss 0.1000 (0.0703)
Epoch: [0][268/500]	Time 46.787 (46.787)	Loss 0.4998 (0.5836)	CeLoss 0.0500 (0.0612)	SegCLSLoss 0.0018 (0.0088)	KLLoss 0.0026 (0.0034)	MaskLoss 0.1258 (0.1607)	MaskBCELoss 0.0284 (0.0641)	MaskDICELoss 0.0974 (0.0965)
Epoch: [0][269/500]	Time 50.369 (50.369)	Loss 0.4963 (0.4594)	CeLoss 0.0322 (0.0556)	SegCLSLoss 0.0327 (0.0171)	KLLoss 0.0035 (0.0028)	MaskLoss 0.1263 (0.1128)	MaskBCELoss 0.0306 (0.0295)	MaskDICELoss 0.0957 (0.0834)
Epoch: [0][270/500]	Time 44.919 (44.919)	Loss 0.4683 (0.4613)	CeLoss 0.0352 (0.0554)	SegCLSLoss 0.0103 (0.0092)	KLLoss 0.0025 (0.0030)	MaskLoss 0.1146 (0.1077)	MaskBCELoss 0.0165 (0.0162)	MaskDICELoss 0.0981 (0.0915)
Epoch: [0][271/500]	Time 45.622 (45.622)	Loss 0.5233 (0.4562)	CeLoss 0.0417 (0.0515)	SegCLSLoss 0.0077 (0.0078)	KLLoss 0.0039 (0.0033)	MaskLoss 0.1462 (0.1199)	MaskBCELoss 0.0555 (0.0411)	MaskDICELoss 0.0907 (0.0788)
Epoch: [0][272/500]	Time 49.181 (49.181)	Loss 0.4279 (0.4144)	CeLoss 0.0520 (0.0465)	SegCLSLoss 0.0030 (0.0065)	KLLoss 0.0047 (0.0035)	MaskLoss 0.1002 (0.1060)	MaskBCELoss 0.0155 (0.0314)	MaskDICELoss 0.0847 (0.0746)
Epoch: [0][273/500]	Time 47.434 (47.434)	Loss 0.5155 (0.4574)	CeLoss 0.0737 (0.0594)	SegCLSLoss 0.0032 (0.0044)	KLLoss 0.0045 (0.0037)	MaskLoss 0.1197 (0.1111)	MaskBCELoss 0.0215 (0.0261)	MaskDICELoss 0.0982 (0.0850)
Epoch: [0][274/500]	Time 46.367 (46.367)	Loss 0.4575 (0.5071)	CeLoss 0.0767 (0.0580)	SegCLSLoss 0.0017 (0.0084)	KLLoss 0.0053 (0.0042)	MaskLoss 0.1210 (0.1321)	MaskBCELoss 0.0547 (0.0439)	MaskDICELoss 0.0663 (0.0882)
Epoch: [0][275/500]	Time 53.978 (53.978)	Loss 0.0279 (0.3622)	CeLoss 0.0280 (0.0496)	SegCLSLoss 0.0000 (0.0027)	KLLoss 0.0000 (0.0040)	MaskLoss 0.0000 (0.0883)	MaskBCELoss 0.0000 (0.0230)	MaskDICELoss 0.0000 (0.0653)
Epoch: [0][276/500]	Time 47.685 (47.685)	Loss 0.4583 (0.4578)	CeLoss 0.0297 (0.0546)	SegCLSLoss 0.0033 (0.0086)	KLLoss 0.0040 (0.0037)	MaskLoss 0.1188 (0.1197)	MaskBCELoss 0.0259 (0.0419)	MaskDICELoss 0.0928 (0.0778)
Epoch: [0][277/500]	Time 48.128 (48.128)	Loss 0.0668 (0.4017)	CeLoss 0.0669 (0.0424)	SegCLSLoss 0.0000 (0.0047)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.1062)	MaskBCELoss 0.0000 (0.0358)	MaskDICELoss 0.0000 (0.0705)
Epoch: [0][278/500]	Time 48.074 (48.074)	Loss 0.3862 (0.4417)	CeLoss 0.0273 (0.0580)	SegCLSLoss 0.0046 (0.0052)	KLLoss 0.0031 (0.0038)	MaskLoss 0.1012 (0.1109)	MaskBCELoss 0.0256 (0.0331)	MaskDICELoss 0.0755 (0.0778)
Epoch: [0][279/500]	Time 51.302 (51.302)	Loss 0.4538 (0.3737)	CeLoss 0.0270 (0.0543)	SegCLSLoss 0.0535 (0.0092)	KLLoss 0.0027 (0.0031)	MaskLoss 0.1043 (0.0870)	MaskBCELoss 0.0100 (0.0182)	MaskDICELoss 0.0943 (0.0688)
Epoch: [0][280/500]	Time 53.703 (53.703)	Loss 0.1938 (0.2996)	CeLoss 0.0991 (0.0539)	SegCLSLoss 0.0012 (0.0039)	KLLoss 0.0055 (0.0029)	MaskLoss 0.0361 (0.0700)	MaskBCELoss 0.0279 (0.0196)	MaskDICELoss 0.0081 (0.0504)
Epoch: [0][281/500]	Time 49.770 (49.770)	Loss 0.4991 (0.4998)	CeLoss 0.1001 (0.0675)	SegCLSLoss 0.0035 (0.0067)	KLLoss 0.0043 (0.0041)	MaskLoss 0.1067 (0.1175)	MaskBCELoss 0.0166 (0.0227)	MaskDICELoss 0.0901 (0.0948)
Epoch: [0][282/500]	Time 48.928 (48.928)	Loss 0.4364 (0.4008)	CeLoss 0.0295 (0.0546)	SegCLSLoss 0.0226 (0.0058)	KLLoss 0.0035 (0.0029)	MaskLoss 0.1051 (0.0944)	MaskBCELoss 0.0141 (0.0185)	MaskDICELoss 0.0910 (0.0759)
Epoch: [0][283/500]	Time 45.864 (45.864)	Loss 0.6307 (0.4023)	CeLoss 0.0884 (0.0483)	SegCLSLoss 0.0078 (0.0113)	KLLoss 0.0030 (0.0030)	MaskLoss 0.1696 (0.0984)	MaskBCELoss 0.0715 (0.0242)	MaskDICELoss 0.0981 (0.0743)
Epoch: [0][284/500]	Time 48.337 (48.337)	Loss 0.5276 (0.3571)	CeLoss 0.1006 (0.0630)	SegCLSLoss 0.0120 (0.0057)	KLLoss 0.0052 (0.0029)	MaskLoss 0.1078 (0.0810)	MaskBCELoss 0.0081 (0.0177)	MaskDICELoss 0.0997 (0.0632)
Epoch: [0][285/500]	Time 45.579 (45.579)	Loss 0.1946 (0.4735)	CeLoss 0.0310 (0.0501)	SegCLSLoss 0.0193 (0.0062)	KLLoss 0.0030 (0.0038)	MaskLoss 0.0475 (0.1322)	MaskBCELoss 0.0195 (0.0561)	MaskDICELoss 0.0280 (0.0761)
Epoch: [0][286/500]	Time 49.987 (49.987)	Loss 0.4650 (0.4433)	CeLoss 0.0562 (0.0530)	SegCLSLoss 0.0032 (0.0056)	KLLoss 0.0043 (0.0029)	MaskLoss 0.1193 (0.1050)	MaskBCELoss 0.0371 (0.0177)	MaskDICELoss 0.0822 (0.0873)
Epoch: [0][287/500]	Time 48.667 (48.667)	Loss 0.4961 (0.4046)	CeLoss 0.0337 (0.0479)	SegCLSLoss 0.0029 (0.0048)	KLLoss 0.0093 (0.0039)	MaskLoss 0.1351 (0.1031)	MaskBCELoss 0.0444 (0.0309)	MaskDICELoss 0.0907 (0.0721)
Epoch: [0][288/500]	Time 49.982 (49.982)	Loss 0.4452 (0.4375)	CeLoss 0.0344 (0.0536)	SegCLSLoss 0.0036 (0.0062)	KLLoss 0.0007 (0.0035)	MaskLoss 0.1042 (0.1025)	MaskBCELoss 0.0043 (0.0164)	MaskDICELoss 0.0999 (0.0861)
Epoch: [0][289/500]	Time 44.824 (44.824)	Loss 0.2943 (0.3620)	CeLoss 0.0310 (0.0477)	SegCLSLoss 0.0146 (0.0076)	KLLoss 0.0042 (0.0038)	MaskLoss 0.0811 (0.0931)	MaskBCELoss 0.0363 (0.0329)	MaskDICELoss 0.0448 (0.0603)
Epoch: [0][290/500]	Time 44.703 (44.703)	Loss 0.4286 (0.4261)	CeLoss 0.0339 (0.0629)	SegCLSLoss 0.0075 (0.0051)	KLLoss 0.0049 (0.0034)	MaskLoss 0.1130 (0.1004)	MaskBCELoss 0.0330 (0.0221)	MaskDICELoss 0.0800 (0.0783)
Epoch: [0][291/500]	Time 49.542 (49.542)	Loss 0.5256 (0.4519)	CeLoss 0.0796 (0.0564)	SegCLSLoss 0.0015 (0.0075)	KLLoss 0.0043 (0.0032)	MaskLoss 0.1215 (0.1080)	MaskBCELoss 0.0225 (0.0216)	MaskDICELoss 0.0990 (0.0863)
Epoch: [0][292/500]	Time 47.758 (47.758)	Loss 0.5398 (0.4729)	CeLoss 0.0474 (0.0399)	SegCLSLoss 0.0013 (0.0078)	KLLoss 0.0033 (0.0030)	MaskLoss 0.1818 (0.1251)	MaskBCELoss 0.1192 (0.0371)	MaskDICELoss 0.0625 (0.0880)
Epoch: [0][293/500]	Time 49.649 (49.649)	Loss 0.6295 (0.4378)	CeLoss 0.0508 (0.0405)	SegCLSLoss 0.0024 (0.0081)	KLLoss 0.0029 (0.0037)	MaskLoss 0.1981 (0.1166)	MaskBCELoss 0.1087 (0.0384)	MaskDICELoss 0.0893 (0.0782)
Epoch: [0][294/500]	Time 46.236 (46.236)	Loss 0.3577 (0.3804)	CeLoss 0.0300 (0.0468)	SegCLSLoss 0.0110 (0.0099)	KLLoss 0.0041 (0.0033)	MaskLoss 0.1057 (0.0941)	MaskBCELoss 0.0523 (0.0255)	MaskDICELoss 0.0533 (0.0686)
Epoch: [0][295/500]	Time 49.941 (49.941)	Loss 0.3327 (0.4427)	CeLoss 0.0654 (0.0605)	SegCLSLoss 0.0025 (0.0055)	KLLoss 0.0030 (0.0038)	MaskLoss 0.0868 (0.1091)	MaskBCELoss 0.0423 (0.0303)	MaskDICELoss 0.0446 (0.0787)
Epoch: [0][296/500]	Time 44.750 (44.750)	Loss 0.5195 (0.4120)	CeLoss 0.0559 (0.0526)	SegCLSLoss 0.0366 (0.0091)	KLLoss 0.0047 (0.0038)	MaskLoss 0.1205 (0.1009)	MaskBCELoss 0.0207 (0.0263)	MaskDICELoss 0.0998 (0.0747)
Epoch: [0][297/500]	Time 45.412 (45.412)	Loss 0.5745 (0.4803)	CeLoss 0.0635 (0.0524)	SegCLSLoss 0.0013 (0.0072)	KLLoss 0.0043 (0.0029)	MaskLoss 0.2152 (0.1291)	MaskBCELoss 0.1774 (0.0475)	MaskDICELoss 0.0378 (0.0816)
Epoch: [0][298/500]	Time 46.853 (46.853)	Loss 0.4556 (0.4481)	CeLoss 0.0425 (0.0542)	SegCLSLoss 0.0018 (0.0074)	KLLoss 0.0026 (0.0033)	MaskLoss 0.1069 (0.1119)	MaskBCELoss 0.0091 (0.0304)	MaskDICELoss 0.0978 (0.0815)
Epoch: [0][299/500]	Time 49.154 (49.154)	Loss 0.5415 (0.4881)	CeLoss 0.0898 (0.0523)	SegCLSLoss 0.0102 (0.0090)	KLLoss 0.0023 (0.0039)	MaskLoss 0.1226 (0.1303)	MaskBCELoss 0.0230 (0.0470)	MaskDICELoss 0.0995 (0.0834)
[2025-03-11 03:03:08,965] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.0002972650602409638], mom=[(0.9, 0.95)]
[2025-03-11 03:03:08,972] [INFO] [timer.py:215:stop] epoch=0/micro_step=300/global_step=30, RunningAvgSamplesPerSec=0.827742285810538, CurrSamplesPerSec=0.8154226739097936, MemAllocated=58.16GB, MaxMemAllocated=73.59GB
Epoch: [0][300/500]	Time 46.507 (46.507)	Loss 0.6292 (0.4946)	CeLoss 0.0957 (0.0570)	SegCLSLoss 0.0035 (0.0064)	KLLoss 0.0042 (0.0036)	MaskLoss 0.1665 (0.1245)	MaskBCELoss 0.0691 (0.0336)	MaskDICELoss 0.0974 (0.0909)
Epoch: [0][301/500]	Time 50.523 (50.523)	Loss 0.5092 (0.4545)	CeLoss 0.0289 (0.0543)	SegCLSLoss 0.0334 (0.0098)	KLLoss 0.0020 (0.0030)	MaskLoss 0.1404 (0.1201)	MaskBCELoss 0.0500 (0.0440)	MaskDICELoss 0.0904 (0.0761)
Epoch: [0][302/500]	Time 45.284 (45.284)	Loss 0.3882 (0.4612)	CeLoss 0.0303 (0.0468)	SegCLSLoss 0.0154 (0.0090)	KLLoss 0.0042 (0.0031)	MaskLoss 0.1024 (0.1170)	MaskBCELoss 0.0319 (0.0307)	MaskDICELoss 0.0706 (0.0863)
Epoch: [0][303/500]	Time 50.288 (50.288)	Loss 0.4511 (0.4642)	CeLoss 0.0571 (0.0472)	SegCLSLoss 0.0154 (0.0072)	KLLoss 0.0026 (0.0036)	MaskLoss 0.1073 (0.1210)	MaskBCELoss 0.0228 (0.0372)	MaskDICELoss 0.0845 (0.0839)
Epoch: [0][304/500]	Time 40.540 (40.540)	Loss 0.5246 (0.4307)	CeLoss 0.0869 (0.0651)	SegCLSLoss 0.0057 (0.0088)	KLLoss 0.0045 (0.0032)	MaskLoss 0.1158 (0.0999)	MaskBCELoss 0.0162 (0.0209)	MaskDICELoss 0.0996 (0.0790)
Epoch: [0][305/500]	Time 49.291 (49.291)	Loss 0.2265 (0.3857)	CeLoss 0.0630 (0.0528)	SegCLSLoss 0.0017 (0.0079)	KLLoss 0.0061 (0.0043)	MaskLoss 0.0405 (0.0928)	MaskBCELoss 0.0028 (0.0232)	MaskDICELoss 0.0377 (0.0696)
Epoch: [0][306/500]	Time 49.094 (49.094)	Loss 0.4550 (0.4532)	CeLoss 0.0474 (0.0498)	SegCLSLoss 0.0109 (0.0051)	KLLoss 0.0046 (0.0043)	MaskLoss 0.1136 (0.1122)	MaskBCELoss 0.0283 (0.0261)	MaskDICELoss 0.0852 (0.0861)
Epoch: [0][307/500]	Time 48.698 (48.698)	Loss 0.5086 (0.3678)	CeLoss 0.0991 (0.0469)	SegCLSLoss 0.0087 (0.0057)	KLLoss 0.0041 (0.0031)	MaskLoss 0.1150 (0.0887)	MaskBCELoss 0.0295 (0.0200)	MaskDICELoss 0.0855 (0.0687)
Epoch: [0][308/500]	Time 49.259 (49.259)	Loss 0.5196 (0.4239)	CeLoss 0.0581 (0.0585)	SegCLSLoss 0.0032 (0.0039)	KLLoss 0.0047 (0.0043)	MaskLoss 0.1288 (0.1020)	MaskBCELoss 0.0300 (0.0243)	MaskDICELoss 0.0988 (0.0777)
Epoch: [0][309/500]	Time 49.438 (49.438)	Loss 0.5152 (0.3873)	CeLoss 0.0520 (0.0463)	SegCLSLoss 0.0071 (0.0079)	KLLoss 0.0046 (0.0035)	MaskLoss 0.1281 (0.0992)	MaskBCELoss 0.0287 (0.0316)	MaskDICELoss 0.0994 (0.0676)
Epoch: [0][310/500]	Time 48.633 (48.633)	Loss 0.5115 (0.4787)	CeLoss 0.0854 (0.0762)	SegCLSLoss 0.0079 (0.0034)	KLLoss 0.0045 (0.0043)	MaskLoss 0.1222 (0.1208)	MaskBCELoss 0.0354 (0.0434)	MaskDICELoss 0.0867 (0.0774)
Epoch: [0][311/500]	Time 45.272 (45.272)	Loss 0.5161 (0.4175)	CeLoss 0.0732 (0.0392)	SegCLSLoss 0.0047 (0.0059)	KLLoss 0.0027 (0.0028)	MaskLoss 0.1273 (0.1095)	MaskBCELoss 0.0359 (0.0326)	MaskDICELoss 0.0915 (0.0768)
Epoch: [0][312/500]	Time 48.878 (48.878)	Loss 0.4279 (0.4577)	CeLoss 0.0520 (0.0447)	SegCLSLoss 0.0042 (0.0076)	KLLoss 0.0040 (0.0039)	MaskLoss 0.1026 (0.1141)	MaskBCELoss 0.0201 (0.0256)	MaskDICELoss 0.0825 (0.0885)
Epoch: [0][313/500]	Time 47.090 (47.090)	Loss 0.4832 (0.4208)	CeLoss 0.0483 (0.0590)	SegCLSLoss 0.0046 (0.0032)	KLLoss 0.0029 (0.0038)	MaskLoss 0.1233 (0.1039)	MaskBCELoss 0.0320 (0.0296)	MaskDICELoss 0.0914 (0.0743)
Epoch: [0][314/500]	Time 50.242 (50.242)	Loss 0.5336 (0.4315)	CeLoss 0.0801 (0.0427)	SegCLSLoss 0.0013 (0.0036)	KLLoss 0.0037 (0.0033)	MaskLoss 0.1286 (0.1153)	MaskBCELoss 0.0325 (0.0387)	MaskDICELoss 0.0961 (0.0766)
Epoch: [0][315/500]	Time 50.913 (50.913)	Loss 0.3115 (0.4151)	CeLoss 0.0532 (0.0486)	SegCLSLoss 0.0018 (0.0044)	KLLoss 0.0045 (0.0039)	MaskLoss 0.0801 (0.1095)	MaskBCELoss 0.0335 (0.0388)	MaskDICELoss 0.0466 (0.0707)
Epoch: [0][316/500]	Time 49.176 (49.176)	Loss 0.4904 (0.4848)	CeLoss 0.0542 (0.0436)	SegCLSLoss 0.0022 (0.0123)	KLLoss 0.0026 (0.0033)	MaskLoss 0.1163 (0.1224)	MaskBCELoss 0.0165 (0.0289)	MaskDICELoss 0.0998 (0.0935)
Epoch: [0][317/500]	Time 48.481 (48.481)	Loss 0.4861 (0.3724)	CeLoss 0.0356 (0.0505)	SegCLSLoss 0.0334 (0.0100)	KLLoss 0.0035 (0.0023)	MaskLoss 0.1174 (0.0882)	MaskBCELoss 0.0196 (0.0191)	MaskDICELoss 0.0978 (0.0691)
Epoch: [0][318/500]	Time 44.995 (44.995)	Loss 0.5404 (0.4326)	CeLoss 0.0732 (0.0478)	SegCLSLoss 0.0093 (0.0081)	KLLoss 0.0040 (0.0039)	MaskLoss 0.1350 (0.1089)	MaskBCELoss 0.0408 (0.0293)	MaskDICELoss 0.0942 (0.0795)
Epoch: [0][319/500]	Time 47.081 (47.081)	Loss 0.0643 (0.3235)	CeLoss 0.0315 (0.0495)	SegCLSLoss 0.0024 (0.0056)	KLLoss 0.0048 (0.0035)	MaskLoss 0.0109 (0.0805)	MaskBCELoss 0.0083 (0.0271)	MaskDICELoss 0.0025 (0.0534)
Epoch: [0][320/500]	Time 46.780 (46.780)	Loss 0.4810 (0.4062)	CeLoss 0.0654 (0.0540)	SegCLSLoss 0.0045 (0.0094)	KLLoss 0.0032 (0.0031)	MaskLoss 0.1055 (0.1013)	MaskBCELoss 0.0061 (0.0304)	MaskDICELoss 0.0994 (0.0709)
Epoch: [0][321/500]	Time 47.552 (47.552)	Loss 0.5063 (0.4292)	CeLoss 0.0251 (0.0380)	SegCLSLoss 0.0061 (0.0042)	KLLoss 0.0047 (0.0046)	MaskLoss 0.1374 (0.1058)	MaskBCELoss 0.0383 (0.0193)	MaskDICELoss 0.0992 (0.0865)
Epoch: [0][322/500]	Time 42.051 (42.051)	Loss 0.4928 (0.4005)	CeLoss 0.0310 (0.0483)	SegCLSLoss 0.0146 (0.0065)	KLLoss 0.0053 (0.0036)	MaskLoss 0.1330 (0.0998)	MaskBCELoss 0.0414 (0.0268)	MaskDICELoss 0.0916 (0.0729)
Epoch: [0][323/500]	Time 44.984 (44.984)	Loss 0.4705 (0.4103)	CeLoss 0.0309 (0.0508)	SegCLSLoss 0.0026 (0.0060)	KLLoss 0.0033 (0.0038)	MaskLoss 0.1183 (0.1005)	MaskBCELoss 0.0190 (0.0247)	MaskDICELoss 0.0992 (0.0758)
Epoch: [0][324/500]	Time 47.490 (47.490)	Loss 0.5446 (0.3803)	CeLoss 0.0757 (0.0541)	SegCLSLoss 0.0063 (0.0039)	KLLoss 0.0039 (0.0042)	MaskLoss 0.1326 (0.0890)	MaskBCELoss 0.0342 (0.0181)	MaskDICELoss 0.0983 (0.0710)
Epoch: [0][325/500]	Time 52.371 (52.371)	Loss 0.4933 (0.4661)	CeLoss 0.0601 (0.0364)	SegCLSLoss 0.0121 (0.0089)	KLLoss 0.0018 (0.0029)	MaskLoss 0.1158 (0.1229)	MaskBCELoss 0.0191 (0.0347)	MaskDICELoss 0.0967 (0.0882)
Epoch: [0][326/500]	Time 46.346 (46.346)	Loss 0.5404 (0.3983)	CeLoss 0.0703 (0.0612)	SegCLSLoss 0.0030 (0.0035)	KLLoss 0.0041 (0.0041)	MaskLoss 0.1453 (0.1011)	MaskBCELoss 0.0582 (0.0366)	MaskDICELoss 0.0871 (0.0645)
Epoch: [0][327/500]	Time 48.728 (48.728)	Loss 0.4318 (0.4285)	CeLoss 0.0239 (0.0476)	SegCLSLoss 0.0077 (0.0060)	KLLoss 0.0014 (0.0030)	MaskLoss 0.1059 (0.1082)	MaskBCELoss 0.0105 (0.0290)	MaskDICELoss 0.0954 (0.0792)
Epoch: [0][328/500]	Time 46.878 (46.878)	Loss 0.4411 (0.3914)	CeLoss 0.0981 (0.0584)	SegCLSLoss 0.0030 (0.0074)	KLLoss 0.0060 (0.0034)	MaskLoss 0.0975 (0.0925)	MaskBCELoss 0.0272 (0.0220)	MaskDICELoss 0.0703 (0.0705)
Epoch: [0][329/500]	Time 45.470 (45.470)	Loss 0.4711 (0.3489)	CeLoss 0.0266 (0.0536)	SegCLSLoss 0.0096 (0.0048)	KLLoss 0.0060 (0.0036)	MaskLoss 0.1261 (0.0824)	MaskBCELoss 0.0354 (0.0201)	MaskDICELoss 0.0908 (0.0623)
Epoch: [0][330/500]	Time 51.390 (51.390)	Loss 0.4138 (0.4601)	CeLoss 0.0815 (0.0552)	SegCLSLoss 0.0016 (0.0047)	KLLoss 0.0038 (0.0035)	MaskLoss 0.0970 (0.1127)	MaskBCELoss 0.0302 (0.0259)	MaskDICELoss 0.0668 (0.0868)
Epoch: [0][331/500]	Time 45.853 (45.853)	Loss 0.4706 (0.4436)	CeLoss 0.0535 (0.0569)	SegCLSLoss 0.0020 (0.0053)	KLLoss 0.0052 (0.0038)	MaskLoss 0.1181 (0.1110)	MaskBCELoss 0.0309 (0.0318)	MaskDICELoss 0.0873 (0.0792)
Epoch: [0][332/500]	Time 48.148 (48.148)	Loss 0.5941 (0.3873)	CeLoss 0.0752 (0.0453)	SegCLSLoss 0.0008 (0.0053)	KLLoss 0.0051 (0.0031)	MaskLoss 0.1942 (0.0984)	MaskBCELoss 0.1318 (0.0287)	MaskDICELoss 0.0624 (0.0697)
Epoch: [0][333/500]	Time 47.011 (47.011)	Loss 0.4730 (0.4642)	CeLoss 0.0547 (0.0613)	SegCLSLoss 0.0026 (0.0067)	KLLoss 0.0008 (0.0029)	MaskLoss 0.1098 (0.1105)	MaskBCELoss 0.0115 (0.0226)	MaskDICELoss 0.0984 (0.0879)
Epoch: [0][334/500]	Time 44.438 (44.438)	Loss 0.5392 (0.4459)	CeLoss 0.0903 (0.0624)	SegCLSLoss 0.0038 (0.0027)	KLLoss 0.0036 (0.0033)	MaskLoss 0.1284 (0.1091)	MaskBCELoss 0.0351 (0.0287)	MaskDICELoss 0.0933 (0.0803)
Epoch: [0][335/500]	Time 47.098 (47.098)	Loss 0.4297 (0.4667)	CeLoss 0.0276 (0.0569)	SegCLSLoss 0.0123 (0.0076)	KLLoss 0.0042 (0.0035)	MaskLoss 0.1024 (0.1133)	MaskBCELoss 0.0089 (0.0253)	MaskDICELoss 0.0935 (0.0880)
Epoch: [0][336/500]	Time 47.551 (47.551)	Loss 0.2604 (0.4187)	CeLoss 0.0540 (0.0546)	SegCLSLoss 0.0008 (0.0061)	KLLoss 0.0042 (0.0034)	MaskLoss 0.0716 (0.1066)	MaskBCELoss 0.0422 (0.0345)	MaskDICELoss 0.0293 (0.0721)
Epoch: [0][337/500]	Time 48.482 (48.482)	Loss 0.3961 (0.4704)	CeLoss 0.0251 (0.0614)	SegCLSLoss 0.0064 (0.0060)	KLLoss 0.0024 (0.0030)	MaskLoss 0.1098 (0.1107)	MaskBCELoss 0.0369 (0.0200)	MaskDICELoss 0.0729 (0.0908)
Epoch: [0][338/500]	Time 45.556 (45.556)	Loss 0.5146 (0.4142)	CeLoss 0.0303 (0.0481)	SegCLSLoss 0.0164 (0.0044)	KLLoss 0.0026 (0.0038)	MaskLoss 0.1521 (0.1049)	MaskBCELoss 0.0674 (0.0296)	MaskDICELoss 0.0847 (0.0752)
Epoch: [0][339/500]	Time 47.025 (47.025)	Loss 0.6836 (0.4210)	CeLoss 0.0820 (0.0530)	SegCLSLoss 0.0011 (0.0039)	KLLoss 0.0042 (0.0033)	MaskLoss 0.1996 (0.1049)	MaskBCELoss 0.1008 (0.0283)	MaskDICELoss 0.0988 (0.0766)
Epoch: [0][340/500]	Time 46.702 (46.702)	Loss 0.2471 (0.3420)	CeLoss 0.0366 (0.0403)	SegCLSLoss 0.0011 (0.0065)	KLLoss 0.0070 (0.0042)	MaskLoss 0.0550 (0.0847)	MaskBCELoss 0.0085 (0.0223)	MaskDICELoss 0.0465 (0.0624)
Epoch: [0][341/500]	Time 53.262 (53.262)	Loss 0.4631 (0.3951)	CeLoss 0.0520 (0.0496)	SegCLSLoss 0.0019 (0.0020)	KLLoss 0.0013 (0.0025)	MaskLoss 0.1047 (0.0974)	MaskBCELoss 0.0048 (0.0238)	MaskDICELoss 0.0999 (0.0736)
Epoch: [0][342/500]	Time 48.719 (48.719)	Loss 0.5132 (0.3723)	CeLoss 0.0601 (0.0395)	SegCLSLoss 0.0007 (0.0120)	KLLoss 0.0053 (0.0032)	MaskLoss 0.1336 (0.0925)	MaskBCELoss 0.0436 (0.0231)	MaskDICELoss 0.0900 (0.0693)
Epoch: [0][343/500]	Time 40.363 (40.363)	Loss 0.4971 (0.3763)	CeLoss 0.0693 (0.0586)	SegCLSLoss 0.0027 (0.0035)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1172 (0.0897)	MaskBCELoss 0.0228 (0.0229)	MaskDICELoss 0.0944 (0.0668)
Epoch: [0][344/500]	Time 45.632 (45.632)	Loss 0.4513 (0.3077)	CeLoss 0.1147 (0.0513)	SegCLSLoss 0.0087 (0.0061)	KLLoss 0.0040 (0.0035)	MaskLoss 0.1007 (0.0726)	MaskBCELoss 0.0375 (0.0203)	MaskDICELoss 0.0632 (0.0524)
Epoch: [0][345/500]	Time 48.931 (48.931)	Loss 0.4839 (0.4330)	CeLoss 0.0198 (0.0544)	SegCLSLoss 0.0121 (0.0056)	KLLoss 0.0023 (0.0041)	MaskLoss 0.1280 (0.1107)	MaskBCELoss 0.0281 (0.0355)	MaskDICELoss 0.0999 (0.0752)
Epoch: [0][346/500]	Time 47.660 (47.660)	Loss 0.4698 (0.4793)	CeLoss 0.0771 (0.0381)	SegCLSLoss 0.0013 (0.0052)	KLLoss 0.0060 (0.0039)	MaskLoss 0.1179 (0.1258)	MaskBCELoss 0.0429 (0.0341)	MaskDICELoss 0.0750 (0.0916)
Epoch: [0][347/500]	Time 47.457 (47.457)	Loss 0.0196 (0.3970)	CeLoss 0.0197 (0.0456)	SegCLSLoss 0.0000 (0.0025)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.1031)	MaskBCELoss 0.0000 (0.0329)	MaskDICELoss 0.0000 (0.0702)
Epoch: [0][348/500]	Time 48.813 (48.813)	Loss 0.2608 (0.3966)	CeLoss 0.0260 (0.0451)	SegCLSLoss 0.0025 (0.0050)	KLLoss 0.0032 (0.0039)	MaskLoss 0.0635 (0.0972)	MaskBCELoss 0.0119 (0.0218)	MaskDICELoss 0.0517 (0.0754)
Epoch: [0][349/500]	Time 42.955 (42.955)	Loss 0.3712 (0.3855)	CeLoss 0.0248 (0.0534)	SegCLSLoss 0.0167 (0.0109)	KLLoss 0.0048 (0.0035)	MaskLoss 0.0933 (0.0937)	MaskBCELoss 0.0201 (0.0259)	MaskDICELoss 0.0733 (0.0679)
Epoch: [0][350/500]	Time 45.421 (45.421)	Loss 0.3489 (0.4198)	CeLoss 0.0245 (0.0505)	SegCLSLoss 0.0258 (0.0074)	KLLoss 0.0018 (0.0031)	MaskLoss 0.0966 (0.1014)	MaskBCELoss 0.0383 (0.0217)	MaskDICELoss 0.0582 (0.0798)
Epoch: [0][351/500]	Time 47.189 (47.189)	Loss 0.2257 (0.3946)	CeLoss 0.0277 (0.0393)	SegCLSLoss 0.0029 (0.0082)	KLLoss 0.0030 (0.0035)	MaskLoss 0.0496 (0.0960)	MaskBCELoss 0.0025 (0.0182)	MaskDICELoss 0.0471 (0.0778)
Epoch: [0][352/500]	Time 49.171 (49.171)	Loss 0.4443 (0.4319)	CeLoss 0.0303 (0.0427)	SegCLSLoss 0.0016 (0.0045)	KLLoss 0.0049 (0.0032)	MaskLoss 0.1359 (0.1131)	MaskBCELoss 0.0676 (0.0344)	MaskDICELoss 0.0683 (0.0788)
Epoch: [0][353/500]	Time 51.520 (51.520)	Loss 0.8541 (0.4848)	CeLoss 0.0547 (0.0548)	SegCLSLoss 0.0031 (0.0037)	KLLoss 0.0016 (0.0033)	MaskLoss 0.3250 (0.1289)	MaskBCELoss 0.2518 (0.0453)	MaskDICELoss 0.0732 (0.0836)
Epoch: [0][354/500]	Time 42.121 (42.121)	Loss 0.5482 (0.4858)	CeLoss 0.0243 (0.0508)	SegCLSLoss 0.0082 (0.0066)	KLLoss 0.0040 (0.0035)	MaskLoss 0.1592 (0.1312)	MaskBCELoss 0.0604 (0.0483)	MaskDICELoss 0.0987 (0.0829)
Epoch: [0][355/500]	Time 42.635 (42.635)	Loss 0.4473 (0.4276)	CeLoss 0.0850 (0.0606)	SegCLSLoss 0.0011 (0.0071)	KLLoss 0.0016 (0.0035)	MaskLoss 0.1064 (0.0995)	MaskBCELoss 0.0326 (0.0191)	MaskDICELoss 0.0737 (0.0804)
Epoch: [0][356/500]	Time 47.353 (47.353)	Loss 0.3349 (0.4321)	CeLoss 0.0496 (0.0594)	SegCLSLoss 0.0027 (0.0054)	KLLoss 0.0036 (0.0042)	MaskLoss 0.0745 (0.1033)	MaskBCELoss 0.0088 (0.0237)	MaskDICELoss 0.0658 (0.0796)
Epoch: [0][357/500]	Time 47.045 (47.045)	Loss 0.2976 (0.3473)	CeLoss 0.0688 (0.0465)	SegCLSLoss 0.0017 (0.0059)	KLLoss 0.0037 (0.0037)	MaskLoss 0.0753 (0.0850)	MaskBCELoss 0.0384 (0.0228)	MaskDICELoss 0.0368 (0.0621)
Epoch: [0][358/500]	Time 46.278 (46.278)	Loss 0.4595 (0.4191)	CeLoss 0.0432 (0.0453)	SegCLSLoss 0.0016 (0.0033)	KLLoss 0.0015 (0.0028)	MaskLoss 0.1071 (0.1049)	MaskBCELoss 0.0071 (0.0252)	MaskDICELoss 0.1000 (0.0798)
Epoch: [0][359/500]	Time 53.142 (53.142)	Loss 0.5884 (0.4404)	CeLoss 0.0830 (0.0647)	SegCLSLoss 0.0032 (0.0018)	KLLoss 0.0022 (0.0038)	MaskLoss 0.1663 (0.1053)	MaskBCELoss 0.0818 (0.0250)	MaskDICELoss 0.0845 (0.0802)
Epoch: [0][360/500]	Time 46.676 (46.676)	Loss 0.5151 (0.4792)	CeLoss 0.0659 (0.0504)	SegCLSLoss 0.0084 (0.0059)	KLLoss 0.0049 (0.0032)	MaskLoss 0.1202 (0.1381)	MaskBCELoss 0.0204 (0.0649)	MaskDICELoss 0.0998 (0.0732)
Epoch: [0][361/500]	Time 58.641 (58.641)	Loss 0.3428 (0.3199)	CeLoss 0.0654 (0.0494)	SegCLSLoss 0.0045 (0.0028)	KLLoss 0.0028 (0.0033)	MaskLoss 0.0755 (0.0726)	MaskBCELoss 0.0150 (0.0124)	MaskDICELoss 0.0605 (0.0602)
Epoch: [0][362/500]	Time 48.666 (48.666)	Loss 0.4693 (0.3644)	CeLoss 0.0447 (0.0537)	SegCLSLoss 0.0016 (0.0023)	KLLoss 0.0034 (0.0030)	MaskLoss 0.1138 (0.0834)	MaskBCELoss 0.0173 (0.0135)	MaskDICELoss 0.0965 (0.0699)
Epoch: [0][363/500]	Time 48.834 (48.834)	Loss 0.4864 (0.3866)	CeLoss 0.0762 (0.0380)	SegCLSLoss 0.0030 (0.0026)	KLLoss 0.0023 (0.0023)	MaskLoss 0.1040 (0.1012)	MaskBCELoss 0.0047 (0.0299)	MaskDICELoss 0.0992 (0.0713)
Epoch: [0][364/500]	Time 47.591 (47.591)	Loss 0.4961 (0.4156)	CeLoss 0.0581 (0.0540)	SegCLSLoss 0.0011 (0.0019)	KLLoss 0.0012 (0.0037)	MaskLoss 0.1188 (0.1004)	MaskBCELoss 0.0194 (0.0223)	MaskDICELoss 0.0994 (0.0781)
Epoch: [0][365/500]	Time 55.831 (55.831)	Loss 0.2969 (0.3837)	CeLoss 0.0276 (0.0408)	SegCLSLoss 0.0015 (0.0034)	KLLoss 0.0053 (0.0027)	MaskLoss 0.0962 (0.0950)	MaskBCELoss 0.0607 (0.0208)	MaskDICELoss 0.0355 (0.0742)
Epoch: [0][366/500]	Time 43.383 (43.383)	Loss 0.0551 (0.3756)	CeLoss 0.0552 (0.0553)	SegCLSLoss 0.0000 (0.0028)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0866)	MaskBCELoss 0.0000 (0.0153)	MaskDICELoss 0.0000 (0.0713)
Epoch: [0][367/500]	Time 49.425 (49.425)	Loss 0.2469 (0.3188)	CeLoss 0.0266 (0.0461)	SegCLSLoss 0.0205 (0.0048)	KLLoss 0.0029 (0.0029)	MaskLoss 0.0643 (0.0741)	MaskBCELoss 0.0249 (0.0145)	MaskDICELoss 0.0393 (0.0597)
Epoch: [0][368/500]	Time 49.983 (49.983)	Loss 0.4356 (0.3328)	CeLoss 0.0260 (0.0529)	SegCLSLoss 0.0017 (0.0019)	KLLoss 0.0048 (0.0032)	MaskLoss 0.1099 (0.0781)	MaskBCELoss 0.0177 (0.0183)	MaskDICELoss 0.0921 (0.0598)
Epoch: [0][369/500]	Time 49.209 (49.209)	Loss 0.4939 (0.4228)	CeLoss 0.0708 (0.0530)	SegCLSLoss 0.0026 (0.0067)	KLLoss 0.0031 (0.0030)	MaskLoss 0.1170 (0.0983)	MaskBCELoss 0.0245 (0.0149)	MaskDICELoss 0.0925 (0.0834)
Epoch: [0][370/500]	Time 47.802 (47.802)	Loss 0.6858 (0.4466)	CeLoss 0.0522 (0.0570)	SegCLSLoss 0.0010 (0.0041)	KLLoss 0.0037 (0.0036)	MaskLoss 0.2413 (0.1156)	MaskBCELoss 0.1679 (0.0392)	MaskDICELoss 0.0735 (0.0764)
Epoch: [0][371/500]	Time 48.882 (48.882)	Loss 0.4386 (0.3856)	CeLoss 0.0273 (0.0356)	SegCLSLoss 0.0038 (0.0020)	KLLoss 0.0025 (0.0041)	MaskLoss 0.1112 (0.0971)	MaskBCELoss 0.0191 (0.0218)	MaskDICELoss 0.0922 (0.0753)
Epoch: [0][372/500]	Time 54.033 (54.033)	Loss 0.4727 (0.4451)	CeLoss 0.0811 (0.0499)	SegCLSLoss 0.0008 (0.0023)	KLLoss 0.0052 (0.0036)	MaskLoss 0.1355 (0.1170)	MaskBCELoss 0.0779 (0.0388)	MaskDICELoss 0.0575 (0.0782)
Epoch: [0][373/500]	Time 51.105 (51.105)	Loss 0.4840 (0.3748)	CeLoss 0.0515 (0.0463)	SegCLSLoss 0.0024 (0.0032)	KLLoss 0.0033 (0.0024)	MaskLoss 0.1171 (0.0875)	MaskBCELoss 0.0201 (0.0127)	MaskDICELoss 0.0970 (0.0747)
Epoch: [0][374/500]	Time 49.233 (49.233)	Loss 0.0602 (0.3583)	CeLoss 0.0601 (0.0406)	SegCLSLoss 0.0000 (0.0033)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0889)	MaskBCELoss 0.0000 (0.0209)	MaskDICELoss 0.0000 (0.0680)
Epoch: [0][375/500]	Time 45.156 (45.156)	Loss 0.0398 (0.4137)	CeLoss 0.0398 (0.0464)	SegCLSLoss 0.0000 (0.0034)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.1077)	MaskBCELoss 0.0000 (0.0342)	MaskDICELoss 0.0000 (0.0734)
Epoch: [0][376/500]	Time 51.648 (51.648)	Loss 0.4980 (0.4029)	CeLoss 0.0520 (0.0523)	SegCLSLoss 0.0006 (0.0022)	KLLoss 0.0038 (0.0027)	MaskLoss 0.1211 (0.0995)	MaskBCELoss 0.0214 (0.0256)	MaskDICELoss 0.0997 (0.0739)
Epoch: [0][377/500]	Time 52.133 (52.133)	Loss 0.5242 (0.3416)	CeLoss 0.1016 (0.0586)	SegCLSLoss 0.0017 (0.0023)	KLLoss 0.0032 (0.0019)	MaskLoss 0.1114 (0.0789)	MaskBCELoss 0.0135 (0.0179)	MaskDICELoss 0.0979 (0.0610)
Epoch: [0][378/500]	Time 45.513 (45.513)	Loss 0.2690 (0.4331)	CeLoss 0.0238 (0.0479)	SegCLSLoss 0.0029 (0.0054)	KLLoss 0.0036 (0.0032)	MaskLoss 0.0752 (0.1133)	MaskBCELoss 0.0304 (0.0369)	MaskDICELoss 0.0448 (0.0763)
Epoch: [0][379/500]	Time 48.261 (48.261)	Loss 0.0901 (0.2621)	CeLoss 0.0483 (0.0534)	SegCLSLoss 0.0017 (0.0056)	KLLoss 0.0070 (0.0026)	MaskLoss 0.0119 (0.0580)	MaskBCELoss 0.0070 (0.0142)	MaskDICELoss 0.0050 (0.0438)
Epoch: [0][380/500]	Time 44.593 (44.593)	Loss 0.4257 (0.3895)	CeLoss 0.0256 (0.0461)	SegCLSLoss 0.0101 (0.0047)	KLLoss 0.0037 (0.0034)	MaskLoss 0.1213 (0.0945)	MaskBCELoss 0.0469 (0.0202)	MaskDICELoss 0.0744 (0.0743)
Epoch: [0][381/500]	Time 50.186 (50.186)	Loss 0.0508 (0.3210)	CeLoss 0.0508 (0.0567)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0711)	MaskBCELoss 0.0000 (0.0116)	MaskDICELoss 0.0000 (0.0595)
Epoch: [0][382/500]	Time 51.258 (51.258)	Loss 0.5367 (0.4014)	CeLoss 0.0986 (0.0512)	SegCLSLoss 0.0046 (0.0019)	KLLoss 0.0023 (0.0023)	MaskLoss 0.1183 (0.0972)	MaskBCELoss 0.0199 (0.0210)	MaskDICELoss 0.0984 (0.0763)
Epoch: [0][383/500]	Time 54.828 (54.828)	Loss 0.3664 (0.3966)	CeLoss 0.0242 (0.0484)	SegCLSLoss 0.0193 (0.0043)	KLLoss 0.0031 (0.0032)	MaskLoss 0.0873 (0.0976)	MaskBCELoss 0.0098 (0.0237)	MaskDICELoss 0.0775 (0.0738)
Epoch: [0][384/500]	Time 45.661 (45.661)	Loss 0.6374 (0.4614)	CeLoss 0.0610 (0.0395)	SegCLSLoss 0.0010 (0.0062)	KLLoss 0.0054 (0.0038)	MaskLoss 0.1866 (0.1168)	MaskBCELoss 0.0878 (0.0261)	MaskDICELoss 0.0988 (0.0907)
Epoch: [0][385/500]	Time 44.857 (44.857)	Loss 0.4492 (0.4263)	CeLoss 0.0840 (0.0635)	SegCLSLoss 0.0011 (0.0019)	KLLoss 0.0047 (0.0046)	MaskLoss 0.1015 (0.1035)	MaskBCELoss 0.0229 (0.0283)	MaskDICELoss 0.0786 (0.0752)
Epoch: [0][386/500]	Time 50.400 (50.400)	Loss 0.4763 (0.4790)	CeLoss 0.0251 (0.0554)	SegCLSLoss 0.0018 (0.0023)	KLLoss 0.0042 (0.0030)	MaskLoss 0.1237 (0.1162)	MaskBCELoss 0.0245 (0.0226)	MaskDICELoss 0.0993 (0.0936)
Epoch: [0][387/500]	Time 48.995 (48.995)	Loss 0.4825 (0.3827)	CeLoss 0.0579 (0.0448)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0030 (0.0041)	MaskLoss 0.1120 (0.0981)	MaskBCELoss 0.0135 (0.0296)	MaskDICELoss 0.0986 (0.0685)
Epoch: [0][388/500]	Time 46.648 (46.648)	Loss 0.4332 (0.4321)	CeLoss 0.0991 (0.0533)	SegCLSLoss 0.0082 (0.0031)	KLLoss 0.0029 (0.0037)	MaskLoss 0.0908 (0.1124)	MaskBCELoss 0.0181 (0.0381)	MaskDICELoss 0.0727 (0.0743)
Epoch: [0][389/500]	Time 48.114 (48.114)	Loss 0.5128 (0.4123)	CeLoss 0.0752 (0.0652)	SegCLSLoss 0.0012 (0.0040)	KLLoss 0.0029 (0.0028)	MaskLoss 0.1183 (0.0942)	MaskBCELoss 0.0196 (0.0172)	MaskDICELoss 0.0987 (0.0770)
Epoch: [0][390/500]	Time 47.235 (47.235)	Loss 0.4490 (0.4681)	CeLoss 0.0178 (0.0414)	SegCLSLoss 0.0033 (0.0031)	KLLoss 0.0043 (0.0035)	MaskLoss 0.1126 (0.1232)	MaskBCELoss 0.0127 (0.0355)	MaskDICELoss 0.1000 (0.0877)
Epoch: [0][391/500]	Time 49.982 (49.982)	Loss 0.3907 (0.4247)	CeLoss 0.0540 (0.0470)	SegCLSLoss 0.0125 (0.0035)	KLLoss 0.0040 (0.0032)	MaskLoss 0.0953 (0.1081)	MaskBCELoss 0.0272 (0.0297)	MaskDICELoss 0.0681 (0.0784)
Epoch: [0][392/500]	Time 51.968 (51.968)	Loss 0.4889 (0.4397)	CeLoss 0.0264 (0.0413)	SegCLSLoss 0.0020 (0.0036)	KLLoss 0.0035 (0.0031)	MaskLoss 0.1291 (0.1131)	MaskBCELoss 0.0292 (0.0294)	MaskDICELoss 0.0999 (0.0837)
Epoch: [0][393/500]	Time 49.022 (49.022)	Loss 0.4145 (0.4444)	CeLoss 0.0327 (0.0581)	SegCLSLoss 0.0103 (0.0041)	KLLoss 0.0045 (0.0037)	MaskLoss 0.1064 (0.1084)	MaskBCELoss 0.0267 (0.0265)	MaskDICELoss 0.0797 (0.0819)
Epoch: [0][394/500]	Time 43.867 (43.867)	Loss 0.3226 (0.3904)	CeLoss 0.0249 (0.0369)	SegCLSLoss 0.0028 (0.0039)	KLLoss 0.0033 (0.0030)	MaskLoss 0.1033 (0.1034)	MaskBCELoss 0.0602 (0.0325)	MaskDICELoss 0.0431 (0.0709)
Epoch: [0][395/500]	Time 51.568 (51.568)	Loss 0.4175 (0.4655)	CeLoss 0.0894 (0.0592)	SegCLSLoss 0.0014 (0.0020)	KLLoss 0.0022 (0.0028)	MaskLoss 0.0995 (0.1177)	MaskBCELoss 0.0365 (0.0341)	MaskDICELoss 0.0630 (0.0836)
Epoch: [0][396/500]	Time 53.705 (53.705)	Loss 0.4435 (0.3395)	CeLoss 0.0422 (0.0396)	SegCLSLoss 0.0014 (0.0035)	KLLoss 0.0029 (0.0032)	MaskLoss 0.1033 (0.0857)	MaskBCELoss 0.0078 (0.0239)	MaskDICELoss 0.0955 (0.0618)
Epoch: [0][397/500]	Time 45.408 (45.408)	Loss 0.5274 (0.4453)	CeLoss 0.0669 (0.0524)	SegCLSLoss 0.0027 (0.0053)	KLLoss 0.0024 (0.0038)	MaskLoss 0.1427 (0.1062)	MaskBCELoss 0.0568 (0.0193)	MaskDICELoss 0.0859 (0.0870)
Epoch: [0][398/500]	Time 47.492 (47.492)	Loss 0.3916 (0.3630)	CeLoss 0.0209 (0.0431)	SegCLSLoss 0.0036 (0.0020)	KLLoss 0.0015 (0.0028)	MaskLoss 0.1127 (0.0931)	MaskBCELoss 0.0417 (0.0282)	MaskDICELoss 0.0710 (0.0649)
Epoch: [0][399/500]	Time 48.330 (48.330)	Loss 0.4074 (0.3368)	CeLoss 0.0261 (0.0320)	SegCLSLoss 0.0026 (0.0027)	KLLoss 0.0046 (0.0028)	MaskLoss 0.1340 (0.0874)	MaskBCELoss 0.0804 (0.0245)	MaskDICELoss 0.0536 (0.0629)
[2025-03-11 04:23:22,056] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.00029593975903614454], mom=[(0.9, 0.95)]
[2025-03-11 04:23:22,064] [INFO] [timer.py:215:stop] epoch=0/micro_step=400/global_step=40, RunningAvgSamplesPerSec=0.8321922903171052, CurrSamplesPerSec=0.8547312184874459, MemAllocated=59.87GB, MaxMemAllocated=74.15GB
Epoch: [0][400/500]	Time 50.224 (50.224)	Loss 0.5127 (0.4816)	CeLoss 0.0645 (0.0653)	SegCLSLoss 0.0009 (0.0019)	KLLoss 0.0031 (0.0035)	MaskLoss 0.1506 (0.1184)	MaskBCELoss 0.0789 (0.0308)	MaskDICELoss 0.0718 (0.0876)
Epoch: [0][401/500]	Time 48.059 (48.059)	Loss 0.0984 (0.4055)	CeLoss 0.0986 (0.0599)	SegCLSLoss 0.0000 (0.0032)	KLLoss 0.0000 (0.0025)	MaskLoss 0.0000 (0.0954)	MaskBCELoss 0.0000 (0.0201)	MaskDICELoss 0.0000 (0.0753)
Epoch: [0][402/500]	Time 45.985 (45.985)	Loss 0.4959 (0.3777)	CeLoss 0.0854 (0.0601)	SegCLSLoss 0.0039 (0.0023)	KLLoss 0.0025 (0.0035)	MaskLoss 0.1093 (0.0881)	MaskBCELoss 0.0156 (0.0198)	MaskDICELoss 0.0937 (0.0683)
Epoch: [0][403/500]	Time 47.464 (47.464)	Loss 0.4663 (0.4103)	CeLoss 0.0297 (0.0334)	SegCLSLoss 0.0043 (0.0076)	KLLoss 0.0026 (0.0032)	MaskLoss 0.1301 (0.1049)	MaskBCELoss 0.0443 (0.0249)	MaskDICELoss 0.0859 (0.0800)
Epoch: [0][404/500]	Time 41.689 (41.689)	Loss 0.5139 (0.4289)	CeLoss 0.0869 (0.0566)	SegCLSLoss 0.0033 (0.0060)	KLLoss 0.0063 (0.0039)	MaskLoss 0.1108 (0.1012)	MaskBCELoss 0.0121 (0.0196)	MaskDICELoss 0.0987 (0.0816)
Epoch: [0][405/500]	Time 45.496 (45.496)	Loss 0.5039 (0.4250)	CeLoss 0.0659 (0.0419)	SegCLSLoss 0.0049 (0.0044)	KLLoss 0.0027 (0.0026)	MaskLoss 0.1186 (0.1069)	MaskBCELoss 0.0207 (0.0247)	MaskDICELoss 0.0978 (0.0822)
Epoch: [0][406/500]	Time 49.810 (49.810)	Loss 0.4358 (0.4833)	CeLoss 0.0242 (0.0504)	SegCLSLoss 0.0054 (0.0028)	KLLoss 0.0035 (0.0031)	MaskLoss 0.1043 (0.1201)	MaskBCELoss 0.0059 (0.0260)	MaskDICELoss 0.0984 (0.0941)
Epoch: [0][407/500]	Time 48.021 (48.021)	Loss 0.4905 (0.4633)	CeLoss 0.0491 (0.0490)	SegCLSLoss 0.0016 (0.0026)	KLLoss 0.0042 (0.0029)	MaskLoss 0.1215 (0.1151)	MaskBCELoss 0.0248 (0.0250)	MaskDICELoss 0.0968 (0.0900)
Epoch: [0][408/500]	Time 50.972 (50.972)	Loss 0.4489 (0.3479)	CeLoss 0.0698 (0.0427)	SegCLSLoss 0.0007 (0.0022)	KLLoss 0.0039 (0.0031)	MaskLoss 0.0978 (0.0870)	MaskBCELoss 0.0083 (0.0235)	MaskDICELoss 0.0895 (0.0635)
Epoch: [0][409/500]	Time 47.929 (47.929)	Loss 0.5022 (0.3900)	CeLoss 0.0752 (0.0582)	SegCLSLoss 0.0011 (0.0031)	KLLoss 0.0035 (0.0025)	MaskLoss 0.1123 (0.0945)	MaskBCELoss 0.0131 (0.0252)	MaskDICELoss 0.0992 (0.0694)
Epoch: [0][410/500]	Time 55.257 (55.257)	Loss 0.4596 (0.3776)	CeLoss 0.0270 (0.0493)	SegCLSLoss 0.0017 (0.0012)	KLLoss 0.0033 (0.0031)	MaskLoss 0.1143 (0.0910)	MaskBCELoss 0.0143 (0.0197)	MaskDICELoss 0.1000 (0.0713)
Epoch: [0][411/500]	Time 47.046 (47.046)	Loss 0.2195 (0.3511)	CeLoss 0.0264 (0.0339)	SegCLSLoss 0.0018 (0.0023)	KLLoss 0.0045 (0.0024)	MaskLoss 0.0652 (0.0934)	MaskBCELoss 0.0366 (0.0299)	MaskDICELoss 0.0286 (0.0635)
Epoch: [0][412/500]	Time 46.163 (46.163)	Loss 0.3700 (0.4104)	CeLoss 0.0830 (0.0618)	SegCLSLoss 0.0019 (0.0025)	KLLoss 0.0032 (0.0032)	MaskLoss 0.0880 (0.1021)	MaskBCELoss 0.0346 (0.0321)	MaskDICELoss 0.0534 (0.0700)
Epoch: [0][413/500]	Time 49.901 (49.901)	Loss 0.3833 (0.3870)	CeLoss 0.0679 (0.0599)	SegCLSLoss 0.0020 (0.0022)	KLLoss 0.0033 (0.0029)	MaskLoss 0.0832 (0.0899)	MaskBCELoss 0.0108 (0.0182)	MaskDICELoss 0.0723 (0.0717)
Epoch: [0][414/500]	Time 42.980 (42.980)	Loss 0.4252 (0.4799)	CeLoss 0.0562 (0.0601)	SegCLSLoss 0.0026 (0.0031)	KLLoss 0.0042 (0.0037)	MaskLoss 0.0932 (0.1153)	MaskBCELoss 0.0046 (0.0233)	MaskDICELoss 0.0886 (0.0920)
Epoch: [0][415/500]	Time 49.427 (49.427)	Loss 0.2183 (0.4077)	CeLoss 0.0669 (0.0584)	SegCLSLoss 0.0020 (0.0016)	KLLoss 0.0013 (0.0026)	MaskLoss 0.0426 (0.0958)	MaskBCELoss 0.0106 (0.0186)	MaskDICELoss 0.0320 (0.0772)
Epoch: [0][416/500]	Time 46.977 (46.977)	Loss 0.4796 (0.4690)	CeLoss 0.0223 (0.0445)	SegCLSLoss 0.0044 (0.0024)	KLLoss 0.0014 (0.0033)	MaskLoss 0.1278 (0.1203)	MaskBCELoss 0.0288 (0.0306)	MaskDICELoss 0.0990 (0.0897)
Epoch: [0][417/500]	Time 44.927 (44.927)	Loss 0.2418 (0.3955)	CeLoss 0.0286 (0.0394)	SegCLSLoss 0.0035 (0.0024)	KLLoss 0.0026 (0.0031)	MaskLoss 0.0588 (0.0998)	MaskBCELoss 0.0132 (0.0237)	MaskDICELoss 0.0456 (0.0761)
Epoch: [0][418/500]	Time 50.033 (50.033)	Loss 0.0781 (0.3776)	CeLoss 0.0781 (0.0629)	SegCLSLoss 0.0000 (0.0035)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0856)	MaskBCELoss 0.0000 (0.0160)	MaskDICELoss 0.0000 (0.0696)
Epoch: [0][419/500]	Time 47.691 (47.691)	Loss 0.4638 (0.3564)	CeLoss 0.0527 (0.0420)	SegCLSLoss 0.0005 (0.0027)	KLLoss 0.0018 (0.0023)	MaskLoss 0.1057 (0.0921)	MaskBCELoss 0.0071 (0.0288)	MaskDICELoss 0.0986 (0.0633)
Epoch: [0][420/500]	Time 52.006 (52.006)	Loss 0.4375 (0.4351)	CeLoss 0.0854 (0.0616)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0033 (0.0020)	MaskLoss 0.0968 (0.1050)	MaskBCELoss 0.0198 (0.0247)	MaskDICELoss 0.0770 (0.0803)
Epoch: [0][421/500]	Time 48.751 (48.751)	Loss 0.4651 (0.3495)	CeLoss 0.0581 (0.0454)	SegCLSLoss 0.0006 (0.0022)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1317 (0.0893)	MaskBCELoss 0.0617 (0.0286)	MaskDICELoss 0.0700 (0.0607)
Epoch: [0][422/500]	Time 45.521 (45.521)	Loss 0.2670 (0.3718)	CeLoss 0.0214 (0.0422)	SegCLSLoss 0.0148 (0.0037)	KLLoss 0.0034 (0.0032)	MaskLoss 0.0732 (0.0980)	MaskBCELoss 0.0292 (0.0337)	MaskDICELoss 0.0440 (0.0643)
Epoch: [0][423/500]	Time 45.729 (45.729)	Loss 0.1639 (0.3356)	CeLoss 0.0184 (0.0465)	SegCLSLoss 0.0019 (0.0019)	KLLoss 0.0033 (0.0028)	MaskLoss 0.0423 (0.0850)	MaskBCELoss 0.0141 (0.0273)	MaskDICELoss 0.0282 (0.0577)
Epoch: [0][424/500]	Time 51.049 (51.049)	Loss 0.4797 (0.3528)	CeLoss 0.0613 (0.0570)	SegCLSLoss 0.0023 (0.0012)	KLLoss 0.0019 (0.0023)	MaskLoss 0.1076 (0.0810)	MaskBCELoss 0.0077 (0.0156)	MaskDICELoss 0.1000 (0.0655)
Epoch: [0][425/500]	Time 48.667 (48.667)	Loss 0.5304 (0.4403)	CeLoss 0.0698 (0.0424)	SegCLSLoss 0.0007 (0.0039)	KLLoss 0.0020 (0.0039)	MaskLoss 0.1312 (0.1107)	MaskBCELoss 0.0333 (0.0253)	MaskDICELoss 0.0979 (0.0854)
Epoch: [0][426/500]	Time 49.470 (49.470)	Loss 0.0490 (0.3946)	CeLoss 0.0491 (0.0449)	SegCLSLoss 0.0000 (0.0023)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0948)	MaskBCELoss 0.0000 (0.0165)	MaskDICELoss 0.0000 (0.0783)
Epoch: [0][427/500]	Time 46.145 (46.145)	Loss 0.5239 (0.3811)	CeLoss 0.1064 (0.0547)	SegCLSLoss 0.0051 (0.0028)	KLLoss 0.0033 (0.0033)	MaskLoss 0.1061 (0.0870)	MaskBCELoss 0.0061 (0.0131)	MaskDICELoss 0.1000 (0.0739)
Epoch: [0][428/500]	Time 42.820 (42.820)	Loss 0.4996 (0.3330)	CeLoss 0.0869 (0.0491)	SegCLSLoss 0.0007 (0.0031)	KLLoss 0.0036 (0.0024)	MaskLoss 0.1050 (0.0791)	MaskBCELoss 0.0056 (0.0183)	MaskDICELoss 0.0994 (0.0609)
Epoch: [0][429/500]	Time 51.527 (51.527)	Loss 0.0434 (0.3060)	CeLoss 0.0435 (0.0428)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0017)	MaskLoss 0.0000 (0.0746)	MaskBCELoss 0.0000 (0.0189)	MaskDICELoss 0.0000 (0.0557)
Epoch: [0][430/500]	Time 54.518 (54.518)	Loss 0.2667 (0.3955)	CeLoss 0.0281 (0.0355)	SegCLSLoss 0.0021 (0.0018)	KLLoss 0.0025 (0.0032)	MaskLoss 0.0726 (0.1087)	MaskBCELoss 0.0277 (0.0394)	MaskDICELoss 0.0449 (0.0693)
Epoch: [0][431/500]	Time 53.566 (53.566)	Loss 0.4371 (0.4249)	CeLoss 0.0249 (0.0490)	SegCLSLoss 0.0045 (0.0020)	KLLoss 0.0012 (0.0026)	MaskLoss 0.1044 (0.1047)	MaskBCELoss 0.0044 (0.0232)	MaskDICELoss 0.1000 (0.0815)
Epoch: [0][432/500]	Time 55.813 (55.813)	Loss 0.5003 (0.4618)	CeLoss 0.0815 (0.0444)	SegCLSLoss 0.0014 (0.0020)	KLLoss 0.0019 (0.0023)	MaskLoss 0.1079 (0.1270)	MaskBCELoss 0.0080 (0.0470)	MaskDICELoss 0.1000 (0.0800)
Epoch: [0][433/500]	Time 42.617 (42.617)	Loss 0.3781 (0.3692)	CeLoss 0.0283 (0.0606)	SegCLSLoss 0.0019 (0.0022)	KLLoss 0.0031 (0.0016)	MaskLoss 0.0900 (0.0852)	MaskBCELoss 0.0072 (0.0176)	MaskDICELoss 0.0828 (0.0677)
Epoch: [0][434/500]	Time 49.744 (49.744)	Loss 0.4619 (0.4902)	CeLoss 0.0183 (0.0359)	SegCLSLoss 0.0025 (0.0038)	KLLoss 0.0017 (0.0029)	MaskLoss 0.1242 (0.1304)	MaskBCELoss 0.0282 (0.0361)	MaskDICELoss 0.0961 (0.0943)
Epoch: [0][435/500]	Time 48.375 (48.375)	Loss 0.3895 (0.4176)	CeLoss 0.0579 (0.0401)	SegCLSLoss 0.0012 (0.0035)	KLLoss 0.0009 (0.0033)	MaskLoss 0.0856 (0.1055)	MaskBCELoss 0.0060 (0.0249)	MaskDICELoss 0.0796 (0.0807)
Epoch: [0][436/500]	Time 49.456 (49.456)	Loss 0.4931 (0.4143)	CeLoss 0.0703 (0.0468)	SegCLSLoss 0.0009 (0.0025)	KLLoss 0.0038 (0.0030)	MaskLoss 0.1130 (0.1024)	MaskBCELoss 0.0168 (0.0232)	MaskDICELoss 0.0963 (0.0792)
Epoch: [0][437/500]	Time 47.641 (47.641)	Loss 0.4309 (0.3683)	CeLoss 0.0249 (0.0455)	SegCLSLoss 0.0018 (0.0023)	KLLoss 0.0028 (0.0023)	MaskLoss 0.1122 (0.0921)	MaskBCELoss 0.0233 (0.0245)	MaskDICELoss 0.0890 (0.0676)
Epoch: [0][438/500]	Time 47.516 (47.516)	Loss 0.2935 (0.4353)	CeLoss 0.0610 (0.0571)	SegCLSLoss 0.0018 (0.0021)	KLLoss 0.0020 (0.0032)	MaskLoss 0.0682 (0.1055)	MaskBCELoss 0.0215 (0.0240)	MaskDICELoss 0.0467 (0.0815)
Epoch: [0][439/500]	Time 49.506 (49.506)	Loss 0.5092 (0.3686)	CeLoss 0.0566 (0.0497)	SegCLSLoss 0.0015 (0.0022)	KLLoss 0.0037 (0.0025)	MaskLoss 0.1374 (0.0933)	MaskBCELoss 0.0506 (0.0290)	MaskDICELoss 0.0868 (0.0643)
Epoch: [0][440/500]	Time 46.533 (46.533)	Loss 0.4380 (0.4274)	CeLoss 0.0247 (0.0437)	SegCLSLoss 0.0016 (0.0024)	KLLoss 0.0033 (0.0033)	MaskLoss 0.1046 (0.1048)	MaskBCELoss 0.0047 (0.0200)	MaskDICELoss 0.1000 (0.0848)
Epoch: [0][441/500]	Time 44.655 (44.655)	Loss 0.4357 (0.3752)	CeLoss 0.0574 (0.0504)	SegCLSLoss 0.0007 (0.0030)	KLLoss 0.0020 (0.0025)	MaskLoss 0.1033 (0.0931)	MaskBCELoss 0.0185 (0.0259)	MaskDICELoss 0.0847 (0.0673)
Epoch: [0][442/500]	Time 52.350 (52.350)	Loss 0.3715 (0.3607)	CeLoss 0.0491 (0.0423)	SegCLSLoss 0.0009 (0.0020)	KLLoss 0.0029 (0.0022)	MaskLoss 0.1083 (0.0955)	MaskBCELoss 0.0570 (0.0334)	MaskDICELoss 0.0513 (0.0621)
Epoch: [0][443/500]	Time 53.255 (53.255)	Loss 0.0179 (0.3480)	CeLoss 0.0178 (0.0420)	SegCLSLoss 0.0000 (0.0019)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0827)	MaskBCELoss 0.0000 (0.0142)	MaskDICELoss 0.0000 (0.0686)
Epoch: [0][444/500]	Time 46.509 (46.509)	Loss 0.1393 (0.3722)	CeLoss 0.0674 (0.0600)	SegCLSLoss 0.0006 (0.0019)	KLLoss 0.0030 (0.0030)	MaskLoss 0.0231 (0.0856)	MaskBCELoss 0.0122 (0.0171)	MaskDICELoss 0.0110 (0.0685)
Epoch: [0][445/500]	Time 46.964 (46.964)	Loss 0.3384 (0.3706)	CeLoss 0.0256 (0.0438)	SegCLSLoss 0.0041 (0.0026)	KLLoss 0.0031 (0.0025)	MaskLoss 0.0849 (0.0972)	MaskBCELoss 0.0159 (0.0330)	MaskDICELoss 0.0690 (0.0642)
Epoch: [0][446/500]	Time 45.799 (45.799)	Loss 0.3341 (0.3883)	CeLoss 0.0283 (0.0489)	SegCLSLoss 0.0034 (0.0023)	KLLoss 0.0023 (0.0028)	MaskLoss 0.0989 (0.1013)	MaskBCELoss 0.0470 (0.0349)	MaskDICELoss 0.0519 (0.0664)
Epoch: [0][447/500]	Time 44.733 (44.733)	Loss 0.5276 (0.4660)	CeLoss 0.0737 (0.0450)	SegCLSLoss 0.0050 (0.0053)	KLLoss 0.0027 (0.0024)	MaskLoss 0.1335 (0.1345)	MaskBCELoss 0.0427 (0.0611)	MaskDICELoss 0.0908 (0.0734)
Epoch: [0][448/500]	Time 45.415 (45.415)	Loss 0.4894 (0.3994)	CeLoss 0.0830 (0.0613)	SegCLSLoss 0.0009 (0.0020)	KLLoss 0.0032 (0.0026)	MaskLoss 0.1019 (0.0983)	MaskBCELoss 0.0023 (0.0293)	MaskDICELoss 0.0996 (0.0690)
Epoch: [0][449/500]	Time 48.439 (48.439)	Loss 0.0264 (0.3361)	CeLoss 0.0264 (0.0411)	SegCLSLoss 0.0000 (0.0036)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0792)	MaskBCELoss 0.0000 (0.0128)	MaskDICELoss 0.0000 (0.0665)
Epoch: [0][450/500]	Time 51.896 (51.896)	Loss 0.5192 (0.4508)	CeLoss 0.0630 (0.0524)	SegCLSLoss 0.0005 (0.0022)	KLLoss 0.0027 (0.0024)	MaskLoss 0.1266 (0.1062)	MaskBCELoss 0.0267 (0.0150)	MaskDICELoss 0.1000 (0.0912)
Epoch: [0][451/500]	Time 46.628 (46.628)	Loss 0.4506 (0.4710)	CeLoss 0.0698 (0.0565)	SegCLSLoss 0.0025 (0.0024)	KLLoss 0.0038 (0.0026)	MaskLoss 0.1398 (0.1243)	MaskBCELoss 0.0918 (0.0432)	MaskDICELoss 0.0480 (0.0811)
Epoch: [0][452/500]	Time 43.781 (43.781)	Loss 0.3181 (0.3697)	CeLoss 0.0248 (0.0475)	SegCLSLoss 0.0208 (0.0041)	KLLoss 0.0029 (0.0027)	MaskLoss 0.0811 (0.0860)	MaskBCELoss 0.0222 (0.0132)	MaskDICELoss 0.0589 (0.0728)
Epoch: [0][453/500]	Time 50.170 (50.170)	Loss 0.3944 (0.4183)	CeLoss 0.0425 (0.0469)	SegCLSLoss 0.0026 (0.0027)	KLLoss 0.0017 (0.0026)	MaskLoss 0.0908 (0.1036)	MaskBCELoss 0.0072 (0.0235)	MaskDICELoss 0.0836 (0.0801)
Epoch: [0][454/500]	Time 47.458 (47.458)	Loss 0.2518 (0.4126)	CeLoss 0.0261 (0.0415)	SegCLSLoss 0.0025 (0.0030)	KLLoss 0.0038 (0.0029)	MaskLoss 0.0659 (0.1048)	MaskBCELoss 0.0215 (0.0262)	MaskDICELoss 0.0444 (0.0786)
Epoch: [0][455/500]	Time 47.935 (47.935)	Loss 0.4415 (0.3692)	CeLoss 0.0256 (0.0332)	SegCLSLoss 0.0036 (0.0023)	KLLoss 0.0019 (0.0023)	MaskLoss 0.1148 (0.0936)	MaskBCELoss 0.0235 (0.0210)	MaskDICELoss 0.0913 (0.0727)
Epoch: [0][456/500]	Time 50.011 (50.011)	Loss 0.3426 (0.3826)	CeLoss 0.0635 (0.0358)	SegCLSLoss 0.0017 (0.0033)	KLLoss 0.0039 (0.0030)	MaskLoss 0.0814 (0.0998)	MaskBCELoss 0.0255 (0.0285)	MaskDICELoss 0.0559 (0.0713)
Epoch: [0][457/500]	Time 51.047 (51.047)	Loss 0.4922 (0.4400)	CeLoss 0.0459 (0.0484)	SegCLSLoss 0.0009 (0.0021)	KLLoss 0.0018 (0.0024)	MaskLoss 0.1565 (0.1227)	MaskBCELoss 0.0910 (0.0513)	MaskDICELoss 0.0656 (0.0714)
Epoch: [0][458/500]	Time 48.790 (48.790)	Loss 0.4431 (0.4269)	CeLoss 0.0500 (0.0483)	SegCLSLoss 0.0009 (0.0020)	KLLoss 0.0018 (0.0023)	MaskLoss 0.0995 (0.1072)	MaskBCELoss 0.0036 (0.0268)	MaskDICELoss 0.0959 (0.0804)
Epoch: [0][459/500]	Time 41.647 (41.647)	Loss 0.4727 (0.3576)	CeLoss 0.0496 (0.0540)	SegCLSLoss 0.0034 (0.0020)	KLLoss 0.0027 (0.0020)	MaskLoss 0.1146 (0.0843)	MaskBCELoss 0.0197 (0.0182)	MaskDICELoss 0.0948 (0.0661)
Epoch: [0][460/500]	Time 50.155 (50.155)	Loss 0.3679 (0.3410)	CeLoss 0.0245 (0.0440)	SegCLSLoss 0.0052 (0.0023)	KLLoss 0.0030 (0.0024)	MaskLoss 0.0948 (0.0827)	MaskBCELoss 0.0206 (0.0187)	MaskDICELoss 0.0741 (0.0640)
Epoch: [0][461/500]	Time 50.762 (50.762)	Loss 0.0641 (0.3533)	CeLoss 0.0640 (0.0598)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0029)	MaskLoss 0.0000 (0.0797)	MaskBCELoss 0.0000 (0.0145)	MaskDICELoss 0.0000 (0.0652)
Epoch: [0][462/500]	Time 48.508 (48.508)	Loss 0.4511 (0.4100)	CeLoss 0.0898 (0.0488)	SegCLSLoss 0.0015 (0.0032)	KLLoss 0.0028 (0.0022)	MaskLoss 0.1024 (0.0993)	MaskBCELoss 0.0259 (0.0200)	MaskDICELoss 0.0765 (0.0793)
Epoch: [0][463/500]	Time 47.981 (47.981)	Loss 0.4766 (0.4025)	CeLoss 0.0574 (0.0385)	SegCLSLoss 0.0006 (0.0039)	KLLoss 0.0024 (0.0024)	MaskLoss 0.1221 (0.0998)	MaskBCELoss 0.0360 (0.0198)	MaskDICELoss 0.0861 (0.0800)
Epoch: [0][464/500]	Time 47.074 (47.074)	Loss 0.4576 (0.4156)	CeLoss 0.0240 (0.0509)	SegCLSLoss 0.0039 (0.0025)	KLLoss 0.0033 (0.0029)	MaskLoss 0.1142 (0.1027)	MaskBCELoss 0.0143 (0.0251)	MaskDICELoss 0.0999 (0.0776)
Epoch: [0][465/500]	Time 48.121 (48.121)	Loss 0.4659 (0.3913)	CeLoss 0.0542 (0.0463)	SegCLSLoss 0.0016 (0.0021)	KLLoss 0.0033 (0.0031)	MaskLoss 0.1190 (0.0994)	MaskBCELoss 0.0343 (0.0283)	MaskDICELoss 0.0847 (0.0711)
Epoch: [0][466/500]	Time 46.139 (46.139)	Loss 0.4774 (0.4274)	CeLoss 0.0540 (0.0365)	SegCLSLoss 0.0034 (0.0041)	KLLoss 0.0030 (0.0027)	MaskLoss 0.1160 (0.1075)	MaskBCELoss 0.0226 (0.0219)	MaskDICELoss 0.0934 (0.0856)
Epoch: [0][467/500]	Time 48.939 (48.939)	Loss 0.4848 (0.4172)	CeLoss 0.0254 (0.0455)	SegCLSLoss 0.0074 (0.0017)	KLLoss 0.0035 (0.0023)	MaskLoss 0.1339 (0.1018)	MaskBCELoss 0.0417 (0.0192)	MaskDICELoss 0.0922 (0.0826)
Epoch: [0][468/500]	Time 46.763 (46.763)	Loss 0.4989 (0.4171)	CeLoss 0.0923 (0.0550)	SegCLSLoss 0.0011 (0.0019)	KLLoss 0.0006 (0.0026)	MaskLoss 0.1057 (0.1033)	MaskBCELoss 0.0084 (0.0273)	MaskDICELoss 0.0973 (0.0760)
Epoch: [0][469/500]	Time 48.529 (48.529)	Loss 0.4482 (0.3817)	CeLoss 0.0249 (0.0492)	SegCLSLoss 0.0030 (0.0020)	KLLoss 0.0037 (0.0025)	MaskLoss 0.1094 (0.0909)	MaskBCELoss 0.0097 (0.0174)	MaskDICELoss 0.0997 (0.0735)
Epoch: [0][470/500]	Time 54.137 (54.137)	Loss 0.4559 (0.4382)	CeLoss 0.0452 (0.0432)	SegCLSLoss 0.0008 (0.0022)	KLLoss 0.0018 (0.0029)	MaskLoss 0.1086 (0.1096)	MaskBCELoss 0.0129 (0.0236)	MaskDICELoss 0.0957 (0.0860)
Epoch: [0][471/500]	Time 49.493 (49.493)	Loss 0.4974 (0.4428)	CeLoss 0.0552 (0.0453)	SegCLSLoss 0.0010 (0.0021)	KLLoss 0.0030 (0.0026)	MaskLoss 0.1344 (0.1121)	MaskBCELoss 0.0494 (0.0271)	MaskDICELoss 0.0850 (0.0849)
Epoch: [0][472/500]	Time 46.247 (46.247)	Loss 0.3383 (0.4457)	CeLoss 0.0442 (0.0471)	SegCLSLoss 0.0045 (0.0026)	KLLoss 0.0025 (0.0020)	MaskLoss 0.0985 (0.1098)	MaskBCELoss 0.0524 (0.0219)	MaskDICELoss 0.0461 (0.0879)
Epoch: [0][473/500]	Time 47.227 (47.227)	Loss 0.0911 (0.3236)	CeLoss 0.0496 (0.0502)	SegCLSLoss 0.0011 (0.0018)	KLLoss 0.0033 (0.0019)	MaskLoss 0.0116 (0.0757)	MaskBCELoss 0.0042 (0.0161)	MaskDICELoss 0.0074 (0.0596)
Epoch: [0][474/500]	Time 46.486 (46.486)	Loss 0.3047 (0.4002)	CeLoss 0.0830 (0.0617)	SegCLSLoss 0.0019 (0.0017)	KLLoss 0.0040 (0.0025)	MaskLoss 0.0639 (0.0927)	MaskBCELoss 0.0194 (0.0179)	MaskDICELoss 0.0445 (0.0749)
Epoch: [0][475/500]	Time 50.495 (50.495)	Loss 0.2975 (0.3865)	CeLoss 0.0233 (0.0485)	SegCLSLoss 0.0041 (0.0026)	KLLoss 0.0023 (0.0020)	MaskLoss 0.0801 (0.0914)	MaskBCELoss 0.0253 (0.0156)	MaskDICELoss 0.0548 (0.0759)
Epoch: [0][476/500]	Time 52.883 (52.883)	Loss 0.3367 (0.4262)	CeLoss 0.0256 (0.0472)	SegCLSLoss 0.0100 (0.0028)	KLLoss 0.0041 (0.0029)	MaskLoss 0.0812 (0.1110)	MaskBCELoss 0.0114 (0.0347)	MaskDICELoss 0.0698 (0.0763)
Epoch: [0][477/500]	Time 45.123 (45.123)	Loss 0.4524 (0.4293)	CeLoss 0.0271 (0.0404)	SegCLSLoss 0.0054 (0.0049)	KLLoss 0.0049 (0.0034)	MaskLoss 0.1098 (0.1105)	MaskBCELoss 0.0108 (0.0295)	MaskDICELoss 0.0990 (0.0810)
Epoch: [0][478/500]	Time 44.813 (44.813)	Loss 0.4104 (0.4107)	CeLoss 0.0198 (0.0426)	SegCLSLoss 0.0022 (0.0021)	KLLoss 0.0031 (0.0029)	MaskLoss 0.1078 (0.1021)	MaskBCELoss 0.0224 (0.0220)	MaskDICELoss 0.0854 (0.0800)
Epoch: [0][479/500]	Time 48.215 (48.215)	Loss 0.3562 (0.4514)	CeLoss 0.0562 (0.0567)	SegCLSLoss 0.0020 (0.0019)	KLLoss 0.0016 (0.0026)	MaskLoss 0.0881 (0.1153)	MaskBCELoss 0.0277 (0.0350)	MaskDICELoss 0.0605 (0.0803)
Epoch: [0][480/500]	Time 51.438 (51.438)	Loss 0.2974 (0.4560)	CeLoss 0.0757 (0.0562)	SegCLSLoss 0.0005 (0.0019)	KLLoss 0.0023 (0.0030)	MaskLoss 0.0615 (0.1086)	MaskBCELoss 0.0135 (0.0192)	MaskDICELoss 0.0479 (0.0894)
Epoch: [0][481/500]	Time 43.463 (43.463)	Loss 0.4041 (0.4069)	CeLoss 0.0708 (0.0482)	SegCLSLoss 0.0034 (0.0019)	KLLoss 0.0022 (0.0022)	MaskLoss 0.0887 (0.0951)	MaskBCELoss 0.0126 (0.0124)	MaskDICELoss 0.0761 (0.0827)
Epoch: [0][482/500]	Time 45.913 (45.913)	Loss 0.4869 (0.4046)	CeLoss 0.0581 (0.0561)	SegCLSLoss 0.0014 (0.0015)	KLLoss 0.0052 (0.0031)	MaskLoss 0.1116 (0.0950)	MaskBCELoss 0.0119 (0.0176)	MaskDICELoss 0.0998 (0.0774)
Epoch: [0][483/500]	Time 46.093 (46.093)	Loss 0.0527 (0.2893)	CeLoss 0.0527 (0.0503)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0653)	MaskBCELoss 0.0000 (0.0125)	MaskDICELoss 0.0000 (0.0528)
Epoch: [0][484/500]	Time 49.902 (49.902)	Loss 0.1640 (0.3765)	CeLoss 0.0713 (0.0501)	SegCLSLoss 0.0006 (0.0014)	KLLoss 0.0031 (0.0027)	MaskLoss 0.0289 (0.0913)	MaskBCELoss 0.0133 (0.0210)	MaskDICELoss 0.0156 (0.0703)
Epoch: [0][485/500]	Time 47.506 (47.506)	Loss 0.5330 (0.3770)	CeLoss 0.0859 (0.0547)	SegCLSLoss 0.0011 (0.0022)	KLLoss 0.0019 (0.0025)	MaskLoss 0.1510 (0.0937)	MaskBCELoss 0.0797 (0.0280)	MaskDICELoss 0.0713 (0.0657)
Epoch: [0][486/500]	Time 46.878 (46.878)	Loss 0.4642 (0.3485)	CeLoss 0.0645 (0.0610)	SegCLSLoss 0.0073 (0.0016)	KLLoss 0.0033 (0.0026)	MaskLoss 0.1088 (0.0809)	MaskBCELoss 0.0210 (0.0198)	MaskDICELoss 0.0878 (0.0611)
Epoch: [0][487/500]	Time 49.440 (49.440)	Loss 0.3347 (0.3885)	CeLoss 0.0171 (0.0374)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0024 (0.0024)	MaskLoss 0.0868 (0.1065)	MaskBCELoss 0.0162 (0.0390)	MaskDICELoss 0.0706 (0.0675)
Epoch: [0][488/500]	Time 47.571 (47.571)	Loss 0.3254 (0.4320)	CeLoss 0.0223 (0.0523)	SegCLSLoss 0.0023 (0.0013)	KLLoss 0.0033 (0.0026)	MaskLoss 0.0927 (0.1058)	MaskBCELoss 0.0361 (0.0234)	MaskDICELoss 0.0566 (0.0824)
Epoch: [0][489/500]	Time 45.520 (45.520)	Loss 0.3845 (0.4382)	CeLoss 0.0228 (0.0244)	SegCLSLoss 0.0014 (0.0030)	KLLoss 0.0034 (0.0026)	MaskLoss 0.0945 (0.1187)	MaskBCELoss 0.0102 (0.0325)	MaskDICELoss 0.0843 (0.0862)
Epoch: [0][490/500]	Time 44.151 (44.151)	Loss 0.2599 (0.4493)	CeLoss 0.0303 (0.0696)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0008 (0.0024)	MaskLoss 0.0643 (0.1104)	MaskBCELoss 0.0144 (0.0325)	MaskDICELoss 0.0499 (0.0779)
Epoch: [0][491/500]	Time 51.883 (51.883)	Loss 0.4806 (0.2725)	CeLoss 0.0574 (0.0443)	SegCLSLoss 0.0010 (0.0005)	KLLoss 0.0022 (0.0019)	MaskLoss 0.1103 (0.0636)	MaskBCELoss 0.0105 (0.0142)	MaskDICELoss 0.0999 (0.0494)
Epoch: [0][492/500]	Time 47.890 (47.890)	Loss 0.4360 (0.4532)	CeLoss 0.0228 (0.0509)	SegCLSLoss 0.0046 (0.0022)	KLLoss 0.0030 (0.0026)	MaskLoss 0.1040 (0.1099)	MaskBCELoss 0.0040 (0.0205)	MaskDICELoss 0.1000 (0.0894)
Epoch: [0][493/500]	Time 49.616 (49.616)	Loss 0.4234 (0.4051)	CeLoss 0.0250 (0.0330)	SegCLSLoss 0.0078 (0.0033)	KLLoss 0.0022 (0.0030)	MaskLoss 0.1099 (0.1022)	MaskBCELoss 0.0237 (0.0207)	MaskDICELoss 0.0862 (0.0815)
Epoch: [0][494/500]	Time 47.817 (47.817)	Loss 0.5206 (0.3396)	CeLoss 0.0869 (0.0563)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0026 (0.0027)	MaskLoss 0.1180 (0.0825)	MaskBCELoss 0.0209 (0.0250)	MaskDICELoss 0.0972 (0.0574)
Epoch: [0][495/500]	Time 50.468 (50.468)	Loss 0.0948 (0.3852)	CeLoss 0.0317 (0.0488)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0056 (0.0028)	MaskLoss 0.0223 (0.0935)	MaskBCELoss 0.0161 (0.0206)	MaskDICELoss 0.0062 (0.0729)
Epoch: [0][496/500]	Time 45.696 (45.696)	Loss 0.0973 (0.2754)	CeLoss 0.0243 (0.0434)	SegCLSLoss 0.0022 (0.0011)	KLLoss 0.0037 (0.0021)	MaskLoss 0.0201 (0.0645)	MaskBCELoss 0.0061 (0.0143)	MaskDICELoss 0.0140 (0.0502)
Epoch: [0][497/500]	Time 50.420 (50.420)	Loss 0.3765 (0.4233)	CeLoss 0.0223 (0.0410)	SegCLSLoss 0.0036 (0.0025)	KLLoss 0.0027 (0.0033)	MaskLoss 0.0936 (0.1063)	MaskBCELoss 0.0123 (0.0237)	MaskDICELoss 0.0813 (0.0826)
Epoch: [0][498/500]	Time 49.192 (49.192)	Loss 0.4354 (0.4361)	CeLoss 0.0219 (0.0416)	SegCLSLoss 0.0034 (0.0023)	KLLoss 0.0039 (0.0028)	MaskLoss 0.1078 (0.1054)	MaskBCELoss 0.0115 (0.0155)	MaskDICELoss 0.0963 (0.0899)
Epoch: [0][499/500]	Time 53.288 (53.288)	Loss 0.4364 (0.3541)	CeLoss 0.0454 (0.0470)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0024 (0.0031)	MaskLoss 0.1011 (0.0832)	MaskBCELoss 0.0081 (0.0146)	MaskDICELoss 0.0930 (0.0686)
[2025-03-11 05:43:37,215] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.00029461445783132527], mom=[(0.9, 0.95)]
[2025-03-11 05:43:37,226] [INFO] [timer.py:215:stop] epoch=0/micro_step=500/global_step=50, RunningAvgSamplesPerSec=0.8355148104443346, CurrSamplesPerSec=0.8541212998523317, MemAllocated=60.05GB, MaxMemAllocated=74.15GB
Epoch: [0][500/500]	Time 42.648 (42.648)	Loss 0.5730 (0.4464)	CeLoss 0.0825 (0.0556)	SegCLSLoss 0.0007 (0.0054)	KLLoss 0.0028 (0.0023)	MaskLoss 0.1501 (0.1116)	MaskBCELoss 0.0565 (0.0304)	MaskDICELoss 0.0936 (0.0812)






























100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 199/200 [01:01<00:00,  3.66it/s]

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:02<00:00,  3.22it/s]
[2025-03-11 05:44:45,106] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 499. Dropping entry: {'val/giou': 0.1733895242214203, 'val/ciou': 0.15157513320446014, '_timestamp': 1741689885.064232}).
[2025-03-11 05:45:21,520] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step50/mp_rank_00_model_states.pt
[2025-03-11 05:45:21,521] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step50/mp_rank_00_model_states.pt...
[2025-03-11 05:48:48,978] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step50/mp_rank_00_model_states.pt.
[2025-03-11 05:48:50,483] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-11 05:49:01,455] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-11 05:49:01,487] [INFO] [engine.py:3244:_save_zero_checkpoint] zero checkpoint saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-11 05:49:01,487] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch: [1][  1/500]	Time 48.196 (48.196)	Loss 0.0344 (0.3559)	CeLoss 0.0344 (0.0573)	SegCLSLoss 0.0000 (0.0030)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0909)	MaskBCELoss 0.0000 (0.0344)	MaskDICELoss 0.0000 (0.0566)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 499. Dropping entry: {'train/loss': 0.355868311598897, 'train/ce_loss': 0.05732421875, 'train/seg_cls_loss': 0.002980804443359375, 'train/kl_loss': 0.002093505859375, 'train/mask_bce_loss': 0.034377101063728335, 'train/mask_dice_loss': 0.05655391924083233, 'train/mask_loss': 0.09093101918697358, 'metrics/total_secs_per_batch': 48.195839405059814, 'metrics/data_secs_per_batch': 22.38008828163147, '_timestamp': 1741690189.709632}).
Epoch: [1][  2/500]	Time 48.139 (48.139)	Loss 0.4042 (0.3606)	CeLoss 0.0554 (0.0384)	SegCLSLoss 0.0017 (0.0016)	KLLoss 0.0012 (0.0021)	MaskLoss 0.0990 (0.0910)	MaskBCELoss 0.0246 (0.0224)	MaskDICELoss 0.0744 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 499. Dropping entry: {'train/loss': 0.3605955183506012, 'train/ce_loss': 0.03841552734375, 'train/seg_cls_loss': 0.0015865325927734374, 'train/kl_loss': 0.002095794677734375, 'train/mask_bce_loss': 0.02236348671140149, 'train/mask_dice_loss': 0.06864486746490002, 'train/mask_loss': 0.0910083532333374, 'metrics/total_secs_per_batch': 48.138771533966064, 'metrics/data_secs_per_batch': 22.32710301876068, '_timestamp': 1741690237.848193}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945903614457831, '_timestamp': 1741690237.8486595}).
Epoch: [1][  3/500]	Time 52.581 (52.581)	Loss 0.4724 (0.3896)	CeLoss 0.0469 (0.0419)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0035 (0.0029)	MaskLoss 0.1118 (0.0958)	MaskBCELoss 0.0128 (0.0195)	MaskDICELoss 0.0990 (0.0763)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 2 is less than current step: 499. Dropping entry: {'train/loss': 0.38962411396205426, 'train/ce_loss': 0.041943359375, 'train/seg_cls_loss': 0.0009876251220703124, 'train/kl_loss': 0.00286712646484375, 'train/mask_bce_loss': 0.019475696492008865, 'train/mask_dice_loss': 0.07634005537256598, 'train/mask_loss': 0.09581575207412243, 'metrics/total_secs_per_batch': 52.581218957901, 'metrics/data_secs_per_batch': 23.0345338344574, '_timestamp': 1741690290.429563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 2 is less than current step: 499. Dropping entry: {'train/lr': 0.000294578313253012, '_timestamp': 1741690290.42986}).
Epoch: [1][  4/500]	Time 45.435 (45.435)	Loss 0.4644 (0.4128)	CeLoss 0.0270 (0.0517)	SegCLSLoss 0.0008 (0.0025)	KLLoss 0.0029 (0.0025)	MaskLoss 0.1174 (0.1005)	MaskBCELoss 0.0178 (0.0223)	MaskDICELoss 0.0996 (0.0782)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 3 is less than current step: 499. Dropping entry: {'train/loss': 0.4128022938966751, 'train/ce_loss': 0.05167236328125, 'train/seg_cls_loss': 0.002474212646484375, 'train/kl_loss': 0.002509307861328125, 'train/mask_bce_loss': 0.022320411982946098, 'train/mask_dice_loss': 0.0781585294753313, 'train/mask_loss': 0.10047894418239593, 'metrics/total_secs_per_batch': 45.43514060974121, 'metrics/data_secs_per_batch': 19.792580819129945, '_timestamp': 1741690335.8645957}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 3 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945662650602409, '_timestamp': 1741690335.8648782}).
Epoch: [1][  5/500]	Time 52.581 (52.581)	Loss 0.5387 (0.3777)	CeLoss 0.0752 (0.0466)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0053 (0.0029)	MaskLoss 0.1312 (0.0923)	MaskBCELoss 0.0336 (0.0208)	MaskDICELoss 0.0976 (0.0715)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 4 is less than current step: 499. Dropping entry: {'train/loss': 0.3776636697351933, 'train/ce_loss': 0.04659423828125, 'train/seg_cls_loss': 0.0010347366333007812, 'train/kl_loss': 0.002861785888671875, 'train/mask_bce_loss': 0.020770518854260445, 'train/mask_dice_loss': 0.07153553981333971, 'train/mask_loss': 0.09230606108903885, 'metrics/total_secs_per_batch': 52.5814163684845, 'metrics/data_secs_per_batch': 23.947955226898195, '_timestamp': 1741690388.445985}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 4 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945542168674699, '_timestamp': 1741690388.4462664}).
Epoch: [1][  6/500]	Time 46.370 (46.370)	Loss 0.4490 (0.4045)	CeLoss 0.0811 (0.0500)	SegCLSLoss 0.0019 (0.0029)	KLLoss 0.0031 (0.0028)	MaskLoss 0.0931 (0.0968)	MaskBCELoss 0.0043 (0.0184)	MaskDICELoss 0.0888 (0.0784)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 5 is less than current step: 499. Dropping entry: {'train/loss': 0.40447331219911575, 'train/ce_loss': 0.04996337890625, 'train/seg_cls_loss': 0.002923583984375, 'train/kl_loss': 0.00277252197265625, 'train/mask_bce_loss': 0.01841050423681736, 'train/mask_dice_loss': 0.07836815342307091, 'train/mask_loss': 0.09677865840494633, 'metrics/total_secs_per_batch': 46.37032198905945, 'metrics/data_secs_per_batch': 21.699766325950623, '_timestamp': 1741690434.8163228}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 5 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945421686746988, '_timestamp': 1741690434.8166018}).
Epoch: [1][  7/500]	Time 48.349 (48.349)	Loss 0.0246 (0.3620)	CeLoss 0.0247 (0.0415)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0940)	MaskBCELoss 0.0000 (0.0290)	MaskDICELoss 0.0000 (0.0650)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 6 is less than current step: 499. Dropping entry: {'train/loss': 0.3620257405564189, 'train/ce_loss': 0.04149169921875, 'train/seg_cls_loss': 0.0014072418212890624, 'train/kl_loss': 0.00196075439453125, 'train/mask_bce_loss': 0.02897530170157552, 'train/mask_dice_loss': 0.06498362645506858, 'train/mask_loss': 0.09395892964676023, 'metrics/total_secs_per_batch': 48.34940052032471, 'metrics/data_secs_per_batch': 21.031990242004394, '_timestamp': 1741690483.1657352}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 6 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945301204819277, '_timestamp': 1741690483.1660235}).
Epoch: [1][  8/500]	Time 45.968 (45.968)	Loss 0.4406 (0.4155)	CeLoss 0.0210 (0.0433)	SegCLSLoss 0.0062 (0.0021)	KLLoss 0.0053 (0.0030)	MaskLoss 0.1106 (0.1023)	MaskBCELoss 0.0155 (0.0205)	MaskDICELoss 0.0951 (0.0818)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 7 is less than current step: 499. Dropping entry: {'train/loss': 0.41551630944013596, 'train/ce_loss': 0.043310546875, 'train/seg_cls_loss': 0.0020732879638671875, 'train/kl_loss': 0.00303192138671875, 'train/mask_bce_loss': 0.02052160110324621, 'train/mask_dice_loss': 0.0817774549126625, 'train/mask_loss': 0.10229905806481839, 'metrics/total_secs_per_batch': 45.96795868873596, 'metrics/data_secs_per_batch': 21.202701115608214, '_timestamp': 1741690529.1337447}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 7 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945180722891566, '_timestamp': 1741690529.1341732}).
Epoch: [1][  9/500]	Time 53.562 (53.562)	Loss 0.4582 (0.4064)	CeLoss 0.0547 (0.0449)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0042 (0.0031)	MaskLoss 0.1043 (0.1002)	MaskBCELoss 0.0092 (0.0216)	MaskDICELoss 0.0951 (0.0786)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 8 is less than current step: 499. Dropping entry: {'train/loss': 0.4064100347459316, 'train/ce_loss': 0.04488525390625, 'train/seg_cls_loss': 0.00155487060546875, 'train/kl_loss': 0.003061676025390625, 'train/mask_bce_loss': 0.021624087961390613, 'train/mask_dice_loss': 0.07860052427276969, 'train/mask_loss': 0.10022461395710706, 'metrics/total_secs_per_batch': 53.56209850311279, 'metrics/data_secs_per_batch': 24.65613498687744, '_timestamp': 1741690582.695879}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 8 is less than current step: 499. Dropping entry: {'train/lr': 0.0002945060240963855, '_timestamp': 1741690582.6961765}).
Epoch: [1][ 10/500]	Time 47.665 (47.665)	Loss 0.4809 (0.4048)	CeLoss 0.0698 (0.0387)	SegCLSLoss 0.0012 (0.0024)	KLLoss 0.0015 (0.0026)	MaskLoss 0.1045 (0.1024)	MaskBCELoss 0.0045 (0.0235)	MaskDICELoss 0.1000 (0.0788)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 9 is less than current step: 499. Dropping entry: {'train/loss': 0.4047601342201233, 'train/ce_loss': 0.03868408203125, 'train/seg_cls_loss': 0.002428436279296875, 'train/kl_loss': 0.0025665283203125, 'train/mask_bce_loss': 0.023539102962240578, 'train/mask_dice_loss': 0.07881257273256778, 'train/mask_loss': 0.10235167667269707, 'metrics/total_secs_per_batch': 47.66460609436035, 'metrics/data_secs_per_batch': 21.28823058605194, '_timestamp': 1741690630.360413}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 9 is less than current step: 499. Dropping entry: {'train/lr': 0.00029448192771084334, '_timestamp': 1741690630.360668}).
Epoch: [1][ 11/500]	Time 41.185 (41.185)	Loss 0.4491 (0.3078)	CeLoss 0.0225 (0.0411)	SegCLSLoss 0.0018 (0.0027)	KLLoss 0.0025 (0.0025)	MaskLoss 0.1118 (0.0805)	MaskBCELoss 0.0119 (0.0296)	MaskDICELoss 0.0999 (0.0509)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 10 is less than current step: 499. Dropping entry: {'train/loss': 0.3077956039458513, 'train/ce_loss': 0.041064453125, 'train/seg_cls_loss': 0.0027008056640625, 'train/kl_loss': 0.002521514892578125, 'train/mask_bce_loss': 0.02956390818580985, 'train/mask_dice_loss': 0.05094136237166822, 'train/mask_loss': 0.08050526864826679, 'metrics/total_secs_per_batch': 41.18497705459595, 'metrics/data_secs_per_batch': 17.905736637115478, '_timestamp': 1741690671.5454035}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 10 is less than current step: 499. Dropping entry: {'train/lr': 0.00029446987951807225, '_timestamp': 1741690671.5457077}).
Epoch: [1][ 12/500]	Time 43.502 (43.502)	Loss 0.4438 (0.4420)	CeLoss 0.0150 (0.0564)	SegCLSLoss 0.0020 (0.0017)	KLLoss 0.0032 (0.0025)	MaskLoss 0.1151 (0.1059)	MaskBCELoss 0.0180 (0.0206)	MaskDICELoss 0.0972 (0.0852)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 11 is less than current step: 499. Dropping entry: {'train/loss': 0.4419779598712921, 'train/ce_loss': 0.05635986328125, 'train/seg_cls_loss': 0.001729583740234375, 'train/kl_loss': 0.002475738525390625, 'train/mask_bce_loss': 0.020612271223217248, 'train/mask_dice_loss': 0.08524206541478634, 'train/mask_loss': 0.10585433579981327, 'metrics/total_secs_per_batch': 43.502235651016235, 'metrics/data_secs_per_batch': 19.24640338420868, '_timestamp': 1741690715.0477586}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 11 is less than current step: 499. Dropping entry: {'train/lr': 0.00029445783132530116, '_timestamp': 1741690715.0480647}).
Epoch: [1][ 13/500]	Time 47.994 (47.994)	Loss 0.3988 (0.4242)	CeLoss 0.0649 (0.0476)	SegCLSLoss 0.0045 (0.0019)	KLLoss 0.0024 (0.0035)	MaskLoss 0.0888 (0.1033)	MaskBCELoss 0.0129 (0.0205)	MaskDICELoss 0.0758 (0.0828)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 12 is less than current step: 499. Dropping entry: {'train/loss': 0.4242309287190437, 'train/ce_loss': 0.047625732421875, 'train/seg_cls_loss': 0.0018764495849609374, 'train/kl_loss': 0.00353546142578125, 'train/mask_bce_loss': 0.020496345352148636, 'train/mask_dice_loss': 0.08276268225163222, 'train/mask_loss': 0.10325902551412583, 'metrics/total_secs_per_batch': 47.9940288066864, 'metrics/data_secs_per_batch': 21.99370231628418, '_timestamp': 1741690763.0417407}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 12 is less than current step: 499. Dropping entry: {'train/lr': 0.00029444578313253013, '_timestamp': 1741690763.0420265}).
Epoch: [1][ 14/500]	Time 49.334 (49.334)	Loss 0.2800 (0.3739)	CeLoss 0.0830 (0.0469)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0023 (0.0023)	MaskLoss 0.0627 (0.0947)	MaskBCELoss 0.0283 (0.0275)	MaskDICELoss 0.0344 (0.0672)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 13 is less than current step: 499. Dropping entry: {'train/loss': 0.37389680854976176, 'train/ce_loss': 0.04691162109375, 'train/seg_cls_loss': 0.0015621185302734375, 'train/kl_loss': 0.002310943603515625, 'train/mask_bce_loss': 0.02745653479360044, 'train/mask_dice_loss': 0.06723861061036587, 'train/mask_loss': 0.09469514638185501, 'metrics/total_secs_per_batch': 49.33437776565552, 'metrics/data_secs_per_batch': 21.925130677223205, '_timestamp': 1741690812.377295}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 13 is less than current step: 499. Dropping entry: {'train/lr': 0.00029443373493975904, '_timestamp': 1741690812.3783593}).
Epoch: [1][ 15/500]	Time 47.181 (47.181)	Loss 0.3801 (0.4231)	CeLoss 0.0381 (0.0491)	SegCLSLoss 0.0029 (0.0029)	KLLoss 0.0023 (0.0028)	MaskLoss 0.0927 (0.1036)	MaskBCELoss 0.0163 (0.0222)	MaskDICELoss 0.0764 (0.0814)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 14 is less than current step: 499. Dropping entry: {'train/loss': 0.4231167122721672, 'train/ce_loss': 0.0490966796875, 'train/seg_cls_loss': 0.002912139892578125, 'train/kl_loss': 0.002759552001953125, 'train/mask_bce_loss': 0.022170287976041436, 'train/mask_dice_loss': 0.08138836920261383, 'train/mask_loss': 0.10355865620076657, 'metrics/total_secs_per_batch': 47.18065428733826, 'metrics/data_secs_per_batch': 20.951057481765748, '_timestamp': 1741690859.5567796}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 14 is less than current step: 499. Dropping entry: {'train/lr': 0.00029442168674698795, '_timestamp': 1741690859.5571983}).
Epoch: [1][ 16/500]	Time 48.029 (48.029)	Loss 0.4467 (0.4489)	CeLoss 0.0410 (0.0435)	SegCLSLoss 0.0009 (0.0021)	KLLoss 0.0040 (0.0029)	MaskLoss 0.1055 (0.1115)	MaskBCELoss 0.0103 (0.0223)	MaskDICELoss 0.0952 (0.0892)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 15 is less than current step: 499. Dropping entry: {'train/loss': 0.44893267154693606, 'train/ce_loss': 0.043505859375, 'train/seg_cls_loss': 0.0021198272705078127, 'train/kl_loss': 0.002852630615234375, 'train/mask_bce_loss': 0.02227564980275929, 'train/mask_dice_loss': 0.08924475871026516, 'train/mask_loss': 0.11152040995657445, 'metrics/total_secs_per_batch': 48.028828382492065, 'metrics/data_secs_per_batch': 22.63502676486969, '_timestamp': 1741690907.5855885}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 15 is less than current step: 499. Dropping entry: {'train/lr': 0.00029440963855421686, '_timestamp': 1741690907.5858803}).
Epoch: [1][ 17/500]	Time 50.174 (50.174)	Loss 0.3411 (0.3612)	CeLoss 0.0723 (0.0469)	SegCLSLoss 0.0005 (0.0020)	KLLoss 0.0026 (0.0021)	MaskLoss 0.0799 (0.0908)	MaskBCELoss 0.0269 (0.0259)	MaskDICELoss 0.0530 (0.0649)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 16 is less than current step: 499. Dropping entry: {'train/loss': 0.36124164760112765, 'train/ce_loss': 0.0468994140625, 'train/seg_cls_loss': 0.0019802093505859376, 'train/kl_loss': 0.00207366943359375, 'train/mask_bce_loss': 0.025857913488289343, 'train/mask_dice_loss': 0.0648985456675291, 'train/mask_loss': 0.09075645878911018, 'metrics/total_secs_per_batch': 50.17382454872131, 'metrics/data_secs_per_batch': 22.517740893363953, '_timestamp': 1741690957.7593863}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 16 is less than current step: 499. Dropping entry: {'train/lr': 0.00029439759036144577, '_timestamp': 1741690957.7596562}).
Epoch: [1][ 18/500]	Time 48.318 (48.318)	Loss 0.4837 (0.4888)	CeLoss 0.0347 (0.0517)	SegCLSLoss 0.0021 (0.0018)	KLLoss 0.0007 (0.0021)	MaskLoss 0.1664 (0.1497)	MaskBCELoss 0.1092 (0.0823)	MaskDICELoss 0.0572 (0.0673)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 17 is less than current step: 499. Dropping entry: {'train/loss': 0.4888494998216629, 'train/ce_loss': 0.05166015625, 'train/seg_cls_loss': 0.0018138885498046875, 'train/kl_loss': 0.002115631103515625, 'train/mask_bce_loss': 0.08233938440680504, 'train/mask_dice_loss': 0.06734883487224579, 'train/mask_loss': 0.14968821927905082, 'metrics/total_secs_per_batch': 48.31760239601135, 'metrics/data_secs_per_batch': 20.03568196296692, '_timestamp': 1741691006.0782764}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 17 is less than current step: 499. Dropping entry: {'train/lr': 0.0002943855421686747, '_timestamp': 1741691006.0793161}).
Epoch: [1][ 19/500]	Time 46.929 (46.929)	Loss 0.3813 (0.3593)	CeLoss 0.0239 (0.0320)	SegCLSLoss 0.0036 (0.0022)	KLLoss 0.0039 (0.0032)	MaskLoss 0.0947 (0.0935)	MaskBCELoss 0.0136 (0.0256)	MaskDICELoss 0.0811 (0.0679)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 18 is less than current step: 499. Dropping entry: {'train/loss': 0.3592977523803711, 'train/ce_loss': 0.031982421875, 'train/seg_cls_loss': 0.0022274017333984374, 'train/kl_loss': 0.003179168701171875, 'train/mask_bce_loss': 0.025589434150606393, 'train/mask_dice_loss': 0.06794769084081054, 'train/mask_loss': 0.09353712573647499, 'metrics/total_secs_per_batch': 46.929463624954224, 'metrics/data_secs_per_batch': 21.072551107406618, '_timestamp': 1741691053.0064712}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 18 is less than current step: 499. Dropping entry: {'train/lr': 0.0002943734939759036, '_timestamp': 1741691053.0068805}).
Epoch: [1][ 20/500]	Time 50.608 (50.608)	Loss 0.4720 (0.3789)	CeLoss 0.0732 (0.0554)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0024 (0.0028)	MaskLoss 0.1135 (0.0920)	MaskBCELoss 0.0292 (0.0240)	MaskDICELoss 0.0844 (0.0680)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 19 is less than current step: 499. Dropping entry: {'train/loss': 0.3788868598639965, 'train/ce_loss': 0.0554443359375, 'train/seg_cls_loss': 0.0012826919555664062, 'train/kl_loss': 0.00277557373046875, 'train/mask_bce_loss': 0.024040132854133846, 'train/mask_dice_loss': 0.06798973446711898, 'train/mask_loss': 0.092029869556427, 'metrics/total_secs_per_batch': 50.60801553726196, 'metrics/data_secs_per_batch': 23.41087050437927, '_timestamp': 1741691103.6145945}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 19 is less than current step: 499. Dropping entry: {'train/lr': 0.0002943493975903614, '_timestamp': 1741691103.6148612}).
Epoch: [1][ 21/500]	Time 49.394 (49.394)	Loss 0.0307 (0.3981)	CeLoss 0.0306 (0.0385)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0022)	MaskLoss 0.0000 (0.1055)	MaskBCELoss 0.0000 (0.0327)	MaskDICELoss 0.0000 (0.0728)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 20 is less than current step: 499. Dropping entry: {'train/loss': 0.39806343223899604, 'train/ce_loss': 0.038525390625, 'train/seg_cls_loss': 0.0014862060546875, 'train/kl_loss': 0.0022350311279296874, 'train/mask_bce_loss': 0.03273806327488273, 'train/mask_dice_loss': 0.07277573328465223, 'train/mask_loss': 0.1055137973278761, 'metrics/total_secs_per_batch': 49.394065618515015, 'metrics/data_secs_per_batch': 21.638373804092407, '_timestamp': 1741691153.0085728}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 20 is less than current step: 499. Dropping entry: {'train/lr': 0.0002943373493975903, '_timestamp': 1741691153.0089839}).
Epoch: [1][ 22/500]	Time 47.936 (47.936)	Loss 0.2588 (0.3664)	CeLoss 0.0226 (0.0488)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0012 (0.0027)	MaskLoss 0.0701 (0.0880)	MaskBCELoss 0.0232 (0.0189)	MaskDICELoss 0.0469 (0.0691)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 21 is less than current step: 499. Dropping entry: {'train/loss': 0.36639743447303774, 'train/ce_loss': 0.04876708984375, 'train/seg_cls_loss': 0.0013187408447265625, 'train/kl_loss': 0.002686309814453125, 'train/mask_bce_loss': 0.018942904681898652, 'train/mask_dice_loss': 0.06910055950284004, 'train/mask_loss': 0.08804346602410078, 'metrics/total_secs_per_batch': 47.93565845489502, 'metrics/data_secs_per_batch': 21.37155375480652, '_timestamp': 1741691200.9456534}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 21 is less than current step: 499. Dropping entry: {'train/lr': 0.00029432530120481924, '_timestamp': 1741691200.9467592}).
Epoch: [1][ 23/500]	Time 49.409 (49.409)	Loss 0.4750 (0.3439)	CeLoss 0.0244 (0.0367)	SegCLSLoss 0.0070 (0.0018)	KLLoss 0.0028 (0.0026)	MaskLoss 0.1222 (0.0840)	MaskBCELoss 0.0224 (0.0162)	MaskDICELoss 0.0998 (0.0678)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 22 is less than current step: 499. Dropping entry: {'train/loss': 0.34386114291846753, 'train/ce_loss': 0.03665771484375, 'train/seg_cls_loss': 0.001772308349609375, 'train/kl_loss': 0.002555084228515625, 'train/mask_bce_loss': 0.01618556692264974, 'train/mask_dice_loss': 0.06783831929787994, 'train/mask_loss': 0.08402388747781515, 'metrics/total_secs_per_batch': 49.40851187705994, 'metrics/data_secs_per_batch': 22.176704978942873, '_timestamp': 1741691250.352855}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 22 is less than current step: 499. Dropping entry: {'train/lr': 0.00029431325301204815, '_timestamp': 1741691250.3532772}).
Epoch: [1][ 24/500]	Time 47.207 (47.207)	Loss 0.6005 (0.4025)	CeLoss 0.1006 (0.0469)	SegCLSLoss 0.0005 (0.0039)	KLLoss 0.0035 (0.0022)	MaskLoss 0.1900 (0.0996)	MaskBCELoss 0.1316 (0.0235)	MaskDICELoss 0.0584 (0.0762)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 23 is less than current step: 499. Dropping entry: {'train/loss': 0.4025042738765478, 'train/ce_loss': 0.0469482421875, 'train/seg_cls_loss': 0.003887176513671875, 'train/kl_loss': 0.0021518707275390626, 'train/mask_bce_loss': 0.023465763800777494, 'train/mask_dice_loss': 0.07615392953157425, 'train/mask_loss': 0.09961969330906868, 'metrics/total_secs_per_batch': 47.20686316490173, 'metrics/data_secs_per_batch': 21.412711572647094, '_timestamp': 1741691297.5597503}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 23 is less than current step: 499. Dropping entry: {'train/lr': 0.00029430120481927706, '_timestamp': 1741691297.5600424}).
Epoch: [1][ 25/500]	Time 43.734 (43.734)	Loss 0.4736 (0.4450)	CeLoss 0.0251 (0.0418)	SegCLSLoss 0.0077 (0.0034)	KLLoss 0.0020 (0.0029)	MaskLoss 0.1293 (0.1337)	MaskBCELoss 0.0373 (0.0681)	MaskDICELoss 0.0920 (0.0656)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 24 is less than current step: 499. Dropping entry: {'train/loss': 0.4449914898723364, 'train/ce_loss': 0.041796875, 'train/seg_cls_loss': 0.003350067138671875, 'train/kl_loss': 0.002886962890625, 'train/mask_bce_loss': 0.06809104080311953, 'train/mask_dice_loss': 0.06561055495403707, 'train/mask_loss': 0.13370159780606627, 'metrics/total_secs_per_batch': 43.73431658744812, 'metrics/data_secs_per_batch': 20.869614577293397, '_timestamp': 1741691341.2939343}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 24 is less than current step: 499. Dropping entry: {'train/lr': 0.00029428915662650597, '_timestamp': 1741691341.2943356}).
Epoch: [1][ 26/500]	Time 43.011 (43.011)	Loss 0.0883 (0.3533)	CeLoss 0.0728 (0.0470)	SegCLSLoss 0.0005 (0.0039)	KLLoss 0.0060 (0.0030)	MaskLoss 0.0032 (0.0808)	MaskBCELoss 0.0016 (0.0110)	MaskDICELoss 0.0015 (0.0698)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 25 is less than current step: 499. Dropping entry: {'train/loss': 0.353276876732707, 'train/ce_loss': 0.047021484375, 'train/seg_cls_loss': 0.003933334350585937, 'train/kl_loss': 0.00298919677734375, 'train/mask_bce_loss': 0.011015099857468158, 'train/mask_dice_loss': 0.06982338831294328, 'train/mask_loss': 0.0808384871808812, 'metrics/total_secs_per_batch': 43.01064705848694, 'metrics/data_secs_per_batch': 19.671568870544434, '_timestamp': 1741691384.304822}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 25 is less than current step: 499. Dropping entry: {'train/lr': 0.00029427710843373493, '_timestamp': 1741691384.305162}).
Epoch: [1][ 27/500]	Time 47.099 (47.099)	Loss 0.4393 (0.4391)	CeLoss 0.0554 (0.0388)	SegCLSLoss 0.0011 (0.0032)	KLLoss 0.0028 (0.0028)	MaskLoss 0.1410 (0.1119)	MaskBCELoss 0.0917 (0.0259)	MaskDICELoss 0.0493 (0.0860)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 26 is less than current step: 499. Dropping entry: {'train/loss': 0.43909880220890046, 'train/ce_loss': 0.03875732421875, 'train/seg_cls_loss': 0.00324859619140625, 'train/kl_loss': 0.002790069580078125, 'train/mask_bce_loss': 0.025891491456422954, 'train/mask_dice_loss': 0.08603305481374264, 'train/mask_loss': 0.11192454993724824, 'metrics/total_secs_per_batch': 47.099109411239624, 'metrics/data_secs_per_batch': 22.758587884902955, '_timestamp': 1741691431.403783}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 26 is less than current step: 499. Dropping entry: {'train/lr': 0.00029426506024096384, '_timestamp': 1741691431.4040778}).
Epoch: [1][ 28/500]	Time 47.445 (47.445)	Loss 0.3563 (0.3632)	CeLoss 0.0645 (0.0661)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0031 (0.0036)	MaskLoss 0.0857 (0.0886)	MaskBCELoss 0.0275 (0.0307)	MaskDICELoss 0.0582 (0.0579)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 27 is less than current step: 499. Dropping entry: {'train/loss': 0.3631751976907253, 'train/ce_loss': 0.06605224609375, 'train/seg_cls_loss': 0.001071929931640625, 'train/kl_loss': 0.00358123779296875, 'train/mask_bce_loss': 0.03068207233445719, 'train/mask_dice_loss': 0.05789905439596623, 'train/mask_loss': 0.08858112683519721, 'metrics/total_secs_per_batch': 47.444902181625366, 'metrics/data_secs_per_batch': 21.426339793205262, '_timestamp': 1741691478.8501916}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 27 is less than current step: 499. Dropping entry: {'train/lr': 0.00029425301204819276, '_timestamp': 1741691478.851364}).
Epoch: [1][ 29/500]	Time 48.036 (48.036)	Loss 0.4881 (0.3887)	CeLoss 0.0479 (0.0423)	SegCLSLoss 0.0007 (0.0017)	KLLoss 0.0063 (0.0030)	MaskLoss 0.1224 (0.0971)	MaskBCELoss 0.0280 (0.0229)	MaskDICELoss 0.0943 (0.0742)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 28 is less than current step: 499. Dropping entry: {'train/loss': 0.3887411534786224, 'train/ce_loss': 0.0422607421875, 'train/seg_cls_loss': 0.0016998291015625, 'train/kl_loss': 0.003009033203125, 'train/mask_bce_loss': 0.022917497763410212, 'train/mask_dice_loss': 0.07418356947600842, 'train/mask_loss': 0.09710106588900089, 'metrics/total_secs_per_batch': 48.035751819610596, 'metrics/data_secs_per_batch': 21.389928269386292, '_timestamp': 1741691526.8844109}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 28 is less than current step: 499. Dropping entry: {'train/lr': 0.00029424096385542167, '_timestamp': 1741691526.884693}).
Epoch: [1][ 30/500]	Time 42.712 (42.712)	Loss 0.4004 (0.4540)	CeLoss 0.0703 (0.0571)	SegCLSLoss 0.0042 (0.0034)	KLLoss 0.0030 (0.0024)	MaskLoss 0.0901 (0.1126)	MaskBCELoss 0.0177 (0.0287)	MaskDICELoss 0.0724 (0.0839)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 29 is less than current step: 499. Dropping entry: {'train/loss': 0.45400373786687853, 'train/ce_loss': 0.0570556640625, 'train/seg_cls_loss': 0.0033693313598632812, 'train/kl_loss': 0.00238494873046875, 'train/mask_bce_loss': 0.02873732631560415, 'train/mask_dice_loss': 0.08385883308947087, 'train/mask_loss': 0.1125961571931839, 'metrics/total_secs_per_batch': 42.711546897888184, 'metrics/data_secs_per_batch': 17.747758626937866, '_timestamp': 1741691569.5960014}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 29 is less than current step: 499. Dropping entry: {'train/lr': 0.0002942168674698795, '_timestamp': 1741691569.5964015}).
Epoch: [1][ 31/500]	Time 50.024 (50.024)	Loss 0.3525 (0.3741)	CeLoss 0.0437 (0.0424)	SegCLSLoss 0.0011 (0.0028)	KLLoss 0.0019 (0.0033)	MaskLoss 0.0827 (0.0925)	MaskBCELoss 0.0124 (0.0215)	MaskDICELoss 0.0704 (0.0710)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 30 is less than current step: 499. Dropping entry: {'train/loss': 0.37406031638383863, 'train/ce_loss': 0.0423583984375, 'train/seg_cls_loss': 0.002826690673828125, 'train/kl_loss': 0.003325653076171875, 'train/mask_bce_loss': 0.021533645084127785, 'train/mask_dice_loss': 0.07097091153264046, 'train/mask_loss': 0.09250455722212791, 'metrics/total_secs_per_batch': 50.02438998222351, 'metrics/data_secs_per_batch': 22.255697703361513, '_timestamp': 1741691619.620997}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 30 is less than current step: 499. Dropping entry: {'train/lr': 0.0002942048192771084, '_timestamp': 1741691619.6214669}).
Epoch: [1][ 32/500]	Time 46.060 (46.060)	Loss 0.0775 (0.4147)	CeLoss 0.0435 (0.0481)	SegCLSLoss 0.0007 (0.0019)	KLLoss 0.0039 (0.0027)	MaskLoss 0.0084 (0.1156)	MaskBCELoss 0.0020 (0.0497)	MaskDICELoss 0.0064 (0.0659)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 31 is less than current step: 499. Dropping entry: {'train/loss': 0.41472528874874115, 'train/ce_loss': 0.04805908203125, 'train/seg_cls_loss': 0.0019161224365234375, 'train/kl_loss': 0.00273590087890625, 'train/mask_bce_loss': 0.0496581160579808, 'train/mask_dice_loss': 0.06592746139504016, 'train/mask_loss': 0.11558557394891977, 'metrics/total_secs_per_batch': 46.059959173202515, 'metrics/data_secs_per_batch': 19.46427195072174, '_timestamp': 1741691665.680551}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 31 is less than current step: 499. Dropping entry: {'train/lr': 0.0002941927710843373, '_timestamp': 1741691665.6808786}).
Epoch: [1][ 33/500]	Time 43.380 (43.380)	Loss 0.4183 (0.4373)	CeLoss 0.0261 (0.0507)	SegCLSLoss 0.0053 (0.0020)	KLLoss 0.0018 (0.0024)	MaskLoss 0.1041 (0.1097)	MaskBCELoss 0.0145 (0.0278)	MaskDICELoss 0.0897 (0.0819)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 32 is less than current step: 499. Dropping entry: {'train/loss': 0.43731348775327206, 'train/ce_loss': 0.05067138671875, 'train/seg_cls_loss': 0.0019863128662109377, 'train/kl_loss': 0.0024444580078125, 'train/mask_bce_loss': 0.027822851913515478, 'train/mask_dice_loss': 0.0818964384496212, 'train/mask_loss': 0.10971928625367582, 'metrics/total_secs_per_batch': 43.37966704368591, 'metrics/data_secs_per_batch': 20.89922716617584, '_timestamp': 1741691709.0625293}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 32 is less than current step: 499. Dropping entry: {'train/lr': 0.0002941807228915662, '_timestamp': 1741691709.063879}).
Epoch: [1][ 34/500]	Time 48.322 (48.322)	Loss 0.1291 (0.3916)	CeLoss 0.1108 (0.0509)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0045 (0.0028)	MaskLoss 0.0041 (0.0983)	MaskBCELoss 0.0015 (0.0279)	MaskDICELoss 0.0026 (0.0704)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 33 is less than current step: 499. Dropping entry: {'train/loss': 0.3915724728256464, 'train/ce_loss': 0.05087890625, 'train/seg_cls_loss': 0.0011857986450195313, 'train/kl_loss': 0.0027801513671875, 'train/mask_bce_loss': 0.027852914342656732, 'train/mask_dice_loss': 0.07042173908557743, 'train/mask_loss': 0.0982746530789882, 'metrics/total_secs_per_batch': 48.32224941253662, 'metrics/data_secs_per_batch': 22.86963288784027, '_timestamp': 1741691757.3823915}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 33 is less than current step: 499. Dropping entry: {'train/lr': 0.0002941686746987952, '_timestamp': 1741691757.3826756}).
Epoch: [1][ 35/500]	Time 46.410 (46.410)	Loss 0.4690 (0.3160)	CeLoss 0.0344 (0.0347)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0025 (0.0027)	MaskLoss 0.1224 (0.0837)	MaskBCELoss 0.0293 (0.0284)	MaskDICELoss 0.0931 (0.0553)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 34 is less than current step: 499. Dropping entry: {'train/loss': 0.31602294659242036, 'train/ce_loss': 0.03470458984375, 'train/seg_cls_loss': 0.0014669418334960938, 'train/kl_loss': 0.002703857421875, 'train/mask_bce_loss': 0.02841072711162269, 'train/mask_dice_loss': 0.05527644702233374, 'train/mask_loss': 0.08368717418052256, 'metrics/total_secs_per_batch': 46.40964341163635, 'metrics/data_secs_per_batch': 19.839675641059877, '_timestamp': 1741691803.7919269}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 34 is less than current step: 499. Dropping entry: {'train/lr': 0.0002941566265060241, '_timestamp': 1741691803.7923615}).
Epoch: [1][ 36/500]	Time 44.985 (44.985)	Loss 0.3233 (0.3573)	CeLoss 0.0771 (0.0406)	SegCLSLoss 0.0020 (0.0012)	KLLoss 0.0015 (0.0024)	MaskLoss 0.0726 (0.0903)	MaskBCELoss 0.0235 (0.0237)	MaskDICELoss 0.0492 (0.0666)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 35 is less than current step: 499. Dropping entry: {'train/loss': 0.35727021675556897, 'train/ce_loss': 0.040576171875, 'train/seg_cls_loss': 0.0012392044067382813, 'train/kl_loss': 0.002388763427734375, 'train/mask_bce_loss': 0.02372368611395359, 'train/mask_dice_loss': 0.06657192055135966, 'train/mask_loss': 0.0902956061065197, 'metrics/total_secs_per_batch': 44.98451375961304, 'metrics/data_secs_per_batch': 20.54813895225525, '_timestamp': 1741691848.7764869}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 35 is less than current step: 499. Dropping entry: {'train/lr': 0.000294144578313253, '_timestamp': 1741691848.7767642}).
Epoch: [1][ 37/500]	Time 46.999 (46.999)	Loss 0.0878 (0.3756)	CeLoss 0.0500 (0.0354)	SegCLSLoss 0.0004 (0.0017)	KLLoss 0.0038 (0.0034)	MaskLoss 0.0106 (0.1002)	MaskBCELoss 0.0043 (0.0324)	MaskDICELoss 0.0063 (0.0678)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 36 is less than current step: 499. Dropping entry: {'train/loss': 0.3755988717079163, 'train/ce_loss': 0.0353759765625, 'train/seg_cls_loss': 0.0017286300659179687, 'train/kl_loss': 0.003363037109375, 'train/mask_bce_loss': 0.03239708639448509, 'train/mask_dice_loss': 0.0678012754302472, 'train/mask_loss': 0.10019836248829961, 'metrics/total_secs_per_batch': 46.99882674217224, 'metrics/data_secs_per_batch': 19.998616933822632, '_timestamp': 1741691895.7754056}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 36 is less than current step: 499. Dropping entry: {'train/lr': 0.0002941325301204819, '_timestamp': 1741691895.775858}).
Epoch: [1][ 38/500]	Time 46.349 (46.349)	Loss 0.4111 (0.4409)	CeLoss 0.0250 (0.0523)	SegCLSLoss 0.0018 (0.0022)	KLLoss 0.0033 (0.0034)	MaskLoss 0.1361 (0.1116)	MaskBCELoss 0.0813 (0.0311)	MaskDICELoss 0.0548 (0.0805)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 37 is less than current step: 499. Dropping entry: {'train/loss': 0.44091654419898985, 'train/ce_loss': 0.05225830078125, 'train/seg_cls_loss': 0.0021511077880859374, 'train/kl_loss': 0.003387451171875, 'train/mask_bce_loss': 0.03111069112783298, 'train/mask_dice_loss': 0.08050386868417263, 'train/mask_loss': 0.11161456033587455, 'metrics/total_secs_per_batch': 46.34948468208313, 'metrics/data_secs_per_batch': 21.386501002311707, '_timestamp': 1741691942.1248584}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 37 is less than current step: 499. Dropping entry: {'train/lr': 0.00029412048192771083, '_timestamp': 1741691942.125148}).
Epoch: [1][ 39/500]	Time 50.100 (50.100)	Loss 0.4547 (0.3079)	CeLoss 0.0449 (0.0455)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0026 (0.0022)	MaskLoss 0.1062 (0.0756)	MaskBCELoss 0.0090 (0.0215)	MaskDICELoss 0.0972 (0.0541)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 38 is less than current step: 499. Dropping entry: {'train/loss': 0.30788308624178173, 'train/ce_loss': 0.04547119140625, 'train/seg_cls_loss': 0.00142669677734375, 'train/kl_loss': 0.00221099853515625, 'train/mask_bce_loss': 0.02149674128741026, 'train/mask_dice_loss': 0.05414964873343706, 'train/mask_loss': 0.07564638946205378, 'metrics/total_secs_per_batch': 50.09969186782837, 'metrics/data_secs_per_batch': 21.351050758361815, '_timestamp': 1741691992.2252436}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 38 is less than current step: 499. Dropping entry: {'train/lr': 0.00029410843373493974, '_timestamp': 1741691992.22566}).
Epoch: [1][ 40/500]	Time 49.076 (49.076)	Loss 0.5500 (0.3382)	CeLoss 0.0598 (0.0478)	SegCLSLoss 0.0012 (0.0009)	KLLoss 0.0041 (0.0026)	MaskLoss 0.1458 (0.0818)	MaskBCELoss 0.0490 (0.0200)	MaskDICELoss 0.0968 (0.0618)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 39 is less than current step: 499. Dropping entry: {'train/loss': 0.33819803670048715, 'train/ce_loss': 0.04781494140625, 'train/seg_cls_loss': 0.0008760452270507813, 'train/kl_loss': 0.002590179443359375, 'train/mask_bce_loss': 0.019953213934786617, 'train/mask_dice_loss': 0.06184829324483872, 'train/mask_loss': 0.08180150762200356, 'metrics/total_secs_per_batch': 49.07581543922424, 'metrics/data_secs_per_batch': 21.115362763404846, '_timestamp': 1741692041.300425}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 39 is less than current step: 499. Dropping entry: {'train/lr': 0.00029408433734939756, '_timestamp': 1741692041.3006861}).
Epoch: [1][ 41/500]	Time 50.943 (50.943)	Loss 0.3516 (0.4552)	CeLoss 0.0479 (0.0366)	SegCLSLoss 0.0003 (0.0018)	KLLoss 0.0026 (0.0025)	MaskLoss 0.0868 (0.1175)	MaskBCELoss 0.0231 (0.0274)	MaskDICELoss 0.0636 (0.0901)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 40 is less than current step: 499. Dropping entry: {'train/loss': 0.45515272617340086, 'train/ce_loss': 0.03663330078125, 'train/seg_cls_loss': 0.0017856597900390626, 'train/kl_loss': 0.002541351318359375, 'train/mask_bce_loss': 0.027367210341617466, 'train/mask_dice_loss': 0.09008992649614811, 'train/mask_loss': 0.11745713800191879, 'metrics/total_secs_per_batch': 50.942880630493164, 'metrics/data_secs_per_batch': 22.50744023323059, '_timestamp': 1741692092.2433357}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 40 is less than current step: 499. Dropping entry: {'train/lr': 0.00029407228915662647, '_timestamp': 1741692092.2436328}).
Epoch: [1][ 42/500]	Time 49.233 (49.233)	Loss 0.5534 (0.3642)	CeLoss 0.0732 (0.0448)	SegCLSLoss 0.0011 (0.0018)	KLLoss 0.0026 (0.0025)	MaskLoss 0.1458 (0.0906)	MaskBCELoss 0.0529 (0.0232)	MaskDICELoss 0.0928 (0.0675)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 41 is less than current step: 499. Dropping entry: {'train/loss': 0.3642361782491207, 'train/ce_loss': 0.044775390625, 'train/seg_cls_loss': 0.00180206298828125, 'train/kl_loss': 0.002477264404296875, 'train/mask_bce_loss': 0.023152916901744904, 'train/mask_dice_loss': 0.06745865917764604, 'train/mask_loss': 0.09061157666146755, 'metrics/total_secs_per_batch': 49.2333562374115, 'metrics/data_secs_per_batch': 21.335210657119752, '_timestamp': 1741692141.4766095}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 41 is less than current step: 499. Dropping entry: {'train/lr': 0.0002940602409638554, '_timestamp': 1741692141.4768813}).
Epoch: [1][ 43/500]	Time 44.444 (44.444)	Loss 0.3663 (0.2881)	CeLoss 0.0212 (0.0409)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0022 (0.0030)	MaskLoss 0.0939 (0.0685)	MaskBCELoss 0.0168 (0.0151)	MaskDICELoss 0.0771 (0.0533)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 42 is less than current step: 499. Dropping entry: {'train/loss': 0.2881267011165619, 'train/ce_loss': 0.04093017578125, 'train/seg_cls_loss': 0.0009937286376953125, 'train/kl_loss': 0.002993011474609375, 'train/mask_bce_loss': 0.015142171620391309, 'train/mask_dice_loss': 0.05334974993020296, 'train/mask_loss': 0.06849192115478217, 'metrics/total_secs_per_batch': 44.44350242614746, 'metrics/data_secs_per_batch': 19.215419673919676, '_timestamp': 1741692185.9200215}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 42 is less than current step: 499. Dropping entry: {'train/lr': 0.0002940481927710843, '_timestamp': 1741692185.9202888}).
Epoch: [1][ 44/500]	Time 45.580 (45.580)	Loss 0.2167 (0.3100)	CeLoss 0.0286 (0.0395)	SegCLSLoss 0.0008 (0.0027)	KLLoss 0.0015 (0.0020)	MaskLoss 0.0591 (0.0775)	MaskBCELoss 0.0252 (0.0214)	MaskDICELoss 0.0340 (0.0561)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 43 is less than current step: 499. Dropping entry: {'train/loss': 0.3099959913641214, 'train/ce_loss': 0.0394775390625, 'train/seg_cls_loss': 0.00270538330078125, 'train/kl_loss': 0.002019500732421875, 'train/mask_bce_loss': 0.02139527495019138, 'train/mask_dice_loss': 0.05607870439998806, 'train/mask_loss': 0.07747397990897298, 'metrics/total_secs_per_batch': 45.580169677734375, 'metrics/data_secs_per_batch': 20.151821041107176, '_timestamp': 1741692231.5013871}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 43 is less than current step: 499. Dropping entry: {'train/lr': 0.0002940361445783132, '_timestamp': 1741692231.5024178}).
Epoch: [1][ 45/500]	Time 43.942 (43.942)	Loss 0.4362 (0.4330)	CeLoss 0.0236 (0.0438)	SegCLSLoss 0.0015 (0.0022)	KLLoss 0.0031 (0.0031)	MaskLoss 0.1198 (0.1148)	MaskBCELoss 0.0352 (0.0371)	MaskDICELoss 0.0845 (0.0777)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 44 is less than current step: 499. Dropping entry: {'train/loss': 0.43304692804813383, 'train/ce_loss': 0.0437744140625, 'train/seg_cls_loss': 0.0022144317626953125, 'train/kl_loss': 0.003128814697265625, 'train/mask_bce_loss': 0.0371209199540317, 'train/mask_dice_loss': 0.07767978720366955, 'train/mask_loss': 0.11480070874094964, 'metrics/total_secs_per_batch': 43.941582679748535, 'metrics/data_secs_per_batch': 20.03340287208557, '_timestamp': 1741692275.4430501}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 44 is less than current step: 499. Dropping entry: {'train/lr': 0.0002940240963855421, '_timestamp': 1741692275.4440343}).
Epoch: [1][ 46/500]	Time 50.253 (50.253)	Loss 0.4108 (0.3997)	CeLoss 0.0554 (0.0457)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0021 (0.0020)	MaskLoss 0.1183 (0.1037)	MaskBCELoss 0.0602 (0.0317)	MaskDICELoss 0.0582 (0.0720)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 45 is less than current step: 499. Dropping entry: {'train/loss': 0.3996588207781315, 'train/ce_loss': 0.04566650390625, 'train/seg_cls_loss': 0.001183319091796875, 'train/kl_loss': 0.002033233642578125, 'train/mask_bce_loss': 0.0316990016028285, 'train/mask_dice_loss': 0.07199489362537861, 'train/mask_loss': 0.10369389280676841, 'metrics/total_secs_per_batch': 50.25322127342224, 'metrics/data_secs_per_batch': 22.225837469100952, '_timestamp': 1741692325.6950994}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 45 is less than current step: 499. Dropping entry: {'train/lr': 0.0002940120481927711, '_timestamp': 1741692325.6953762}).
Epoch: [1][ 47/500]	Time 51.109 (51.109)	Loss 0.4884 (0.4271)	CeLoss 0.0493 (0.0480)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0022 (0.0030)	MaskLoss 0.1393 (0.1152)	MaskBCELoss 0.0603 (0.0428)	MaskDICELoss 0.0790 (0.0724)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 46 is less than current step: 499. Dropping entry: {'train/loss': 0.42711823880672456, 'train/ce_loss': 0.048046875, 'train/seg_cls_loss': 0.0016082763671875, 'train/kl_loss': 0.00302734375, 'train/mask_bce_loss': 0.04284662418067455, 'train/mask_dice_loss': 0.07237284702714533, 'train/mask_loss': 0.11521947383880615, 'metrics/total_secs_per_batch': 51.109338998794556, 'metrics/data_secs_per_batch': 22.130910205841065, '_timestamp': 1741692376.8044803}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 46 is less than current step: 499. Dropping entry: {'train/lr': 0.000294, '_timestamp': 1741692376.8047707}).
Epoch: [1][ 48/500]	Time 48.517 (48.517)	Loss 0.4706 (0.3925)	CeLoss 0.0236 (0.0486)	SegCLSLoss 0.0012 (0.0009)	KLLoss 0.0034 (0.0025)	MaskLoss 0.1251 (0.0979)	MaskBCELoss 0.0286 (0.0253)	MaskDICELoss 0.0965 (0.0726)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 47 is less than current step: 499. Dropping entry: {'train/loss': 0.3924823457375169, 'train/ce_loss': 0.04859619140625, 'train/seg_cls_loss': 0.0008878707885742188, 'train/kl_loss': 0.0024505615234375, 'train/mask_bce_loss': 0.025289706885814667, 'train/mask_dice_loss': 0.07260708101093769, 'train/mask_loss': 0.09789678752422333, 'metrics/total_secs_per_batch': 48.517210960388184, 'metrics/data_secs_per_batch': 21.140712213516235, '_timestamp': 1741692425.321772}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 47 is less than current step: 499. Dropping entry: {'train/lr': 0.0002939879518072289, '_timestamp': 1741692425.322237}).
Epoch: [1][ 49/500]	Time 49.463 (49.463)	Loss 0.4972 (0.4200)	CeLoss 0.0571 (0.0469)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0033 (0.0028)	MaskLoss 0.1184 (0.1042)	MaskBCELoss 0.0185 (0.0237)	MaskDICELoss 0.0999 (0.0805)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 48 is less than current step: 499. Dropping entry: {'train/loss': 0.41999300122261046, 'train/ce_loss': 0.04693603515625, 'train/seg_cls_loss': 0.0016237258911132812, 'train/kl_loss': 0.002845001220703125, 'train/mask_bce_loss': 0.02370284472126514, 'train/mask_dice_loss': 0.08050034209154547, 'train/mask_loss': 0.1042031859047711, 'metrics/total_secs_per_batch': 49.46320986747742, 'metrics/data_secs_per_batch': 22.94086663722992, '_timestamp': 1741692474.7860928}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 48 is less than current step: 499. Dropping entry: {'train/lr': 0.0002939759036144578, '_timestamp': 1741692474.7870772}).
Epoch: [1][ 50/500]	Time 51.427 (51.427)	Loss 0.5161 (0.4186)	CeLoss 0.0703 (0.0492)	SegCLSLoss 0.0047 (0.0022)	KLLoss 0.0024 (0.0028)	MaskLoss 0.1334 (0.1057)	MaskBCELoss 0.0462 (0.0286)	MaskDICELoss 0.0872 (0.0771)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 49 is less than current step: 499. Dropping entry: {'train/loss': 0.41863427609205245, 'train/ce_loss': 0.04923095703125, 'train/seg_cls_loss': 0.0021863937377929687, 'train/kl_loss': 0.002843475341796875, 'train/mask_bce_loss': 0.02859937408939004, 'train/mask_dice_loss': 0.07707763016223908, 'train/mask_loss': 0.10567700453102588, 'metrics/total_secs_per_batch': 51.42741537094116, 'metrics/data_secs_per_batch': 23.05357427597046, '_timestamp': 1741692526.212247}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 49 is less than current step: 499. Dropping entry: {'train/lr': 0.00029395180722891563, '_timestamp': 1741692526.2126226}).
Epoch: [1][ 51/500]	Time 46.257 (46.257)	Loss 0.4354 (0.3732)	CeLoss 0.0703 (0.0510)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0033 (0.0026)	MaskLoss 0.0944 (0.0944)	MaskBCELoss 0.0082 (0.0293)	MaskDICELoss 0.0862 (0.0651)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 50 is less than current step: 499. Dropping entry: {'train/loss': 0.37317472249269484, 'train/ce_loss': 0.0509521484375, 'train/seg_cls_loss': 0.001378631591796875, 'train/kl_loss': 0.002559661865234375, 'train/mask_bce_loss': 0.02928973282687366, 'train/mask_dice_loss': 0.06509901024401188, 'train/mask_loss': 0.09438874348998069, 'metrics/total_secs_per_batch': 46.25691628456116, 'metrics/data_secs_per_batch': 21.614755606651308, '_timestamp': 1741692572.4692545}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 50 is less than current step: 499. Dropping entry: {'train/lr': 0.00029393975903614454, '_timestamp': 1741692572.4696856}).
Epoch: [1][ 52/500]	Time 47.131 (47.131)	Loss 0.4419 (0.3612)	CeLoss 0.0242 (0.0283)	SegCLSLoss 0.0020 (0.0023)	KLLoss 0.0039 (0.0029)	MaskLoss 0.1073 (0.0906)	MaskBCELoss 0.0082 (0.0167)	MaskDICELoss 0.0991 (0.0738)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 51 is less than current step: 499. Dropping entry: {'train/loss': 0.36117718229070306, 'train/ce_loss': 0.028302001953125, 'train/seg_cls_loss': 0.0023145675659179688, 'train/kl_loss': 0.002877044677734375, 'train/mask_bce_loss': 0.016743559669703246, 'train/mask_dice_loss': 0.07382193058729172, 'train/mask_loss': 0.09056548848748207, 'metrics/total_secs_per_batch': 47.13129997253418, 'metrics/data_secs_per_batch': 20.919534230232237, '_timestamp': 1741692619.6006167}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 51 is less than current step: 499. Dropping entry: {'train/lr': 0.00029392771084337346, '_timestamp': 1741692619.6010542}).
Epoch: [1][ 53/500]	Time 49.728 (49.728)	Loss 0.5362 (0.4302)	CeLoss 0.0508 (0.0428)	SegCLSLoss 0.0008 (0.0018)	KLLoss 0.0027 (0.0028)	MaskLoss 0.1423 (0.1094)	MaskBCELoss 0.0435 (0.0270)	MaskDICELoss 0.0989 (0.0824)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 52 is less than current step: 499. Dropping entry: {'train/loss': 0.43018696308135984, 'train/ce_loss': 0.04283447265625, 'train/seg_cls_loss': 0.0017877578735351562, 'train/kl_loss': 0.00283203125, 'train/mask_bce_loss': 0.02697946606203914, 'train/mask_dice_loss': 0.0824066162109375, 'train/mask_loss': 0.10938608385622502, 'metrics/total_secs_per_batch': 49.72849750518799, 'metrics/data_secs_per_batch': 22.524749302864073, '_timestamp': 1741692669.32915}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 52 is less than current step: 499. Dropping entry: {'train/lr': 0.00029391566265060237, '_timestamp': 1741692669.329443}).
Epoch: [1][ 54/500]	Time 48.147 (48.147)	Loss 0.4049 (0.3663)	CeLoss 0.0444 (0.0419)	SegCLSLoss 0.0041 (0.0021)	KLLoss 0.0044 (0.0034)	MaskLoss 0.1050 (0.0893)	MaskBCELoss 0.0330 (0.0186)	MaskDICELoss 0.0720 (0.0707)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 53 is less than current step: 499. Dropping entry: {'train/loss': 0.3662583827972412, 'train/ce_loss': 0.04185791015625, 'train/seg_cls_loss': 0.0021373748779296873, 'train/kl_loss': 0.003400421142578125, 'train/mask_bce_loss': 0.018569551524706185, 'train/mask_dice_loss': 0.07071731826290488, 'train/mask_loss': 0.08928687181323766, 'metrics/total_secs_per_batch': 48.146734952926636, 'metrics/data_secs_per_batch': 21.0866760969162, '_timestamp': 1741692717.4758542}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 53 is less than current step: 499. Dropping entry: {'train/lr': 0.00029390361445783133, '_timestamp': 1741692717.476274}).
Epoch: [1][ 55/500]	Time 47.275 (47.275)	Loss 0.4707 (0.3713)	CeLoss 0.0559 (0.0389)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0023 (0.0023)	MaskLoss 0.1076 (0.0979)	MaskBCELoss 0.0091 (0.0312)	MaskDICELoss 0.0985 (0.0668)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 54 is less than current step: 499. Dropping entry: {'train/loss': 0.3713123336434364, 'train/ce_loss': 0.03890380859375, 'train/seg_cls_loss': 0.001397705078125, 'train/kl_loss': 0.00231475830078125, 'train/mask_bce_loss': 0.031150979548692705, 'train/mask_dice_loss': 0.06677163429558278, 'train/mask_loss': 0.09792261309921742, 'metrics/total_secs_per_batch': 47.274893283843994, 'metrics/data_secs_per_batch': 20.38189787864685, '_timestamp': 1741692764.7520897}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 54 is less than current step: 499. Dropping entry: {'train/lr': 0.00029389156626506024, '_timestamp': 1741692764.7531352}).
Epoch: [1][ 56/500]	Time 49.768 (49.768)	Loss 0.2708 (0.4309)	CeLoss 0.0386 (0.0520)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0020 (0.0026)	MaskLoss 0.0615 (0.1039)	MaskBCELoss 0.0079 (0.0200)	MaskDICELoss 0.0536 (0.0840)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 55 is less than current step: 499. Dropping entry: {'train/loss': 0.43094556480646135, 'train/ce_loss': 0.05201416015625, 'train/seg_cls_loss': 0.0010831832885742187, 'train/kl_loss': 0.0026275634765625, 'train/mask_bce_loss': 0.01995537825860083, 'train/mask_dice_loss': 0.08397940285503865, 'train/mask_loss': 0.10393477976322174, 'metrics/total_secs_per_batch': 49.768351316452026, 'metrics/data_secs_per_batch': 22.161503672599792, '_timestamp': 1741692814.5191793}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 55 is less than current step: 499. Dropping entry: {'train/lr': 0.00029387951807228915, '_timestamp': 1741692814.51962}).
Epoch: [1][ 57/500]	Time 41.265 (41.265)	Loss 0.4172 (0.3889)	CeLoss 0.0850 (0.0396)	SegCLSLoss 0.0041 (0.0021)	KLLoss 0.0027 (0.0027)	MaskLoss 0.0934 (0.0988)	MaskBCELoss 0.0231 (0.0248)	MaskDICELoss 0.0703 (0.0740)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 56 is less than current step: 499. Dropping entry: {'train/loss': 0.3889221716672182, 'train/ce_loss': 0.03958740234375, 'train/seg_cls_loss': 0.00206298828125, 'train/kl_loss': 0.002679443359375, 'train/mask_bce_loss': 0.024757073447108268, 'train/mask_dice_loss': 0.07402192875742912, 'train/mask_loss': 0.0987790010869503, 'metrics/total_secs_per_batch': 41.264803409576416, 'metrics/data_secs_per_batch': 20.051239943504335, '_timestamp': 1741692855.7838857}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 56 is less than current step: 499. Dropping entry: {'train/lr': 0.00029386746987951806, '_timestamp': 1741692855.7842896}).
Epoch: [1][ 58/500]	Time 47.126 (47.126)	Loss 0.4905 (0.3152)	CeLoss 0.0266 (0.0379)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0022 (0.0033)	MaskLoss 0.1621 (0.0812)	MaskBCELoss 0.0939 (0.0258)	MaskDICELoss 0.0682 (0.0554)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 57 is less than current step: 499. Dropping entry: {'train/loss': 0.3152261212468147, 'train/ce_loss': 0.0378662109375, 'train/seg_cls_loss': 0.0014902114868164062, 'train/kl_loss': 0.00330810546875, 'train/mask_bce_loss': 0.025845113629475235, 'train/mask_dice_loss': 0.055400572903454307, 'train/mask_loss': 0.08124568536877633, 'metrics/total_secs_per_batch': 47.125776529312134, 'metrics/data_secs_per_batch': 21.016904044151307, '_timestamp': 1741692902.9096406}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 57 is less than current step: 499. Dropping entry: {'train/lr': 0.000293855421686747, '_timestamp': 1741692902.910068}).
Epoch: [1][ 59/500]	Time 40.297 (40.297)	Loss 0.5423 (0.4740)	CeLoss 0.0640 (0.0545)	SegCLSLoss 0.0005 (0.0030)	KLLoss 0.0039 (0.0035)	MaskLoss 0.1381 (0.1178)	MaskBCELoss 0.0393 (0.0283)	MaskDICELoss 0.0988 (0.0895)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 58 is less than current step: 499. Dropping entry: {'train/loss': 0.4740363985300064, 'train/ce_loss': 0.0544921875, 'train/seg_cls_loss': 0.0030071258544921873, 'train/kl_loss': 0.003533935546875, 'train/mask_bce_loss': 0.028296415321528913, 'train/mask_dice_loss': 0.08947808146476746, 'train/mask_loss': 0.11777449622750283, 'metrics/total_secs_per_batch': 40.296714544296265, 'metrics/data_secs_per_batch': 18.705876111984253, '_timestamp': 1741692943.2064164}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 58 is less than current step: 499. Dropping entry: {'train/lr': 0.0002938433734939759, '_timestamp': 1741692943.206694}).
Epoch: [1][ 60/500]	Time 47.003 (47.003)	Loss 0.4497 (0.4033)	CeLoss 0.0239 (0.0385)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0036 (0.0029)	MaskLoss 0.1266 (0.1064)	MaskBCELoss 0.0424 (0.0322)	MaskDICELoss 0.0842 (0.0742)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 59 is less than current step: 499. Dropping entry: {'train/loss': 0.40325070917606354, 'train/ce_loss': 0.0385009765625, 'train/seg_cls_loss': 0.0014562606811523438, 'train/kl_loss': 0.00292816162109375, 'train/mask_bce_loss': 0.03218455165624619, 'train/mask_dice_loss': 0.07418329222127795, 'train/mask_loss': 0.10636784341186285, 'metrics/total_secs_per_batch': 47.00308918952942, 'metrics/data_secs_per_batch': 21.024329805374144, '_timestamp': 1741692990.2094464}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 59 is less than current step: 499. Dropping entry: {'train/lr': 0.0002938192771084337, '_timestamp': 1741692990.209835}).
Epoch: [1][ 61/500]	Time 52.160 (52.160)	Loss 0.2640 (0.3405)	CeLoss 0.0286 (0.0433)	SegCLSLoss 0.0016 (0.0018)	KLLoss 0.0033 (0.0024)	MaskLoss 0.0697 (0.0811)	MaskBCELoss 0.0236 (0.0152)	MaskDICELoss 0.0460 (0.0659)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 60 is less than current step: 499. Dropping entry: {'train/loss': 0.3404935199767351, 'train/ce_loss': 0.04332275390625, 'train/seg_cls_loss': 0.0018245697021484375, 'train/kl_loss': 0.00242156982421875, 'train/mask_bce_loss': 0.015216667391359805, 'train/mask_dice_loss': 0.06585244797170162, 'train/mask_loss': 0.08106911405920983, 'metrics/total_secs_per_batch': 52.160223960876465, 'metrics/data_secs_per_batch': 23.758117866516113, '_timestamp': 1741693042.3698611}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 60 is less than current step: 499. Dropping entry: {'train/lr': 0.0002938072289156626, '_timestamp': 1741693042.3701675}).
Epoch: [1][ 62/500]	Time 49.713 (49.713)	Loss 0.4694 (0.4311)	CeLoss 0.0693 (0.0492)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0025 (0.0026)	MaskLoss 0.1083 (0.1069)	MaskBCELoss 0.0178 (0.0245)	MaskDICELoss 0.0905 (0.0824)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 61 is less than current step: 499. Dropping entry: {'train/loss': 0.43111990094184877, 'train/ce_loss': 0.0491943359375, 'train/seg_cls_loss': 0.001271820068359375, 'train/kl_loss': 0.00261688232421875, 'train/mask_bce_loss': 0.024453244614414872, 'train/mask_dice_loss': 0.08244300242513418, 'train/mask_loss': 0.10689624901860953, 'metrics/total_secs_per_batch': 49.71257734298706, 'metrics/data_secs_per_batch': 21.12826814651489, '_timestamp': 1741693092.0823946}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 61 is less than current step: 499. Dropping entry: {'train/lr': 0.00029379518072289153, '_timestamp': 1741693092.0828297}).
Epoch: [1][ 63/500]	Time 50.081 (50.081)	Loss 0.0988 (0.3032)	CeLoss 0.0723 (0.0372)	SegCLSLoss 0.0006 (0.0018)	KLLoss 0.0051 (0.0026)	MaskLoss 0.0077 (0.0736)	MaskBCELoss 0.0048 (0.0159)	MaskDICELoss 0.0029 (0.0577)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 62 is less than current step: 499. Dropping entry: {'train/loss': 0.30318425986915826, 'train/ce_loss': 0.0372314453125, 'train/seg_cls_loss': 0.0017538070678710938, 'train/kl_loss': 0.0026031494140625, 'train/mask_bce_loss': 0.015891645895317198, 'train/mask_dice_loss': 0.05765981189906597, 'train/mask_loss': 0.07355145998299122, 'metrics/total_secs_per_batch': 50.08103585243225, 'metrics/data_secs_per_batch': 22.985585165023803, '_timestamp': 1741693142.1633155}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 62 is less than current step: 499. Dropping entry: {'train/lr': 0.00029378313253012044, '_timestamp': 1741693142.1637156}).
Epoch: [1][ 64/500]	Time 53.256 (53.256)	Loss 0.4565 (0.4368)	CeLoss 0.0276 (0.0393)	SegCLSLoss 0.0019 (0.0019)	KLLoss 0.0022 (0.0031)	MaskLoss 0.1145 (0.1094)	MaskBCELoss 0.0161 (0.0221)	MaskDICELoss 0.0984 (0.0873)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 63 is less than current step: 499. Dropping entry: {'train/loss': 0.43677937388420107, 'train/ce_loss': 0.039276123046875, 'train/seg_cls_loss': 0.0018827438354492188, 'train/kl_loss': 0.0030670166015625, 'train/mask_bce_loss': 0.022131665889173747, 'train/mask_dice_loss': 0.08731357865035534, 'train/mask_loss': 0.1094452440738678, 'metrics/total_secs_per_batch': 53.255653858184814, 'metrics/data_secs_per_batch': 24.52044813632965, '_timestamp': 1741693195.4189727}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 63 is less than current step: 499. Dropping entry: {'train/lr': 0.00029377108433734935, '_timestamp': 1741693195.41925}).
Epoch: [1][ 65/500]	Time 46.510 (46.510)	Loss 0.4682 (0.4184)	CeLoss 0.0554 (0.0413)	SegCLSLoss 0.0021 (0.0021)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1042 (0.1047)	MaskBCELoss 0.0042 (0.0229)	MaskDICELoss 0.1000 (0.0818)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 64 is less than current step: 499. Dropping entry: {'train/loss': 0.4184007704257965, 'train/ce_loss': 0.041302490234375, 'train/seg_cls_loss': 0.002117156982421875, 'train/kl_loss': 0.003167724609375, 'train/mask_bce_loss': 0.022914591198787092, 'train/mask_dice_loss': 0.08177570682018995, 'train/mask_loss': 0.1046902984380722, 'metrics/total_secs_per_batch': 46.51026463508606, 'metrics/data_secs_per_batch': 21.116233396530152, '_timestamp': 1741693241.9292307}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 64 is less than current step: 499. Dropping entry: {'train/lr': 0.00029375903614457826, '_timestamp': 1741693241.9295018}).
Epoch: [1][ 66/500]	Time 46.222 (46.222)	Loss 0.4626 (0.4690)	CeLoss 0.0454 (0.0497)	SegCLSLoss 0.0012 (0.0018)	KLLoss 0.0031 (0.0036)	MaskLoss 0.1072 (0.1230)	MaskBCELoss 0.0076 (0.0386)	MaskDICELoss 0.0995 (0.0844)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 65 is less than current step: 499. Dropping entry: {'train/loss': 0.4689611613750458, 'train/ce_loss': 0.04971923828125, 'train/seg_cls_loss': 0.00175628662109375, 'train/kl_loss': 0.0035736083984375, 'train/mask_bce_loss': 0.03861835170537233, 'train/mask_dice_loss': 0.08439596109092236, 'train/mask_loss': 0.12301431261003018, 'metrics/total_secs_per_batch': 46.22213268280029, 'metrics/data_secs_per_batch': 19.845974159240722, '_timestamp': 1741693288.152536}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 65 is less than current step: 499. Dropping entry: {'train/lr': 0.0002937469879518072, '_timestamp': 1741693288.153552}).
Epoch: [1][ 67/500]	Time 46.379 (46.379)	Loss 0.4516 (0.3710)	CeLoss 0.0405 (0.0542)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0030 (0.0037)	MaskLoss 0.1147 (0.0856)	MaskBCELoss 0.0256 (0.0151)	MaskDICELoss 0.0891 (0.0706)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 66 is less than current step: 499. Dropping entry: {'train/loss': 0.37101051285862924, 'train/ce_loss': 0.054150390625, 'train/seg_cls_loss': 0.0014787673950195312, 'train/kl_loss': 0.003734588623046875, 'train/mask_bce_loss': 0.015090792928822339, 'train/mask_dice_loss': 0.0705587946344167, 'train/mask_loss': 0.08564958786591888, 'metrics/total_secs_per_batch': 46.37889385223389, 'metrics/data_secs_per_batch': 20.626680397987364, '_timestamp': 1741693334.5314746}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 66 is less than current step: 499. Dropping entry: {'train/lr': 0.00029373493975903614, '_timestamp': 1741693334.5324457}).
Epoch: [1][ 68/500]	Time 48.825 (48.825)	Loss 0.2308 (0.3678)	CeLoss 0.0908 (0.0551)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0035 (0.0039)	MaskLoss 0.0376 (0.0866)	MaskBCELoss 0.0073 (0.0191)	MaskDICELoss 0.0303 (0.0675)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 67 is less than current step: 499. Dropping entry: {'train/loss': 0.367814963310957, 'train/ce_loss': 0.0550537109375, 'train/seg_cls_loss': 0.0012186050415039062, 'train/kl_loss': 0.00385894775390625, 'train/mask_bce_loss': 0.019131568691227584, 'train/mask_dice_loss': 0.06750514466548338, 'train/mask_loss': 0.08663671223912388, 'metrics/total_secs_per_batch': 48.82537317276001, 'metrics/data_secs_per_batch': 22.77211813926697, '_timestamp': 1741693383.3557034}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 67 is less than current step: 499. Dropping entry: {'train/lr': 0.00029372289156626505, '_timestamp': 1741693383.3559883}).
Epoch: [1][ 69/500]	Time 52.152 (52.152)	Loss 0.2811 (0.3308)	CeLoss 0.0554 (0.0358)	SegCLSLoss 0.0029 (0.0019)	KLLoss 0.0039 (0.0022)	MaskLoss 0.0686 (0.0842)	MaskBCELoss 0.0271 (0.0224)	MaskDICELoss 0.0415 (0.0618)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 68 is less than current step: 499. Dropping entry: {'train/loss': 0.33076241221278907, 'train/ce_loss': 0.03575439453125, 'train/seg_cls_loss': 0.0018566131591796875, 'train/kl_loss': 0.002155303955078125, 'train/mask_bce_loss': 0.022385495016351342, 'train/mask_dice_loss': 0.06178594119846821, 'train/mask_loss': 0.08417143858969212, 'metrics/total_secs_per_batch': 52.152326583862305, 'metrics/data_secs_per_batch': 24.400230288505554, '_timestamp': 1741693435.5080051}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 68 is less than current step: 499. Dropping entry: {'train/lr': 0.00029371084337349396, '_timestamp': 1741693435.50828}).
Epoch: [1][ 70/500]	Time 48.838 (48.838)	Loss 0.4313 (0.3118)	CeLoss 0.0216 (0.0451)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0018 (0.0023)	MaskLoss 0.1041 (0.0709)	MaskBCELoss 0.0046 (0.0100)	MaskDICELoss 0.0995 (0.0609)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 69 is less than current step: 499. Dropping entry: {'train/loss': 0.3117959413677454, 'train/ce_loss': 0.045068359375, 'train/seg_cls_loss': 0.0014863967895507812, 'train/kl_loss': 0.002327728271484375, 'train/mask_bce_loss': 0.009997702459804714, 'train/mask_dice_loss': 0.06092620827257633, 'train/mask_loss': 0.07092390931211412, 'metrics/total_secs_per_batch': 48.83817744255066, 'metrics/data_secs_per_batch': 21.671247816085817, '_timestamp': 1741693484.346258}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 69 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936867469879518, '_timestamp': 1741693484.3465388}).
Epoch: [1][ 71/500]	Time 48.509 (48.509)	Loss 0.4761 (0.3391)	CeLoss 0.0405 (0.0433)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0013 (0.0024)	MaskLoss 0.1171 (0.0805)	MaskBCELoss 0.0171 (0.0147)	MaskDICELoss 0.1000 (0.0658)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 70 is less than current step: 499. Dropping entry: {'train/loss': 0.33906028866767884, 'train/ce_loss': 0.0432861328125, 'train/seg_cls_loss': 0.0015880584716796875, 'train/kl_loss': 0.002381134033203125, 'train/mask_bce_loss': 0.014662117150146514, 'train/mask_dice_loss': 0.06583733228035271, 'train/mask_loss': 0.08049944750964641, 'metrics/total_secs_per_batch': 48.50947070121765, 'metrics/data_secs_per_batch': 21.309178280830384, '_timestamp': 1741693532.8571095}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 70 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936746987951807, '_timestamp': 1741693532.858242}).
Epoch: [1][ 72/500]	Time 47.781 (47.781)	Loss 0.2930 (0.3989)	CeLoss 0.0786 (0.0555)	SegCLSLoss 0.0005 (0.0051)	KLLoss 0.0016 (0.0028)	MaskLoss 0.0607 (0.0954)	MaskBCELoss 0.0152 (0.0218)	MaskDICELoss 0.0455 (0.0736)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 71 is less than current step: 499. Dropping entry: {'train/loss': 0.39894096106290816, 'train/ce_loss': 0.055517578125, 'train/seg_cls_loss': 0.00509033203125, 'train/kl_loss': 0.002825927734375, 'train/mask_bce_loss': 0.021847172081470488, 'train/mask_dice_loss': 0.0735797207802534, 'train/mask_loss': 0.09542689248919486, 'metrics/total_secs_per_batch': 47.78116059303284, 'metrics/data_secs_per_batch': 21.458362650871276, '_timestamp': 1741693580.6369016}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 71 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936626506024096, '_timestamp': 1741693580.6371896}).
Epoch: [1][ 73/500]	Time 49.402 (49.402)	Loss 0.4408 (0.4011)	CeLoss 0.0359 (0.0404)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0020 (0.0033)	MaskLoss 0.1017 (0.1020)	MaskBCELoss 0.0020 (0.0256)	MaskDICELoss 0.0996 (0.0764)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 72 is less than current step: 499. Dropping entry: {'train/loss': 0.40109870582818985, 'train/ce_loss': 0.04039306640625, 'train/seg_cls_loss': 0.0012752532958984375, 'train/kl_loss': 0.003275299072265625, 'train/mask_bce_loss': 0.025632220617262648, 'train/mask_dice_loss': 0.076389230042696, 'train/mask_loss': 0.10202145390212536, 'metrics/total_secs_per_batch': 49.401700258255005, 'metrics/data_secs_per_batch': 20.11150281429291, '_timestamp': 1741693630.0385633}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 72 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936506024096385, '_timestamp': 1741693630.038849}).
Epoch: [1][ 74/500]	Time 48.549 (48.549)	Loss 0.4015 (0.3898)	CeLoss 0.0270 (0.0362)	SegCLSLoss 0.0022 (0.0023)	KLLoss 0.0053 (0.0032)	MaskLoss 0.0932 (0.1002)	MaskBCELoss 0.0023 (0.0258)	MaskDICELoss 0.0909 (0.0744)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 73 is less than current step: 499. Dropping entry: {'train/loss': 0.3898116897791624, 'train/ce_loss': 0.0361572265625, 'train/seg_cls_loss': 0.0023057937622070314, 'train/kl_loss': 0.00316619873046875, 'train/mask_bce_loss': 0.025794043391942977, 'train/mask_dice_loss': 0.07442894950509071, 'train/mask_loss': 0.10022299066185951, 'metrics/total_secs_per_batch': 48.54890751838684, 'metrics/data_secs_per_batch': 22.759943199157714, '_timestamp': 1741693678.5875423}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 73 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936385542168674, '_timestamp': 1741693678.5878377}).
Epoch: [1][ 75/500]	Time 47.513 (47.513)	Loss 0.2231 (0.3631)	CeLoss 0.0247 (0.0436)	SegCLSLoss 0.0026 (0.0013)	KLLoss 0.0017 (0.0032)	MaskLoss 0.0510 (0.0863)	MaskBCELoss 0.0044 (0.0148)	MaskDICELoss 0.0466 (0.0715)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 74 is less than current step: 499. Dropping entry: {'train/loss': 0.363090755417943, 'train/ce_loss': 0.04364013671875, 'train/seg_cls_loss': 0.0012897491455078126, 'train/kl_loss': 0.0032135009765625, 'train/mask_bce_loss': 0.014832023764029145, 'train/mask_dice_loss': 0.07148411720991135, 'train/mask_loss': 0.08631614111363888, 'metrics/total_secs_per_batch': 47.51279282569885, 'metrics/data_secs_per_batch': 22.28904745578766, '_timestamp': 1741693726.1003118}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 74 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936265060240964, '_timestamp': 1741693726.100591}).
Epoch: [1][ 76/500]	Time 48.473 (48.473)	Loss 0.6204 (0.3714)	CeLoss 0.0688 (0.0488)	SegCLSLoss 0.0014 (0.0017)	KLLoss 0.0038 (0.0024)	MaskLoss 0.1754 (0.0915)	MaskBCELoss 0.0774 (0.0233)	MaskDICELoss 0.0981 (0.0681)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 75 is less than current step: 499. Dropping entry: {'train/loss': 0.37135639153420924, 'train/ce_loss': 0.04879150390625, 'train/seg_cls_loss': 0.001749420166015625, 'train/kl_loss': 0.002391815185546875, 'train/mask_bce_loss': 0.0233424554055091, 'train/mask_dice_loss': 0.06814541034400463, 'train/mask_loss': 0.09148786189034581, 'metrics/total_secs_per_batch': 48.47260665893555, 'metrics/data_secs_per_batch': 21.48998625278473, '_timestamp': 1741693774.5742207}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 75 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936144578313253, '_timestamp': 1741693774.5752802}).
Epoch: [1][ 77/500]	Time 49.376 (49.376)	Loss 0.4199 (0.4547)	CeLoss 0.0630 (0.0392)	SegCLSLoss 0.0013 (0.0020)	KLLoss 0.0031 (0.0029)	MaskLoss 0.0926 (0.1164)	MaskBCELoss 0.0086 (0.0270)	MaskDICELoss 0.0840 (0.0894)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 76 is less than current step: 499. Dropping entry: {'train/loss': 0.45473321080207824, 'train/ce_loss': 0.03922119140625, 'train/seg_cls_loss': 0.0019763946533203126, 'train/kl_loss': 0.00289154052734375, 'train/mask_bce_loss': 0.026954152062535285, 'train/mask_dice_loss': 0.08942986279726028, 'train/mask_loss': 0.11638401225209236, 'metrics/total_secs_per_batch': 49.37574052810669, 'metrics/data_secs_per_batch': 22.574314403533936, '_timestamp': 1741693823.9486477}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 76 is less than current step: 499. Dropping entry: {'train/lr': 0.0002936024096385542, '_timestamp': 1741693823.9489346}).
Epoch: [1][ 78/500]	Time 45.056 (45.056)	Loss 0.4821 (0.3707)	CeLoss 0.0708 (0.0628)	SegCLSLoss 0.0015 (0.0017)	KLLoss 0.0037 (0.0034)	MaskLoss 0.1154 (0.0858)	MaskBCELoss 0.0273 (0.0198)	MaskDICELoss 0.0880 (0.0660)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 77 is less than current step: 499. Dropping entry: {'train/loss': 0.3707259126007557, 'train/ce_loss': 0.06275634765625, 'train/seg_cls_loss': 0.00166473388671875, 'train/kl_loss': 0.00343170166015625, 'train/mask_bce_loss': 0.01976619167253375, 'train/mask_dice_loss': 0.06604057028889657, 'train/mask_loss': 0.08580676261335611, 'metrics/total_secs_per_batch': 45.05647921562195, 'metrics/data_secs_per_batch': 19.33255033493042, '_timestamp': 1741693869.0051348}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 77 is less than current step: 499. Dropping entry: {'train/lr': 0.0002935903614457831, '_timestamp': 1741693869.0054045}).
Epoch: [1][ 79/500]	Time 48.895 (48.895)	Loss 0.1362 (0.4488)	CeLoss 0.0204 (0.0336)	SegCLSLoss 0.0092 (0.0025)	KLLoss 0.0031 (0.0030)	MaskLoss 0.0313 (0.1211)	MaskBCELoss 0.0085 (0.0368)	MaskDICELoss 0.0228 (0.0843)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 78 is less than current step: 499. Dropping entry: {'train/loss': 0.44875160455703733, 'train/ce_loss': 0.0336181640625, 'train/seg_cls_loss': 0.00245361328125, 'train/kl_loss': 0.00295257568359375, 'train/mask_bce_loss': 0.03676895657554269, 'train/mask_dice_loss': 0.08434541188180447, 'train/mask_loss': 0.12111436761915684, 'metrics/total_secs_per_batch': 48.89470410346985, 'metrics/data_secs_per_batch': 22.120618748664857, '_timestamp': 1741693917.8999298}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 78 is less than current step: 499. Dropping entry: {'train/lr': 0.00029357831325301203, '_timestamp': 1741693917.9002233}).
Epoch: [1][ 80/500]	Time 44.541 (44.541)	Loss 0.3293 (0.4168)	CeLoss 0.0459 (0.0457)	SegCLSLoss 0.0004 (0.0024)	KLLoss 0.0044 (0.0034)	MaskLoss 0.0718 (0.1001)	MaskBCELoss 0.0041 (0.0170)	MaskDICELoss 0.0676 (0.0831)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 79 is less than current step: 499. Dropping entry: {'train/loss': 0.4168431550264359, 'train/ce_loss': 0.04571533203125, 'train/seg_cls_loss': 0.0023712158203125, 'train/kl_loss': 0.0034423828125, 'train/mask_bce_loss': 0.01699690616223961, 'train/mask_dice_loss': 0.08312444481998682, 'train/mask_loss': 0.10012135244905948, 'metrics/total_secs_per_batch': 44.541239738464355, 'metrics/data_secs_per_batch': 19.377978110313414, '_timestamp': 1741693962.4412236}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 79 is less than current step: 499. Dropping entry: {'train/lr': 0.00029355421686746985, '_timestamp': 1741693962.4414737}).
Epoch: [1][ 81/500]	Time 48.682 (48.682)	Loss 0.4975 (0.3636)	CeLoss 0.0493 (0.0546)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0019 (0.0023)	MaskLoss 0.1315 (0.0949)	MaskBCELoss 0.0402 (0.0368)	MaskDICELoss 0.0913 (0.0581)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 80 is less than current step: 499. Dropping entry: {'train/loss': 0.36360937654972075, 'train/ce_loss': 0.054638671875, 'train/seg_cls_loss': 0.0013349533081054687, 'train/kl_loss': 0.002323150634765625, 'train/mask_bce_loss': 0.03684937092475593, 'train/mask_dice_loss': 0.05805139001458883, 'train/mask_loss': 0.09490076191723347, 'metrics/total_secs_per_batch': 48.682425022125244, 'metrics/data_secs_per_batch': 21.334934377670287, '_timestamp': 1741694011.123643}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 80 is less than current step: 499. Dropping entry: {'train/lr': 0.00029354216867469876, '_timestamp': 1741694011.1239443}).
Epoch: [1][ 82/500]	Time 42.315 (42.315)	Loss 0.3245 (0.4227)	CeLoss 0.0967 (0.0467)	SegCLSLoss 0.0120 (0.0026)	KLLoss 0.0049 (0.0029)	MaskLoss 0.0657 (0.1010)	MaskBCELoss 0.0231 (0.0160)	MaskDICELoss 0.0426 (0.0850)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 81 is less than current step: 499. Dropping entry: {'train/loss': 0.4227280914783478, 'train/ce_loss': 0.04671630859375, 'train/seg_cls_loss': 0.002562713623046875, 'train/kl_loss': 0.00286102294921875, 'train/mask_bce_loss': 0.0159824134549126, 'train/mask_dice_loss': 0.08497109040617942, 'train/mask_loss': 0.10095350369811058, 'metrics/total_secs_per_batch': 42.31498885154724, 'metrics/data_secs_per_batch': 20.00972716808319, '_timestamp': 1741694053.4385774}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 81 is less than current step: 499. Dropping entry: {'train/lr': 0.0002935301204819277, '_timestamp': 1741694053.4389005}).
Epoch: [1][ 83/500]	Time 48.760 (48.760)	Loss 0.3683 (0.3564)	CeLoss 0.0659 (0.0366)	SegCLSLoss 0.0023 (0.0017)	KLLoss 0.0019 (0.0023)	MaskLoss 0.0856 (0.0911)	MaskBCELoss 0.0216 (0.0239)	MaskDICELoss 0.0640 (0.0672)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 82 is less than current step: 499. Dropping entry: {'train/loss': 0.35640966836363075, 'train/ce_loss': 0.0366455078125, 'train/seg_cls_loss': 0.001729583740234375, 'train/kl_loss': 0.00225677490234375, 'train/mask_bce_loss': 0.02391881535295397, 'train/mask_dice_loss': 0.06718207076191902, 'train/mask_loss': 0.09110088795423507, 'metrics/total_secs_per_batch': 48.75970387458801, 'metrics/data_secs_per_batch': 23.77129406929016, '_timestamp': 1741694102.1997328}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 82 is less than current step: 499. Dropping entry: {'train/lr': 0.0002935180722891566, '_timestamp': 1741694102.2008076}).
Epoch: [1][ 84/500]	Time 46.076 (46.076)	Loss 0.2718 (0.3136)	CeLoss 0.0236 (0.0338)	SegCLSLoss 0.0040 (0.0019)	KLLoss 0.0049 (0.0030)	MaskLoss 0.0712 (0.0763)	MaskBCELoss 0.0218 (0.0147)	MaskDICELoss 0.0494 (0.0617)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 83 is less than current step: 499. Dropping entry: {'train/loss': 0.3136356107890606, 'train/ce_loss': 0.03375244140625, 'train/seg_cls_loss': 0.001888275146484375, 'train/kl_loss': 0.00295867919921875, 'train/mask_bce_loss': 0.01468001060129609, 'train/mask_dice_loss': 0.061662159487605096, 'train/mask_loss': 0.0763421718031168, 'metrics/total_secs_per_batch': 46.07616376876831, 'metrics/data_secs_per_batch': 19.900108790397645, '_timestamp': 1741694148.2745113}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 83 is less than current step: 499. Dropping entry: {'train/lr': 0.0002935060240963855, '_timestamp': 1741694148.2748418}).
Epoch: [1][ 85/500]	Time 47.734 (47.734)	Loss 0.4763 (0.3541)	CeLoss 0.0674 (0.0364)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0019 (0.0031)	MaskLoss 0.1177 (0.0843)	MaskBCELoss 0.0320 (0.0116)	MaskDICELoss 0.0857 (0.0727)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 84 is less than current step: 499. Dropping entry: {'train/loss': 0.35409800335764885, 'train/ce_loss': 0.03641357421875, 'train/seg_cls_loss': 0.0011409759521484376, 'train/kl_loss': 0.00312347412109375, 'train/mask_bce_loss': 0.011598750890698284, 'train/mask_dice_loss': 0.07269094616640359, 'train/mask_loss': 0.08428969564847648, 'metrics/total_secs_per_batch': 47.73353362083435, 'metrics/data_secs_per_batch': 20.639229321479796, '_timestamp': 1741694196.0080516}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 84 is less than current step: 499. Dropping entry: {'train/lr': 0.0002934939759036144, '_timestamp': 1741694196.008347}).
Epoch: [1][ 86/500]	Time 46.218 (46.218)	Loss 0.4805 (0.4382)	CeLoss 0.0708 (0.0568)	SegCLSLoss 0.0011 (0.0017)	KLLoss 0.0032 (0.0031)	MaskLoss 0.1264 (0.1093)	MaskBCELoss 0.0497 (0.0299)	MaskDICELoss 0.0767 (0.0794)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 85 is less than current step: 499. Dropping entry: {'train/loss': 0.43816103637218473, 'train/ce_loss': 0.0567626953125, 'train/seg_cls_loss': 0.0017070770263671875, 'train/kl_loss': 0.003082275390625, 'train/mask_bce_loss': 0.029906048346310853, 'train/mask_dice_loss': 0.07941145300865174, 'train/mask_loss': 0.10931750163435935, 'metrics/total_secs_per_batch': 46.21831703186035, 'metrics/data_secs_per_batch': 20.97000160217285, '_timestamp': 1741694242.2262757}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 85 is less than current step: 499. Dropping entry: {'train/lr': 0.00029348192771084337, '_timestamp': 1741694242.226552}).
Epoch: [1][ 87/500]	Time 48.409 (48.409)	Loss 0.4026 (0.4121)	CeLoss 0.0287 (0.0469)	SegCLSLoss 0.0008 (0.0017)	KLLoss 0.0047 (0.0043)	MaskLoss 0.1105 (0.0982)	MaskBCELoss 0.0367 (0.0165)	MaskDICELoss 0.0739 (0.0818)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 86 is less than current step: 499. Dropping entry: {'train/loss': 0.41212058514356614, 'train/ce_loss': 0.0469482421875, 'train/seg_cls_loss': 0.001697540283203125, 'train/kl_loss': 0.00427703857421875, 'train/mask_bce_loss': 0.01645918021094985, 'train/mask_dice_loss': 0.08176833018660545, 'train/mask_loss': 0.09822751022875309, 'metrics/total_secs_per_batch': 48.408825159072876, 'metrics/data_secs_per_batch': 21.979416060447694, '_timestamp': 1741694290.6350913}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 86 is less than current step: 499. Dropping entry: {'train/lr': 0.0002934698795180723, '_timestamp': 1741694290.6353567}).
Epoch: [1][ 88/500]	Time 48.675 (48.675)	Loss 0.2746 (0.4385)	CeLoss 0.0354 (0.0486)	SegCLSLoss 0.0008 (0.0018)	KLLoss 0.0036 (0.0029)	MaskLoss 0.0623 (0.1153)	MaskBCELoss 0.0071 (0.0375)	MaskDICELoss 0.0552 (0.0778)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 87 is less than current step: 499. Dropping entry: {'train/loss': 0.438467213511467, 'train/ce_loss': 0.0485595703125, 'train/seg_cls_loss': 0.0017726898193359375, 'train/kl_loss': 0.00291290283203125, 'train/mask_bce_loss': 0.03752884530695155, 'train/mask_dice_loss': 0.07777132242918014, 'train/mask_loss': 0.11530016884207725, 'metrics/total_secs_per_batch': 48.67458891868591, 'metrics/data_secs_per_batch': 22.37649009227753, '_timestamp': 1741694339.3109756}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 87 is less than current step: 499. Dropping entry: {'train/lr': 0.0002934578313253012, '_timestamp': 1741694339.3120742}).
Epoch: [1][ 89/500]	Time 44.358 (44.358)	Loss 0.5043 (0.4333)	CeLoss 0.0830 (0.0545)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0025 (0.0035)	MaskLoss 0.1317 (0.1116)	MaskBCELoss 0.0546 (0.0359)	MaskDICELoss 0.0771 (0.0757)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 88 is less than current step: 499. Dropping entry: {'train/loss': 0.43325318694114684, 'train/ce_loss': 0.0544921875, 'train/seg_cls_loss': 0.0013515472412109375, 'train/kl_loss': 0.00354156494140625, 'train/mask_bce_loss': 0.035911038308404385, 'train/mask_dice_loss': 0.07566539607942105, 'train/mask_loss': 0.11157643496990204, 'metrics/total_secs_per_batch': 44.357585191726685, 'metrics/data_secs_per_batch': 20.33188638687134, '_timestamp': 1741694383.6673667}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 88 is less than current step: 499. Dropping entry: {'train/lr': 0.0002934457831325301, '_timestamp': 1741694383.6676533}).
Epoch: [1][ 90/500]	Time 44.858 (44.858)	Loss 0.4449 (0.3888)	CeLoss 0.0254 (0.0400)	SegCLSLoss 0.0013 (0.0023)	KLLoss 0.0022 (0.0029)	MaskLoss 0.1154 (0.0932)	MaskBCELoss 0.0224 (0.0140)	MaskDICELoss 0.0930 (0.0792)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 89 is less than current step: 499. Dropping entry: {'train/loss': 0.3887724906206131, 'train/ce_loss': 0.04002685546875, 'train/seg_cls_loss': 0.002339935302734375, 'train/kl_loss': 0.00293121337890625, 'train/mask_bce_loss': 0.01401799765881151, 'train/mask_dice_loss': 0.07915385328233242, 'train/mask_loss': 0.09317185170948505, 'metrics/total_secs_per_batch': 44.85782432556152, 'metrics/data_secs_per_batch': 20.165892672538757, '_timestamp': 1741694428.5250702}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 89 is less than current step: 499. Dropping entry: {'train/lr': 0.0002934216867469879, '_timestamp': 1741694428.5253098}).
Epoch: [1][ 91/500]	Time 48.888 (48.888)	Loss 0.5749 (0.4201)	CeLoss 0.0610 (0.0391)	SegCLSLoss 0.0004 (0.0024)	KLLoss 0.0025 (0.0027)	MaskLoss 0.1743 (0.1069)	MaskBCELoss 0.0930 (0.0253)	MaskDICELoss 0.0813 (0.0816)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 90 is less than current step: 499. Dropping entry: {'train/loss': 0.4201012566685677, 'train/ce_loss': 0.0391357421875, 'train/seg_cls_loss': 0.0023777008056640623, 'train/kl_loss': 0.002679443359375, 'train/mask_bce_loss': 0.025321965869807173, 'train/mask_dice_loss': 0.08161237444728613, 'train/mask_loss': 0.10693434327840805, 'metrics/total_secs_per_batch': 48.88760709762573, 'metrics/data_secs_per_batch': 21.650197529792784, '_timestamp': 1741694477.4128137}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 90 is less than current step: 499. Dropping entry: {'train/lr': 0.00029340963855421684, '_timestamp': 1741694477.4131002}).
Epoch: [1][ 92/500]	Time 47.647 (47.647)	Loss 0.1169 (0.3306)	CeLoss 0.0239 (0.0419)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0049 (0.0029)	MaskLoss 0.0322 (0.0836)	MaskBCELoss 0.0207 (0.0245)	MaskDICELoss 0.0114 (0.0591)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 91 is less than current step: 499. Dropping entry: {'train/loss': 0.33060796558856964, 'train/ce_loss': 0.0418701171875, 'train/seg_cls_loss': 0.0012298583984375, 'train/kl_loss': 0.00289306640625, 'train/mask_bce_loss': 0.024499921407550574, 'train/mask_dice_loss': 0.059059256501495835, 'train/mask_loss': 0.0835591796785593, 'metrics/total_secs_per_batch': 47.64725089073181, 'metrics/data_secs_per_batch': 20.544938945770262, '_timestamp': 1741694525.060146}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 91 is less than current step: 499. Dropping entry: {'train/lr': 0.00029339759036144575, '_timestamp': 1741694525.0604498}).
Epoch: [1][ 93/500]	Time 50.245 (50.245)	Loss 0.5647 (0.3737)	CeLoss 0.0281 (0.0382)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0025 (0.0032)	MaskLoss 0.1735 (0.0937)	MaskBCELoss 0.0803 (0.0215)	MaskDICELoss 0.0933 (0.0722)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 92 is less than current step: 499. Dropping entry: {'train/loss': 0.37369784340262413, 'train/ce_loss': 0.03824462890625, 'train/seg_cls_loss': 0.0009935379028320312, 'train/kl_loss': 0.003179168701171875, 'train/mask_bce_loss': 0.021473558410070835, 'train/mask_dice_loss': 0.07221404770389199, 'train/mask_loss': 0.09368760511279106, 'metrics/total_secs_per_batch': 50.244741916656494, 'metrics/data_secs_per_batch': 23.077768754959106, '_timestamp': 1741694575.304733}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 92 is less than current step: 499. Dropping entry: {'train/lr': 0.00029338554216867466, '_timestamp': 1741694575.3050184}).
Epoch: [1][ 94/500]	Time 45.647 (45.647)	Loss 0.4597 (0.4435)	CeLoss 0.0503 (0.0402)	SegCLSLoss 0.0018 (0.0022)	KLLoss 0.0013 (0.0023)	MaskLoss 0.1042 (0.1202)	MaskBCELoss 0.0047 (0.0404)	MaskDICELoss 0.0995 (0.0798)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 93 is less than current step: 499. Dropping entry: {'train/loss': 0.44354572482407095, 'train/ce_loss': 0.04017333984375, 'train/seg_cls_loss': 0.00215911865234375, 'train/kl_loss': 0.002321624755859375, 'train/mask_bce_loss': 0.04043955532833934, 'train/mask_dice_loss': 0.07979018986225128, 'train/mask_loss': 0.12022974193096161, 'metrics/total_secs_per_batch': 45.647260427474976, 'metrics/data_secs_per_batch': 20.057170152664185, '_timestamp': 1741694620.9530814}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 93 is less than current step: 499. Dropping entry: {'train/lr': 0.00029337349397590357, '_timestamp': 1741694620.9540386}).
Epoch: [1][ 95/500]	Time 48.908 (48.908)	Loss 0.3624 (0.3708)	CeLoss 0.0164 (0.0500)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0034 (0.0026)	MaskLoss 0.0866 (0.0903)	MaskBCELoss 0.0022 (0.0217)	MaskDICELoss 0.0844 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 94 is less than current step: 499. Dropping entry: {'train/loss': 0.3708196260035038, 'train/ce_loss': 0.0499755859375, 'train/seg_cls_loss': 0.0012300491333007812, 'train/kl_loss': 0.00255126953125, 'train/mask_bce_loss': 0.021711844485253096, 'train/mask_dice_loss': 0.06860679360106588, 'train/mask_loss': 0.09031863734126092, 'metrics/total_secs_per_batch': 48.908323764801025, 'metrics/data_secs_per_batch': 21.306196331977844, '_timestamp': 1741694669.8603854}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 94 is less than current step: 499. Dropping entry: {'train/lr': 0.00029336144578313253, '_timestamp': 1741694669.8606677}).
Epoch: [1][ 96/500]	Time 45.189 (45.189)	Loss 0.4710 (0.3959)	CeLoss 0.0449 (0.0444)	SegCLSLoss 0.0011 (0.0028)	KLLoss 0.0036 (0.0026)	MaskLoss 0.1116 (0.0930)	MaskBCELoss 0.0124 (0.0122)	MaskDICELoss 0.0993 (0.0808)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 95 is less than current step: 499. Dropping entry: {'train/loss': 0.3959375761449337, 'train/ce_loss': 0.04443359375, 'train/seg_cls_loss': 0.0028079986572265626, 'train/kl_loss': 0.002616119384765625, 'train/mask_bce_loss': 0.012153893115464599, 'train/mask_dice_loss': 0.08079807348549366, 'train/mask_loss': 0.0929519658908248, 'metrics/total_secs_per_batch': 45.188865184783936, 'metrics/data_secs_per_batch': 19.182484602928163, '_timestamp': 1741694715.049361}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 95 is less than current step: 499. Dropping entry: {'train/lr': 0.00029334939759036144, '_timestamp': 1741694715.0496805}).
Epoch: [1][ 97/500]	Time 46.281 (46.281)	Loss 0.3574 (0.3332)	CeLoss 0.0261 (0.0469)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0033 (0.0026)	MaskLoss 0.0987 (0.0831)	MaskBCELoss 0.0337 (0.0248)	MaskDICELoss 0.0650 (0.0583)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 96 is less than current step: 499. Dropping entry: {'train/loss': 0.33319254256784914, 'train/ce_loss': 0.04691162109375, 'train/seg_cls_loss': 0.0012928009033203124, 'train/kl_loss': 0.0026458740234375, 'train/mask_bce_loss': 0.024817013740539552, 'train/mask_dice_loss': 0.05832615084946156, 'train/mask_loss': 0.08314316496253013, 'metrics/total_secs_per_batch': 46.28107213973999, 'metrics/data_secs_per_batch': 20.677047348022462, '_timestamp': 1741694761.33035}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 96 is less than current step: 499. Dropping entry: {'train/lr': 0.00029333734939759036, '_timestamp': 1741694761.3306615}).
Epoch: [1][ 98/500]	Time 50.806 (50.806)	Loss 0.4354 (0.3251)	CeLoss 0.0228 (0.0465)	SegCLSLoss 0.0030 (0.0010)	KLLoss 0.0015 (0.0022)	MaskLoss 0.1098 (0.0777)	MaskBCELoss 0.0147 (0.0174)	MaskDICELoss 0.0950 (0.0603)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 97 is less than current step: 499. Dropping entry: {'train/loss': 0.3251100622117519, 'train/ce_loss': 0.04647216796875, 'train/seg_cls_loss': 0.000995635986328125, 'train/kl_loss': 0.0022216796875, 'train/mask_bce_loss': 0.017376701987814158, 'train/mask_dice_loss': 0.06030889041721821, 'train/mask_loss': 0.07768559055402875, 'metrics/total_secs_per_batch': 50.805532455444336, 'metrics/data_secs_per_batch': 23.760534787178038, '_timestamp': 1741694812.1358194}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 97 is less than current step: 499. Dropping entry: {'train/lr': 0.00029332530120481927, '_timestamp': 1741694812.136095}).
Epoch: [1][ 99/500]	Time 51.932 (51.932)	Loss 0.0340 (0.2844)	CeLoss 0.0339 (0.0395)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0678)	MaskBCELoss 0.0000 (0.0149)	MaskDICELoss 0.0000 (0.0529)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 98 is less than current step: 499. Dropping entry: {'train/loss': 0.28436823152005675, 'train/ce_loss': 0.039453125, 'train/seg_cls_loss': 0.0014614105224609376, 'train/kl_loss': 0.002679443359375, 'train/mask_bce_loss': 0.014901968697085977, 'train/mask_dice_loss': 0.052935505844652654, 'train/mask_loss': 0.06783747225999832, 'metrics/total_secs_per_batch': 51.932496786117554, 'metrics/data_secs_per_batch': 22.782886123657228, '_timestamp': 1741694864.0692034}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 98 is less than current step: 499. Dropping entry: {'train/lr': 0.0002933132530120482, '_timestamp': 1741694864.0695114}).
[2025-03-11 07:08:33,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[0.0002933012048192771], mom=[(0.9, 0.95)]
[2025-03-11 07:08:33,465] [INFO] [timer.py:215:stop] epoch=0/micro_step=600/global_step=60, RunningAvgSamplesPerSec=0.8330137398309746, CurrSamplesPerSec=0.7509436245854801, MemAllocated=60.25GB, MaxMemAllocated=74.15GB
Epoch: [1][100/500]	Time 49.399 (49.399)	Loss 0.2789 (0.3951)	CeLoss 0.0381 (0.0453)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0029 (0.0030)	MaskLoss 0.0656 (0.0974)	MaskBCELoss 0.0124 (0.0217)	MaskDICELoss 0.0532 (0.0757)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 99 is less than current step: 499. Dropping entry: {'train/loss': 0.3951087720692158, 'train/ce_loss': 0.04534912109375, 'train/seg_cls_loss': 0.0012073516845703125, 'train/kl_loss': 0.00296783447265625, 'train/mask_bce_loss': 0.0216759993461892, 'train/mask_dice_loss': 0.07570286430418491, 'train/mask_loss': 0.09737886339426041, 'metrics/total_secs_per_batch': 49.39853382110596, 'metrics/data_secs_per_batch': 20.19298937320709, '_timestamp': 1741694913.466641}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 99 is less than current step: 499. Dropping entry: {'train/lr': 0.000293289156626506, '_timestamp': 1741694913.4670038}).
Epoch: [1][101/500]	Time 46.823 (46.823)	Loss 0.4769 (0.2976)	CeLoss 0.0562 (0.0403)	SegCLSLoss 0.0020 (0.0024)	KLLoss 0.0019 (0.0025)	MaskLoss 0.1088 (0.0763)	MaskBCELoss 0.0088 (0.0257)	MaskDICELoss 0.1000 (0.0505)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 100 is less than current step: 499. Dropping entry: {'train/loss': 0.2976205710321665, 'train/ce_loss': 0.04029541015625, 'train/seg_cls_loss': 0.002410888671875, 'train/kl_loss': 0.002498626708984375, 'train/mask_bce_loss': 0.025705519132316113, 'train/mask_dice_loss': 0.05054652336984873, 'train/mask_loss': 0.07625204175710679, 'metrics/total_secs_per_batch': 46.82330799102783, 'metrics/data_secs_per_batch': 21.348723554611205, '_timestamp': 1741694960.2902896}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 100 is less than current step: 499. Dropping entry: {'train/lr': 0.0002932771084337349, '_timestamp': 1741694960.2905822}).
Epoch: [1][102/500]	Time 49.020 (49.020)	Loss 0.4672 (0.3956)	CeLoss 0.0442 (0.0385)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0014 (0.0027)	MaskLoss 0.1116 (0.1064)	MaskBCELoss 0.0125 (0.0360)	MaskDICELoss 0.0991 (0.0704)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 101 is less than current step: 499. Dropping entry: {'train/loss': 0.39559886008501055, 'train/ce_loss': 0.038507080078125, 'train/seg_cls_loss': 0.0012989044189453125, 'train/kl_loss': 0.002728271484375, 'train/mask_bce_loss': 0.03597597936168313, 'train/mask_dice_loss': 0.0704405315220356, 'train/mask_loss': 0.10641651228070259, 'metrics/total_secs_per_batch': 49.01966595649719, 'metrics/data_secs_per_batch': 22.533967399597167, '_timestamp': 1741695009.3098924}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 101 is less than current step: 499. Dropping entry: {'train/lr': 0.0002932650602409638, '_timestamp': 1741695009.3101695}).
Epoch: [1][103/500]	Time 49.308 (49.308)	Loss 0.0928 (0.3608)	CeLoss 0.0243 (0.0448)	SegCLSLoss 0.0027 (0.0018)	KLLoss 0.0032 (0.0022)	MaskLoss 0.0231 (0.0893)	MaskBCELoss 0.0142 (0.0221)	MaskDICELoss 0.0089 (0.0672)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 102 is less than current step: 499. Dropping entry: {'train/loss': 0.36083904542028905, 'train/ce_loss': 0.04482421875, 'train/seg_cls_loss': 0.0018070220947265625, 'train/kl_loss': 0.002239990234375, 'train/mask_bce_loss': 0.02210581535473466, 'train/mask_dice_loss': 0.06717931693419814, 'train/mask_loss': 0.08928513508290052, 'metrics/total_secs_per_batch': 49.30834412574768, 'metrics/data_secs_per_batch': 23.617992448806763, '_timestamp': 1741695058.618198}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 102 is less than current step: 499. Dropping entry: {'train/lr': 0.00029325301204819273, '_timestamp': 1741695058.6186047}).
Epoch: [1][104/500]	Time 50.574 (50.574)	Loss 0.4235 (0.4186)	CeLoss 0.0210 (0.0363)	SegCLSLoss 0.0051 (0.0025)	KLLoss 0.0030 (0.0027)	MaskLoss 0.1170 (0.1102)	MaskBCELoss 0.0355 (0.0312)	MaskDICELoss 0.0815 (0.0790)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 103 is less than current step: 499. Dropping entry: {'train/loss': 0.4186037749052048, 'train/ce_loss': 0.03631591796875, 'train/seg_cls_loss': 0.0024997711181640623, 'train/kl_loss': 0.002675628662109375, 'train/mask_bce_loss': 0.03118002349510789, 'train/mask_dice_loss': 0.07899989672005177, 'train/mask_loss': 0.11017991900444031, 'metrics/total_secs_per_batch': 50.57380127906799, 'metrics/data_secs_per_batch': 22.381186151504515, '_timestamp': 1741695109.1920288}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 103 is less than current step: 499. Dropping entry: {'train/lr': 0.00029324096385542164, '_timestamp': 1741695109.1922934}).
Epoch: [1][105/500]	Time 48.227 (48.227)	Loss 0.5098 (0.3554)	CeLoss 0.0967 (0.0358)	SegCLSLoss 0.0018 (0.0018)	KLLoss 0.0039 (0.0023)	MaskLoss 0.1057 (0.0920)	MaskBCELoss 0.0072 (0.0258)	MaskDICELoss 0.0985 (0.0662)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 104 is less than current step: 499. Dropping entry: {'train/loss': 0.35538232550024984, 'train/ce_loss': 0.03582763671875, 'train/seg_cls_loss': 0.0017681121826171875, 'train/kl_loss': 0.002313232421875, 'train/mask_bce_loss': 0.02576966308988631, 'train/mask_dice_loss': 0.06620000787079335, 'train/mask_loss': 0.09196966961026191, 'metrics/total_secs_per_batch': 48.22672414779663, 'metrics/data_secs_per_batch': 21.208128333091736, '_timestamp': 1741695157.4197986}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 104 is less than current step: 499. Dropping entry: {'train/lr': 0.00029322891566265055, '_timestamp': 1741695157.420744}).
Epoch: [1][106/500]	Time 43.787 (43.787)	Loss 0.2268 (0.3834)	CeLoss 0.0256 (0.0468)	SegCLSLoss 0.0011 (0.0030)	KLLoss 0.0050 (0.0028)	MaskLoss 0.0630 (0.0979)	MaskBCELoss 0.0282 (0.0296)	MaskDICELoss 0.0348 (0.0683)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 105 is less than current step: 499. Dropping entry: {'train/loss': 0.3834379896521568, 'train/ce_loss': 0.04681396484375, 'train/seg_cls_loss': 0.00301513671875, 'train/kl_loss': 0.00276947021484375, 'train/mask_bce_loss': 0.029648929182440043, 'train/mask_dice_loss': 0.06827624328434467, 'train/mask_loss': 0.09792517423629761, 'metrics/total_secs_per_batch': 43.787330865859985, 'metrics/data_secs_per_batch': 19.274757814407348, '_timestamp': 1741695201.206361}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 105 is less than current step: 499. Dropping entry: {'train/lr': 0.0002932168674698795, '_timestamp': 1741695201.2067678}).
Epoch: [1][107/500]	Time 45.639 (45.639)	Loss 0.4725 (0.4458)	CeLoss 0.0649 (0.0492)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0018 (0.0023)	MaskLoss 0.1035 (0.1147)	MaskBCELoss 0.0043 (0.0326)	MaskDICELoss 0.0992 (0.0821)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 106 is less than current step: 499. Dropping entry: {'train/loss': 0.445818030834198, 'train/ce_loss': 0.0492431640625, 'train/seg_cls_loss': 0.0012058258056640626, 'train/kl_loss': 0.00234832763671875, 'train/mask_bce_loss': 0.03261420466005802, 'train/mask_dice_loss': 0.08210297115147114, 'train/mask_loss': 0.11471717357635498, 'metrics/total_secs_per_batch': 45.63882493972778, 'metrics/data_secs_per_batch': 20.51074254512787, '_timestamp': 1741695246.8449416}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 106 is less than current step: 499. Dropping entry: {'train/lr': 0.00029320481927710843, '_timestamp': 1741695246.8452349}).
Epoch: [1][108/500]	Time 46.487 (46.487)	Loss 0.4705 (0.4046)	CeLoss 0.0508 (0.0468)	SegCLSLoss 0.0013 (0.0021)	KLLoss 0.0011 (0.0026)	MaskLoss 0.1089 (0.1070)	MaskBCELoss 0.0090 (0.0369)	MaskDICELoss 0.1000 (0.0701)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 107 is less than current step: 499. Dropping entry: {'train/loss': 0.404601089283824, 'train/ce_loss': 0.046826171875, 'train/seg_cls_loss': 0.0020671844482421874, 'train/kl_loss': 0.002623748779296875, 'train/mask_bce_loss': 0.03691238635219633, 'train/mask_dice_loss': 0.07007200587540865, 'train/mask_loss': 0.10698439180850983, 'metrics/total_secs_per_batch': 46.4865460395813, 'metrics/data_secs_per_batch': 19.940518069267274, '_timestamp': 1741695293.331685}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 107 is less than current step: 499. Dropping entry: {'train/lr': 0.00029319277108433734, '_timestamp': 1741695293.3321507}).
Epoch: [1][109/500]	Time 49.393 (49.393)	Loss 0.4137 (0.4760)	CeLoss 0.0220 (0.0459)	SegCLSLoss 0.0043 (0.0018)	KLLoss 0.0035 (0.0030)	MaskLoss 0.1012 (0.1240)	MaskBCELoss 0.0094 (0.0350)	MaskDICELoss 0.0918 (0.0890)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 108 is less than current step: 499. Dropping entry: {'train/loss': 0.47603967487812043, 'train/ce_loss': 0.04593505859375, 'train/seg_cls_loss': 0.001834869384765625, 'train/kl_loss': 0.002999114990234375, 'train/mask_bce_loss': 0.03499323618598282, 'train/mask_dice_loss': 0.0890474770218134, 'train/mask_loss': 0.12404071539640427, 'metrics/total_secs_per_batch': 49.393080711364746, 'metrics/data_secs_per_batch': 22.10904903411865, '_timestamp': 1741695342.7245781}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 108 is less than current step: 499. Dropping entry: {'train/lr': 0.00029318072289156625, '_timestamp': 1741695342.7248516}).
Epoch: [1][110/500]	Time 47.245 (47.245)	Loss 0.4208 (0.4289)	CeLoss 0.0140 (0.0294)	SegCLSLoss 0.0041 (0.0024)	KLLoss 0.0019 (0.0025)	MaskLoss 0.1100 (0.1129)	MaskBCELoss 0.0185 (0.0278)	MaskDICELoss 0.0915 (0.0851)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 109 is less than current step: 499. Dropping entry: {'train/loss': 0.42888844311237334, 'train/ce_loss': 0.029351806640625, 'train/seg_cls_loss': 0.00237579345703125, 'train/kl_loss': 0.002454376220703125, 'train/mask_bce_loss': 0.027788573503494264, 'train/mask_dice_loss': 0.08508075326681137, 'train/mask_loss': 0.11286932751536369, 'metrics/total_secs_per_batch': 47.244521617889404, 'metrics/data_secs_per_batch': 20.3639732837677, '_timestamp': 1741695389.9691854}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 109 is less than current step: 499. Dropping entry: {'train/lr': 0.00029315662650602407, '_timestamp': 1741695389.9695802}).
Epoch: [1][111/500]	Time 44.410 (44.410)	Loss 0.5370 (0.4087)	CeLoss 0.0991 (0.0666)	SegCLSLoss 0.0023 (0.0011)	KLLoss 0.0037 (0.0029)	MaskLoss 0.1169 (0.0956)	MaskBCELoss 0.0172 (0.0219)	MaskDICELoss 0.0996 (0.0737)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 110 is less than current step: 499. Dropping entry: {'train/loss': 0.40872173607349394, 'train/ce_loss': 0.06663818359375, 'train/seg_cls_loss': 0.0011013031005859375, 'train/kl_loss': 0.00287933349609375, 'train/mask_bce_loss': 0.021943452209234236, 'train/mask_dice_loss': 0.07370382472872734, 'train/mask_loss': 0.0956472758203745, 'metrics/total_secs_per_batch': 44.410014629364014, 'metrics/data_secs_per_batch': 19.260780262947083, '_timestamp': 1741695434.3791606}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 110 is less than current step: 499. Dropping entry: {'train/lr': 0.000293144578313253, '_timestamp': 1741695434.3795621}).
Epoch: [1][112/500]	Time 45.616 (45.616)	Loss 0.4433 (0.3890)	CeLoss 0.0276 (0.0327)	SegCLSLoss 0.0017 (0.0023)	KLLoss 0.0022 (0.0024)	MaskLoss 0.1069 (0.0992)	MaskBCELoss 0.0074 (0.0220)	MaskDICELoss 0.0995 (0.0772)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 111 is less than current step: 499. Dropping entry: {'train/loss': 0.3889930259436369, 'train/ce_loss': 0.03270263671875, 'train/seg_cls_loss': 0.0022861480712890623, 'train/kl_loss': 0.002423858642578125, 'train/mask_bce_loss': 0.021997179044410585, 'train/mask_dice_loss': 0.07718716931995004, 'train/mask_loss': 0.09918434782885015, 'metrics/total_secs_per_batch': 45.61589765548706, 'metrics/data_secs_per_batch': 20.42335786819458, '_timestamp': 1741695479.9950926}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 111 is less than current step: 499. Dropping entry: {'train/lr': 0.0002931325301204819, '_timestamp': 1741695479.995391}).
Epoch: [1][113/500]	Time 52.406 (52.406)	Loss 0.1996 (0.3619)	CeLoss 0.0430 (0.0414)	SegCLSLoss 0.0005 (0.0021)	KLLoss 0.0054 (0.0030)	MaskLoss 0.0409 (0.0951)	MaskBCELoss 0.0061 (0.0320)	MaskDICELoss 0.0347 (0.0631)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 112 is less than current step: 499. Dropping entry: {'train/loss': 0.36194024607539177, 'train/ce_loss': 0.04140625, 'train/seg_cls_loss': 0.0020782470703125, 'train/kl_loss': 0.00296173095703125, 'train/mask_bce_loss': 0.03197891913587227, 'train/mask_dice_loss': 0.06312353238463402, 'train/mask_loss': 0.095102449785918, 'metrics/total_secs_per_batch': 52.40635085105896, 'metrics/data_secs_per_batch': 23.56625053882599, '_timestamp': 1741695532.401384}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 112 is less than current step: 499. Dropping entry: {'train/lr': 0.0002931204819277108, '_timestamp': 1741695532.4016554}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 113 is less than current step: 499. Dropping entry: {'train/loss': 0.4502051889896393, 'train/ce_loss': 0.06119384765625, 'train/seg_cls_loss': 0.001617431640625, 'train/kl_loss': 0.00299224853515625, 'train/mask_bce_loss': 0.033558567566797134, 'train/mask_dice_loss': 0.07951713241636753, 'train/mask_loss': 0.11307570189237595, 'metrics/total_secs_per_batch': 43.440646171569824, 'metrics/data_secs_per_batch': 20.0750009059906, '_timestamp': 1741695575.8420804}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 113 is less than current step: 499. Dropping entry: {'train/lr': 0.0002931084337349397, '_timestamp': 1741695575.8423643}).
Epoch: [1][114/500]	Time 43.441 (43.441)	Loss 0.2944 (0.4502)	CeLoss 0.0635 (0.0612)	SegCLSLoss 0.0020 (0.0016)	KLLoss 0.0047 (0.0030)	MaskLoss 0.0671 (0.1131)	MaskBCELoss 0.0217 (0.0336)	MaskDICELoss 0.0454 (0.0795)
Epoch: [1][115/500]	Time 49.598 (49.598)	Loss 0.2984 (0.3839)	CeLoss 0.0281 (0.0418)	SegCLSLoss 0.0005 (0.0017)	KLLoss 0.0026 (0.0022)	MaskLoss 0.0731 (0.0967)	MaskBCELoss 0.0124 (0.0239)	MaskDICELoss 0.0607 (0.0728)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 114 is less than current step: 499. Dropping entry: {'train/loss': 0.38393767438828946, 'train/ce_loss': 0.04176025390625, 'train/seg_cls_loss': 0.0016959190368652343, 'train/kl_loss': 0.00219879150390625, 'train/mask_bce_loss': 0.023912589671090244, 'train/mask_dice_loss': 0.07283671833574772, 'train/mask_loss': 0.09674930609762669, 'metrics/total_secs_per_batch': 49.598140716552734, 'metrics/data_secs_per_batch': 22.75361647605896, '_timestamp': 1741695625.441345}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 114 is less than current step: 499. Dropping entry: {'train/lr': 0.0002930963855421686, '_timestamp': 1741695625.442394}).
Epoch: [1][116/500]	Time 48.685 (48.685)	Loss 0.3349 (0.3107)	CeLoss 0.0815 (0.0428)	SegCLSLoss 0.0004 (0.0015)	KLLoss 0.0034 (0.0027)	MaskLoss 0.0766 (0.0758)	MaskBCELoss 0.0286 (0.0194)	MaskDICELoss 0.0480 (0.0564)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 115 is less than current step: 499. Dropping entry: {'train/loss': 0.31068058535456655, 'train/ce_loss': 0.0427734375, 'train/seg_cls_loss': 0.00149383544921875, 'train/kl_loss': 0.002712249755859375, 'train/mask_bce_loss': 0.019353406876325606, 'train/mask_dice_loss': 0.05641629323363304, 'train/mask_loss': 0.0757697008550167, 'metrics/total_secs_per_batch': 48.68492603302002, 'metrics/data_secs_per_batch': 22.40711302757263, '_timestamp': 1741695674.1252782}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 115 is less than current step: 499. Dropping entry: {'train/lr': 0.0002930843373493976, '_timestamp': 1741695674.1255696}).
Epoch: [1][117/500]	Time 49.221 (49.221)	Loss 0.4852 (0.4196)	CeLoss 0.0728 (0.0448)	SegCLSLoss 0.0008 (0.0024)	KLLoss 0.0010 (0.0027)	MaskLoss 0.1055 (0.1086)	MaskBCELoss 0.0055 (0.0317)	MaskDICELoss 0.1000 (0.0769)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 116 is less than current step: 499. Dropping entry: {'train/loss': 0.41958658024668694, 'train/ce_loss': 0.04476318359375, 'train/seg_cls_loss': 0.0023681640625, 'train/kl_loss': 0.002655029296875, 'train/mask_bce_loss': 0.03173262919299304, 'train/mask_dice_loss': 0.07688189186155796, 'train/mask_loss': 0.1086145207285881, 'metrics/total_secs_per_batch': 49.220818519592285, 'metrics/data_secs_per_batch': 21.550103092193602, '_timestamp': 1741695723.346097}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 116 is less than current step: 499. Dropping entry: {'train/lr': 0.0002930722891566265, '_timestamp': 1741695723.3465495}).
Epoch: [1][118/500]	Time 51.955 (51.955)	Loss 0.5216 (0.3950)	CeLoss 0.0742 (0.0480)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0025 (0.0020)	MaskLoss 0.1376 (0.0979)	MaskBCELoss 0.0529 (0.0235)	MaskDICELoss 0.0847 (0.0744)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 117 is less than current step: 499. Dropping entry: {'train/loss': 0.3949952347204089, 'train/ce_loss': 0.04798583984375, 'train/seg_cls_loss': 0.0010843276977539062, 'train/kl_loss': 0.001970672607421875, 'train/mask_bce_loss': 0.023470867704600096, 'train/mask_dice_loss': 0.07439863011240959, 'train/mask_loss': 0.09786949902772904, 'metrics/total_secs_per_batch': 51.95534420013428, 'metrics/data_secs_per_batch': 23.719322943687438, '_timestamp': 1741695775.3013775}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 117 is less than current step: 499. Dropping entry: {'train/lr': 0.0002930602409638554, '_timestamp': 1741695775.3016613}).
Epoch: [1][119/500]	Time 45.913 (45.913)	Loss 0.4902 (0.3715)	CeLoss 0.0173 (0.0303)	SegCLSLoss 0.0022 (0.0015)	KLLoss 0.0049 (0.0024)	MaskLoss 0.1337 (0.0948)	MaskBCELoss 0.0339 (0.0205)	MaskDICELoss 0.0998 (0.0743)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 118 is less than current step: 499. Dropping entry: {'train/loss': 0.3715324180200696, 'train/ce_loss': 0.030303955078125, 'train/seg_cls_loss': 0.0014505386352539062, 'train/kl_loss': 0.0023590087890625, 'train/mask_bce_loss': 0.020526311313733458, 'train/mask_dice_loss': 0.07426057551056146, 'train/mask_loss': 0.09478688891977072, 'metrics/total_secs_per_batch': 45.91273260116577, 'metrics/data_secs_per_batch': 21.577169871330263, '_timestamp': 1741695821.2141364}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 118 is less than current step: 499. Dropping entry: {'train/lr': 0.0002930481927710843, '_timestamp': 1741695821.2144308}).
Epoch: [1][120/500]	Time 47.587 (47.587)	Loss 0.2698 (0.3925)	CeLoss 0.0486 (0.0514)	SegCLSLoss 0.0034 (0.0014)	KLLoss 0.0022 (0.0027)	MaskLoss 0.0638 (0.1013)	MaskBCELoss 0.0192 (0.0337)	MaskDICELoss 0.0447 (0.0675)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 119 is less than current step: 499. Dropping entry: {'train/loss': 0.39245546609163284, 'train/ce_loss': 0.05140380859375, 'train/seg_cls_loss': 0.0014278411865234375, 'train/kl_loss': 0.00270843505859375, 'train/mask_bce_loss': 0.033725484367460014, 'train/mask_dice_loss': 0.06752798072993756, 'train/mask_loss': 0.1012534648180008, 'metrics/total_secs_per_batch': 47.58693289756775, 'metrics/data_secs_per_batch': 20.957789254188537, '_timestamp': 1741695868.8010185}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 119 is less than current step: 499. Dropping entry: {'train/lr': 0.00029302409638554214, '_timestamp': 1741695868.8014064}).
Epoch: [1][121/500]	Time 51.717 (51.717)	Loss 0.0287 (0.3618)	CeLoss 0.0287 (0.0349)	SegCLSLoss 0.0000 (0.0023)	KLLoss 0.0000 (0.0016)	MaskLoss 0.0000 (0.0905)	MaskBCELoss 0.0000 (0.0190)	MaskDICELoss 0.0000 (0.0716)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 120 is less than current step: 499. Dropping entry: {'train/loss': 0.36178482342511414, 'train/ce_loss': 0.0348876953125, 'train/seg_cls_loss': 0.0023181915283203127, 'train/kl_loss': 0.001615142822265625, 'train/mask_bce_loss': 0.018965903762727977, 'train/mask_dice_loss': 0.07155407220125198, 'train/mask_loss': 0.09051997661590576, 'metrics/total_secs_per_batch': 51.7166633605957, 'metrics/data_secs_per_batch': 21.606606101989748, '_timestamp': 1741695920.5190704}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 120 is less than current step: 499. Dropping entry: {'train/lr': 0.00029301204819277106, '_timestamp': 1741695920.5201402}).
Epoch: [1][122/500]	Time 44.356 (44.356)	Loss 0.4715 (0.3342)	CeLoss 0.0898 (0.0457)	SegCLSLoss 0.0022 (0.0020)	KLLoss 0.0006 (0.0019)	MaskLoss 0.0959 (0.0811)	MaskBCELoss 0.0018 (0.0194)	MaskDICELoss 0.0941 (0.0617)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 121 is less than current step: 499. Dropping entry: {'train/loss': 0.3342342458665371, 'train/ce_loss': 0.04571533203125, 'train/seg_cls_loss': 0.0019527435302734374, 'train/kl_loss': 0.0019195556640625, 'train/mask_bce_loss': 0.01936334198107943, 'train/mask_dice_loss': 0.06172356978058815, 'train/mask_loss': 0.08108691088855266, 'metrics/total_secs_per_batch': 44.35591006278992, 'metrics/data_secs_per_batch': 20.401781702041625, '_timestamp': 1741695964.873641}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 121 is less than current step: 499. Dropping entry: {'train/lr': 0.00029299999999999997, '_timestamp': 1741695964.8740752}).
Epoch: [1][123/500]	Time 48.861 (48.861)	Loss 0.3442 (0.3272)	CeLoss 0.0215 (0.0444)	SegCLSLoss 0.0050 (0.0016)	KLLoss 0.0020 (0.0023)	MaskLoss 0.0910 (0.0815)	MaskBCELoss 0.0229 (0.0231)	MaskDICELoss 0.0681 (0.0584)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 122 is less than current step: 499. Dropping entry: {'train/loss': 0.32724025212228297, 'train/ce_loss': 0.04439697265625, 'train/seg_cls_loss': 0.0015514373779296875, 'train/kl_loss': 0.0023406982421875, 'train/mask_bce_loss': 0.023059949185699223, 'train/mask_dice_loss': 0.05840997193008661, 'train/mask_loss': 0.0814699187874794, 'metrics/total_secs_per_batch': 48.86131453514099, 'metrics/data_secs_per_batch': 22.78868501186371, '_timestamp': 1741696013.7349875}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 122 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929879518072289, '_timestamp': 1741696013.735404}).
Epoch: [1][124/500]	Time 50.574 (50.574)	Loss 0.5312 (0.4107)	CeLoss 0.0986 (0.0442)	SegCLSLoss 0.0019 (0.0017)	KLLoss 0.0017 (0.0025)	MaskLoss 0.1379 (0.1034)	MaskBCELoss 0.0606 (0.0252)	MaskDICELoss 0.0773 (0.0782)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 123 is less than current step: 499. Dropping entry: {'train/loss': 0.4107158649712801, 'train/ce_loss': 0.04417724609375, 'train/seg_cls_loss': 0.0016796112060546875, 'train/kl_loss': 0.002481842041015625, 'train/mask_bce_loss': 0.02522903304779902, 'train/mask_dice_loss': 0.07820409722626209, 'train/mask_loss': 0.10343312993645667, 'metrics/total_secs_per_batch': 50.57430410385132, 'metrics/data_secs_per_batch': 23.233382844924925, '_timestamp': 1741696064.3092654}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 123 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929759036144578, '_timestamp': 1741696064.3096735}).
Epoch: [1][125/500]	Time 51.163 (51.163)	Loss 0.0412 (0.3938)	CeLoss 0.0413 (0.0498)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0969)	MaskBCELoss 0.0000 (0.0233)	MaskDICELoss 0.0000 (0.0735)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 124 is less than current step: 499. Dropping entry: {'train/loss': 0.3937961984425783, 'train/ce_loss': 0.049835205078125, 'train/seg_cls_loss': 0.0013637542724609375, 'train/kl_loss': 0.0026031494140625, 'train/mask_bce_loss': 0.02334817871451378, 'train/mask_dice_loss': 0.07350835725665092, 'train/mask_loss': 0.0968565359711647, 'metrics/total_secs_per_batch': 51.162689447402954, 'metrics/data_secs_per_batch': 22.28600196838379, '_timestamp': 1741696115.4721413}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 124 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929638554216867, '_timestamp': 1741696115.4726071}).
Epoch: [1][126/500]	Time 46.546 (46.546)	Loss 0.4872 (0.4407)	CeLoss 0.0649 (0.0411)	SegCLSLoss 0.0034 (0.0012)	KLLoss 0.0028 (0.0025)	MaskLoss 0.1099 (0.1171)	MaskBCELoss 0.0109 (0.0359)	MaskDICELoss 0.0991 (0.0812)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 125 is less than current step: 499. Dropping entry: {'train/loss': 0.4407233685255051, 'train/ce_loss': 0.04114990234375, 'train/seg_cls_loss': 0.001200103759765625, 'train/kl_loss': 0.002529144287109375, 'train/mask_bce_loss': 0.035927717573940754, 'train/mask_dice_loss': 0.08115497082471848, 'train/mask_loss': 0.11708268895745277, 'metrics/total_secs_per_batch': 46.54601716995239, 'metrics/data_secs_per_batch': 21.151586484909057, '_timestamp': 1741696162.0179455}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 125 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929518072289156, '_timestamp': 1741696162.0183516}).
Epoch: [1][127/500]	Time 44.493 (44.493)	Loss 0.4145 (0.3901)	CeLoss 0.0245 (0.0451)	SegCLSLoss 0.0010 (0.0023)	KLLoss 0.0037 (0.0027)	MaskLoss 0.1002 (0.0989)	MaskBCELoss 0.0076 (0.0273)	MaskDICELoss 0.0927 (0.0716)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 126 is less than current step: 499. Dropping entry: {'train/loss': 0.3900937281548977, 'train/ce_loss': 0.04512939453125, 'train/seg_cls_loss': 0.0023456573486328124, 'train/kl_loss': 0.0027313232421875, 'train/mask_bce_loss': 0.027303965482860803, 'train/mask_dice_loss': 0.07161314534023404, 'train/mask_loss': 0.09891711361706257, 'metrics/total_secs_per_batch': 44.49291396141052, 'metrics/data_secs_per_batch': 19.684791231155394, '_timestamp': 1741696206.5119689}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 126 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929397590361446, '_timestamp': 1741696206.5129154}).
Epoch: [1][128/500]	Time 46.104 (46.104)	Loss 0.4480 (0.3275)	CeLoss 0.0172 (0.0401)	SegCLSLoss 0.0009 (0.0021)	KLLoss 0.0032 (0.0020)	MaskLoss 0.1246 (0.0821)	MaskBCELoss 0.0357 (0.0221)	MaskDICELoss 0.0889 (0.0600)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 127 is less than current step: 499. Dropping entry: {'train/loss': 0.32745514884591104, 'train/ce_loss': 0.04007568359375, 'train/seg_cls_loss': 0.0020999908447265625, 'train/kl_loss': 0.00204315185546875, 'train/mask_bce_loss': 0.022079063951969145, 'train/mask_dice_loss': 0.06002591550350189, 'train/mask_loss': 0.08210497871041297, 'metrics/total_secs_per_batch': 46.10364103317261, 'metrics/data_secs_per_batch': 20.740822315216064, '_timestamp': 1741696252.6157117}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 127 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929277108433735, '_timestamp': 1741696252.616701}).
Epoch: [1][129/500]	Time 50.500 (50.500)	Loss 0.4384 (0.4159)	CeLoss 0.0227 (0.0489)	SegCLSLoss 0.0015 (0.0023)	KLLoss 0.0026 (0.0023)	MaskLoss 0.1071 (0.1054)	MaskBCELoss 0.0081 (0.0290)	MaskDICELoss 0.0990 (0.0764)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 128 is less than current step: 499. Dropping entry: {'train/loss': 0.4158805400133133, 'train/ce_loss': 0.04886474609375, 'train/seg_cls_loss': 0.002289581298828125, 'train/kl_loss': 0.00230255126953125, 'train/mask_bce_loss': 0.02904918887652457, 'train/mask_dice_loss': 0.07636936753988266, 'train/mask_loss': 0.10541855953633786, 'metrics/total_secs_per_batch': 50.499690532684326, 'metrics/data_secs_per_batch': 22.55432996749878, '_timestamp': 1741696303.114346}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 128 is less than current step: 499. Dropping entry: {'train/lr': 0.0002929156626506024, '_timestamp': 1741696303.1146455}).
Epoch: [1][130/500]	Time 51.389 (51.389)	Loss 0.4448 (0.3964)	CeLoss 0.0254 (0.0454)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0038 (0.0025)	MaskLoss 0.1077 (0.0990)	MaskBCELoss 0.0077 (0.0242)	MaskDICELoss 0.1000 (0.0748)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 129 is less than current step: 499. Dropping entry: {'train/loss': 0.3964055098593235, 'train/ce_loss': 0.04544677734375, 'train/seg_cls_loss': 0.0015827178955078124, 'train/kl_loss': 0.0024932861328125, 'train/mask_bce_loss': 0.02419439204968512, 'train/mask_dice_loss': 0.07483621463179588, 'train/mask_loss': 0.09903060793876647, 'metrics/total_secs_per_batch': 51.38920450210571, 'metrics/data_secs_per_batch': 22.53234143257141, '_timestamp': 1741696354.5035715}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 129 is less than current step: 499. Dropping entry: {'train/lr': 0.0002928915662650602, '_timestamp': 1741696354.5038388}).
Epoch: [1][131/500]	Time 48.179 (48.179)	Loss 0.4485 (0.3124)	CeLoss 0.0215 (0.0400)	SegCLSLoss 0.0021 (0.0016)	KLLoss 0.0017 (0.0017)	MaskLoss 0.1146 (0.0771)	MaskBCELoss 0.0171 (0.0192)	MaskDICELoss 0.0975 (0.0579)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 130 is less than current step: 499. Dropping entry: {'train/loss': 0.31242491602897643, 'train/ce_loss': 0.0400146484375, 'train/seg_cls_loss': 0.0016307830810546875, 'train/kl_loss': 0.001717376708984375, 'train/mask_bce_loss': 0.019241423206403853, 'train/mask_dice_loss': 0.05785319246351719, 'train/mask_loss': 0.07709461525082588, 'metrics/total_secs_per_batch': 48.17940640449524, 'metrics/data_secs_per_batch': 21.661135506629943, '_timestamp': 1741696402.6828568}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 130 is less than current step: 499. Dropping entry: {'train/lr': 0.00029287951807228913, '_timestamp': 1741696402.683133}).
Epoch: [1][132/500]	Time 43.945 (43.945)	Loss 0.4997 (0.4225)	CeLoss 0.0874 (0.0679)	SegCLSLoss 0.0021 (0.0013)	KLLoss 0.0020 (0.0023)	MaskLoss 0.1054 (0.0996)	MaskBCELoss 0.0062 (0.0233)	MaskDICELoss 0.0991 (0.0762)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 131 is less than current step: 499. Dropping entry: {'train/loss': 0.42247856203466655, 'train/ce_loss': 0.06788330078125, 'train/seg_cls_loss': 0.0013202667236328126, 'train/kl_loss': 0.00228271484375, 'train/mask_bce_loss': 0.023324244283139707, 'train/mask_dice_loss': 0.07624999955296516, 'train/mask_loss': 0.09957424253225326, 'metrics/total_secs_per_batch': 43.944965839385986, 'metrics/data_secs_per_batch': 20.23237979412079, '_timestamp': 1741696446.6277826}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 131 is less than current step: 499. Dropping entry: {'train/lr': 0.00029286746987951804, '_timestamp': 1741696446.6280534}).
Epoch: [1][133/500]	Time 50.112 (50.112)	Loss 0.4178 (0.3954)	CeLoss 0.0579 (0.0538)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0020 (0.0029)	MaskLoss 0.1047 (0.0931)	MaskBCELoss 0.0305 (0.0171)	MaskDICELoss 0.0742 (0.0760)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 132 is less than current step: 499. Dropping entry: {'train/loss': 0.39541804045438766, 'train/ce_loss': 0.0537841796875, 'train/seg_cls_loss': 0.001175689697265625, 'train/kl_loss': 0.00289154052734375, 'train/mask_bce_loss': 0.017074707569554447, 'train/mask_dice_loss': 0.0760154003277421, 'train/mask_loss': 0.09309010617434979, 'metrics/total_secs_per_batch': 50.11191916465759, 'metrics/data_secs_per_batch': 23.043722653388976, '_timestamp': 1741696496.739858}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 132 is less than current step: 499. Dropping entry: {'train/lr': 0.00029285542168674695, '_timestamp': 1741696496.7401478}).
Epoch: [1][134/500]	Time 48.025 (48.025)	Loss 0.4844 (0.4507)	CeLoss 0.0620 (0.0482)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0021 (0.0024)	MaskLoss 0.1145 (0.1067)	MaskBCELoss 0.0190 (0.0137)	MaskDICELoss 0.0955 (0.0930)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 133 is less than current step: 499. Dropping entry: {'train/loss': 0.4507309108972549, 'train/ce_loss': 0.0482177734375, 'train/seg_cls_loss': 0.0014125823974609375, 'train/kl_loss': 0.002373504638671875, 'train/mask_bce_loss': 0.01374962948029861, 'train/mask_dice_loss': 0.09299541488289834, 'train/mask_loss': 0.10674504488706589, 'metrics/total_secs_per_batch': 48.02467131614685, 'metrics/data_secs_per_batch': 21.768756246566774, '_timestamp': 1741696544.7645752}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 133 is less than current step: 499. Dropping entry: {'train/lr': 0.00029284337349397586, '_timestamp': 1741696544.7648816}).
Epoch: [1][135/500]	Time 44.628 (44.628)	Loss 0.4375 (0.4321)	CeLoss 0.0223 (0.0557)	SegCLSLoss 0.0027 (0.0016)	KLLoss 0.0026 (0.0028)	MaskLoss 0.1128 (0.1044)	MaskBCELoss 0.0201 (0.0224)	MaskDICELoss 0.0927 (0.0820)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 134 is less than current step: 499. Dropping entry: {'train/loss': 0.4321182943880558, 'train/ce_loss': 0.05574951171875, 'train/seg_cls_loss': 0.0016284942626953124, 'train/kl_loss': 0.00279998779296875, 'train/mask_bce_loss': 0.022399325110018253, 'train/mask_dice_loss': 0.08197639496065676, 'train/mask_loss': 0.10437571927905083, 'metrics/total_secs_per_batch': 44.62764501571655, 'metrics/data_secs_per_batch': 21.14749367237091, '_timestamp': 1741696589.3921077}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 134 is less than current step: 499. Dropping entry: {'train/lr': 0.00029283132530120477, '_timestamp': 1741696589.3925107}).
Epoch: [1][136/500]	Time 48.472 (48.472)	Loss 0.4305 (0.3809)	CeLoss 0.0227 (0.0444)	SegCLSLoss 0.0023 (0.0022)	KLLoss 0.0035 (0.0029)	MaskLoss 0.1018 (0.0917)	MaskBCELoss 0.0020 (0.0171)	MaskDICELoss 0.0998 (0.0746)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 135 is less than current step: 499. Dropping entry: {'train/loss': 0.3809319272637367, 'train/ce_loss': 0.04442138671875, 'train/seg_cls_loss': 0.0021511077880859374, 'train/kl_loss': 0.002948760986328125, 'train/mask_bce_loss': 0.017085375310853124, 'train/mask_dice_loss': 0.07457603747025132, 'train/mask_loss': 0.09166141264140606, 'metrics/total_secs_per_batch': 48.47226285934448, 'metrics/data_secs_per_batch': 22.479480051994322, '_timestamp': 1741696637.8658922}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 135 is less than current step: 499. Dropping entry: {'train/lr': 0.00029281927710843374, '_timestamp': 1741696637.8669536}).
Epoch: [1][137/500]	Time 44.816 (44.816)	Loss 0.4248 (0.4080)	CeLoss 0.0211 (0.0481)	SegCLSLoss 0.0028 (0.0019)	KLLoss 0.0015 (0.0023)	MaskLoss 0.1018 (0.0978)	MaskBCELoss 0.0031 (0.0174)	MaskDICELoss 0.0987 (0.0805)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 136 is less than current step: 499. Dropping entry: {'train/loss': 0.40798950251191857, 'train/ce_loss': 0.04810791015625, 'train/seg_cls_loss': 0.0018701553344726562, 'train/kl_loss': 0.002285003662109375, 'train/mask_bce_loss': 0.017356067057698966, 'train/mask_dice_loss': 0.08048243001103401, 'train/mask_loss': 0.09783849716186524, 'metrics/total_secs_per_batch': 44.815818548202515, 'metrics/data_secs_per_batch': 19.741854500770568, '_timestamp': 1741696682.6807244}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 136 is less than current step: 499. Dropping entry: {'train/lr': 0.00029280722891566265, '_timestamp': 1741696682.6811075}).
Epoch: [1][138/500]	Time 50.179 (50.179)	Loss 0.3885 (0.3620)	CeLoss 0.0554 (0.0407)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0044 (0.0022)	MaskLoss 0.1123 (0.0881)	MaskBCELoss 0.0604 (0.0170)	MaskDICELoss 0.0519 (0.0711)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 137 is less than current step: 499. Dropping entry: {'train/loss': 0.3619766443967819, 'train/ce_loss': 0.040728759765625, 'train/seg_cls_loss': 0.0013896942138671875, 'train/kl_loss': 0.0021942138671875, 'train/mask_bce_loss': 0.017022371734492482, 'train/mask_dice_loss': 0.07105523962527513, 'train/mask_loss': 0.0880776111036539, 'metrics/total_secs_per_batch': 50.17861986160278, 'metrics/data_secs_per_batch': 22.3441410779953, '_timestamp': 1741696732.8588052}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 137 is less than current step: 499. Dropping entry: {'train/lr': 0.00029279518072289156, '_timestamp': 1741696732.8590827}).
Epoch: [1][139/500]	Time 43.936 (43.936)	Loss 0.2919 (0.4401)	CeLoss 0.0635 (0.0610)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0031 (0.0025)	MaskLoss 0.0712 (0.1024)	MaskBCELoss 0.0298 (0.0167)	MaskDICELoss 0.0414 (0.0856)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 138 is less than current step: 499. Dropping entry: {'train/loss': 0.44009708166122435, 'train/ce_loss': 0.06097412109375, 'train/seg_cls_loss': 0.001306915283203125, 'train/kl_loss': 0.002509307861328125, 'train/mask_bce_loss': 0.016716389753855764, 'train/mask_dice_loss': 0.08563580214977265, 'train/mask_loss': 0.10235219299793244, 'metrics/total_secs_per_batch': 43.93647027015686, 'metrics/data_secs_per_batch': 19.769882488250733, '_timestamp': 1741696776.7952938}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 138 is less than current step: 499. Dropping entry: {'train/lr': 0.00029278313253012047, '_timestamp': 1741696776.7956984}).
Epoch: [1][140/500]	Time 43.667 (43.667)	Loss 0.4372 (0.4439)	CeLoss 0.0258 (0.0409)	SegCLSLoss 0.0017 (0.0022)	KLLoss 0.0024 (0.0029)	MaskLoss 0.1042 (0.1106)	MaskBCELoss 0.0042 (0.0217)	MaskDICELoss 0.1000 (0.0889)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 139 is less than current step: 499. Dropping entry: {'train/loss': 0.4438617080450058, 'train/ce_loss': 0.04085693359375, 'train/seg_cls_loss': 0.002240753173828125, 'train/kl_loss': 0.00293731689453125, 'train/mask_bce_loss': 0.021687381574884056, 'train/mask_dice_loss': 0.08890591487288475, 'train/mask_loss': 0.11059329509735108, 'metrics/total_secs_per_batch': 43.66710543632507, 'metrics/data_secs_per_batch': 19.13863410949707, '_timestamp': 1741696820.4624422}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 139 is less than current step: 499. Dropping entry: {'train/lr': 0.0002927590361445783, '_timestamp': 1741696820.4628153}).
Epoch: [1][141/500]	Time 47.309 (47.309)	Loss 0.3390 (0.3484)	CeLoss 0.0378 (0.0420)	SegCLSLoss 0.0007 (0.0022)	KLLoss 0.0019 (0.0024)	MaskLoss 0.0844 (0.0832)	MaskBCELoss 0.0194 (0.0150)	MaskDICELoss 0.0650 (0.0682)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 140 is less than current step: 499. Dropping entry: {'train/loss': 0.34840352460741997, 'train/ce_loss': 0.04197998046875, 'train/seg_cls_loss': 0.00224609375, 'train/kl_loss': 0.002433013916015625, 'train/mask_bce_loss': 0.015039440034888685, 'train/mask_dice_loss': 0.06820908971130848, 'train/mask_loss': 0.08324853219091892, 'metrics/total_secs_per_batch': 47.309250593185425, 'metrics/data_secs_per_batch': 21.784920048713683, '_timestamp': 1741696867.7716541}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 140 is less than current step: 499. Dropping entry: {'train/lr': 0.0002927469879518072, '_timestamp': 1741696867.7719376}).
Epoch: [1][142/500]	Time 49.170 (49.170)	Loss 0.4833 (0.4206)	CeLoss 0.0674 (0.0546)	SegCLSLoss 0.0009 (0.0028)	KLLoss 0.0020 (0.0027)	MaskLoss 0.1107 (0.1004)	MaskBCELoss 0.0145 (0.0198)	MaskDICELoss 0.0962 (0.0806)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 141 is less than current step: 499. Dropping entry: {'train/loss': 0.4205867022275925, 'train/ce_loss': 0.05460205078125, 'train/seg_cls_loss': 0.0027568817138671877, 'train/kl_loss': 0.0026641845703125, 'train/mask_bce_loss': 0.019825977645814417, 'train/mask_dice_loss': 0.080595014244318, 'train/mask_loss': 0.10042099207639694, 'metrics/total_secs_per_batch': 49.17017364501953, 'metrics/data_secs_per_batch': 22.46719846725464, '_timestamp': 1741696916.9420516}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 141 is less than current step: 499. Dropping entry: {'train/lr': 0.0002927349397590361, '_timestamp': 1741696916.9423535}).
Epoch: [1][143/500]	Time 44.419 (44.419)	Loss 0.4249 (0.3940)	CeLoss 0.0247 (0.0486)	SegCLSLoss 0.0011 (0.0018)	KLLoss 0.0022 (0.0021)	MaskLoss 0.1073 (0.0929)	MaskBCELoss 0.0158 (0.0147)	MaskDICELoss 0.0915 (0.0783)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 142 is less than current step: 499. Dropping entry: {'train/loss': 0.39398544281721115, 'train/ce_loss': 0.0485595703125, 'train/seg_cls_loss': 0.001824951171875, 'train/kl_loss': 0.002121734619140625, 'train/mask_bce_loss': 0.01468468679813668, 'train/mask_dice_loss': 0.07826339304447175, 'train/mask_loss': 0.09294807948172093, 'metrics/total_secs_per_batch': 44.41926407814026, 'metrics/data_secs_per_batch': 19.546469044685363, '_timestamp': 1741696961.361267}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 142 is less than current step: 499. Dropping entry: {'train/lr': 0.000292722891566265, '_timestamp': 1741696961.3615792}).
Epoch: [1][144/500]	Time 42.776 (42.776)	Loss 0.1976 (0.4168)	CeLoss 0.0243 (0.0396)	SegCLSLoss 0.0015 (0.0027)	KLLoss 0.0032 (0.0028)	MaskLoss 0.0532 (0.1034)	MaskBCELoss 0.0217 (0.0203)	MaskDICELoss 0.0315 (0.0831)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 143 is less than current step: 499. Dropping entry: {'train/loss': 0.4167980536818504, 'train/ce_loss': 0.03963623046875, 'train/seg_cls_loss': 0.0027225494384765627, 'train/kl_loss': 0.0028411865234375, 'train/mask_bce_loss': 0.02026311825029552, 'train/mask_dice_loss': 0.08311092294752598, 'train/mask_loss': 0.10337404124438762, 'metrics/total_secs_per_batch': 42.77626943588257, 'metrics/data_secs_per_batch': 19.501495170593262, '_timestamp': 1741697004.1373956}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 143 is less than current step: 499. Dropping entry: {'train/lr': 0.00029271084337349393, '_timestamp': 1741697004.1376758}).
Epoch: [1][145/500]	Time 51.634 (51.634)	Loss 0.4181 (0.3460)	CeLoss 0.0737 (0.0400)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0038 (0.0025)	MaskLoss 0.0930 (0.0801)	MaskBCELoss 0.0162 (0.0087)	MaskDICELoss 0.0768 (0.0714)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 144 is less than current step: 499. Dropping entry: {'train/loss': 0.34600067026913167, 'train/ce_loss': 0.0400146484375, 'train/seg_cls_loss': 0.00082244873046875, 'train/kl_loss': 0.00250244140625, 'train/mask_bce_loss': 0.008667275169864297, 'train/mask_dice_loss': 0.07142922542989254, 'train/mask_loss': 0.0800965003669262, 'metrics/total_secs_per_batch': 51.633941411972046, 'metrics/data_secs_per_batch': 24.05893654823303, '_timestamp': 1741697055.7713923}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 144 is less than current step: 499. Dropping entry: {'train/lr': 0.00029269879518072284, '_timestamp': 1741697055.7716775}).
Epoch: [1][146/500]	Time 50.035 (50.035)	Loss 0.4868 (0.3654)	CeLoss 0.0559 (0.0383)	SegCLSLoss 0.0007 (0.0019)	KLLoss 0.0019 (0.0026)	MaskLoss 0.1143 (0.0883)	MaskBCELoss 0.0143 (0.0148)	MaskDICELoss 0.1000 (0.0735)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 145 is less than current step: 499. Dropping entry: {'train/loss': 0.36541187278926374, 'train/ce_loss': 0.03829345703125, 'train/seg_cls_loss': 0.0018707275390625, 'train/kl_loss': 0.00264739990234375, 'train/mask_bce_loss': 0.014828570652753115, 'train/mask_dice_loss': 0.07346016742521896, 'train/mask_loss': 0.08828873932361603, 'metrics/total_secs_per_batch': 50.03540062904358, 'metrics/data_secs_per_batch': 22.006785988807678, '_timestamp': 1741697105.8081565}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 145 is less than current step: 499. Dropping entry: {'train/lr': 0.00029268674698795176, '_timestamp': 1741697105.809208}).
Epoch: [1][147/500]	Time 44.830 (44.830)	Loss 0.4805 (0.3100)	CeLoss 0.0287 (0.0433)	SegCLSLoss 0.0047 (0.0020)	KLLoss 0.0032 (0.0027)	MaskLoss 0.1271 (0.0734)	MaskBCELoss 0.0312 (0.0153)	MaskDICELoss 0.0960 (0.0581)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 146 is less than current step: 499. Dropping entry: {'train/loss': 0.3100345306098461, 'train/ce_loss': 0.0432861328125, 'train/seg_cls_loss': 0.0019840240478515626, 'train/kl_loss': 0.002725982666015625, 'train/mask_bce_loss': 0.01530730543890968, 'train/mask_dice_loss': 0.058111815224401654, 'train/mask_loss': 0.07341911827679723, 'metrics/total_secs_per_batch': 44.83002424240112, 'metrics/data_secs_per_batch': 19.696456408500673, '_timestamp': 1741697150.6380863}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 146 is less than current step: 499. Dropping entry: {'train/lr': 0.0002926746987951807, '_timestamp': 1741697150.6391373}).
Epoch: [1][148/500]	Time 50.611 (50.611)	Loss 0.4350 (0.3644)	CeLoss 0.0245 (0.0280)	SegCLSLoss 0.0015 (0.0019)	KLLoss 0.0029 (0.0032)	MaskLoss 0.1431 (0.0966)	MaskBCELoss 0.0827 (0.0272)	MaskDICELoss 0.0604 (0.0695)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 147 is less than current step: 499. Dropping entry: {'train/loss': 0.3644410833716393, 'train/ce_loss': 0.02803955078125, 'train/seg_cls_loss': 0.0019283294677734375, 'train/kl_loss': 0.003159332275390625, 'train/mask_bce_loss': 0.027154782926663755, 'train/mask_dice_loss': 0.06949088517576456, 'train/mask_loss': 0.09664566777646541, 'metrics/total_secs_per_batch': 50.61086630821228, 'metrics/data_secs_per_batch': 23.405406737327574, '_timestamp': 1741697201.2477653}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 147 is less than current step: 499. Dropping entry: {'train/lr': 0.00029266265060240963, '_timestamp': 1741697201.2480533}).
Epoch: [1][149/500]	Time 50.869 (50.869)	Loss 0.5030 (0.4175)	CeLoss 0.0811 (0.0592)	SegCLSLoss 0.0017 (0.0011)	KLLoss 0.0026 (0.0028)	MaskLoss 0.1192 (0.0978)	MaskBCELoss 0.0292 (0.0181)	MaskDICELoss 0.0901 (0.0797)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 148 is less than current step: 499. Dropping entry: {'train/loss': 0.417529021948576, 'train/ce_loss': 0.05919189453125, 'train/seg_cls_loss': 0.0010562896728515624, 'train/kl_loss': 0.00281219482421875, 'train/mask_bce_loss': 0.01812665381003171, 'train/mask_dice_loss': 0.07967928217258305, 'train/mask_loss': 0.09780593458563089, 'metrics/total_secs_per_batch': 50.86850619316101, 'metrics/data_secs_per_batch': 24.733781337738037, '_timestamp': 1741697252.1163585}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 148 is less than current step: 499. Dropping entry: {'train/lr': 0.00029265060240963854, '_timestamp': 1741697252.116682}).
Epoch: [1][150/500]	Time 48.564 (48.564)	Loss 0.4509 (0.3518)	CeLoss 0.0160 (0.0424)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0032 (0.0021)	MaskLoss 0.1215 (0.0844)	MaskBCELoss 0.0274 (0.0156)	MaskDICELoss 0.0940 (0.0688)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 149 is less than current step: 499. Dropping entry: {'train/loss': 0.3517753018066287, 'train/ce_loss': 0.042431640625, 'train/seg_cls_loss': 0.00135040283203125, 'train/kl_loss': 0.0020843505859375, 'train/mask_bce_loss': 0.015631634346209466, 'train/mask_dice_loss': 0.06881452994421125, 'train/mask_loss': 0.08444616459310055, 'metrics/total_secs_per_batch': 48.563535928726196, 'metrics/data_secs_per_batch': 22.555180191993713, '_timestamp': 1741697300.679785}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 149 is less than current step: 499. Dropping entry: {'train/lr': 0.00029262650602409636, '_timestamp': 1741697300.6800456}).
Epoch: [1][151/500]	Time 49.276 (49.276)	Loss 0.1823 (0.2978)	CeLoss 0.0645 (0.0451)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0033 (0.0024)	MaskLoss 0.0377 (0.0727)	MaskBCELoss 0.0183 (0.0206)	MaskDICELoss 0.0194 (0.0521)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 150 is less than current step: 499. Dropping entry: {'train/loss': 0.2978228373453021, 'train/ce_loss': 0.0450927734375, 'train/seg_cls_loss': 0.0014263153076171874, 'train/kl_loss': 0.00236968994140625, 'train/mask_bce_loss': 0.02058446075534448, 'train/mask_dice_loss': 0.052112700510770084, 'train/mask_loss': 0.07269716020673514, 'metrics/total_secs_per_batch': 49.27553725242615, 'metrics/data_secs_per_batch': 21.812833762168886, '_timestamp': 1741697349.9553406}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 150 is less than current step: 499. Dropping entry: {'train/lr': 0.0002926144578313253, '_timestamp': 1741697349.955621}).
Epoch: [1][152/500]	Time 47.900 (47.900)	Loss 0.4481 (0.2781)	CeLoss 0.0250 (0.0403)	SegCLSLoss 0.0016 (0.0009)	KLLoss 0.0018 (0.0015)	MaskLoss 0.1105 (0.0632)	MaskBCELoss 0.0108 (0.0084)	MaskDICELoss 0.0998 (0.0548)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 151 is less than current step: 499. Dropping entry: {'train/loss': 0.2781399076804519, 'train/ce_loss': 0.04033203125, 'train/seg_cls_loss': 0.000888824462890625, 'train/kl_loss': 0.0014923095703125, 'train/mask_bce_loss': 0.008361034328117967, 'train/mask_dice_loss': 0.05479049384593963, 'train/mask_loss': 0.06315152645111084, 'metrics/total_secs_per_batch': 47.900474309921265, 'metrics/data_secs_per_batch': 22.678646945953368, '_timestamp': 1741697397.8557956}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 151 is less than current step: 499. Dropping entry: {'train/lr': 0.0002926024096385542, '_timestamp': 1741697397.8562076}).
Epoch: [1][153/500]	Time 47.950 (47.950)	Loss 0.0578 (0.3168)	CeLoss 0.0579 (0.0479)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0778)	MaskBCELoss 0.0000 (0.0227)	MaskDICELoss 0.0000 (0.0551)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 152 is less than current step: 499. Dropping entry: {'train/loss': 0.3167643342167139, 'train/ce_loss': 0.04791259765625, 'train/seg_cls_loss': 0.00125274658203125, 'train/kl_loss': 0.0022857666015625, 'train/mask_bce_loss': 0.022702177381142975, 'train/mask_dice_loss': 0.05513003512751311, 'train/mask_loss': 0.07783221276476979, 'metrics/total_secs_per_batch': 47.94969129562378, 'metrics/data_secs_per_batch': 22.326469516754152, '_timestamp': 1741697445.8068388}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 152 is less than current step: 499. Dropping entry: {'train/lr': 0.0002925903614457831, '_timestamp': 1741697445.8079174}).
Epoch: [1][154/500]	Time 44.978 (44.978)	Loss 0.4403 (0.4380)	CeLoss 0.0214 (0.0450)	SegCLSLoss 0.0016 (0.0028)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1075 (0.1065)	MaskBCELoss 0.0076 (0.0188)	MaskDICELoss 0.0999 (0.0877)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 153 is less than current step: 499. Dropping entry: {'train/loss': 0.4379693686962128, 'train/ce_loss': 0.04501953125, 'train/seg_cls_loss': 0.00281219482421875, 'train/kl_loss': 0.0031829833984375, 'train/mask_bce_loss': 0.018806502548977734, 'train/mask_dice_loss': 0.08766233175992966, 'train/mask_loss': 0.10646883472800255, 'metrics/total_secs_per_batch': 44.978010416030884, 'metrics/data_secs_per_batch': 20.044274640083312, '_timestamp': 1741697490.7846794}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 153 is less than current step: 499. Dropping entry: {'train/lr': 0.000292578313253012, '_timestamp': 1741697490.7856784}).
Epoch: [1][155/500]	Time 46.323 (46.323)	Loss 0.0544 (0.3654)	CeLoss 0.0139 (0.0380)	SegCLSLoss 0.0009 (0.0023)	KLLoss 0.0027 (0.0028)	MaskLoss 0.0136 (0.0882)	MaskBCELoss 0.0085 (0.0146)	MaskDICELoss 0.0051 (0.0736)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 154 is less than current step: 499. Dropping entry: {'train/loss': 0.36544003915041684, 'train/ce_loss': 0.038006591796875, 'train/seg_cls_loss': 0.0023067474365234377, 'train/kl_loss': 0.0027587890625, 'train/mask_bce_loss': 0.014635708089917899, 'train/mask_dice_loss': 0.07357584754936397, 'train/mask_loss': 0.08821155605837702, 'metrics/total_secs_per_batch': 46.32307314872742, 'metrics/data_secs_per_batch': 20.018598890304567, '_timestamp': 1741697537.1079392}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 154 is less than current step: 499. Dropping entry: {'train/lr': 0.0002925662650602409, '_timestamp': 1741697537.1090379}).
Epoch: [1][156/500]	Time 46.180 (46.180)	Loss 0.4568 (0.4249)	CeLoss 0.0145 (0.0496)	SegCLSLoss 0.0032 (0.0014)	KLLoss 0.0023 (0.0023)	MaskLoss 0.1328 (0.1038)	MaskBCELoss 0.0465 (0.0215)	MaskDICELoss 0.0864 (0.0823)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 155 is less than current step: 499. Dropping entry: {'train/loss': 0.4248756989836693, 'train/ce_loss': 0.0496337890625, 'train/seg_cls_loss': 0.0014070510864257813, 'train/kl_loss': 0.0022922515869140624, 'train/mask_bce_loss': 0.02149495228077285, 'train/mask_dice_loss': 0.08230982888489961, 'train/mask_loss': 0.10380478166043758, 'metrics/total_secs_per_batch': 46.17994689941406, 'metrics/data_secs_per_batch': 22.787554574012756, '_timestamp': 1741697583.2877688}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 155 is less than current step: 499. Dropping entry: {'train/lr': 0.00029255421686746983, '_timestamp': 1741697583.2887933}).
Epoch: [1][157/500]	Time 50.446 (50.446)	Loss 0.4770 (0.3767)	CeLoss 0.0679 (0.0545)	SegCLSLoss 0.0020 (0.0012)	KLLoss 0.0030 (0.0022)	MaskLoss 0.1034 (0.0867)	MaskBCELoss 0.0044 (0.0138)	MaskDICELoss 0.0990 (0.0729)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 156 is less than current step: 499. Dropping entry: {'train/loss': 0.3766562916338444, 'train/ce_loss': 0.0544921875, 'train/seg_cls_loss': 0.0011539459228515625, 'train/kl_loss': 0.002245330810546875, 'train/mask_bce_loss': 0.013794661755673588, 'train/mask_dice_loss': 0.07291615474969149, 'train/mask_loss': 0.08671081699430942, 'metrics/total_secs_per_batch': 50.446009397506714, 'metrics/data_secs_per_batch': 21.682436680793764, '_timestamp': 1741697633.7325327}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 156 is less than current step: 499. Dropping entry: {'train/lr': 0.0002925421686746988, '_timestamp': 1741697633.732807}).
Epoch: [1][158/500]	Time 46.292 (46.292)	Loss 0.1713 (0.4331)	CeLoss 0.0461 (0.0474)	SegCLSLoss 0.0043 (0.0015)	KLLoss 0.0043 (0.0028)	MaskLoss 0.0334 (0.1233)	MaskBCELoss 0.0073 (0.0555)	MaskDICELoss 0.0261 (0.0678)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 157 is less than current step: 499. Dropping entry: {'train/loss': 0.4331204812973738, 'train/ce_loss': 0.04742431640625, 'train/seg_cls_loss': 0.0015399932861328125, 'train/kl_loss': 0.00280609130859375, 'train/mask_bce_loss': 0.05553830587305129, 'train/mask_dice_loss': 0.06776926834136247, 'train/mask_loss': 0.1233075749129057, 'metrics/total_secs_per_batch': 46.291542291641235, 'metrics/data_secs_per_batch': 21.793281078338623, '_timestamp': 1741697680.0241904}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 157 is less than current step: 499. Dropping entry: {'train/lr': 0.0002925301204819277, '_timestamp': 1741697680.0246375}).
Epoch: [1][159/500]	Time 46.256 (46.256)	Loss 0.2878 (0.4347)	CeLoss 0.0664 (0.0611)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0037 (0.0028)	MaskLoss 0.0750 (0.1027)	MaskBCELoss 0.0413 (0.0202)	MaskDICELoss 0.0337 (0.0825)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 158 is less than current step: 499. Dropping entry: {'train/loss': 0.43470683991909026, 'train/ce_loss': 0.0611083984375, 'train/seg_cls_loss': 0.0009927749633789062, 'train/kl_loss': 0.0027820587158203123, 'train/mask_bce_loss': 0.020162747893482446, 'train/mask_dice_loss': 0.08249181881546974, 'train/mask_loss': 0.10265456661581993, 'metrics/total_secs_per_batch': 46.255985736846924, 'metrics/data_secs_per_batch': 20.658142232894896, '_timestamp': 1741697726.2802207}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 158 is less than current step: 499. Dropping entry: {'train/lr': 0.0002925180722891566, '_timestamp': 1741697726.2805126}).
Epoch: [1][160/500]	Time 46.777 (46.777)	Loss 0.3946 (0.4504)	CeLoss 0.0693 (0.0580)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0040 (0.0026)	MaskLoss 0.0895 (0.1119)	MaskBCELoss 0.0183 (0.0293)	MaskDICELoss 0.0711 (0.0826)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 159 is less than current step: 499. Dropping entry: {'train/loss': 0.45038843154907227, 'train/ce_loss': 0.0580078125, 'train/seg_cls_loss': 0.0014934539794921875, 'train/kl_loss': 0.002564239501953125, 'train/mask_bce_loss': 0.029320408485364168, 'train/mask_dice_loss': 0.08261952139437198, 'train/mask_loss': 0.1119399294257164, 'metrics/total_secs_per_batch': 46.77678179740906, 'metrics/data_secs_per_batch': 20.261448979377747, '_timestamp': 1741697773.0569742}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 159 is less than current step: 499. Dropping entry: {'train/lr': 0.00029249397590361444, '_timestamp': 1741697773.0572388}).
Epoch: [1][161/500]	Time 50.225 (50.225)	Loss 0.2185 (0.3748)	CeLoss 0.1172 (0.0517)	SegCLSLoss 0.0004 (0.0016)	KLLoss 0.0025 (0.0021)	MaskLoss 0.0300 (0.0893)	MaskBCELoss 0.0105 (0.0185)	MaskDICELoss 0.0195 (0.0708)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 160 is less than current step: 499. Dropping entry: {'train/loss': 0.3747576197609305, 'train/ce_loss': 0.05174560546875, 'train/seg_cls_loss': 0.001644134521484375, 'train/kl_loss': 0.002133941650390625, 'train/mask_bce_loss': 0.018488372245337815, 'train/mask_dice_loss': 0.07077822834253311, 'train/mask_loss': 0.08926660045981408, 'metrics/total_secs_per_batch': 50.2246413230896, 'metrics/data_secs_per_batch': 21.722963786125185, '_timestamp': 1741697823.2815201}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 160 is less than current step: 499. Dropping entry: {'train/lr': 0.00029248192771084335, '_timestamp': 1741697823.2817965}).
Epoch: [1][162/500]	Time 52.912 (52.912)	Loss 0.4230 (0.3978)	CeLoss 0.0222 (0.0470)	SegCLSLoss 0.0025 (0.0018)	KLLoss 0.0033 (0.0025)	MaskLoss 0.1026 (0.1013)	MaskBCELoss 0.0072 (0.0289)	MaskDICELoss 0.0954 (0.0724)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 161 is less than current step: 499. Dropping entry: {'train/loss': 0.39781962484121325, 'train/ce_loss': 0.04697265625, 'train/seg_cls_loss': 0.0018304824829101563, 'train/kl_loss': 0.002530670166015625, 'train/mask_bce_loss': 0.02885177996940911, 'train/mask_dice_loss': 0.07243624133989215, 'train/mask_loss': 0.1012880189344287, 'metrics/total_secs_per_batch': 52.9119610786438, 'metrics/data_secs_per_batch': 22.998258090019227, '_timestamp': 1741697876.193507}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 161 is less than current step: 499. Dropping entry: {'train/lr': 0.00029246987951807226, '_timestamp': 1741697876.19378}).
Epoch: [1][163/500]	Time 44.810 (44.810)	Loss 0.4414 (0.3682)	CeLoss 0.0260 (0.0385)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0025 (0.0024)	MaskLoss 0.1065 (0.0943)	MaskBCELoss 0.0067 (0.0253)	MaskDICELoss 0.0998 (0.0690)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 162 is less than current step: 499. Dropping entry: {'train/loss': 0.36822268441319467, 'train/ce_loss': 0.038525390625, 'train/seg_cls_loss': 0.001230621337890625, 'train/kl_loss': 0.00243682861328125, 'train/mask_bce_loss': 0.025282962387427686, 'train/mask_dice_loss': 0.06901868265122175, 'train/mask_loss': 0.09430164396762848, 'metrics/total_secs_per_batch': 44.80991792678833, 'metrics/data_secs_per_batch': 20.620157194137573, '_timestamp': 1741697921.0044324}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 162 is less than current step: 499. Dropping entry: {'train/lr': 0.00029245783132530117, '_timestamp': 1741697921.0053425}).
Epoch: [1][164/500]	Time 51.266 (51.266)	Loss 0.4315 (0.4062)	CeLoss 0.0503 (0.0340)	SegCLSLoss 0.0019 (0.0017)	KLLoss 0.0038 (0.0026)	MaskLoss 0.0993 (0.0988)	MaskBCELoss 0.0103 (0.0132)	MaskDICELoss 0.0889 (0.0856)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 163 is less than current step: 499. Dropping entry: {'train/loss': 0.4061654979363084, 'train/ce_loss': 0.03399658203125, 'train/seg_cls_loss': 0.001746368408203125, 'train/kl_loss': 0.002557373046875, 'train/mask_bce_loss': 0.013153333048103377, 'train/mask_dice_loss': 0.08560923933982849, 'train/mask_loss': 0.09876257479190827, 'metrics/total_secs_per_batch': 51.266358613967896, 'metrics/data_secs_per_batch': 22.348061513900756, '_timestamp': 1741697972.2697632}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 163 is less than current step: 499. Dropping entry: {'train/lr': 0.0002924457831325301, '_timestamp': 1741697972.2700427}).
Epoch: [1][165/500]	Time 46.025 (46.025)	Loss 0.4426 (0.3268)	CeLoss 0.0232 (0.0453)	SegCLSLoss 0.0013 (0.0014)	KLLoss 0.0019 (0.0022)	MaskLoss 0.1084 (0.0774)	MaskBCELoss 0.0085 (0.0155)	MaskDICELoss 0.1000 (0.0619)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 164 is less than current step: 499. Dropping entry: {'train/loss': 0.32679333835840224, 'train/ce_loss': 0.045263671875, 'train/seg_cls_loss': 0.0014406204223632812, 'train/kl_loss': 0.00216064453125, 'train/mask_bce_loss': 0.015488325501792133, 'train/mask_dice_loss': 0.06190339084714651, 'train/mask_loss': 0.07739171711727977, 'metrics/total_secs_per_batch': 46.024832248687744, 'metrics/data_secs_per_batch': 19.417482089996337, '_timestamp': 1741698018.2946866}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 164 is less than current step: 499. Dropping entry: {'train/lr': 0.000292433734939759, '_timestamp': 1741698018.2949824}).
Epoch: [1][166/500]	Time 45.125 (45.125)	Loss 0.5880 (0.3293)	CeLoss 0.0601 (0.0455)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0023 (0.0019)	MaskLoss 0.1706 (0.0768)	MaskBCELoss 0.0786 (0.0130)	MaskDICELoss 0.0920 (0.0639)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 165 is less than current step: 499. Dropping entry: {'train/loss': 0.32933577289804816, 'train/ce_loss': 0.045465087890625, 'train/seg_cls_loss': 0.0011844635009765625, 'train/kl_loss': 0.001886749267578125, 'train/mask_bce_loss': 0.012958975380752236, 'train/mask_dice_loss': 0.06386470925062895, 'train/mask_loss': 0.07682368531823158, 'metrics/total_secs_per_batch': 45.12522602081299, 'metrics/data_secs_per_batch': 20.309889316558838, '_timestamp': 1741698063.4199069}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 165 is less than current step: 499. Dropping entry: {'train/lr': 0.0002924216867469879, '_timestamp': 1741698063.4201899}).
Epoch: [1][167/500]	Time 48.574 (48.574)	Loss 0.4766 (0.3260)	CeLoss 0.0635 (0.0541)	SegCLSLoss 0.0016 (0.0009)	KLLoss 0.0039 (0.0023)	MaskLoss 0.1059 (0.0761)	MaskBCELoss 0.0077 (0.0177)	MaskDICELoss 0.0982 (0.0584)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 166 is less than current step: 499. Dropping entry: {'train/loss': 0.3260494373738766, 'train/ce_loss': 0.05411376953125, 'train/seg_cls_loss': 0.0008525848388671875, 'train/kl_loss': 0.00229644775390625, 'train/mask_bce_loss': 0.017661391082219778, 'train/mask_dice_loss': 0.05844826608663425, 'train/mask_loss': 0.07610965620260686, 'metrics/total_secs_per_batch': 48.57406830787659, 'metrics/data_secs_per_batch': 22.885585856437682, '_timestamp': 1741698111.9938931}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 166 is less than current step: 499. Dropping entry: {'train/lr': 0.00029240963855421687, '_timestamp': 1741698111.9941545}).
Epoch: [1][168/500]	Time 48.885 (48.885)	Loss 0.3511 (0.3595)	CeLoss 0.0300 (0.0513)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0042 (0.0032)	MaskLoss 0.0855 (0.0850)	MaskBCELoss 0.0129 (0.0177)	MaskDICELoss 0.0726 (0.0673)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 167 is less than current step: 499. Dropping entry: {'train/loss': 0.35948356539011, 'train/ce_loss': 0.05130615234375, 'train/seg_cls_loss': 0.001146697998046875, 'train/kl_loss': 0.00323944091796875, 'train/mask_bce_loss': 0.017700149770826103, 'train/mask_dice_loss': 0.06725616678595543, 'train/mask_loss': 0.08495631571859122, 'metrics/total_secs_per_batch': 48.884873151779175, 'metrics/data_secs_per_batch': 20.875861406326294, '_timestamp': 1741698160.878848}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 167 is less than current step: 499. Dropping entry: {'train/lr': 0.0002923975903614458, '_timestamp': 1741698160.8791194}).
Epoch: [1][169/500]	Time 43.607 (43.607)	Loss 0.2854 (0.3380)	CeLoss 0.0236 (0.0338)	SegCLSLoss 0.0013 (0.0026)	KLLoss 0.0026 (0.0018)	MaskLoss 0.0795 (0.0871)	MaskBCELoss 0.0296 (0.0237)	MaskDICELoss 0.0499 (0.0635)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 168 is less than current step: 499. Dropping entry: {'train/loss': 0.3380373542197049, 'train/ce_loss': 0.0337646484375, 'train/seg_cls_loss': 0.002576446533203125, 'train/kl_loss': 0.001813507080078125, 'train/mask_bce_loss': 0.02367194416001439, 'train/mask_dice_loss': 0.06345217302441597, 'train/mask_loss': 0.08712411746382713, 'metrics/total_secs_per_batch': 43.607033491134644, 'metrics/data_secs_per_batch': 19.021646189689637, '_timestamp': 1741698204.485836}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 168 is less than current step: 499. Dropping entry: {'train/lr': 0.0002923855421686747, '_timestamp': 1741698204.4862156}).
Epoch: [1][170/500]	Time 47.002 (47.002)	Loss 1.0177 (0.4282)	CeLoss 0.0258 (0.0479)	SegCLSLoss 0.0019 (0.0020)	KLLoss 0.0020 (0.0022)	MaskLoss 0.3950 (0.1161)	MaskBCELoss 0.2957 (0.0437)	MaskDICELoss 0.0994 (0.0724)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 169 is less than current step: 499. Dropping entry: {'train/loss': 0.4281688969582319, 'train/ce_loss': 0.04794921875, 'train/seg_cls_loss': 0.00199432373046875, 'train/kl_loss': 0.0021820068359375, 'train/mask_bce_loss': 0.043747652717866, 'train/mask_dice_loss': 0.0723729875870049, 'train/mask_loss': 0.1161206379532814, 'metrics/total_secs_per_batch': 47.001681327819824, 'metrics/data_secs_per_batch': 21.17990803718567, '_timestamp': 1741698251.4875922}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 169 is less than current step: 499. Dropping entry: {'train/lr': 0.0002923614457831325, '_timestamp': 1741698251.4878433}).
Epoch: [1][171/500]	Time 53.511 (53.511)	Loss 0.3789 (0.3144)	CeLoss 0.0228 (0.0312)	SegCLSLoss 0.0036 (0.0020)	KLLoss 0.0032 (0.0027)	MaskLoss 0.0967 (0.0767)	MaskBCELoss 0.0179 (0.0136)	MaskDICELoss 0.0788 (0.0630)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 170 is less than current step: 499. Dropping entry: {'train/loss': 0.3143554784357548, 'train/ce_loss': 0.03123779296875, 'train/seg_cls_loss': 0.0020364761352539063, 'train/kl_loss': 0.00272369384765625, 'train/mask_bce_loss': 0.013613699586130679, 'train/mask_dice_loss': 0.06304911002516747, 'train/mask_loss': 0.0766628110781312, 'metrics/total_secs_per_batch': 53.51106929779053, 'metrics/data_secs_per_batch': 25.52244598865509, '_timestamp': 1741698304.9986627}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 170 is less than current step: 499. Dropping entry: {'train/lr': 0.0002923493975903614, '_timestamp': 1741698304.9989598}).
Epoch: [1][172/500]	Time 49.898 (49.898)	Loss 0.4437 (0.3464)	CeLoss 0.0245 (0.0435)	SegCLSLoss 0.0014 (0.0009)	KLLoss 0.0033 (0.0027)	MaskLoss 0.1076 (0.0854)	MaskBCELoss 0.0077 (0.0209)	MaskDICELoss 0.0999 (0.0645)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 171 is less than current step: 499. Dropping entry: {'train/loss': 0.3463921047747135, 'train/ce_loss': 0.04345703125, 'train/seg_cls_loss': 0.0008758544921875, 'train/kl_loss': 0.002679443359375, 'train/mask_bce_loss': 0.020864766900194807, 'train/mask_dice_loss': 0.06451037041842937, 'train/mask_loss': 0.08537513706833125, 'metrics/total_secs_per_batch': 49.89845037460327, 'metrics/data_secs_per_batch': 22.692296862602234, '_timestamp': 1741698354.897112}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 171 is less than current step: 499. Dropping entry: {'train/lr': 0.00029233734939759033, '_timestamp': 1741698354.8973932}).
Epoch: [1][173/500]	Time 47.623 (47.623)	Loss 0.0234 (0.3959)	CeLoss 0.0234 (0.0473)	SegCLSLoss 0.0000 (0.0016)	KLLoss 0.0000 (0.0022)	MaskLoss 0.0000 (0.0948)	MaskBCELoss 0.0000 (0.0169)	MaskDICELoss 0.0000 (0.0779)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 172 is less than current step: 499. Dropping entry: {'train/loss': 0.39589847028255465, 'train/ce_loss': 0.047314453125, 'train/seg_cls_loss': 0.0015588760375976562, 'train/kl_loss': 0.0022003173828125, 'train/mask_bce_loss': 0.01692159434314817, 'train/mask_dice_loss': 0.07792104780673981, 'train/mask_loss': 0.09484264180064202, 'metrics/total_secs_per_batch': 47.62298059463501, 'metrics/data_secs_per_batch': 20.025905561447143, '_timestamp': 1741698402.5202138}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 172 is less than current step: 499. Dropping entry: {'train/lr': 0.00029232530120481924, '_timestamp': 1741698402.5205112}).
Epoch: [1][174/500]	Time 51.130 (51.130)	Loss 0.0957 (0.3623)	CeLoss 0.0293 (0.0557)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0023 (0.0024)	MaskLoss 0.0163 (0.0848)	MaskBCELoss 0.0009 (0.0178)	MaskDICELoss 0.0154 (0.0671)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 173 is less than current step: 499. Dropping entry: {'train/loss': 0.3622518017888069, 'train/ce_loss': 0.0556884765625, 'train/seg_cls_loss': 0.00093994140625, 'train/kl_loss': 0.002386474609375, 'train/mask_bce_loss': 0.01775637096725404, 'train/mask_dice_loss': 0.06705585671588779, 'train/mask_loss': 0.08481222875416279, 'metrics/total_secs_per_batch': 51.13030004501343, 'metrics/data_secs_per_batch': 24.06436915397644, '_timestamp': 1741698453.650426}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 173 is less than current step: 499. Dropping entry: {'train/lr': 0.00029231325301204815, '_timestamp': 1741698453.6508532}).
Epoch: [1][175/500]	Time 53.409 (53.409)	Loss 0.4752 (0.3832)	CeLoss 0.0654 (0.0451)	SegCLSLoss 0.0018 (0.0011)	KLLoss 0.0029 (0.0023)	MaskLoss 0.1031 (0.0942)	MaskBCELoss 0.0031 (0.0208)	MaskDICELoss 0.1000 (0.0734)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 174 is less than current step: 499. Dropping entry: {'train/loss': 0.3831719167530537, 'train/ce_loss': 0.0451416015625, 'train/seg_cls_loss': 0.0011425018310546875, 'train/kl_loss': 0.002286529541015625, 'train/mask_bce_loss': 0.02081948348786682, 'train/mask_dice_loss': 0.07340081557631492, 'train/mask_loss': 0.09422030001878738, 'metrics/total_secs_per_batch': 53.409279584884644, 'metrics/data_secs_per_batch': 24.136678624153138, '_timestamp': 1741698507.0596342}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 174 is less than current step: 499. Dropping entry: {'train/lr': 0.00029230120481927706, '_timestamp': 1741698507.0599074}).
Epoch: [1][176/500]	Time 45.405 (45.405)	Loss 0.3411 (0.2965)	CeLoss 0.0217 (0.0412)	SegCLSLoss 0.0030 (0.0020)	KLLoss 0.0048 (0.0020)	MaskLoss 0.0821 (0.0681)	MaskBCELoss 0.0077 (0.0100)	MaskDICELoss 0.0744 (0.0581)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 175 is less than current step: 499. Dropping entry: {'train/loss': 0.2964827738702297, 'train/ce_loss': 0.0412353515625, 'train/seg_cls_loss': 0.0019744873046875, 'train/kl_loss': 0.001978302001953125, 'train/mask_bce_loss': 0.01003658891422674, 'train/mask_dice_loss': 0.05805747788399458, 'train/mask_loss': 0.06809406541287899, 'metrics/total_secs_per_batch': 45.404783964157104, 'metrics/data_secs_per_batch': 20.310245537757872, '_timestamp': 1741698552.4644704}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 175 is less than current step: 499. Dropping entry: {'train/lr': 0.000292289156626506, '_timestamp': 1741698552.4647481}).
Epoch: [1][177/500]	Time 48.636 (48.636)	Loss 0.4739 (0.3654)	CeLoss 0.0610 (0.0391)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0027 (0.0023)	MaskLoss 0.1147 (0.0933)	MaskBCELoss 0.0247 (0.0250)	MaskDICELoss 0.0900 (0.0683)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 176 is less than current step: 499. Dropping entry: {'train/loss': 0.36539559364318847, 'train/ce_loss': 0.03914794921875, 'train/seg_cls_loss': 0.00126495361328125, 'train/kl_loss': 0.002342987060546875, 'train/mask_bce_loss': 0.025040403404273093, 'train/mask_dice_loss': 0.06830623773857951, 'train/mask_loss': 0.09334664111956954, 'metrics/total_secs_per_batch': 48.63554525375366, 'metrics/data_secs_per_batch': 21.0039799451828, '_timestamp': 1741698601.0999565}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 176 is less than current step: 499. Dropping entry: {'train/lr': 0.00029227710843373494, '_timestamp': 1741698601.1002345}).
Epoch: [1][178/500]	Time 48.193 (48.193)	Loss 0.5902 (0.4577)	CeLoss 0.0352 (0.0573)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0028 (0.0026)	MaskLoss 0.1992 (0.1149)	MaskBCELoss 0.1224 (0.0313)	MaskDICELoss 0.0768 (0.0836)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 177 is less than current step: 499. Dropping entry: {'train/loss': 0.45773706138134, 'train/ce_loss': 0.05733642578125, 'train/seg_cls_loss': 0.0012477874755859376, 'train/kl_loss': 0.0026275634765625, 'train/mask_bce_loss': 0.0313088531140238, 'train/mask_dice_loss': 0.08362846747040749, 'train/mask_loss': 0.11493731960654259, 'metrics/total_secs_per_batch': 48.19275522232056, 'metrics/data_secs_per_batch': 21.5556608915329, '_timestamp': 1741698649.2928133}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 177 is less than current step: 499. Dropping entry: {'train/lr': 0.00029226506024096385, '_timestamp': 1741698649.2932382}).
Epoch: [1][179/500]	Time 47.846 (47.846)	Loss 0.3271 (0.3558)	CeLoss 0.0227 (0.0426)	SegCLSLoss 0.0044 (0.0024)	KLLoss 0.0032 (0.0026)	MaskLoss 0.0820 (0.0873)	MaskBCELoss 0.0145 (0.0200)	MaskDICELoss 0.0675 (0.0673)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 178 is less than current step: 499. Dropping entry: {'train/loss': 0.35576823763549326, 'train/ce_loss': 0.04263916015625, 'train/seg_cls_loss': 0.0024341583251953126, 'train/kl_loss': 0.0026031494140625, 'train/mask_bce_loss': 0.019980371091514827, 'train/mask_dice_loss': 0.06734542874619365, 'train/mask_loss': 0.0873258002102375, 'metrics/total_secs_per_batch': 47.84645414352417, 'metrics/data_secs_per_batch': 21.438126850128175, '_timestamp': 1741698697.139216}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 178 is less than current step: 499. Dropping entry: {'train/lr': 0.00029225301204819276, '_timestamp': 1741698697.1395042}).
Epoch: [1][180/500]	Time 47.590 (47.590)	Loss 0.5027 (0.3520)	CeLoss 0.0654 (0.0453)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0027 (0.0023)	MaskLoss 0.1222 (0.0844)	MaskBCELoss 0.0273 (0.0169)	MaskDICELoss 0.0950 (0.0675)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 179 is less than current step: 499. Dropping entry: {'train/loss': 0.3520366780459881, 'train/ce_loss': 0.0453369140625, 'train/seg_cls_loss': 0.0011507034301757812, 'train/kl_loss': 0.00233612060546875, 'train/mask_bce_loss': 0.016874730738345535, 'train/mask_dice_loss': 0.06750637376680971, 'train/mask_loss': 0.084381103515625, 'metrics/total_secs_per_batch': 47.59027290344238, 'metrics/data_secs_per_batch': 21.360760283470153, '_timestamp': 1741698744.7294493}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 179 is less than current step: 499. Dropping entry: {'train/lr': 0.0002922289156626506, '_timestamp': 1741698744.7296944}).
Epoch: [1][181/500]	Time 51.199 (51.199)	Loss 0.4303 (0.3955)	CeLoss 0.0247 (0.0427)	SegCLSLoss 0.0026 (0.0019)	KLLoss 0.0012 (0.0023)	MaskLoss 0.1016 (0.0988)	MaskBCELoss 0.0016 (0.0227)	MaskDICELoss 0.1000 (0.0761)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 180 is less than current step: 499. Dropping entry: {'train/loss': 0.3955457067117095, 'train/ce_loss': 0.04267578125, 'train/seg_cls_loss': 0.0018848419189453126, 'train/kl_loss': 0.002325439453125, 'train/mask_bce_loss': 0.02270879884599708, 'train/mask_dice_loss': 0.07606230303645134, 'train/mask_loss': 0.09877110198140145, 'metrics/total_secs_per_batch': 51.198585748672485, 'metrics/data_secs_per_batch': 22.82605113983154, '_timestamp': 1741698795.9281335}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 180 is less than current step: 499. Dropping entry: {'train/lr': 0.0002922168674698795, '_timestamp': 1741698795.9284189}).
Epoch: [1][182/500]	Time 45.757 (45.757)	Loss 0.4325 (0.3496)	CeLoss 0.0270 (0.0460)	SegCLSLoss 0.0016 (0.0025)	KLLoss 0.0022 (0.0026)	MaskLoss 0.1013 (0.0844)	MaskBCELoss 0.0014 (0.0190)	MaskDICELoss 0.1000 (0.0655)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 181 is less than current step: 499. Dropping entry: {'train/loss': 0.34961840957403184, 'train/ce_loss': 0.04600830078125, 'train/seg_cls_loss': 0.00252685546875, 'train/kl_loss': 0.00258636474609375, 'train/mask_bce_loss': 0.018973943847231566, 'train/mask_dice_loss': 0.06546157686971128, 'train/mask_loss': 0.0844355191104114, 'metrics/total_secs_per_batch': 45.75694155693054, 'metrics/data_secs_per_batch': 19.81856334209442, '_timestamp': 1741698841.6851487}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 181 is less than current step: 499. Dropping entry: {'train/lr': 0.0002922048192771084, '_timestamp': 1741698841.6854484}).
Epoch: [1][183/500]	Time 48.704 (48.704)	Loss 0.4588 (0.3517)	CeLoss 0.0244 (0.0370)	SegCLSLoss 0.0028 (0.0021)	KLLoss 0.0028 (0.0028)	MaskLoss 0.1191 (0.0906)	MaskBCELoss 0.0230 (0.0259)	MaskDICELoss 0.0961 (0.0648)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 182 is less than current step: 499. Dropping entry: {'train/loss': 0.3517159953713417, 'train/ce_loss': 0.03701171875, 'train/seg_cls_loss': 0.002082061767578125, 'train/kl_loss': 0.00279998779296875, 'train/mask_bce_loss': 0.025869230320677162, 'train/mask_dice_loss': 0.06477953996509314, 'train/mask_loss': 0.09064876884222031, 'metrics/total_secs_per_batch': 48.70364952087402, 'metrics/data_secs_per_batch': 23.21727900505066, '_timestamp': 1741698890.3887262}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 182 is less than current step: 499. Dropping entry: {'train/lr': 0.0002921927710843373, '_timestamp': 1741698890.389018}).
Epoch: [1][184/500]	Time 51.166 (51.166)	Loss 0.4288 (0.3271)	CeLoss 0.0222 (0.0365)	SegCLSLoss 0.0033 (0.0019)	KLLoss 0.0028 (0.0027)	MaskLoss 0.1020 (0.0872)	MaskBCELoss 0.0030 (0.0310)	MaskDICELoss 0.0990 (0.0563)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 183 is less than current step: 499. Dropping entry: {'train/loss': 0.3270638570189476, 'train/ce_loss': 0.03646240234375, 'train/seg_cls_loss': 0.0019052505493164062, 'train/kl_loss': 0.002677154541015625, 'train/mask_bce_loss': 0.030981395952403547, 'train/mask_dice_loss': 0.056265500746667384, 'train/mask_loss': 0.08724689781665802, 'metrics/total_secs_per_batch': 51.16571283340454, 'metrics/data_secs_per_batch': 22.871600770950316, '_timestamp': 1741698941.5544634}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 183 is less than current step: 499. Dropping entry: {'train/lr': 0.0002921807228915662, '_timestamp': 1741698941.554768}).
Epoch: [1][185/500]	Time 46.266 (46.266)	Loss 0.0590 (0.3940)	CeLoss 0.0591 (0.0397)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0025)	MaskLoss 0.0000 (0.0955)	MaskBCELoss 0.0000 (0.0155)	MaskDICELoss 0.0000 (0.0800)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 184 is less than current step: 499. Dropping entry: {'train/loss': 0.39396724179387094, 'train/ce_loss': 0.03970947265625, 'train/seg_cls_loss': 0.001470947265625, 'train/kl_loss': 0.00254974365234375, 'train/mask_bce_loss': 0.01551627553999424, 'train/mask_dice_loss': 0.07998660504817963, 'train/mask_loss': 0.09550288356840611, 'metrics/total_secs_per_batch': 46.26551270484924, 'metrics/data_secs_per_batch': 19.272577333450318, '_timestamp': 1741698987.819898}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 184 is less than current step: 499. Dropping entry: {'train/lr': 0.00029216867469879514, '_timestamp': 1741698987.820304}).
Epoch: [1][186/500]	Time 51.372 (51.372)	Loss 0.0162 (0.3704)	CeLoss 0.0162 (0.0459)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0893)	MaskBCELoss 0.0000 (0.0179)	MaskDICELoss 0.0000 (0.0715)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 185 is less than current step: 499. Dropping entry: {'train/loss': 0.3704320082440972, 'train/ce_loss': 0.04588623046875, 'train/seg_cls_loss': 0.0012342453002929688, 'train/kl_loss': 0.0023406982421875, 'train/mask_bce_loss': 0.017856016918085516, 'train/mask_dice_loss': 0.07147540282458067, 'train/mask_loss': 0.0893314179033041, 'metrics/total_secs_per_batch': 51.37165355682373, 'metrics/data_secs_per_batch': 22.17047522068024, '_timestamp': 1741699039.1917028}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 185 is less than current step: 499. Dropping entry: {'train/lr': 0.00029215662650602405, '_timestamp': 1741699039.19218}).
Epoch: [1][187/500]	Time 46.417 (46.417)	Loss 0.4258 (0.3976)	CeLoss 0.0593 (0.0539)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0026 (0.0030)	MaskLoss 0.1255 (0.0961)	MaskBCELoss 0.0694 (0.0222)	MaskDICELoss 0.0561 (0.0739)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 186 is less than current step: 499. Dropping entry: {'train/loss': 0.3975665345788002, 'train/ce_loss': 0.053857421875, 'train/seg_cls_loss': 0.0010601043701171874, 'train/kl_loss': 0.00304718017578125, 'train/mask_bce_loss': 0.022216201829724013, 'train/mask_dice_loss': 0.07393294731155038, 'train/mask_loss': 0.09614914674311877, 'metrics/total_secs_per_batch': 46.41726732254028, 'metrics/data_secs_per_batch': 20.724568128585815, '_timestamp': 1741699085.6088865}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 186 is less than current step: 499. Dropping entry: {'train/lr': 0.000292144578313253, '_timestamp': 1741699085.6092093}).
Epoch: [1][188/500]	Time 46.892 (46.892)	Loss 0.0326 (0.3734)	CeLoss 0.0327 (0.0434)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0889)	MaskBCELoss 0.0000 (0.0141)	MaskDICELoss 0.0000 (0.0748)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 187 is less than current step: 499. Dropping entry: {'train/loss': 0.3733908675611019, 'train/ce_loss': 0.04339599609375, 'train/seg_cls_loss': 0.001482391357421875, 'train/kl_loss': 0.0019123077392578125, 'train/mask_bce_loss': 0.01411776150634978, 'train/mask_dice_loss': 0.0747605174779892, 'train/mask_loss': 0.08887827545404434, 'metrics/total_secs_per_batch': 46.891852140426636, 'metrics/data_secs_per_batch': 20.511812686920166, '_timestamp': 1741699132.5007012}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 187 is less than current step: 499. Dropping entry: {'train/lr': 0.0002921325301204819, '_timestamp': 1741699132.501118}).
Epoch: [1][189/500]	Time 45.903 (45.903)	Loss 0.4647 (0.2835)	CeLoss 0.0496 (0.0608)	SegCLSLoss 0.0003 (0.0006)	KLLoss 0.0036 (0.0025)	MaskLoss 0.1373 (0.0636)	MaskBCELoss 0.0691 (0.0171)	MaskDICELoss 0.0683 (0.0464)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 188 is less than current step: 499. Dropping entry: {'train/loss': 0.28354148641228677, 'train/ce_loss': 0.0608154296875, 'train/seg_cls_loss': 0.0005617141723632812, 'train/kl_loss': 0.002465057373046875, 'train/mask_bce_loss': 0.017129884543828668, 'train/mask_dice_loss': 0.04643175663659349, 'train/mask_loss': 0.06356164054013788, 'metrics/total_secs_per_batch': 45.903424978256226, 'metrics/data_secs_per_batch': 19.500830316543578, '_timestamp': 1741699178.404122}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 188 is less than current step: 499. Dropping entry: {'train/lr': 0.00029212048192771083, '_timestamp': 1741699178.4043887}).
Epoch: [1][190/500]	Time 46.927 (46.927)	Loss 0.3008 (0.3505)	CeLoss 0.0598 (0.0576)	SegCLSLoss 0.0016 (0.0010)	KLLoss 0.0027 (0.0021)	MaskLoss 0.0776 (0.0848)	MaskBCELoss 0.0365 (0.0245)	MaskDICELoss 0.0411 (0.0604)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 189 is less than current step: 499. Dropping entry: {'train/loss': 0.35052030682563784, 'train/ce_loss': 0.05755615234375, 'train/seg_cls_loss': 0.001043701171875, 'train/kl_loss': 0.002114105224609375, 'train/mask_bce_loss': 0.02445121668279171, 'train/mask_dice_loss': 0.06037029009312391, 'train/mask_loss': 0.08482150863856078, 'metrics/total_secs_per_batch': 46.927233934402466, 'metrics/data_secs_per_batch': 21.481313133239745, '_timestamp': 1741699225.331359}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 189 is less than current step: 499. Dropping entry: {'train/lr': 0.00029209638554216866, '_timestamp': 1741699225.3316596}).
Epoch: [1][191/500]	Time 52.017 (52.017)	Loss 0.4257 (0.3490)	CeLoss 0.0227 (0.0354)	SegCLSLoss 0.0023 (0.0016)	KLLoss 0.0031 (0.0022)	MaskLoss 0.1000 (0.0963)	MaskBCELoss 0.0007 (0.0374)	MaskDICELoss 0.0993 (0.0589)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 190 is less than current step: 499. Dropping entry: {'train/loss': 0.349001962505281, 'train/ce_loss': 0.03544921875, 'train/seg_cls_loss': 0.0016422271728515625, 'train/kl_loss': 0.002213287353515625, 'train/mask_bce_loss': 0.03742376915179193, 'train/mask_dice_loss': 0.05892434809356928, 'train/mask_loss': 0.09634811840951443, 'metrics/total_secs_per_batch': 52.01729106903076, 'metrics/data_secs_per_batch': 22.97016727924347, '_timestamp': 1741699277.3487616}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 190 is less than current step: 499. Dropping entry: {'train/lr': 0.00029208433734939757, '_timestamp': 1741699277.349066}).
Epoch: [1][192/500]	Time 46.427 (46.427)	Loss 0.2784 (0.3677)	CeLoss 0.0256 (0.0547)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0042 (0.0029)	MaskLoss 0.0738 (0.0923)	MaskBCELoss 0.0236 (0.0297)	MaskDICELoss 0.0502 (0.0625)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 191 is less than current step: 499. Dropping entry: {'train/loss': 0.3677315775305033, 'train/ce_loss': 0.0546630859375, 'train/seg_cls_loss': 0.001197052001953125, 'train/kl_loss': 0.0029296875, 'train/mask_bce_loss': 0.029744828981347383, 'train/mask_dice_loss': 0.06253411341458559, 'train/mask_loss': 0.09227894172072411, 'metrics/total_secs_per_batch': 46.426947593688965, 'metrics/data_secs_per_batch': 21.17288453578949, '_timestamp': 1741699323.7757392}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 191 is less than current step: 499. Dropping entry: {'train/lr': 0.0002920722891566265, '_timestamp': 1741699323.776185}).
Epoch: [1][193/500]	Time 46.564 (46.564)	Loss 0.4564 (0.3197)	CeLoss 0.0664 (0.0543)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0029 (0.0038)	MaskLoss 0.1181 (0.0764)	MaskBCELoss 0.0431 (0.0224)	MaskDICELoss 0.0751 (0.0540)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 192 is less than current step: 499. Dropping entry: {'train/loss': 0.31967234760522845, 'train/ce_loss': 0.0542724609375, 'train/seg_cls_loss': 0.0013729095458984374, 'train/kl_loss': 0.0038421630859375, 'train/mask_bce_loss': 0.022422086191363634, 'train/mask_dice_loss': 0.05402442621998489, 'train/mask_loss': 0.07644651010632515, 'metrics/total_secs_per_batch': 46.56410789489746, 'metrics/data_secs_per_batch': 21.83625681400299, '_timestamp': 1741699370.339823}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 192 is less than current step: 499. Dropping entry: {'train/lr': 0.0002920602409638554, '_timestamp': 1741699370.3401377}).
Epoch: [1][194/500]	Time 52.154 (52.154)	Loss 0.4607 (0.4280)	CeLoss 0.0527 (0.0457)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0023 (0.0029)	MaskLoss 0.1185 (0.1103)	MaskBCELoss 0.0344 (0.0312)	MaskDICELoss 0.0841 (0.0791)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 193 is less than current step: 499. Dropping entry: {'train/loss': 0.4280305624008179, 'train/ce_loss': 0.0457275390625, 'train/seg_cls_loss': 0.0010463714599609375, 'train/kl_loss': 0.002857208251953125, 'train/mask_bce_loss': 0.031196492473827674, 'train/mask_dice_loss': 0.07912911958992482, 'train/mask_loss': 0.11032561361789703, 'metrics/total_secs_per_batch': 52.15380096435547, 'metrics/data_secs_per_batch': 24.296968245506285, '_timestamp': 1741699422.4935732}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 193 is less than current step: 499. Dropping entry: {'train/lr': 0.0002920481927710843, '_timestamp': 1741699422.493853}).
Epoch: [1][195/500]	Time 48.847 (48.847)	Loss 0.7269 (0.3545)	CeLoss 0.0864 (0.0396)	SegCLSLoss 0.0027 (0.0018)	KLLoss 0.0042 (0.0023)	MaskLoss 0.2405 (0.0965)	MaskBCELoss 0.1635 (0.0372)	MaskDICELoss 0.0770 (0.0593)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 194 is less than current step: 499. Dropping entry: {'train/loss': 0.354491915833205, 'train/ce_loss': 0.039605712890625, 'train/seg_cls_loss': 0.0018054962158203125, 'train/kl_loss': 0.002341461181640625, 'train/mask_bce_loss': 0.03716814601793885, 'train/mask_dice_loss': 0.059332118416205046, 'train/mask_loss': 0.09650026466697455, 'metrics/total_secs_per_batch': 48.84678292274475, 'metrics/data_secs_per_batch': 22.301167678833007, '_timestamp': 1741699471.3404071}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 194 is less than current step: 499. Dropping entry: {'train/lr': 0.0002920361445783132, '_timestamp': 1741699471.340699}).
Epoch: [1][196/500]	Time 46.600 (46.600)	Loss 0.4857 (0.3695)	CeLoss 0.0481 (0.0403)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0009 (0.0029)	MaskLoss 0.1684 (0.0964)	MaskBCELoss 0.1187 (0.0301)	MaskDICELoss 0.0497 (0.0663)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 499. Dropping entry: {'train/loss': 0.36949920989573004, 'train/ce_loss': 0.04031982421875, 'train/seg_cls_loss': 0.00159149169921875, 'train/kl_loss': 0.00290679931640625, 'train/mask_bce_loss': 0.030112653772812338, 'train/mask_dice_loss': 0.066295525431633, 'train/mask_loss': 0.09640818145126104, 'metrics/total_secs_per_batch': 46.599807262420654, 'metrics/data_secs_per_batch': 20.289117312431337, '_timestamp': 1741699517.9402447}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 499. Dropping entry: {'train/lr': 0.0002920240963855421, '_timestamp': 1741699517.9405286}).
Epoch: [1][197/500]	Time 45.567 (45.567)	Loss 0.1505 (0.2677)	CeLoss 0.0339 (0.0397)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0025 (0.0028)	MaskLoss 0.0386 (0.0701)	MaskBCELoss 0.0205 (0.0279)	MaskDICELoss 0.0180 (0.0422)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 499. Dropping entry: {'train/loss': 0.26772462129592894, 'train/ce_loss': 0.03974609375, 'train/seg_cls_loss': 0.001308441162109375, 'train/kl_loss': 0.00283966064453125, 'train/mask_bce_loss': 0.02792358255246654, 'train/mask_dice_loss': 0.04215393294580281, 'train/mask_loss': 0.07007751711644232, 'metrics/total_secs_per_batch': 45.56726026535034, 'metrics/data_secs_per_batch': 20.081789398193358, '_timestamp': 1741699563.5076146}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 499. Dropping entry: {'train/lr': 0.0002920120481927711, '_timestamp': 1741699563.507932}).
Epoch: [1][198/500]	Time 45.851 (45.851)	Loss 0.0377 (0.3568)	CeLoss 0.0376 (0.0375)	SegCLSLoss 0.0000 (0.0018)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0935)	MaskBCELoss 0.0000 (0.0291)	MaskDICELoss 0.0000 (0.0644)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 499. Dropping entry: {'train/loss': 0.35680390559136865, 'train/ce_loss': 0.037548828125, 'train/seg_cls_loss': 0.0017934799194335937, 'train/kl_loss': 0.0027374267578125, 'train/mask_bce_loss': 0.029098350647836925, 'train/mask_dice_loss': 0.06435883212834596, 'train/mask_loss': 0.0934571847319603, 'metrics/total_secs_per_batch': 45.85060691833496, 'metrics/data_secs_per_batch': 20.35782310962677, '_timestamp': 1741699609.3581328}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 499. Dropping entry: {'train/lr': 0.000292, '_timestamp': 1741699609.3584442}).
Epoch: [1][199/500]	Time 48.631 (48.631)	Loss 0.1270 (0.3605)	CeLoss 0.0728 (0.0479)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0040 (0.0025)	MaskLoss 0.0183 (0.0831)	MaskBCELoss 0.0115 (0.0115)	MaskDICELoss 0.0068 (0.0716)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 499. Dropping entry: {'train/loss': 0.36050222888588906, 'train/ce_loss': 0.04788818359375, 'train/seg_cls_loss': 0.0011585235595703125, 'train/kl_loss': 0.002518463134765625, 'train/mask_bce_loss': 0.01148929882911034, 'train/mask_dice_loss': 0.07164164795540273, 'train/mask_loss': 0.08313094747718423, 'metrics/total_secs_per_batch': 48.63092827796936, 'metrics/data_secs_per_batch': 21.691061639785765, '_timestamp': 1741699657.9889522}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 499. Dropping entry: {'train/lr': 0.0002919879518072289, '_timestamp': 1741699657.9892247}).
[2025-03-11 08:28:26,485] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[0.0002919759036144578], mom=[(0.9, 0.95)]
[2025-03-11 08:28:26,498] [INFO] [timer.py:215:stop] epoch=0/micro_step=700/global_step=70, RunningAvgSamplesPerSec=0.8323589533791447, CurrSamplesPerSec=0.8600233207517562, MemAllocated=60.07GB, MaxMemAllocated=74.15GB
Epoch: [1][200/500]	Time 48.510 (48.510)	Loss 0.2989 (0.3540)	CeLoss 0.0327 (0.0451)	SegCLSLoss 0.0010 (0.0015)	KLLoss 0.0028 (0.0029)	MaskLoss 0.1137 (0.0899)	MaskBCELoss 0.0961 (0.0271)	MaskDICELoss 0.0176 (0.0627)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 499. Dropping entry: {'train/loss': 0.35396209433674813, 'train/ce_loss': 0.04510498046875, 'train/seg_cls_loss': 0.0015027999877929687, 'train/kl_loss': 0.002916717529296875, 'train/mask_bce_loss': 0.027118761045858263, 'train/mask_dice_loss': 0.06273143361322582, 'train/mask_loss': 0.08985019661486149, 'metrics/total_secs_per_batch': 48.5103497505188, 'metrics/data_secs_per_batch': 20.676257681846618, '_timestamp': 1741699706.4989972}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 499. Dropping entry: {'train/lr': 0.00029196385542168673, '_timestamp': 1741699706.4992332}).
Epoch: [1][201/500]	Time 44.774 (44.774)	Loss 0.1022 (0.3497)	CeLoss 0.0520 (0.0464)	SegCLSLoss 0.0009 (0.0017)	KLLoss 0.0017 (0.0027)	MaskLoss 0.0129 (0.0913)	MaskBCELoss 0.0017 (0.0327)	MaskDICELoss 0.0112 (0.0586)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 499. Dropping entry: {'train/loss': 0.3497250698506832, 'train/ce_loss': 0.04637451171875, 'train/seg_cls_loss': 0.00165252685546875, 'train/kl_loss': 0.002671051025390625, 'train/mask_bce_loss': 0.03266660562949255, 'train/mask_dice_loss': 0.05862726122140884, 'train/mask_loss': 0.09129386777058243, 'metrics/total_secs_per_batch': 44.77422571182251, 'metrics/data_secs_per_batch': 19.56402180194855, '_timestamp': 1741699751.2735877}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 499. Dropping entry: {'train/lr': 0.00029195180722891564, '_timestamp': 1741699751.2738702}).
Epoch: [1][202/500]	Time 47.513 (47.513)	Loss 0.2319 (0.4038)	CeLoss 0.0258 (0.0504)	SegCLSLoss 0.0008 (0.0015)	KLLoss 0.0033 (0.0036)	MaskLoss 0.0512 (0.0964)	MaskBCELoss 0.0013 (0.0182)	MaskDICELoss 0.0500 (0.0782)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 499. Dropping entry: {'train/loss': 0.4038017712533474, 'train/ce_loss': 0.05040283203125, 'train/seg_cls_loss': 0.0014577865600585937, 'train/kl_loss': 0.00363311767578125, 'train/mask_bce_loss': 0.018205828359350563, 'train/mask_dice_loss': 0.07817077129147947, 'train/mask_loss': 0.09637659881263971, 'metrics/total_secs_per_batch': 47.512603998184204, 'metrics/data_secs_per_batch': 22.293096208572386, '_timestamp': 1741699798.786268}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 499. Dropping entry: {'train/lr': 0.00029193975903614455, '_timestamp': 1741699798.7867243}).
Epoch: [1][203/500]	Time 46.871 (46.871)	Loss 0.4554 (0.4056)	CeLoss 0.0208 (0.0389)	SegCLSLoss 0.0101 (0.0025)	KLLoss 0.0033 (0.0026)	MaskLoss 0.1338 (0.1070)	MaskBCELoss 0.0545 (0.0326)	MaskDICELoss 0.0793 (0.0744)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 499. Dropping entry: {'train/loss': 0.4055743470788002, 'train/ce_loss': 0.0388916015625, 'train/seg_cls_loss': 0.002484893798828125, 'train/kl_loss': 0.002634429931640625, 'train/mask_bce_loss': 0.032632727571763095, 'train/mask_dice_loss': 0.07438142243772745, 'train/mask_loss': 0.1070141490548849, 'metrics/total_secs_per_batch': 46.87143325805664, 'metrics/data_secs_per_batch': 22.322598814964294, '_timestamp': 1741699845.6577902}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 499. Dropping entry: {'train/lr': 0.00029192771084337346, '_timestamp': 1741699845.6580637}).
Epoch: [1][204/500]	Time 49.454 (49.454)	Loss 0.1641 (0.3763)	CeLoss 0.0500 (0.0441)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0030 (0.0026)	MaskLoss 0.0357 (0.1063)	MaskBCELoss 0.0162 (0.0482)	MaskDICELoss 0.0196 (0.0581)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 499. Dropping entry: {'train/loss': 0.37630577413365246, 'train/ce_loss': 0.044146728515625, 'train/seg_cls_loss': 0.001396942138671875, 'train/kl_loss': 0.0026336669921875, 'train/mask_bce_loss': 0.048166499473154545, 'train/mask_dice_loss': 0.05811819229274988, 'train/mask_loss': 0.1062846913933754, 'metrics/total_secs_per_batch': 49.45353937149048, 'metrics/data_secs_per_batch': 22.02941162586212, '_timestamp': 1741699895.1111798}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 499. Dropping entry: {'train/lr': 0.00029191566265060237, '_timestamp': 1741699895.1114533}).
Epoch: [1][205/500]	Time 47.024 (47.024)	Loss 0.4079 (0.4936)	CeLoss 0.1157 (0.0474)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0021 (0.0028)	MaskLoss 0.0801 (0.1342)	MaskBCELoss 0.0156 (0.0471)	MaskDICELoss 0.0645 (0.0872)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 499. Dropping entry: {'train/loss': 0.4935709863901138, 'train/ce_loss': 0.047412109375, 'train/seg_cls_loss': 0.0009405136108398438, 'train/kl_loss': 0.0028045654296875, 'train/mask_bce_loss': 0.04705610414966941, 'train/mask_dice_loss': 0.08716938309371472, 'train/mask_loss': 0.1342254877090454, 'metrics/total_secs_per_batch': 47.02382016181946, 'metrics/data_secs_per_batch': 22.786844897270203, '_timestamp': 1741699942.1350346}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 499. Dropping entry: {'train/lr': 0.0002919036144578313, '_timestamp': 1741699942.1353126}).
Epoch: [1][206/500]	Time 43.129 (43.129)	Loss 0.0340 (0.2778)	CeLoss 0.0339 (0.0481)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0649)	MaskBCELoss 0.0000 (0.0163)	MaskDICELoss 0.0000 (0.0486)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 499. Dropping entry: {'train/loss': 0.2778212882578373, 'train/ce_loss': 0.04805908203125, 'train/seg_cls_loss': 0.0010175704956054688, 'train/kl_loss': 0.00213470458984375, 'train/mask_bce_loss': 0.016304363682866096, 'train/mask_dice_loss': 0.048612708877772096, 'train/mask_loss': 0.06491707209497691, 'metrics/total_secs_per_batch': 43.12916612625122, 'metrics/data_secs_per_batch': 18.46670618057251, '_timestamp': 1741699985.2641246}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 499. Dropping entry: {'train/lr': 0.0002918915662650602, '_timestamp': 1741699985.264399}).
Epoch: [1][207/500]	Time 46.570 (46.570)	Loss 0.4332 (0.4287)	CeLoss 0.0222 (0.0555)	SegCLSLoss 0.0028 (0.0017)	KLLoss 0.0020 (0.0027)	MaskLoss 0.1038 (0.0971)	MaskBCELoss 0.0039 (0.0094)	MaskDICELoss 0.0999 (0.0877)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 499. Dropping entry: {'train/loss': 0.4286579966545105, 'train/ce_loss': 0.0555419921875, 'train/seg_cls_loss': 0.001654815673828125, 'train/kl_loss': 0.00272369384765625, 'train/mask_bce_loss': 0.00938783904130105, 'train/mask_dice_loss': 0.08770007044076919, 'train/mask_loss': 0.09708791077136994, 'metrics/total_secs_per_batch': 46.569947242736816, 'metrics/data_secs_per_batch': 20.553883385658263, '_timestamp': 1741700031.834184}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 499. Dropping entry: {'train/lr': 0.00029187951807228916, '_timestamp': 1741700031.8346581}).
Epoch: [1][208/500]	Time 51.631 (51.631)	Loss 0.4120 (0.3955)	CeLoss 0.0430 (0.0427)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0026 (0.0025)	MaskLoss 0.1183 (0.0985)	MaskBCELoss 0.0535 (0.0222)	MaskDICELoss 0.0648 (0.0762)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 499. Dropping entry: {'train/loss': 0.39551622457802293, 'train/ce_loss': 0.042724609375, 'train/seg_cls_loss': 0.0014904022216796875, 'train/kl_loss': 0.002532958984375, 'train/mask_bce_loss': 0.022246181371156127, 'train/mask_dice_loss': 0.07623985037207603, 'train/mask_loss': 0.09848603084683419, 'metrics/total_secs_per_batch': 51.6314115524292, 'metrics/data_secs_per_batch': 22.916411375999452, '_timestamp': 1741700083.465492}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 499. Dropping entry: {'train/lr': 0.00029186746987951807, '_timestamp': 1741700083.4657574}).
Epoch: [1][209/500]	Time 47.684 (47.684)	Loss 0.0605 (0.4102)	CeLoss 0.0605 (0.0522)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0018)	MaskLoss 0.0000 (0.1026)	MaskBCELoss 0.0000 (0.0276)	MaskDICELoss 0.0000 (0.0750)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 499. Dropping entry: {'train/loss': 0.41016846895217896, 'train/ce_loss': 0.05224609375, 'train/seg_cls_loss': 0.001433563232421875, 'train/kl_loss': 0.001824188232421875, 'train/mask_bce_loss': 0.027635934311547317, 'train/mask_dice_loss': 0.07500832825899124, 'train/mask_loss': 0.10264426320791245, 'metrics/total_secs_per_batch': 47.68411135673523, 'metrics/data_secs_per_batch': 21.433552527427672, '_timestamp': 1741700131.1496284}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 499. Dropping entry: {'train/lr': 0.000291855421686747, '_timestamp': 1741700131.1498997}).
Epoch: [1][210/500]	Time 47.413 (47.413)	Loss 0.3126 (0.4144)	CeLoss 0.0256 (0.0469)	SegCLSLoss 0.0035 (0.0013)	KLLoss 0.0031 (0.0025)	MaskLoss 0.0792 (0.1044)	MaskBCELoss 0.0174 (0.0266)	MaskDICELoss 0.0618 (0.0778)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 499. Dropping entry: {'train/loss': 0.4144055522978306, 'train/ce_loss': 0.0468994140625, 'train/seg_cls_loss': 0.0012516021728515626, 'train/kl_loss': 0.00253753662109375, 'train/mask_bce_loss': 0.026575420750305057, 'train/mask_dice_loss': 0.07780879572965205, 'train/mask_loss': 0.10438421787694097, 'metrics/total_secs_per_batch': 47.41340255737305, 'metrics/data_secs_per_batch': 20.995576524734496, '_timestamp': 1741700178.5630794}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 499. Dropping entry: {'train/lr': 0.0002918313253012048, '_timestamp': 1741700178.5633388}).
Epoch: [1][211/500]	Time 50.666 (50.666)	Loss 0.4682 (0.4545)	CeLoss 0.0840 (0.0518)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0021 (0.0029)	MaskLoss 0.1148 (0.1154)	MaskBCELoss 0.0385 (0.0312)	MaskDICELoss 0.0763 (0.0842)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 499. Dropping entry: {'train/loss': 0.4545332282781601, 'train/ce_loss': 0.051806640625, 'train/seg_cls_loss': 0.0014080047607421876, 'train/kl_loss': 0.002880859375, 'train/mask_bce_loss': 0.031228449381887912, 'train/mask_dice_loss': 0.08417142629623413, 'train/mask_loss': 0.11539987325668336, 'metrics/total_secs_per_batch': 50.665566205978394, 'metrics/data_secs_per_batch': 20.754296588897706, '_timestamp': 1741700229.2285905}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 499. Dropping entry: {'train/lr': 0.0002918192771084337, '_timestamp': 1741700229.2290163}).
Epoch: [1][212/500]	Time 43.194 (43.194)	Loss 0.4340 (0.3512)	CeLoss 0.0231 (0.0553)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0025 (0.0034)	MaskLoss 0.1045 (0.0822)	MaskBCELoss 0.0052 (0.0186)	MaskDICELoss 0.0993 (0.0636)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 499. Dropping entry: {'train/loss': 0.351231736689806, 'train/ce_loss': 0.05533447265625, 'train/seg_cls_loss': 0.00145721435546875, 'train/kl_loss': 0.0033721923828125, 'train/mask_bce_loss': 0.018607372255064546, 'train/mask_dice_loss': 0.06363120162859559, 'train/mask_loss': 0.08223857134580612, 'metrics/total_secs_per_batch': 43.194071531295776, 'metrics/data_secs_per_batch': 19.71903738975525, '_timestamp': 1741700272.4225497}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 499. Dropping entry: {'train/lr': 0.0002918072289156626, '_timestamp': 1741700272.4228277}).
Epoch: [1][213/500]	Time 50.383 (50.383)	Loss 0.4296 (0.4618)	CeLoss 0.0243 (0.0447)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0034 (0.0027)	MaskLoss 0.1240 (0.1210)	MaskBCELoss 0.0471 (0.0353)	MaskDICELoss 0.0769 (0.0857)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 499. Dropping entry: {'train/loss': 0.4617665112018585, 'train/ce_loss': 0.0447021484375, 'train/seg_cls_loss': 0.0015888214111328125, 'train/kl_loss': 0.00273284912109375, 'train/mask_bce_loss': 0.0352949090214679, 'train/mask_dice_loss': 0.08572142012417316, 'train/mask_loss': 0.12101632878184318, 'metrics/total_secs_per_batch': 50.382993936538696, 'metrics/data_secs_per_batch': 23.882959604263306, '_timestamp': 1741700322.8056695}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 499. Dropping entry: {'train/lr': 0.00029179518072289153, '_timestamp': 1741700322.8059413}).
Epoch: [1][214/500]	Time 45.809 (45.809)	Loss 0.4602 (0.3373)	CeLoss 0.0430 (0.0441)	SegCLSLoss 0.0031 (0.0021)	KLLoss 0.0031 (0.0028)	MaskLoss 0.1224 (0.0846)	MaskBCELoss 0.0384 (0.0245)	MaskDICELoss 0.0839 (0.0601)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 499. Dropping entry: {'train/loss': 0.337260165065527, 'train/ce_loss': 0.044091796875, 'train/seg_cls_loss': 0.002085304260253906, 'train/kl_loss': 0.002823638916015625, 'train/mask_bce_loss': 0.024461008320213296, 'train/mask_dice_loss': 0.06010211687535048, 'train/mask_loss': 0.08456312548369169, 'metrics/total_secs_per_batch': 45.80863881111145, 'metrics/data_secs_per_batch': 20.92022662162781, '_timestamp': 1741700368.6143746}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 499. Dropping entry: {'train/lr': 0.00029178313253012044, '_timestamp': 1741700368.6146653}).
Epoch: [1][215/500]	Time 48.579 (48.579)	Loss 0.4693 (0.3377)	CeLoss 0.0535 (0.0365)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0028 (0.0027)	MaskLoss 0.1064 (0.0848)	MaskBCELoss 0.0065 (0.0207)	MaskDICELoss 0.0999 (0.0641)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 499. Dropping entry: {'train/loss': 0.33767595794051886, 'train/ce_loss': 0.036505126953125, 'train/seg_cls_loss': 0.0013727188110351563, 'train/kl_loss': 0.002667999267578125, 'train/mask_bce_loss': 0.020650994940660895, 'train/mask_dice_loss': 0.06413499587215483, 'train/mask_loss': 0.08478599153459072, 'metrics/total_secs_per_batch': 48.57896161079407, 'metrics/data_secs_per_batch': 20.641801047325135, '_timestamp': 1741700417.193306}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 499. Dropping entry: {'train/lr': 0.00029177108433734936, '_timestamp': 1741700417.1937103}).
Epoch: [1][216/500]	Time 41.170 (41.170)	Loss 0.4300 (0.3556)	CeLoss 0.0214 (0.0486)	SegCLSLoss 0.0045 (0.0021)	KLLoss 0.0020 (0.0027)	MaskLoss 0.1022 (0.0918)	MaskBCELoss 0.0023 (0.0321)	MaskDICELoss 0.1000 (0.0597)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 499. Dropping entry: {'train/loss': 0.355566131696105, 'train/ce_loss': 0.0486083984375, 'train/seg_cls_loss': 0.0021068572998046873, 'train/kl_loss': 0.00269622802734375, 'train/mask_bce_loss': 0.03206723101902753, 'train/mask_dice_loss': 0.05974756497889757, 'train/mask_loss': 0.09181479513645172, 'metrics/total_secs_per_batch': 41.1704683303833, 'metrics/data_secs_per_batch': 18.04980676174164, '_timestamp': 1741700458.3637552}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 499. Dropping entry: {'train/lr': 0.00029175903614457827, '_timestamp': 1741700458.3640218}).
Epoch: [1][217/500]	Time 50.021 (50.021)	Loss 0.4706 (0.2906)	CeLoss 0.0601 (0.0549)	SegCLSLoss 0.0022 (0.0008)	KLLoss 0.0018 (0.0024)	MaskLoss 0.1036 (0.0680)	MaskBCELoss 0.0036 (0.0196)	MaskDICELoss 0.1000 (0.0484)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 499. Dropping entry: {'train/loss': 0.29056382942944764, 'train/ce_loss': 0.0548828125, 'train/seg_cls_loss': 0.0007724761962890625, 'train/kl_loss': 0.00240936279296875, 'train/mask_bce_loss': 0.019552476680837573, 'train/mask_dice_loss': 0.04843112551607191, 'train/mask_loss': 0.06798360124230385, 'metrics/total_secs_per_batch': 50.02095317840576, 'metrics/data_secs_per_batch': 22.652577996253967, '_timestamp': 1741700508.3848057}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 499. Dropping entry: {'train/lr': 0.0002917469879518072, '_timestamp': 1741700508.3852527}).
Epoch: [1][218/500]	Time 43.436 (43.436)	Loss 0.4572 (0.3854)	CeLoss 0.0747 (0.0593)	SegCLSLoss 0.0004 (0.0021)	KLLoss 0.0036 (0.0031)	MaskLoss 0.1022 (0.0890)	MaskBCELoss 0.0151 (0.0170)	MaskDICELoss 0.0871 (0.0720)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 499. Dropping entry: {'train/loss': 0.3853935893625021, 'train/ce_loss': 0.05927734375, 'train/seg_cls_loss': 0.002096748352050781, 'train/kl_loss': 0.0031463623046875, 'train/mask_bce_loss': 0.016974543198011817, 'train/mask_dice_loss': 0.07198222009465098, 'train/mask_loss': 0.08895676359534263, 'metrics/total_secs_per_batch': 43.43627953529358, 'metrics/data_secs_per_batch': 19.086396741867066, '_timestamp': 1741700551.821099}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 499. Dropping entry: {'train/lr': 0.00029173493975903614, '_timestamp': 1741700551.8215702}).
Epoch: [1][219/500]	Time 46.350 (46.350)	Loss 0.3540 (0.4380)	CeLoss 0.0317 (0.0372)	SegCLSLoss 0.0028 (0.0019)	KLLoss 0.0017 (0.0028)	MaskLoss 0.1008 (0.1104)	MaskBCELoss 0.0420 (0.0223)	MaskDICELoss 0.0588 (0.0881)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 499. Dropping entry: {'train/loss': 0.4379668921232224, 'train/ce_loss': 0.037200927734375, 'train/seg_cls_loss': 0.0019405364990234375, 'train/kl_loss': 0.002758026123046875, 'train/mask_bce_loss': 0.022333594178780912, 'train/mask_dice_loss': 0.08807590380311012, 'train/mask_loss': 0.1104094997048378, 'metrics/total_secs_per_batch': 46.34977912902832, 'metrics/data_secs_per_batch': 20.570448136329652, '_timestamp': 1741700598.1711133}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 499. Dropping entry: {'train/lr': 0.00029172289156626505, '_timestamp': 1741700598.1716597}).
Epoch: [1][220/500]	Time 46.479 (46.479)	Loss 0.2523 (0.3167)	CeLoss 0.0217 (0.0320)	SegCLSLoss 0.0010 (0.0015)	KLLoss 0.0027 (0.0033)	MaskLoss 0.0579 (0.0767)	MaskBCELoss 0.0020 (0.0130)	MaskDICELoss 0.0558 (0.0637)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 499. Dropping entry: {'train/loss': 0.3166533215902746, 'train/ce_loss': 0.03197021484375, 'train/seg_cls_loss': 0.0014904022216796875, 'train/kl_loss': 0.00327606201171875, 'train/mask_bce_loss': 0.01304250560933724, 'train/mask_dice_loss': 0.06365037839859725, 'train/mask_loss': 0.0766928844153881, 'metrics/total_secs_per_batch': 46.478522062301636, 'metrics/data_secs_per_batch': 21.61823389530182, '_timestamp': 1741700644.6505823}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 499. Dropping entry: {'train/lr': 0.0002916987951807229, '_timestamp': 1741700644.6516466}).
Epoch: [1][221/500]	Time 48.443 (48.443)	Loss 0.0675 (0.3150)	CeLoss 0.0420 (0.0456)	SegCLSLoss 0.0005 (0.0019)	KLLoss 0.0039 (0.0027)	MaskLoss 0.0074 (0.0772)	MaskBCELoss 0.0040 (0.0216)	MaskDICELoss 0.0034 (0.0557)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 499. Dropping entry: {'train/loss': 0.3149958474561572, 'train/ce_loss': 0.04559326171875, 'train/seg_cls_loss': 0.0019046783447265625, 'train/kl_loss': 0.00271148681640625, 'train/mask_bce_loss': 0.021562030486529694, 'train/mask_dice_loss': 0.05567058178130537, 'train/mask_loss': 0.07723261276260018, 'metrics/total_secs_per_batch': 48.44312357902527, 'metrics/data_secs_per_batch': 22.205943822860718, '_timestamp': 1741700693.0924883}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 499. Dropping entry: {'train/lr': 0.0002916867469879518, '_timestamp': 1741700693.0927677}).
Epoch: [1][222/500]	Time 49.031 (49.031)	Loss 0.7067 (0.4365)	CeLoss 0.0811 (0.0611)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0027 (0.0027)	MaskLoss 0.2127 (0.1101)	MaskBCELoss 0.1144 (0.0342)	MaskDICELoss 0.0983 (0.0759)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 499. Dropping entry: {'train/loss': 0.4364868804812431, 'train/ce_loss': 0.06109619140625, 'train/seg_cls_loss': 0.0011051177978515625, 'train/kl_loss': 0.002709197998046875, 'train/mask_bce_loss': 0.03418934519868344, 'train/mask_dice_loss': 0.07591620739549398, 'train/mask_loss': 0.11010555252432823, 'metrics/total_secs_per_batch': 49.03106880187988, 'metrics/data_secs_per_batch': 21.594985318183898, '_timestamp': 1741700742.123597}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 499. Dropping entry: {'train/lr': 0.0002916746987951807, '_timestamp': 1741700742.1240416}).
Epoch: [1][223/500]	Time 49.944 (49.944)	Loss 0.4931 (0.3926)	CeLoss 0.0247 (0.0387)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0024 (0.0031)	MaskLoss 0.1362 (0.1038)	MaskBCELoss 0.0397 (0.0324)	MaskDICELoss 0.0966 (0.0713)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 499. Dropping entry: {'train/loss': 0.39256385117769244, 'train/ce_loss': 0.0386962890625, 'train/seg_cls_loss': 0.0010591506958007812, 'train/kl_loss': 0.00309906005859375, 'train/mask_bce_loss': 0.03244499112479389, 'train/mask_dice_loss': 0.07134229578077793, 'train/mask_loss': 0.10378728732466698, 'metrics/total_secs_per_batch': 49.94392442703247, 'metrics/data_secs_per_batch': 22.57068512439728, '_timestamp': 1741700792.0676782}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 499. Dropping entry: {'train/lr': 0.0002916626506024096, '_timestamp': 1741700792.0681744}).
Epoch: [1][224/500]	Time 47.863 (47.863)	Loss 0.4678 (0.3951)	CeLoss 0.0581 (0.0454)	SegCLSLoss 0.0013 (0.0021)	KLLoss 0.0022 (0.0020)	MaskLoss 0.1057 (0.0946)	MaskBCELoss 0.0081 (0.0158)	MaskDICELoss 0.0976 (0.0788)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 499. Dropping entry: {'train/loss': 0.3950873709283769, 'train/ce_loss': 0.04544677734375, 'train/seg_cls_loss': 0.0020511627197265627, 'train/kl_loss': 0.001952362060546875, 'train/mask_bce_loss': 0.015788803657051174, 'train/mask_dice_loss': 0.07877783067524433, 'train/mask_loss': 0.09456663504242897, 'metrics/total_secs_per_batch': 47.86263704299927, 'metrics/data_secs_per_batch': 22.683371543884277, '_timestamp': 1741700839.9304304}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 499. Dropping entry: {'train/lr': 0.0002916506024096385, '_timestamp': 1741700839.9309156}).
Epoch: [1][225/500]	Time 46.889 (46.889)	Loss 0.0512 (0.3316)	CeLoss 0.0347 (0.0425)	SegCLSLoss 0.0003 (0.0015)	KLLoss 0.0045 (0.0028)	MaskLoss 0.0039 (0.0781)	MaskBCELoss 0.0019 (0.0134)	MaskDICELoss 0.0020 (0.0647)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 499. Dropping entry: {'train/loss': 0.3315848562866449, 'train/ce_loss': 0.0424560546875, 'train/seg_cls_loss': 0.0015413284301757813, 'train/kl_loss': 0.00283203125, 'train/mask_bce_loss': 0.013416970265097916, 'train/mask_dice_loss': 0.06466429003048688, 'train/mask_loss': 0.07808125966694206, 'metrics/total_secs_per_batch': 46.88856315612793, 'metrics/data_secs_per_batch': 20.821172165870667, '_timestamp': 1741700886.820009}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 499. Dropping entry: {'train/lr': 0.00029163855421686743, '_timestamp': 1741700886.8210309}).
Epoch: [1][226/500]	Time 46.409 (46.409)	Loss 0.4383 (0.4564)	CeLoss 0.0515 (0.0544)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0031 (0.0026)	MaskLoss 0.1006 (0.1096)	MaskBCELoss 0.0094 (0.0198)	MaskDICELoss 0.0912 (0.0898)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 499. Dropping entry: {'train/loss': 0.4564350739121437, 'train/ce_loss': 0.05440673828125, 'train/seg_cls_loss': 0.0014005661010742187, 'train/kl_loss': 0.002646636962890625, 'train/mask_bce_loss': 0.01979701081290841, 'train/mask_dice_loss': 0.08975713849067687, 'train/mask_loss': 0.10955414846539498, 'metrics/total_secs_per_batch': 46.40937638282776, 'metrics/data_secs_per_batch': 19.481036877632143, '_timestamp': 1741700933.228092}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 499. Dropping entry: {'train/lr': 0.00029162650602409634, '_timestamp': 1741700933.2285047}).
Epoch: [1][227/500]	Time 49.110 (49.110)	Loss 0.3568 (0.4296)	CeLoss 0.0378 (0.0469)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0015 (0.0026)	MaskLoss 0.0804 (0.1077)	MaskBCELoss 0.0023 (0.0259)	MaskDICELoss 0.0781 (0.0819)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 499. Dropping entry: {'train/loss': 0.42957317680120466, 'train/ce_loss': 0.0469482421875, 'train/seg_cls_loss': 0.0016300201416015625, 'train/kl_loss': 0.002600860595703125, 'train/mask_bce_loss': 0.025855364301241933, 'train/mask_dice_loss': 0.08187771886587143, 'train/mask_loss': 0.1077330831438303, 'metrics/total_secs_per_batch': 49.11012291908264, 'metrics/data_secs_per_batch': 22.102538728713988, '_timestamp': 1741700982.3382735}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 499. Dropping entry: {'train/lr': 0.00029161445783132525, '_timestamp': 1741700982.3387}).
Epoch: [1][228/500]	Time 47.494 (47.494)	Loss 0.3813 (0.3392)	CeLoss 0.0356 (0.0339)	SegCLSLoss 0.0020 (0.0020)	KLLoss 0.0031 (0.0028)	MaskLoss 0.0862 (0.0826)	MaskBCELoss 0.0017 (0.0144)	MaskDICELoss 0.0845 (0.0682)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 499. Dropping entry: {'train/loss': 0.33915745466947556, 'train/ce_loss': 0.033856201171875, 'train/seg_cls_loss': 0.0020252227783203124, 'train/kl_loss': 0.002796173095703125, 'train/mask_bce_loss': 0.0143699539868976, 'train/mask_dice_loss': 0.06818299880251288, 'train/mask_loss': 0.08255295138806104, 'metrics/total_secs_per_batch': 47.49397277832031, 'metrics/data_secs_per_batch': 20.406918787956236, '_timestamp': 1741701029.83222}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 499. Dropping entry: {'train/lr': 0.0002916024096385542, '_timestamp': 1741701029.8326287}).
Epoch: [1][229/500]	Time 46.294 (46.294)	Loss 0.4057 (0.4910)	CeLoss 0.0713 (0.0464)	SegCLSLoss 0.0013 (0.0016)	KLLoss 0.0025 (0.0026)	MaskLoss 0.0836 (0.1354)	MaskBCELoss 0.0015 (0.0502)	MaskDICELoss 0.0821 (0.0852)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 499. Dropping entry: {'train/loss': 0.49095476418733597, 'train/ce_loss': 0.04642333984375, 'train/seg_cls_loss': 0.0015888214111328125, 'train/kl_loss': 0.00261993408203125, 'train/mask_bce_loss': 0.05017855198821053, 'train/mask_dice_loss': 0.08517627008259296, 'train/mask_loss': 0.13535482063889503, 'metrics/total_secs_per_batch': 46.2944233417511, 'metrics/data_secs_per_batch': 20.765079951286317, '_timestamp': 1741701076.1267648}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 499. Dropping entry: {'train/lr': 0.0002915903614457831, '_timestamp': 1741701076.127072}).
Epoch: [1][230/500]	Time 47.262 (47.262)	Loss 0.4557 (0.3504)	CeLoss 0.0223 (0.0434)	SegCLSLoss 0.0011 (0.0017)	KLLoss 0.0035 (0.0027)	MaskLoss 0.1177 (0.0943)	MaskBCELoss 0.0207 (0.0369)	MaskDICELoss 0.0970 (0.0574)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 499. Dropping entry: {'train/loss': 0.35038159154355525, 'train/ce_loss': 0.043408203125, 'train/seg_cls_loss': 0.001666259765625, 'train/kl_loss': 0.00269775390625, 'train/mask_bce_loss': 0.03685422905255109, 'train/mask_dice_loss': 0.057422679441515356, 'train/mask_loss': 0.09427690985612572, 'metrics/total_secs_per_batch': 47.262481927871704, 'metrics/data_secs_per_batch': 20.48951985836029, '_timestamp': 1741701123.389807}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 499. Dropping entry: {'train/lr': 0.00029156626506024095, '_timestamp': 1741701123.3904185}).
Epoch: [1][231/500]	Time 42.540 (42.540)	Loss 0.4253 (0.3724)	CeLoss 0.0786 (0.0381)	SegCLSLoss 0.0008 (0.0028)	KLLoss 0.0018 (0.0028)	MaskLoss 0.1103 (0.0931)	MaskBCELoss 0.0484 (0.0211)	MaskDICELoss 0.0619 (0.0720)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 499. Dropping entry: {'train/loss': 0.37242856100201605, 'train/ce_loss': 0.0381103515625, 'train/seg_cls_loss': 0.002764892578125, 'train/kl_loss': 0.00282440185546875, 'train/mask_bce_loss': 0.021104771317914127, 'train/mask_dice_loss': 0.07197858123108744, 'train/mask_loss': 0.09308335036039353, 'metrics/total_secs_per_batch': 42.53985810279846, 'metrics/data_secs_per_batch': 20.073619318008422, '_timestamp': 1741701165.9304917}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 499. Dropping entry: {'train/lr': 0.00029155421686746986, '_timestamp': 1741701165.9312263}).
Epoch: [1][232/500]	Time 45.472 (45.472)	Loss 0.0688 (0.3095)	CeLoss 0.0688 (0.0386)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0789)	MaskBCELoss 0.0000 (0.0238)	MaskDICELoss 0.0000 (0.0551)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 499. Dropping entry: {'train/loss': 0.3095203645527363, 'train/ce_loss': 0.03863525390625, 'train/seg_cls_loss': 0.0011020660400390624, 'train/kl_loss': 0.00228424072265625, 'train/mask_bce_loss': 0.023838438978418707, 'train/mask_dice_loss': 0.05508733717724681, 'train/mask_loss': 0.07892577648162842, 'metrics/total_secs_per_batch': 45.471834897994995, 'metrics/data_secs_per_batch': 20.073152899742126, '_timestamp': 1741701211.4009464}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 499. Dropping entry: {'train/lr': 0.00029154216867469877, '_timestamp': 1741701211.4012644}).
Epoch: [1][233/500]	Time 47.645 (47.645)	Loss 0.3137 (0.4090)	CeLoss 0.0249 (0.0351)	SegCLSLoss 0.0017 (0.0024)	KLLoss 0.0027 (0.0029)	MaskLoss 0.0776 (0.1005)	MaskBCELoss 0.0126 (0.0162)	MaskDICELoss 0.0650 (0.0843)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 499. Dropping entry: {'train/loss': 0.4089993298053741, 'train/ce_loss': 0.03507080078125, 'train/seg_cls_loss': 0.00235595703125, 'train/kl_loss': 0.002930450439453125, 'train/mask_bce_loss': 0.016218221199233086, 'train/mask_dice_loss': 0.08432871103286743, 'train/mask_loss': 0.1005469337105751, 'metrics/total_secs_per_batch': 47.64520812034607, 'metrics/data_secs_per_batch': 21.77195179462433, '_timestamp': 1741701259.0466328}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 499. Dropping entry: {'train/lr': 0.0002915301204819277, '_timestamp': 1741701259.0472288}).
Epoch: [1][234/500]	Time 49.372 (49.372)	Loss 0.4660 (0.3922)	CeLoss 0.0415 (0.0515)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0025 (0.0031)	MaskLoss 0.1117 (0.0932)	MaskBCELoss 0.0126 (0.0180)	MaskDICELoss 0.0991 (0.0753)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 499. Dropping entry: {'train/loss': 0.39220348596572874, 'train/ce_loss': 0.0515380859375, 'train/seg_cls_loss': 0.0010540008544921875, 'train/kl_loss': 0.00309295654296875, 'train/mask_bce_loss': 0.01795971388928592, 'train/mask_dice_loss': 0.0752819512039423, 'train/mask_loss': 0.09324166737496853, 'metrics/total_secs_per_batch': 49.371617794036865, 'metrics/data_secs_per_batch': 22.773049902915954, '_timestamp': 1741701308.418005}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 499. Dropping entry: {'train/lr': 0.0002915180722891566, '_timestamp': 1741701308.4185855}).
Epoch: [1][235/500]	Time 46.028 (46.028)	Loss 0.3271 (0.4241)	CeLoss 0.0201 (0.0468)	SegCLSLoss 0.0040 (0.0015)	KLLoss 0.0021 (0.0036)	MaskLoss 0.0793 (0.1058)	MaskBCELoss 0.0071 (0.0251)	MaskDICELoss 0.0722 (0.0807)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 499. Dropping entry: {'train/loss': 0.42408612072467805, 'train/ce_loss': 0.04676513671875, 'train/seg_cls_loss': 0.00154876708984375, 'train/kl_loss': 0.0036224365234375, 'train/mask_bce_loss': 0.025066412147134544, 'train/mask_dice_loss': 0.0807002380490303, 'train/mask_loss': 0.1057666502892971, 'metrics/total_secs_per_batch': 46.02828502655029, 'metrics/data_secs_per_batch': 20.729282903671265, '_timestamp': 1741701354.446051}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 499. Dropping entry: {'train/lr': 0.0002915060240963855, '_timestamp': 1741701354.4463308}).
Epoch: [1][236/500]	Time 49.592 (49.592)	Loss 0.4146 (0.4041)	CeLoss 0.0317 (0.0437)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0032 (0.0031)	MaskLoss 0.1100 (0.1041)	MaskBCELoss 0.0304 (0.0298)	MaskDICELoss 0.0797 (0.0743)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 499. Dropping entry: {'train/loss': 0.4040940523147583, 'train/ce_loss': 0.04365234375, 'train/seg_cls_loss': 0.0012409210205078125, 'train/kl_loss': 0.00307159423828125, 'train/mask_bce_loss': 0.029760189913213254, 'train/mask_dice_loss': 0.07431724742054939, 'train/mask_loss': 0.1040774367749691, 'metrics/total_secs_per_batch': 49.59150266647339, 'metrics/data_secs_per_batch': 21.068128657341003, '_timestamp': 1741701404.0390434}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 499. Dropping entry: {'train/lr': 0.0002914939759036144, '_timestamp': 1741701404.04012}).
Epoch: [1][237/500]	Time 50.851 (50.851)	Loss 0.2780 (0.3234)	CeLoss 0.0201 (0.0322)	SegCLSLoss 0.0031 (0.0014)	KLLoss 0.0028 (0.0027)	MaskLoss 0.0693 (0.0797)	MaskBCELoss 0.0119 (0.0155)	MaskDICELoss 0.0574 (0.0642)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 499. Dropping entry: {'train/loss': 0.3234466123394668, 'train/ce_loss': 0.032232666015625, 'train/seg_cls_loss': 0.0013805389404296874, 'train/kl_loss': 0.002690887451171875, 'train/mask_bce_loss': 0.015525271973456257, 'train/mask_dice_loss': 0.06419276827946305, 'train/mask_loss': 0.07971804030239582, 'metrics/total_secs_per_batch': 50.851479053497314, 'metrics/data_secs_per_batch': 22.738317489624023, '_timestamp': 1741701454.8892744}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 499. Dropping entry: {'train/lr': 0.0002914819277108433, '_timestamp': 1741701454.8895724}).
Epoch: [1][238/500]	Time 48.558 (48.558)	Loss 0.2376 (0.3593)	CeLoss 0.0547 (0.0503)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0045 (0.0029)	MaskLoss 0.0521 (0.0873)	MaskBCELoss 0.0151 (0.0219)	MaskDICELoss 0.0370 (0.0654)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 499. Dropping entry: {'train/loss': 0.3592947512865067, 'train/ce_loss': 0.050341796875, 'train/seg_cls_loss': 0.0010654449462890625, 'train/kl_loss': 0.00288848876953125, 'train/mask_bce_loss': 0.021894297376275063, 'train/mask_dice_loss': 0.06541950898244978, 'train/mask_loss': 0.08731380542740226, 'metrics/total_secs_per_batch': 48.55821251869202, 'metrics/data_secs_per_batch': 22.564869713783263, '_timestamp': 1741701503.447198}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 499. Dropping entry: {'train/lr': 0.0002914698795180723, '_timestamp': 1741701503.447467}).
Epoch: [1][239/500]	Time 46.064 (46.064)	Loss 0.4560 (0.4622)	CeLoss 0.0256 (0.0577)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0034 (0.0026)	MaskLoss 0.1142 (0.1109)	MaskBCELoss 0.0151 (0.0212)	MaskDICELoss 0.0991 (0.0898)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 499. Dropping entry: {'train/loss': 0.4622425824403763, 'train/ce_loss': 0.057666015625, 'train/seg_cls_loss': 0.0012035369873046875, 'train/kl_loss': 0.00256500244140625, 'train/mask_bce_loss': 0.02117833634838462, 'train/mask_dice_loss': 0.08977128192782402, 'train/mask_loss': 0.11094961836934089, 'metrics/total_secs_per_batch': 46.063976764678955, 'metrics/data_secs_per_batch': 19.956237626075744, '_timestamp': 1741701549.5112193}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 499. Dropping entry: {'train/lr': 0.0002914578313253012, '_timestamp': 1741701549.5114987}).
Epoch: [1][240/500]	Time 47.369 (47.369)	Loss 0.4415 (0.4008)	CeLoss 0.0347 (0.0389)	SegCLSLoss 0.0013 (0.0023)	KLLoss 0.0025 (0.0027)	MaskLoss 0.1019 (0.1032)	MaskBCELoss 0.0020 (0.0274)	MaskDICELoss 0.1000 (0.0758)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 499. Dropping entry: {'train/loss': 0.4008471829816699, 'train/ce_loss': 0.038897705078125, 'train/seg_cls_loss': 0.002264595031738281, 'train/kl_loss': 0.00272064208984375, 'train/mask_bce_loss': 0.027392444561701267, 'train/mask_dice_loss': 0.07583930492401122, 'train/mask_loss': 0.10323174931108951, 'metrics/total_secs_per_batch': 47.368738651275635, 'metrics/data_secs_per_batch': 20.913906741142274, '_timestamp': 1741701596.880064}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 499. Dropping entry: {'train/lr': 0.000291433734939759, '_timestamp': 1741701596.8803132}).
Epoch: [1][241/500]	Time 47.362 (47.362)	Loss 0.4622 (0.3310)	CeLoss 0.0552 (0.0437)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0027 (0.0022)	MaskLoss 0.1101 (0.0773)	MaskBCELoss 0.0182 (0.0122)	MaskDICELoss 0.0919 (0.0650)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 499. Dropping entry: {'train/loss': 0.3309960927814245, 'train/ce_loss': 0.04371337890625, 'train/seg_cls_loss': 0.00099945068359375, 'train/kl_loss': 0.00215301513671875, 'train/mask_bce_loss': 0.012228818470612168, 'train/mask_dice_loss': 0.06502816751599312, 'train/mask_loss': 0.07725698351860047, 'metrics/total_secs_per_batch': 47.36235213279724, 'metrics/data_secs_per_batch': 21.020531487464904, '_timestamp': 1741701644.2440405}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 499. Dropping entry: {'train/lr': 0.00029142168674698793, '_timestamp': 1741701644.2453022}).
Epoch: [1][242/500]	Time 46.479 (46.479)	Loss 0.3953 (0.3456)	CeLoss 0.0231 (0.0627)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0027 (0.0026)	MaskLoss 0.1147 (0.0826)	MaskBCELoss 0.0449 (0.0253)	MaskDICELoss 0.0698 (0.0573)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 499. Dropping entry: {'train/loss': 0.3455923780798912, 'train/ce_loss': 0.06273193359375, 'train/seg_cls_loss': 0.0011653900146484375, 'train/kl_loss': 0.0025604248046875, 'train/mask_bce_loss': 0.02529803179204464, 'train/mask_dice_loss': 0.057318414375185964, 'train/mask_loss': 0.0826164461672306, 'metrics/total_secs_per_batch': 46.479294300079346, 'metrics/data_secs_per_batch': 20.86297562122345, '_timestamp': 1741701690.721805}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 499. Dropping entry: {'train/lr': 0.00029140963855421684, '_timestamp': 1741701690.7222598}).
Epoch: [1][243/500]	Time 52.644 (52.644)	Loss 0.5102 (0.4033)	CeLoss 0.0703 (0.0443)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0036 (0.0030)	MaskLoss 0.1187 (0.0985)	MaskBCELoss 0.0195 (0.0195)	MaskDICELoss 0.0993 (0.0790)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 499. Dropping entry: {'train/loss': 0.4032724156975746, 'train/ce_loss': 0.0442626953125, 'train/seg_cls_loss': 0.0015256881713867187, 'train/kl_loss': 0.00304718017578125, 'train/mask_bce_loss': 0.01950133804930374, 'train/mask_dice_loss': 0.07904595136642456, 'train/mask_loss': 0.098547288402915, 'metrics/total_secs_per_batch': 52.64396333694458, 'metrics/data_secs_per_batch': 23.964745950698852, '_timestamp': 1741701743.365705}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 499. Dropping entry: {'train/lr': 0.00029139759036144575, '_timestamp': 1741701743.3659945}).
Epoch: [1][244/500]	Time 45.324 (45.324)	Loss 0.4672 (0.4150)	CeLoss 0.0258 (0.0462)	SegCLSLoss 0.0031 (0.0030)	KLLoss 0.0030 (0.0028)	MaskLoss 0.1440 (0.1044)	MaskBCELoss 0.0697 (0.0264)	MaskDICELoss 0.0743 (0.0779)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 499. Dropping entry: {'train/loss': 0.41496882438659666, 'train/ce_loss': 0.04617919921875, 'train/seg_cls_loss': 0.00296173095703125, 'train/kl_loss': 0.00283355712890625, 'train/mask_bce_loss': 0.026449204701930285, 'train/mask_dice_loss': 0.07790285609662533, 'train/mask_loss': 0.10435205921530724, 'metrics/total_secs_per_batch': 45.323867321014404, 'metrics/data_secs_per_batch': 19.900067353248595, '_timestamp': 1741701788.6894996}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 499. Dropping entry: {'train/lr': 0.00029138554216867466, '_timestamp': 1741701788.6899402}).
Epoch: [1][245/500]	Time 46.751 (46.751)	Loss 0.5012 (0.3592)	CeLoss 0.0669 (0.0535)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0026 (0.0025)	MaskLoss 0.1160 (0.0874)	MaskBCELoss 0.0166 (0.0235)	MaskDICELoss 0.0994 (0.0639)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 499. Dropping entry: {'train/loss': 0.35918024703860285, 'train/ce_loss': 0.0535400390625, 'train/seg_cls_loss': 0.0008092880249023438, 'train/kl_loss': 0.002545166015625, 'train/mask_bce_loss': 0.02349275287706405, 'train/mask_dice_loss': 0.06394224036484956, 'train/mask_loss': 0.08743499331176281, 'metrics/total_secs_per_batch': 46.75146961212158, 'metrics/data_secs_per_batch': 21.151233983039855, '_timestamp': 1741701835.441125}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 499. Dropping entry: {'train/lr': 0.0002913734939759036, '_timestamp': 1741701835.4415872}).
Epoch: [1][246/500]	Time 51.021 (51.021)	Loss 0.4292 (0.4221)	CeLoss 0.0243 (0.0392)	SegCLSLoss 0.0015 (0.0022)	KLLoss 0.0020 (0.0030)	MaskLoss 0.1018 (0.1040)	MaskBCELoss 0.0025 (0.0186)	MaskDICELoss 0.0993 (0.0854)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 499. Dropping entry: {'train/loss': 0.42214618623256683, 'train/ce_loss': 0.039208984375, 'train/seg_cls_loss': 0.0021732330322265627, 'train/kl_loss': 0.002959442138671875, 'train/mask_bce_loss': 0.018620980728883296, 'train/mask_dice_loss': 0.08540574330836534, 'train/mask_loss': 0.10402672290802002, 'metrics/total_secs_per_batch': 51.02089214324951, 'metrics/data_secs_per_batch': 23.896983337402343, '_timestamp': 1741701886.461881}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 499. Dropping entry: {'train/lr': 0.0002913614457831325, '_timestamp': 1741701886.462329}).
Epoch: [1][247/500]	Time 47.782 (47.782)	Loss 0.5530 (0.3807)	CeLoss 0.0212 (0.0458)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0041 (0.0027)	MaskLoss 0.1786 (0.0930)	MaskBCELoss 0.0937 (0.0203)	MaskDICELoss 0.0849 (0.0727)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 499. Dropping entry: {'train/loss': 0.3806797105818987, 'train/ce_loss': 0.04581298828125, 'train/seg_cls_loss': 0.0013135910034179688, 'train/kl_loss': 0.00274810791015625, 'train/mask_bce_loss': 0.0202530353795737, 'train/mask_dice_loss': 0.07272651568055152, 'train/mask_loss': 0.0929795503616333, 'metrics/total_secs_per_batch': 47.78198266029358, 'metrics/data_secs_per_batch': 20.997897744178772, '_timestamp': 1741701934.2439442}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 499. Dropping entry: {'train/lr': 0.0002913493975903614, '_timestamp': 1741701934.2443743}).
Epoch: [1][248/500]	Time 54.108 (54.108)	Loss 0.4801 (0.4758)	CeLoss 0.0145 (0.0534)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0033 (0.0029)	MaskLoss 0.1313 (0.1189)	MaskBCELoss 0.0317 (0.0283)	MaskDICELoss 0.0997 (0.0906)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 499. Dropping entry: {'train/loss': 0.47575304806232455, 'train/ce_loss': 0.05340576171875, 'train/seg_cls_loss': 0.0011198043823242188, 'train/kl_loss': 0.00286407470703125, 'train/mask_bce_loss': 0.02828487949445844, 'train/mask_dice_loss': 0.09056730791926385, 'train/mask_loss': 0.11885218918323517, 'metrics/total_secs_per_batch': 54.108028173446655, 'metrics/data_secs_per_batch': 23.086438369750976, '_timestamp': 1741701988.3520496}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 499. Dropping entry: {'train/lr': 0.00029133734939759036, '_timestamp': 1741701988.3525248}).
Epoch: [1][249/500]	Time 45.797 (45.797)	Loss 0.4097 (0.3726)	CeLoss 0.0840 (0.0544)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0030 (0.0029)	MaskLoss 0.0916 (0.0931)	MaskBCELoss 0.0221 (0.0288)	MaskDICELoss 0.0695 (0.0643)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 499. Dropping entry: {'train/loss': 0.3725813770666718, 'train/ce_loss': 0.05440673828125, 'train/seg_cls_loss': 0.0013032913208007812, 'train/kl_loss': 0.00287628173828125, 'train/mask_bce_loss': 0.02876325068064034, 'train/mask_dice_loss': 0.06428862363100052, 'train/mask_loss': 0.09305187314748764, 'metrics/total_secs_per_batch': 45.79716944694519, 'metrics/data_secs_per_batch': 18.86051802635193, '_timestamp': 1741702034.149271}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 499. Dropping entry: {'train/lr': 0.00029132530120481927, '_timestamp': 1741702034.1497421}).
Epoch: [1][250/500]	Time 47.738 (47.738)	Loss 0.2156 (0.4577)	CeLoss 0.0228 (0.0491)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0024 (0.0032)	MaskLoss 0.0608 (0.1142)	MaskBCELoss 0.0267 (0.0261)	MaskDICELoss 0.0341 (0.0881)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 499. Dropping entry: {'train/loss': 0.4577097684144974, 'train/ce_loss': 0.0490966796875, 'train/seg_cls_loss': 0.00159912109375, 'train/kl_loss': 0.003179931640625, 'train/mask_bce_loss': 0.026082063280045985, 'train/mask_dice_loss': 0.08811492398381233, 'train/mask_loss': 0.11419698931276798, 'metrics/total_secs_per_batch': 47.73778295516968, 'metrics/data_secs_per_batch': 22.265125942230224, '_timestamp': 1741702081.8880107}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 499. Dropping entry: {'train/lr': 0.0002913012048192771, '_timestamp': 1741702081.8889217}).
Epoch: [1][251/500]	Time 47.889 (47.889)	Loss 0.1496 (0.3833)	CeLoss 0.0791 (0.0508)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0026 (0.0030)	MaskLoss 0.0190 (0.0939)	MaskBCELoss 0.0042 (0.0233)	MaskDICELoss 0.0148 (0.0706)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 499. Dropping entry: {'train/loss': 0.3833469212055206, 'train/ce_loss': 0.0507568359375, 'train/seg_cls_loss': 0.00120849609375, 'train/kl_loss': 0.002999114990234375, 'train/mask_bce_loss': 0.023309167323168366, 'train/mask_dice_loss': 0.0705835148692131, 'train/mask_loss': 0.09389268215745687, 'metrics/total_secs_per_batch': 47.889185667037964, 'metrics/data_secs_per_batch': 22.783332967758177, '_timestamp': 1741702129.7761345}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 499. Dropping entry: {'train/lr': 0.000291289156626506, '_timestamp': 1741702129.7765594}).
Epoch: [1][252/500]	Time 42.340 (42.340)	Loss 0.3862 (0.4194)	CeLoss 0.0684 (0.0538)	SegCLSLoss 0.0018 (0.0012)	KLLoss 0.0015 (0.0026)	MaskLoss 0.0977 (0.0991)	MaskBCELoss 0.0376 (0.0170)	MaskDICELoss 0.0601 (0.0821)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 499. Dropping entry: {'train/loss': 0.4193671144545078, 'train/ce_loss': 0.053759765625, 'train/seg_cls_loss': 0.0011518478393554687, 'train/kl_loss': 0.002649688720703125, 'train/mask_bce_loss': 0.01702599283307791, 'train/mask_dice_loss': 0.0820758506655693, 'train/mask_loss': 0.09910184442996979, 'metrics/total_secs_per_batch': 42.340070724487305, 'metrics/data_secs_per_batch': 20.214018273353577, '_timestamp': 1741702172.1161907}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 499. Dropping entry: {'train/lr': 0.0002912771084337349, '_timestamp': 1741702172.1166065}).
Epoch: [1][253/500]	Time 46.085 (46.085)	Loss 0.4270 (0.4251)	CeLoss 0.0369 (0.0464)	SegCLSLoss 0.0009 (0.0019)	KLLoss 0.0021 (0.0024)	MaskLoss 0.1076 (0.1045)	MaskBCELoss 0.0214 (0.0212)	MaskDICELoss 0.0862 (0.0833)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 499. Dropping entry: {'train/loss': 0.4250782608985901, 'train/ce_loss': 0.04637451171875, 'train/seg_cls_loss': 0.00186767578125, 'train/kl_loss': 0.002356719970703125, 'train/mask_bce_loss': 0.021193710248917343, 'train/mask_dice_loss': 0.08326060175895691, 'train/mask_loss': 0.10445431023836135, 'metrics/total_secs_per_batch': 46.08512020111084, 'metrics/data_secs_per_batch': 20.720329260826112, '_timestamp': 1741702218.2012494}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 499. Dropping entry: {'train/lr': 0.0002912650602409638, '_timestamp': 1741702218.201677}).
Epoch: [1][254/500]	Time 55.806 (55.806)	Loss 0.0703 (0.2898)	CeLoss 0.0466 (0.0493)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0048 (0.0025)	MaskLoss 0.0065 (0.0650)	MaskBCELoss 0.0037 (0.0111)	MaskDICELoss 0.0029 (0.0539)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 499. Dropping entry: {'train/loss': 0.2898460054770112, 'train/ce_loss': 0.04932861328125, 'train/seg_cls_loss': 0.00071563720703125, 'train/kl_loss': 0.00246124267578125, 'train/mask_bce_loss': 0.011068294709548353, 'train/mask_dice_loss': 0.05388536006212234, 'train/mask_loss': 0.06495365463197231, 'metrics/total_secs_per_batch': 55.806039333343506, 'metrics/data_secs_per_batch': 25.838470816612244, '_timestamp': 1741702274.0083842}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 499. Dropping entry: {'train/lr': 0.00029125301204819274, '_timestamp': 1741702274.009139}).
Epoch: [1][255/500]	Time 48.559 (48.559)	Loss 0.2376 (0.3636)	CeLoss 0.0625 (0.0406)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0017 (0.0028)	MaskLoss 0.0510 (0.0877)	MaskBCELoss 0.0154 (0.0156)	MaskDICELoss 0.0356 (0.0721)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 499. Dropping entry: {'train/loss': 0.363552063703537, 'train/ce_loss': 0.04056396484375, 'train/seg_cls_loss': 0.00109710693359375, 'train/kl_loss': 0.002791595458984375, 'train/mask_bce_loss': 0.015600870997877792, 'train/mask_dice_loss': 0.07213542833924294, 'train/mask_loss': 0.08773630224168301, 'metrics/total_secs_per_batch': 48.5585515499115, 'metrics/data_secs_per_batch': 20.85262088775635, '_timestamp': 1741702322.5661466}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 499. Dropping entry: {'train/lr': 0.00029124096385542165, '_timestamp': 1741702322.5664756}).
Epoch: [1][256/500]	Time 46.903 (46.903)	Loss 0.4517 (0.3520)	CeLoss 0.0405 (0.0513)	SegCLSLoss 0.0021 (0.0012)	KLLoss 0.0030 (0.0029)	MaskLoss 0.1039 (0.0836)	MaskBCELoss 0.0040 (0.0185)	MaskDICELoss 0.0998 (0.0651)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 499. Dropping entry: {'train/loss': 0.35198765322566034, 'train/ce_loss': 0.05130615234375, 'train/seg_cls_loss': 0.0011669158935546874, 'train/kl_loss': 0.002866363525390625, 'train/mask_bce_loss': 0.018535918137058616, 'train/mask_dice_loss': 0.06506684347987175, 'train/mask_loss': 0.08360276110470295, 'metrics/total_secs_per_batch': 46.90268301963806, 'metrics/data_secs_per_batch': 21.7858784198761, '_timestamp': 1741702369.4713042}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 499. Dropping entry: {'train/lr': 0.00029122891566265056, '_timestamp': 1741702369.4727304}).
Epoch: [1][257/500]	Time 52.461 (52.461)	Loss 0.3888 (0.3331)	CeLoss 0.0222 (0.0427)	SegCLSLoss 0.0038 (0.0013)	KLLoss 0.0023 (0.0025)	MaskLoss 0.0912 (0.0773)	MaskBCELoss 0.0012 (0.0109)	MaskDICELoss 0.0900 (0.0663)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 499. Dropping entry: {'train/loss': 0.3331072458997369, 'train/ce_loss': 0.042724609375, 'train/seg_cls_loss': 0.0012844085693359375, 'train/kl_loss': 0.00245361328125, 'train/mask_bce_loss': 0.010932945995591581, 'train/mask_dice_loss': 0.06633572950959206, 'train/mask_loss': 0.0772686742246151, 'metrics/total_secs_per_batch': 52.460527420043945, 'metrics/data_secs_per_batch': 22.811026334762573, '_timestamp': 1741702421.9291856}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 499. Dropping entry: {'train/lr': 0.00029121686746987947, '_timestamp': 1741702421.9296386}).
Epoch: [1][258/500]	Time 49.228 (49.228)	Loss 0.4063 (0.3959)	CeLoss 0.0240 (0.0376)	SegCLSLoss 0.0023 (0.0012)	KLLoss 0.0028 (0.0022)	MaskLoss 0.0955 (0.0969)	MaskBCELoss 0.0019 (0.0160)	MaskDICELoss 0.0936 (0.0809)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 499. Dropping entry: {'train/loss': 0.39586231373250486, 'train/ce_loss': 0.0376220703125, 'train/seg_cls_loss': 0.0011854171752929688, 'train/kl_loss': 0.00220947265625, 'train/mask_bce_loss': 0.01601401548832655, 'train/mask_dice_loss': 0.08085359074175358, 'train/mask_loss': 0.09686760753393173, 'metrics/total_secs_per_batch': 49.227874755859375, 'metrics/data_secs_per_batch': 21.927970695495606, '_timestamp': 1741702471.1570978}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 499. Dropping entry: {'train/lr': 0.0002912048192771084, '_timestamp': 1741702471.1573846}).
Epoch: [1][259/500]	Time 44.706 (44.706)	Loss 0.4308 (0.3839)	CeLoss 0.0659 (0.0413)	SegCLSLoss 0.0017 (0.0012)	KLLoss 0.0051 (0.0039)	MaskLoss 0.1020 (0.0980)	MaskBCELoss 0.0245 (0.0269)	MaskDICELoss 0.0775 (0.0711)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 499. Dropping entry: {'train/loss': 0.3838790953159332, 'train/ce_loss': 0.04129638671875, 'train/seg_cls_loss': 0.00117950439453125, 'train/kl_loss': 0.003851318359375, 'train/mask_bce_loss': 0.026853825873695315, 'train/mask_dice_loss': 0.07110731392167509, 'train/mask_loss': 0.0979611413553357, 'metrics/total_secs_per_batch': 44.70553755760193, 'metrics/data_secs_per_batch': 19.58020281791687, '_timestamp': 1741702515.862629}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 499. Dropping entry: {'train/lr': 0.00029119277108433734, '_timestamp': 1741702515.863039}).
Epoch: [1][260/500]	Time 45.636 (45.636)	Loss 0.5588 (0.4050)	CeLoss 0.0718 (0.0543)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0020 (0.0031)	MaskLoss 0.1472 (0.0955)	MaskBCELoss 0.0521 (0.0176)	MaskDICELoss 0.0951 (0.0779)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 499. Dropping entry: {'train/loss': 0.4050380207598209, 'train/ce_loss': 0.05426025390625, 'train/seg_cls_loss': 0.0013996124267578124, 'train/kl_loss': 0.0030609130859375, 'train/mask_bce_loss': 0.01763058805372566, 'train/mask_dice_loss': 0.07791784405708313, 'train/mask_loss': 0.09554843232035637, 'metrics/total_secs_per_batch': 45.63633894920349, 'metrics/data_secs_per_batch': 21.61770534515381, '_timestamp': 1741702561.4990115}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 499. Dropping entry: {'train/lr': 0.00029116867469879517, '_timestamp': 1741702561.4994092}).
Epoch: [1][261/500]	Time 50.182 (50.182)	Loss 0.4044 (0.3075)	CeLoss 0.0240 (0.0467)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0016 (0.0030)	MaskLoss 0.1073 (0.0734)	MaskBCELoss 0.0254 (0.0182)	MaskDICELoss 0.0819 (0.0552)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 499. Dropping entry: {'train/loss': 0.3075336927548051, 'train/ce_loss': 0.0466796875, 'train/seg_cls_loss': 0.0011754989624023437, 'train/kl_loss': 0.003025054931640625, 'train/mask_bce_loss': 0.018219017365481704, 'train/mask_dice_loss': 0.055215321481227875, 'train/mask_loss': 0.07343434020876885, 'metrics/total_secs_per_batch': 50.1822714805603, 'metrics/data_secs_per_batch': 21.168144464492798, '_timestamp': 1741702611.681286}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 499. Dropping entry: {'train/lr': 0.0002911566265060241, '_timestamp': 1741702611.6815898}).
Epoch: [1][262/500]	Time 52.315 (52.315)	Loss 0.3667 (0.3590)	CeLoss 0.0148 (0.0391)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0039 (0.0032)	MaskLoss 0.0913 (0.0884)	MaskBCELoss 0.0091 (0.0188)	MaskDICELoss 0.0822 (0.0696)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 499. Dropping entry: {'train/loss': 0.3590339757502079, 'train/ce_loss': 0.039141845703125, 'train/seg_cls_loss': 0.0014835357666015624, 'train/kl_loss': 0.00322723388671875, 'train/mask_bce_loss': 0.018815603735856713, 'train/mask_dice_loss': 0.06958409235812724, 'train/mask_loss': 0.0883996938355267, 'metrics/total_secs_per_batch': 52.31476879119873, 'metrics/data_secs_per_batch': 23.260708236694335, '_timestamp': 1741702663.9961312}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 499. Dropping entry: {'train/lr': 0.000291144578313253, '_timestamp': 1741702663.9966013}).
Epoch: [1][263/500]	Time 45.377 (45.377)	Loss 0.4554 (0.4128)	CeLoss 0.0391 (0.0422)	SegCLSLoss 0.0006 (0.0021)	KLLoss 0.0032 (0.0030)	MaskLoss 0.1065 (0.0986)	MaskBCELoss 0.0065 (0.0140)	MaskDICELoss 0.0999 (0.0846)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 499. Dropping entry: {'train/loss': 0.41281007826328275, 'train/ce_loss': 0.0421875, 'train/seg_cls_loss': 0.00206298828125, 'train/kl_loss': 0.003041839599609375, 'train/mask_bce_loss': 0.013978805876104162, 'train/mask_dice_loss': 0.08464085422456265, 'train/mask_loss': 0.09861966222524643, 'metrics/total_secs_per_batch': 45.37660789489746, 'metrics/data_secs_per_batch': 21.038032054901123, '_timestamp': 1741702709.3738604}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 499. Dropping entry: {'train/lr': 0.0002911325301204819, '_timestamp': 1741702709.3749878}).
Epoch: [1][264/500]	Time 45.306 (45.306)	Loss 0.3533 (0.4005)	CeLoss 0.0762 (0.0564)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0021 (0.0027)	MaskLoss 0.0796 (0.0955)	MaskBCELoss 0.0219 (0.0206)	MaskDICELoss 0.0578 (0.0749)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 499. Dropping entry: {'train/loss': 0.4005253255367279, 'train/ce_loss': 0.056396484375, 'train/seg_cls_loss': 0.0015148162841796876, 'train/kl_loss': 0.00269775390625, 'train/mask_bce_loss': 0.02061046699527651, 'train/mask_dice_loss': 0.0748846922069788, 'train/mask_loss': 0.09549515843391418, 'metrics/total_secs_per_batch': 45.306135177612305, 'metrics/data_secs_per_batch': 21.685685777664183, '_timestamp': 1741702754.681464}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 499. Dropping entry: {'train/lr': 0.0002911204819277108, '_timestamp': 1741702754.6829622}).
Epoch: [1][265/500]	Time 50.047 (50.047)	Loss 0.0914 (0.2815)	CeLoss 0.0396 (0.0406)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0020 (0.0026)	MaskLoss 0.0128 (0.0624)	MaskBCELoss 0.0008 (0.0059)	MaskDICELoss 0.0120 (0.0565)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 499. Dropping entry: {'train/loss': 0.28151156529784205, 'train/ce_loss': 0.04056396484375, 'train/seg_cls_loss': 0.0012882232666015625, 'train/kl_loss': 0.002573394775390625, 'train/mask_bce_loss': 0.005859360643080435, 'train/mask_dice_loss': 0.05650582956150174, 'train/mask_loss': 0.06236519077792764, 'metrics/total_secs_per_batch': 50.047109603881836, 'metrics/data_secs_per_batch': 22.312187457084654, '_timestamp': 1741702804.7260234}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 499. Dropping entry: {'train/lr': 0.0002911084337349397, '_timestamp': 1741702804.7264783}).
Epoch: [1][266/500]	Time 49.251 (49.251)	Loss 0.3722 (0.3882)	CeLoss 0.0225 (0.0341)	SegCLSLoss 0.0013 (0.0018)	KLLoss 0.0033 (0.0034)	MaskLoss 0.1205 (0.1013)	MaskBCELoss 0.0682 (0.0278)	MaskDICELoss 0.0524 (0.0735)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 499. Dropping entry: {'train/loss': 0.3881619766354561, 'train/ce_loss': 0.03414306640625, 'train/seg_cls_loss': 0.00182342529296875, 'train/kl_loss': 0.0033966064453125, 'train/mask_bce_loss': 0.027825586614198983, 'train/mask_dice_loss': 0.07351832538843155, 'train/mask_loss': 0.10134391188621521, 'metrics/total_secs_per_batch': 49.25124168395996, 'metrics/data_secs_per_batch': 21.446319484710692, '_timestamp': 1741702853.9771478}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 499. Dropping entry: {'train/lr': 0.00029109638554216863, '_timestamp': 1741702853.9776382}).
Epoch: [1][267/500]	Time 45.163 (45.163)	Loss 0.4193 (0.3963)	CeLoss 0.0162 (0.0469)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0029 (0.0027)	MaskLoss 0.1008 (0.0975)	MaskBCELoss 0.0018 (0.0221)	MaskDICELoss 0.0990 (0.0754)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 499. Dropping entry: {'train/loss': 0.3963121801614761, 'train/ce_loss': 0.0469482421875, 'train/seg_cls_loss': 0.001593017578125, 'train/kl_loss': 0.002707672119140625, 'train/mask_bce_loss': 0.022082983364816754, 'train/mask_dice_loss': 0.075429130718112, 'train/mask_loss': 0.09751211404800415, 'metrics/total_secs_per_batch': 45.162641286849976, 'metrics/data_secs_per_batch': 19.664636492729187, '_timestamp': 1741702899.1401446}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 499. Dropping entry: {'train/lr': 0.00029108433734939754, '_timestamp': 1741702899.1407273}).
Epoch: [1][268/500]	Time 52.697 (52.697)	Loss 0.4056 (0.3630)	CeLoss 0.0542 (0.0473)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0032 (0.0032)	MaskLoss 0.1027 (0.0861)	MaskBCELoss 0.0315 (0.0161)	MaskDICELoss 0.0712 (0.0699)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 499. Dropping entry: {'train/loss': 0.3629752827808261, 'train/ce_loss': 0.04727783203125, 'train/seg_cls_loss': 0.0007587432861328125, 'train/kl_loss': 0.0032379150390625, 'train/mask_bce_loss': 0.01614974131807685, 'train/mask_dice_loss': 0.06994434194639325, 'train/mask_loss': 0.08609408307820558, 'metrics/total_secs_per_batch': 52.6969997882843, 'metrics/data_secs_per_batch': 23.715089440345764, '_timestamp': 1741702951.8368928}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 499. Dropping entry: {'train/lr': 0.0002910722891566265, '_timestamp': 1741702951.8373144}).
Epoch: [1][269/500]	Time 51.727 (51.727)	Loss 0.4411 (0.4227)	CeLoss 0.0454 (0.0468)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0014 (0.0029)	MaskLoss 0.0991 (0.1019)	MaskBCELoss 0.0012 (0.0176)	MaskDICELoss 0.0979 (0.0843)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 499. Dropping entry: {'train/loss': 0.4226819843053818, 'train/ce_loss': 0.04676513671875, 'train/seg_cls_loss': 0.0014516830444335938, 'train/kl_loss': 0.00287628173828125, 'train/mask_bce_loss': 0.017566227761562914, 'train/mask_dice_loss': 0.08428728841245174, 'train/mask_loss': 0.1018535166978836, 'metrics/total_secs_per_batch': 51.727388858795166, 'metrics/data_secs_per_batch': 22.135235261917114, '_timestamp': 1741703003.564753}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 499. Dropping entry: {'train/lr': 0.0002910602409638554, '_timestamp': 1741703003.5652945}).
Epoch: [1][270/500]	Time 52.110 (52.110)	Loss 0.0609 (0.3190)	CeLoss 0.0610 (0.0411)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0752)	MaskBCELoss 0.0000 (0.0130)	MaskDICELoss 0.0000 (0.0622)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 499. Dropping entry: {'train/loss': 0.31903854198753834, 'train/ce_loss': 0.04111328125, 'train/seg_cls_loss': 0.00090484619140625, 'train/kl_loss': 0.00255126953125, 'train/mask_bce_loss': 0.01298171174712479, 'train/mask_dice_loss': 0.06223850585520267, 'train/mask_loss': 0.07522021979093552, 'metrics/total_secs_per_batch': 52.11028981208801, 'metrics/data_secs_per_batch': 24.726966094970702, '_timestamp': 1741703055.6746693}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 499. Dropping entry: {'train/lr': 0.00029103614457831324, '_timestamp': 1741703055.6750743}).
Epoch: [1][271/500]	Time 48.169 (48.169)	Loss 0.4496 (0.4185)	CeLoss 0.0232 (0.0434)	SegCLSLoss 0.0012 (0.0015)	KLLoss 0.0062 (0.0028)	MaskLoss 0.1297 (0.1013)	MaskBCELoss 0.0497 (0.0168)	MaskDICELoss 0.0800 (0.0845)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 499. Dropping entry: {'train/loss': 0.4185340702533722, 'train/ce_loss': 0.04339599609375, 'train/seg_cls_loss': 0.001467132568359375, 'train/kl_loss': 0.00279541015625, 'train/mask_bce_loss': 0.016790207292069682, 'train/mask_dice_loss': 0.0845001295208931, 'train/mask_loss': 0.101290338113904, 'metrics/total_secs_per_batch': 48.169254779815674, 'metrics/data_secs_per_batch': 21.703486967086793, '_timestamp': 1741703103.8450513}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 499. Dropping entry: {'train/lr': 0.00029102409638554215, '_timestamp': 1741703103.8461354}).
Epoch: [1][272/500]	Time 51.078 (51.078)	Loss 0.4420 (0.3457)	CeLoss 0.0369 (0.0432)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0039 (0.0033)	MaskLoss 0.1002 (0.0792)	MaskBCELoss 0.0003 (0.0092)	MaskDICELoss 0.1000 (0.0701)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 499. Dropping entry: {'train/loss': 0.34566854275763037, 'train/ce_loss': 0.0431640625, 'train/seg_cls_loss': 0.00120849609375, 'train/kl_loss': 0.00328521728515625, 'train/mask_bce_loss': 0.009171790178515948, 'train/mask_dice_loss': 0.07007342702709138, 'train/mask_loss': 0.07924521639943123, 'metrics/total_secs_per_batch': 51.07779669761658, 'metrics/data_secs_per_batch': 24.09517695903778, '_timestamp': 1741703154.922667}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 499. Dropping entry: {'train/lr': 0.00029101204819277106, '_timestamp': 1741703154.9236171}).
Epoch: [1][273/500]	Time 43.875 (43.875)	Loss 0.4304 (0.4490)	CeLoss 0.0250 (0.0584)	SegCLSLoss 0.0018 (0.0019)	KLLoss 0.0026 (0.0034)	MaskLoss 0.1034 (0.1099)	MaskBCELoss 0.0058 (0.0267)	MaskDICELoss 0.0976 (0.0832)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 499. Dropping entry: {'train/loss': 0.4489690810441971, 'train/ce_loss': 0.0583984375, 'train/seg_cls_loss': 0.0019266128540039063, 'train/kl_loss': 0.00336151123046875, 'train/mask_bce_loss': 0.02674358079675585, 'train/mask_dice_loss': 0.08320153430104256, 'train/mask_loss': 0.10994511358439922, 'metrics/total_secs_per_batch': 43.87519812583923, 'metrics/data_secs_per_batch': 20.459249472618104, '_timestamp': 1741703198.797832}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 499. Dropping entry: {'train/lr': 0.00029099999999999997, '_timestamp': 1741703198.7987916}).
Epoch: [1][274/500]	Time 50.920 (50.920)	Loss 0.2733 (0.3095)	CeLoss 0.0266 (0.0433)	SegCLSLoss 0.0012 (0.0009)	KLLoss 0.0040 (0.0037)	MaskLoss 0.0728 (0.0688)	MaskBCELoss 0.0246 (0.0065)	MaskDICELoss 0.0483 (0.0623)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 499. Dropping entry: {'train/loss': 0.3094619829207659, 'train/ce_loss': 0.04326171875, 'train/seg_cls_loss': 0.0008764266967773438, 'train/kl_loss': 0.00367584228515625, 'train/mask_bce_loss': 0.006508108659181744, 'train/mask_dice_loss': 0.06228038675617427, 'train/mask_loss': 0.06878849477507173, 'metrics/total_secs_per_batch': 50.91958689689636, 'metrics/data_secs_per_batch': 23.012515592575074, '_timestamp': 1741703249.7171664}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909879518072289, '_timestamp': 1741703249.7178986}).
Epoch: [1][275/500]	Time 43.337 (43.337)	Loss 0.4140 (0.3424)	CeLoss 0.0240 (0.0310)	SegCLSLoss 0.0036 (0.0017)	KLLoss 0.0029 (0.0033)	MaskLoss 0.1013 (0.0851)	MaskBCELoss 0.0100 (0.0165)	MaskDICELoss 0.0913 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 499. Dropping entry: {'train/loss': 0.342405890673399, 'train/ce_loss': 0.0309814453125, 'train/seg_cls_loss': 0.001734161376953125, 'train/kl_loss': 0.00328521728515625, 'train/mask_bce_loss': 0.016466907458379865, 'train/mask_dice_loss': 0.06859116405248641, 'train/mask_loss': 0.08505807127803564, 'metrics/total_secs_per_batch': 43.33655309677124, 'metrics/data_secs_per_batch': 19.276264429092407, '_timestamp': 1741703293.0532923}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909759036144578, '_timestamp': 1741703293.0538027}).
Epoch: [1][276/500]	Time 47.547 (47.547)	Loss 0.4354 (0.3485)	CeLoss 0.0312 (0.0433)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0025 (0.0035)	MaskLoss 0.1011 (0.0819)	MaskBCELoss 0.0017 (0.0133)	MaskDICELoss 0.0994 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 499. Dropping entry: {'train/loss': 0.34848160222172736, 'train/ce_loss': 0.04334716796875, 'train/seg_cls_loss': 0.0010816574096679688, 'train/kl_loss': 0.003537750244140625, 'train/mask_bce_loss': 0.013325744192115963, 'train/mask_dice_loss': 0.06860694293864071, 'train/mask_loss': 0.08193268645554781, 'metrics/total_secs_per_batch': 47.54695677757263, 'metrics/data_secs_per_batch': 22.005296993255616, '_timestamp': 1741703340.600707}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909638554216867, '_timestamp': 1741703340.6013687}).
Epoch: [1][277/500]	Time 51.049 (51.049)	Loss 0.3642 (0.4000)	CeLoss 0.0177 (0.0384)	SegCLSLoss 0.0024 (0.0027)	KLLoss 0.0041 (0.0031)	MaskLoss 0.0944 (0.1005)	MaskBCELoss 0.0182 (0.0223)	MaskDICELoss 0.0762 (0.0782)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 276 is less than current step: 499. Dropping entry: {'train/loss': 0.40002456605434417, 'train/ce_loss': 0.0384033203125, 'train/seg_cls_loss': 0.00267791748046875, 'train/kl_loss': 0.0030548095703125, 'train/mask_bce_loss': 0.0223256386583671, 'train/mask_dice_loss': 0.07816949374973774, 'train/mask_loss': 0.1004951361566782, 'metrics/total_secs_per_batch': 51.04881262779236, 'metrics/data_secs_per_batch': 20.97821400165558, '_timestamp': 1741703391.6493042}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 276 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909518072289156, '_timestamp': 1741703391.6499305}).
Epoch: [1][278/500]	Time 46.958 (46.958)	Loss 0.4751 (0.3436)	CeLoss 0.0693 (0.0443)	SegCLSLoss 0.0029 (0.0013)	KLLoss 0.0019 (0.0031)	MaskLoss 0.1027 (0.0833)	MaskBCELoss 0.0044 (0.0188)	MaskDICELoss 0.0983 (0.0645)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 277 is less than current step: 499. Dropping entry: {'train/loss': 0.34360453486442566, 'train/ce_loss': 0.04434814453125, 'train/seg_cls_loss': 0.0012683868408203125, 'train/kl_loss': 0.0030670166015625, 'train/mask_bce_loss': 0.018789820943493397, 'train/mask_dice_loss': 0.06450182870030403, 'train/mask_loss': 0.08329164758324623, 'metrics/total_secs_per_batch': 46.95798110961914, 'metrics/data_secs_per_batch': 20.54689230918884, '_timestamp': 1741703438.6068196}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 277 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909397590361445, '_timestamp': 1741703438.6073363}).
Epoch: [1][279/500]	Time 43.279 (43.279)	Loss 0.5306 (0.3524)	CeLoss 0.0933 (0.0559)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0037 (0.0041)	MaskLoss 0.1227 (0.0824)	MaskBCELoss 0.0286 (0.0189)	MaskDICELoss 0.0940 (0.0635)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 278 is less than current step: 499. Dropping entry: {'train/loss': 0.35243055149912833, 'train/ce_loss': 0.05587158203125, 'train/seg_cls_loss': 0.0010934829711914062, 'train/kl_loss': 0.004144287109375, 'train/mask_bce_loss': 0.018852487788535655, 'train/mask_dice_loss': 0.06352026308886707, 'train/mask_loss': 0.08237275099381805, 'metrics/total_secs_per_batch': 43.27923941612244, 'metrics/data_secs_per_batch': 20.613720703125, '_timestamp': 1741703481.88612}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 278 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909277108433735, '_timestamp': 1741703481.8865643}).
Epoch: [1][280/500]	Time 51.874 (51.874)	Loss 0.5166 (0.3433)	CeLoss 0.1123 (0.0546)	SegCLSLoss 0.0023 (0.0008)	KLLoss 0.0027 (0.0022)	MaskLoss 0.1005 (0.0796)	MaskBCELoss 0.0005 (0.0162)	MaskDICELoss 0.1000 (0.0634)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 279 is less than current step: 499. Dropping entry: {'train/loss': 0.34326316602528095, 'train/ce_loss': 0.05462646484375, 'train/seg_cls_loss': 0.0008167266845703125, 'train/kl_loss': 0.00217132568359375, 'train/mask_bce_loss': 0.016163802606752143, 'train/mask_dice_loss': 0.06342480629682541, 'train/mask_loss': 0.07958860620856285, 'metrics/total_secs_per_batch': 51.8739378452301, 'metrics/data_secs_per_batch': 23.968144512176515, '_timestamp': 1741703533.761843}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 279 is less than current step: 499. Dropping entry: {'train/lr': 0.0002909036144578313, '_timestamp': 1741703533.762849}).
Epoch: [1][281/500]	Time 49.437 (49.437)	Loss 0.4714 (0.3536)	CeLoss 0.0835 (0.0466)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0037 (0.0031)	MaskLoss 0.1078 (0.0815)	MaskBCELoss 0.0240 (0.0113)	MaskDICELoss 0.0838 (0.0702)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 280 is less than current step: 499. Dropping entry: {'train/loss': 0.3535844229161739, 'train/ce_loss': 0.0465576171875, 'train/seg_cls_loss': 0.0008148193359375, 'train/kl_loss': 0.0031341552734375, 'train/mask_bce_loss': 0.011300681275315583, 'train/mask_dice_loss': 0.07020181901752949, 'train/mask_loss': 0.08150250166654587, 'metrics/total_secs_per_batch': 49.437456130981445, 'metrics/data_secs_per_batch': 22.740315318107605, '_timestamp': 1741703583.198882}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 280 is less than current step: 499. Dropping entry: {'train/lr': 0.0002908915662650602, '_timestamp': 1741703583.2000396}).
Epoch: [1][282/500]	Time 47.048 (47.048)	Loss 0.4296 (0.3987)	CeLoss 0.0216 (0.0404)	SegCLSLoss 0.0024 (0.0010)	KLLoss 0.0046 (0.0037)	MaskLoss 0.1012 (0.1027)	MaskBCELoss 0.0014 (0.0285)	MaskDICELoss 0.0999 (0.0743)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 281 is less than current step: 499. Dropping entry: {'train/loss': 0.3987106442451477, 'train/ce_loss': 0.04039306640625, 'train/seg_cls_loss': 0.0009958267211914063, 'train/kl_loss': 0.0036865234375, 'train/mask_bce_loss': 0.02845194914843887, 'train/mask_dice_loss': 0.07427980825304985, 'train/mask_loss': 0.10273175798356533, 'metrics/total_secs_per_batch': 47.04771590232849, 'metrics/data_secs_per_batch': 20.7463627576828, '_timestamp': 1741703630.2475271}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 281 is less than current step: 499. Dropping entry: {'train/lr': 0.00029087951807228913, '_timestamp': 1741703630.2488072}).
Epoch: [1][283/500]	Time 47.572 (47.572)	Loss 0.4989 (0.4091)	CeLoss 0.0728 (0.0586)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0034 (0.0030)	MaskLoss 0.1113 (0.0984)	MaskBCELoss 0.0115 (0.0235)	MaskDICELoss 0.0998 (0.0749)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 282 is less than current step: 499. Dropping entry: {'train/loss': 0.4091031476855278, 'train/ce_loss': 0.05863037109375, 'train/seg_cls_loss': 0.0014287948608398438, 'train/kl_loss': 0.0029754638671875, 'train/mask_bce_loss': 0.02352332540322095, 'train/mask_dice_loss': 0.07490865625441075, 'train/mask_loss': 0.09843198098242283, 'metrics/total_secs_per_batch': 47.57164025306702, 'metrics/data_secs_per_batch': 21.981149506568908, '_timestamp': 1741703677.816947}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 282 is less than current step: 499. Dropping entry: {'train/lr': 0.00029086746987951804, '_timestamp': 1741703677.817373}).
Epoch: [1][284/500]	Time 41.368 (41.368)	Loss 0.4113 (0.3795)	CeLoss 0.0874 (0.0546)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0028 (0.0030)	MaskLoss 0.0923 (0.0920)	MaskBCELoss 0.0243 (0.0234)	MaskDICELoss 0.0680 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 283 is less than current step: 499. Dropping entry: {'train/loss': 0.37946531604975464, 'train/ce_loss': 0.05457763671875, 'train/seg_cls_loss': 0.0015117645263671875, 'train/kl_loss': 0.003003692626953125, 'train/mask_bce_loss': 0.023406890907790513, 'train/mask_dice_loss': 0.06857303958386182, 'train/mask_loss': 0.09197993129491806, 'metrics/total_secs_per_batch': 41.367760181427, 'metrics/data_secs_per_batch': 18.648594665527344, '_timestamp': 1741703719.1862116}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 283 is less than current step: 499. Dropping entry: {'train/lr': 0.00029085542168674696, '_timestamp': 1741703719.1872292}).
Epoch: [1][285/500]	Time 50.626 (50.626)	Loss 0.4177 (0.3191)	CeLoss 0.0408 (0.0510)	SegCLSLoss 0.0019 (0.0012)	KLLoss 0.0029 (0.0032)	MaskLoss 0.1090 (0.0770)	MaskBCELoss 0.0316 (0.0217)	MaskDICELoss 0.0774 (0.0553)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 284 is less than current step: 499. Dropping entry: {'train/loss': 0.31911624409258366, 'train/ce_loss': 0.0509521484375, 'train/seg_cls_loss': 0.001160430908203125, 'train/kl_loss': 0.003186798095703125, 'train/mask_bce_loss': 0.02169259493093705, 'train/mask_dice_loss': 0.055265771597623824, 'train/mask_loss': 0.07695836760103703, 'metrics/total_secs_per_batch': 50.62566828727722, 'metrics/data_secs_per_batch': 21.782682681083678, '_timestamp': 1741703769.8103158}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 284 is less than current step: 499. Dropping entry: {'train/lr': 0.00029084337349397587, '_timestamp': 1741703769.810739}).
Epoch: [1][286/500]	Time 49.838 (49.838)	Loss 0.4747 (0.4425)	CeLoss 0.0554 (0.0507)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0018 (0.0036)	MaskLoss 0.1083 (0.1144)	MaskBCELoss 0.0083 (0.0349)	MaskDICELoss 0.1000 (0.0794)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 285 is less than current step: 499. Dropping entry: {'train/loss': 0.44253557473421096, 'train/ce_loss': 0.05068359375, 'train/seg_cls_loss': 0.00132904052734375, 'train/kl_loss': 0.003632354736328125, 'train/mask_bce_loss': 0.034948586765676734, 'train/mask_dice_loss': 0.07940715830773115, 'train/mask_loss': 0.11435574684292078, 'metrics/total_secs_per_batch': 49.838330030441284, 'metrics/data_secs_per_batch': 23.375794196128844, '_timestamp': 1741703819.6486695}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 285 is less than current step: 499. Dropping entry: {'train/lr': 0.0002908313253012048, '_timestamp': 1741703819.649101}).
Epoch: [1][287/500]	Time 50.398 (50.398)	Loss 0.3551 (0.4045)	CeLoss 0.0598 (0.0411)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0020 (0.0032)	MaskLoss 0.0818 (0.1019)	MaskBCELoss 0.0171 (0.0241)	MaskDICELoss 0.0647 (0.0778)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 286 is less than current step: 499. Dropping entry: {'train/loss': 0.40449581742286683, 'train/ce_loss': 0.041064453125, 'train/seg_cls_loss': 0.0015026092529296874, 'train/kl_loss': 0.00320892333984375, 'train/mask_bce_loss': 0.024061289062956348, 'train/mask_dice_loss': 0.07782621756196022, 'train/mask_loss': 0.10188750624656677, 'metrics/total_secs_per_batch': 50.397706270217896, 'metrics/data_secs_per_batch': 23.34839196205139, '_timestamp': 1741703870.0465271}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 286 is less than current step: 499. Dropping entry: {'train/lr': 0.0002908192771084337, '_timestamp': 1741703870.0470264}).
Epoch: [1][288/500]	Time 47.499 (47.499)	Loss 0.4383 (0.3372)	CeLoss 0.0317 (0.0379)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0031 (0.0027)	MaskLoss 0.1233 (0.0844)	MaskBCELoss 0.0452 (0.0209)	MaskDICELoss 0.0781 (0.0635)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 287 is less than current step: 499. Dropping entry: {'train/loss': 0.3371866854839027, 'train/ce_loss': 0.037908935546875, 'train/seg_cls_loss': 0.0015092849731445312, 'train/kl_loss': 0.002734375, 'train/mask_bce_loss': 0.020850003947271035, 'train/mask_dice_loss': 0.06350789936259389, 'train/mask_loss': 0.08435790650546551, 'metrics/total_secs_per_batch': 47.49854874610901, 'metrics/data_secs_per_batch': 21.364966106414794, '_timestamp': 1741703917.5450563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 287 is less than current step: 499. Dropping entry: {'train/lr': 0.00029080722891566265, '_timestamp': 1741703917.5455258}).
Epoch: [1][289/500]	Time 49.678 (49.678)	Loss 0.4454 (0.4376)	CeLoss 0.0211 (0.0465)	SegCLSLoss 0.0040 (0.0017)	KLLoss 0.0023 (0.0032)	MaskLoss 0.1100 (0.1025)	MaskBCELoss 0.0101 (0.0114)	MaskDICELoss 0.1000 (0.0910)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 288 is less than current step: 499. Dropping entry: {'train/loss': 0.43757919073104856, 'train/ce_loss': 0.046484375, 'train/seg_cls_loss': 0.001718902587890625, 'train/kl_loss': 0.00323333740234375, 'train/mask_bce_loss': 0.011422812115051783, 'train/mask_dice_loss': 0.09103690907359123, 'train/mask_loss': 0.1024597205221653, 'metrics/total_secs_per_batch': 49.67797327041626, 'metrics/data_secs_per_batch': 22.666767621040343, '_timestamp': 1741703967.2228997}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 288 is less than current step: 499. Dropping entry: {'train/lr': 0.00029079518072289156, '_timestamp': 1741703967.223313}).
Epoch: [1][290/500]	Time 47.083 (47.083)	Loss 0.0933 (0.3909)	CeLoss 0.0273 (0.0392)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0024 (0.0033)	MaskLoss 0.0161 (0.0962)	MaskBCELoss 0.0005 (0.0185)	MaskDICELoss 0.0156 (0.0777)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 289 is less than current step: 499. Dropping entry: {'train/loss': 0.39090114533901216, 'train/ce_loss': 0.03919677734375, 'train/seg_cls_loss': 0.0011714935302734376, 'train/kl_loss': 0.00328216552734375, 'train/mask_bce_loss': 0.018493226304417475, 'train/mask_dice_loss': 0.07771695461124181, 'train/mask_loss': 0.09621018152683973, 'metrics/total_secs_per_batch': 47.08280301094055, 'metrics/data_secs_per_batch': 21.805713295936584, '_timestamp': 1741704014.3057888}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 289 is less than current step: 499. Dropping entry: {'train/lr': 0.0002907710843373494, '_timestamp': 1741704014.3062077}).
Epoch: [1][291/500]	Time 47.571 (47.571)	Loss 0.4354 (0.3844)	CeLoss 0.0574 (0.0460)	SegCLSLoss 0.0056 (0.0016)	KLLoss 0.0032 (0.0027)	MaskLoss 0.1125 (0.0919)	MaskBCELoss 0.0389 (0.0163)	MaskDICELoss 0.0736 (0.0756)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 290 is less than current step: 499. Dropping entry: {'train/loss': 0.3844412100501359, 'train/ce_loss': 0.045953369140625, 'train/seg_cls_loss': 0.0015939712524414063, 'train/kl_loss': 0.00271759033203125, 'train/mask_bce_loss': 0.016299057356081902, 'train/mask_dice_loss': 0.07560481876134872, 'train/mask_loss': 0.09190387390553952, 'metrics/total_secs_per_batch': 47.57144618034363, 'metrics/data_secs_per_batch': 22.925171422958375, '_timestamp': 1741704061.8783848}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 290 is less than current step: 499. Dropping entry: {'train/lr': 0.0002907590361445783, '_timestamp': 1741704061.8793533}).
Epoch: [1][292/500]	Time 47.769 (47.769)	Loss 0.4398 (0.3147)	CeLoss 0.0250 (0.0473)	SegCLSLoss 0.0052 (0.0013)	KLLoss 0.0037 (0.0032)	MaskLoss 0.1049 (0.0703)	MaskBCELoss 0.0055 (0.0088)	MaskDICELoss 0.0994 (0.0615)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 291 is less than current step: 499. Dropping entry: {'train/loss': 0.31469741128385065, 'train/ce_loss': 0.0473388671875, 'train/seg_cls_loss': 0.00128936767578125, 'train/kl_loss': 0.0032012939453125, 'train/mask_bce_loss': 0.008753371919738129, 'train/mask_dice_loss': 0.06150958240032196, 'train/mask_loss': 0.07026295298710465, 'metrics/total_secs_per_batch': 47.76896381378174, 'metrics/data_secs_per_batch': 21.116175651550293, '_timestamp': 1741704109.6475368}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 291 is less than current step: 499. Dropping entry: {'train/lr': 0.0002907469879518072, '_timestamp': 1741704109.6486254}).
Epoch: [1][293/500]	Time 53.481 (53.481)	Loss 0.4336 (0.3695)	CeLoss 0.0270 (0.0349)	SegCLSLoss 0.0020 (0.0017)	KLLoss 0.0034 (0.0034)	MaskLoss 0.1015 (0.0900)	MaskBCELoss 0.0019 (0.0149)	MaskDICELoss 0.0996 (0.0751)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 292 is less than current step: 499. Dropping entry: {'train/loss': 0.3694516524672508, 'train/ce_loss': 0.0349365234375, 'train/seg_cls_loss': 0.0016557693481445313, 'train/kl_loss': 0.0034393310546875, 'train/mask_bce_loss': 0.014875448337988928, 'train/mask_dice_loss': 0.0751351485028863, 'train/mask_loss': 0.0900105968117714, 'metrics/total_secs_per_batch': 53.48068118095398, 'metrics/data_secs_per_batch': 24.45384826660156, '_timestamp': 1741704163.1270087}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 292 is less than current step: 499. Dropping entry: {'train/lr': 0.0002907349397590361, '_timestamp': 1741704163.1274974}).
Epoch: [1][294/500]	Time 49.466 (49.466)	Loss 0.3948 (0.3642)	CeLoss 0.0193 (0.0503)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0030 (0.0030)	MaskLoss 0.1087 (0.0877)	MaskBCELoss 0.0315 (0.0202)	MaskDICELoss 0.0772 (0.0675)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 293 is less than current step: 499. Dropping entry: {'train/loss': 0.3641980117186904, 'train/ce_loss': 0.05029296875, 'train/seg_cls_loss': 0.0012605667114257812, 'train/kl_loss': 0.00298004150390625, 'train/mask_bce_loss': 0.020183107419870793, 'train/mask_dice_loss': 0.0674838300794363, 'train/mask_loss': 0.08766693770885467, 'metrics/total_secs_per_batch': 49.46599841117859, 'metrics/data_secs_per_batch': 21.646266865730286, '_timestamp': 1741704212.5939438}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 293 is less than current step: 499. Dropping entry: {'train/lr': 0.00029072289156626503, '_timestamp': 1741704212.5950935}).
Epoch: [1][295/500]	Time 47.993 (47.993)	Loss 0.4608 (0.3903)	CeLoss 0.0737 (0.0434)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0044 (0.0037)	MaskLoss 0.0980 (0.1006)	MaskBCELoss 0.0051 (0.0299)	MaskDICELoss 0.0929 (0.0706)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 294 is less than current step: 499. Dropping entry: {'train/loss': 0.39025405049324036, 'train/ce_loss': 0.043408203125, 'train/seg_cls_loss': 0.0014127731323242188, 'train/kl_loss': 0.00369720458984375, 'train/mask_bce_loss': 0.029932355415076016, 'train/mask_dice_loss': 0.07063932809978724, 'train/mask_loss': 0.10057168416678905, 'metrics/total_secs_per_batch': 47.9934766292572, 'metrics/data_secs_per_batch': 22.665696120262147, '_timestamp': 1741704260.5873353}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 294 is less than current step: 499. Dropping entry: {'train/lr': 0.00029071084337349394, '_timestamp': 1741704260.5883906}).
Epoch: [1][296/500]	Time 50.938 (50.938)	Loss 0.4857 (0.3830)	CeLoss 0.0168 (0.0402)	SegCLSLoss 0.0007 (0.0008)	KLLoss 0.0039 (0.0035)	MaskLoss 0.1336 (0.0927)	MaskBCELoss 0.0349 (0.0159)	MaskDICELoss 0.0987 (0.0767)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 295 is less than current step: 499. Dropping entry: {'train/loss': 0.3829601931385696, 'train/ce_loss': 0.040216064453125, 'train/seg_cls_loss': 0.0007968902587890625, 'train/kl_loss': 0.00351409912109375, 'train/mask_bce_loss': 0.015919839835260064, 'train/mask_dice_loss': 0.07673764787614346, 'train/mask_loss': 0.09265748858451843, 'metrics/total_secs_per_batch': 50.938232421875, 'metrics/data_secs_per_batch': 22.752877283096314, '_timestamp': 1741704311.5245974}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 295 is less than current step: 499. Dropping entry: {'train/lr': 0.00029069879518072285, '_timestamp': 1741704311.524874}).
Epoch: [1][297/500]	Time 46.821 (46.821)	Loss 0.3322 (0.4046)	CeLoss 0.0277 (0.0391)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0038 (0.0039)	MaskLoss 0.0880 (0.1058)	MaskBCELoss 0.0260 (0.0312)	MaskDICELoss 0.0620 (0.0746)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 296 is less than current step: 499. Dropping entry: {'train/loss': 0.40457175523042677, 'train/ce_loss': 0.0391357421875, 'train/seg_cls_loss': 0.00151214599609375, 'train/kl_loss': 0.003887176513671875, 'train/mask_bce_loss': 0.03121869554743171, 'train/mask_dice_loss': 0.07458144370466471, 'train/mask_loss': 0.10580014102160931, 'metrics/total_secs_per_batch': 46.82107973098755, 'metrics/data_secs_per_batch': 21.217329144477844, '_timestamp': 1741704358.345654}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 296 is less than current step: 499. Dropping entry: {'train/lr': 0.00029068674698795176, '_timestamp': 1741704358.3460796}).
Epoch: [1][298/500]	Time 46.213 (46.213)	Loss 0.0969 (0.3799)	CeLoss 0.0276 (0.0461)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0026 (0.0034)	MaskLoss 0.0198 (0.0913)	MaskBCELoss 0.0065 (0.0176)	MaskDICELoss 0.0134 (0.0737)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 297 is less than current step: 499. Dropping entry: {'train/loss': 0.3798918329179287, 'train/ce_loss': 0.0460693359375, 'train/seg_cls_loss': 0.0012989044189453125, 'train/kl_loss': 0.0033599853515625, 'train/mask_bce_loss': 0.01757833966985345, 'train/mask_dice_loss': 0.07367890672758222, 'train/mask_loss': 0.0912572454661131, 'metrics/total_secs_per_batch': 46.21347117424011, 'metrics/data_secs_per_batch': 20.579775166511535, '_timestamp': 1741704404.5591393}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 297 is less than current step: 499. Dropping entry: {'train/lr': 0.00029067469879518067, '_timestamp': 1741704404.5594127}).
Epoch: [1][299/500]	Time 47.595 (47.595)	Loss 0.0551 (0.3886)	CeLoss 0.0552 (0.0575)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0923)	MaskBCELoss 0.0000 (0.0209)	MaskDICELoss 0.0000 (0.0714)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 298 is less than current step: 499. Dropping entry: {'train/loss': 0.38856885600835084, 'train/ce_loss': 0.05753173828125, 'train/seg_cls_loss': 0.0009857177734375, 'train/kl_loss': 0.00322265625, 'train/mask_bce_loss': 0.020911127654835583, 'train/mask_dice_loss': 0.07139612138271331, 'train/mask_loss': 0.09230725169181823, 'metrics/total_secs_per_batch': 47.59456968307495, 'metrics/data_secs_per_batch': 21.114562463760375, '_timestamp': 1741704452.1537812}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 298 is less than current step: 499. Dropping entry: {'train/lr': 0.0002906626506024096, '_timestamp': 1741704452.1540732}).
[2025-03-11 09:48:22,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[0.00029065060240963855], mom=[(0.9, 0.95)]
[2025-03-11 09:48:22,610] [INFO] [timer.py:215:stop] epoch=0/micro_step=800/global_step=80, RunningAvgSamplesPerSec=0.8315606077300287, CurrSamplesPerSec=0.7492859366141645, MemAllocated=62.08GB, MaxMemAllocated=74.15GB
Epoch: [1][300/500]	Time 50.458 (50.458)	Loss 0.0221 (0.3004)	CeLoss 0.0221 (0.0552)	SegCLSLoss 0.0000 (0.0005)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0697)	MaskBCELoss 0.0000 (0.0183)	MaskDICELoss 0.0000 (0.0514)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 299 is less than current step: 499. Dropping entry: {'train/loss': 0.3003630114719272, 'train/ce_loss': 0.0551513671875, 'train/seg_cls_loss': 0.000506591796875, 'train/kl_loss': 0.00273284912109375, 'train/mask_bce_loss': 0.018349595367908478, 'train/mask_dice_loss': 0.05138958655297756, 'train/mask_loss': 0.06973918192088605, 'metrics/total_secs_per_batch': 50.45779848098755, 'metrics/data_secs_per_batch': 20.602349710464477, '_timestamp': 1741704502.6111763}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 299 is less than current step: 499. Dropping entry: {'train/lr': 0.00029063855421686746, '_timestamp': 1741704502.611583}).
Epoch: [1][301/500]	Time 45.838 (45.838)	Loss 0.3951 (0.4187)	CeLoss 0.0223 (0.0416)	SegCLSLoss 0.0049 (0.0024)	KLLoss 0.0054 (0.0036)	MaskLoss 0.1039 (0.1029)	MaskBCELoss 0.0254 (0.0196)	MaskDICELoss 0.0785 (0.0832)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 300 is less than current step: 499. Dropping entry: {'train/loss': 0.4186760112643242, 'train/ce_loss': 0.0416259765625, 'train/seg_cls_loss': 0.002362060546875, 'train/kl_loss': 0.0035614013671875, 'train/mask_bce_loss': 0.01964853040408343, 'train/mask_dice_loss': 0.08324561808258295, 'train/mask_loss': 0.10289414748549461, 'metrics/total_secs_per_batch': 45.83842420578003, 'metrics/data_secs_per_batch': 19.50707597732544, '_timestamp': 1741704548.4499135}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 300 is less than current step: 499. Dropping entry: {'train/lr': 0.00029062650602409637, '_timestamp': 1741704548.4503355}).
Epoch: [1][302/500]	Time 43.534 (43.534)	Loss 0.0480 (0.3648)	CeLoss 0.0481 (0.0478)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0855)	MaskBCELoss 0.0000 (0.0139)	MaskDICELoss 0.0000 (0.0716)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 301 is less than current step: 499. Dropping entry: {'train/loss': 0.36480297092348335, 'train/ce_loss': 0.0477783203125, 'train/seg_cls_loss': 0.0008869171142578125, 'train/kl_loss': 0.002141571044921875, 'train/mask_bce_loss': 0.013921823701821268, 'train/mask_dice_loss': 0.07162752598524094, 'train/mask_loss': 0.08554934859275817, 'metrics/total_secs_per_batch': 43.53368782997131, 'metrics/data_secs_per_batch': 19.28943274021149, '_timestamp': 1741704591.9836094}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 301 is less than current step: 499. Dropping entry: {'train/lr': 0.0002906144578313253, '_timestamp': 1741704591.9838731}).
Epoch: [1][303/500]	Time 46.913 (46.913)	Loss 0.3190 (0.3927)	CeLoss 0.0579 (0.0393)	SegCLSLoss 0.0009 (0.0019)	KLLoss 0.0023 (0.0027)	MaskLoss 0.0800 (0.1069)	MaskBCELoss 0.0307 (0.0390)	MaskDICELoss 0.0492 (0.0679)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 302 is less than current step: 499. Dropping entry: {'train/loss': 0.3926852822303772, 'train/ce_loss': 0.0393310546875, 'train/seg_cls_loss': 0.001873779296875, 'train/kl_loss': 0.002725982666015625, 'train/mask_bce_loss': 0.039030455285683274, 'train/mask_dice_loss': 0.06788705009967089, 'train/mask_loss': 0.10691750477999448, 'metrics/total_secs_per_batch': 46.912984132766724, 'metrics/data_secs_per_batch': 20.820105814933775, '_timestamp': 1741704638.8967333}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 302 is less than current step: 499. Dropping entry: {'train/lr': 0.0002906024096385542, '_timestamp': 1741704638.8970375}).
Epoch: [1][304/500]	Time 51.080 (51.080)	Loss 0.2582 (0.3575)	CeLoss 0.0752 (0.0413)	SegCLSLoss 0.0007 (0.0022)	KLLoss 0.0020 (0.0033)	MaskLoss 0.0497 (0.0923)	MaskBCELoss 0.0092 (0.0288)	MaskDICELoss 0.0405 (0.0635)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 303 is less than current step: 499. Dropping entry: {'train/loss': 0.3574586249887943, 'train/ce_loss': 0.041259765625, 'train/seg_cls_loss': 0.0022365570068359373, 'train/kl_loss': 0.0033233642578125, 'train/mask_bce_loss': 0.02877935110591352, 'train/mask_dice_loss': 0.06353455022908747, 'train/mask_loss': 0.09231390226632356, 'metrics/total_secs_per_batch': 51.080183029174805, 'metrics/data_secs_per_batch': 21.48995988368988, '_timestamp': 1741704689.976807}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 303 is less than current step: 499. Dropping entry: {'train/lr': 0.0002905903614457831, '_timestamp': 1741704689.977086}).
Epoch: [1][305/500]	Time 46.633 (46.633)	Loss 0.4586 (0.3470)	CeLoss 0.0240 (0.0365)	SegCLSLoss 0.0018 (0.0018)	KLLoss 0.0044 (0.0026)	MaskLoss 0.1176 (0.0892)	MaskBCELoss 0.0205 (0.0248)	MaskDICELoss 0.0971 (0.0644)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 304 is less than current step: 499. Dropping entry: {'train/loss': 0.3470005955547094, 'train/ce_loss': 0.036474609375, 'train/seg_cls_loss': 0.0018430709838867187, 'train/kl_loss': 0.00257415771484375, 'train/mask_bce_loss': 0.024829240795224906, 'train/mask_dice_loss': 0.0643550593405962, 'train/mask_loss': 0.08918430022895336, 'metrics/total_secs_per_batch': 46.63256025314331, 'metrics/data_secs_per_batch': 20.733895826339722, '_timestamp': 1741704736.609351}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 304 is less than current step: 499. Dropping entry: {'train/lr': 0.000290578313253012, '_timestamp': 1741704736.6096237}).
Epoch: [1][306/500]	Time 47.448 (47.448)	Loss 0.4341 (0.3420)	CeLoss 0.0234 (0.0369)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0038 (0.0027)	MaskLoss 0.1033 (0.0846)	MaskBCELoss 0.0036 (0.0183)	MaskDICELoss 0.0998 (0.0663)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 305 is less than current step: 499. Dropping entry: {'train/loss': 0.3420493880286813, 'train/ce_loss': 0.036871337890625, 'train/seg_cls_loss': 0.0011674880981445313, 'train/kl_loss': 0.0027252197265625, 'train/mask_bce_loss': 0.018305421411059796, 'train/mask_dice_loss': 0.06630592569708824, 'train/mask_loss': 0.08461134694516659, 'metrics/total_secs_per_batch': 47.448399782180786, 'metrics/data_secs_per_batch': 23.13125650882721, '_timestamp': 1741704784.058946}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 305 is less than current step: 499. Dropping entry: {'train/lr': 0.0002905662650602409, '_timestamp': 1741704784.0599542}).
Epoch: [1][307/500]	Time 52.956 (52.956)	Loss 0.4206 (0.3774)	CeLoss 0.0476 (0.0408)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0039 (0.0036)	MaskLoss 0.1015 (0.0976)	MaskBCELoss 0.0185 (0.0290)	MaskDICELoss 0.0830 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 306 is less than current step: 499. Dropping entry: {'train/loss': 0.37744393907487395, 'train/ce_loss': 0.0407958984375, 'train/seg_cls_loss': 0.0009967803955078125, 'train/kl_loss': 0.003630828857421875, 'train/mask_bce_loss': 0.029015249013900755, 'train/mask_dice_loss': 0.06862289120908827, 'train/mask_loss': 0.09763814168982207, 'metrics/total_secs_per_batch': 52.95590782165527, 'metrics/data_secs_per_batch': 23.33756265640259, '_timestamp': 1741704837.0147946}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 306 is less than current step: 499. Dropping entry: {'train/lr': 0.00029055421686746983, '_timestamp': 1741704837.0157416}).
Epoch: [1][308/500]	Time 48.541 (48.541)	Loss 0.4702 (0.2764)	CeLoss 0.0422 (0.0506)	SegCLSLoss 0.0022 (0.0008)	KLLoss 0.0057 (0.0029)	MaskLoss 0.1107 (0.0631)	MaskBCELoss 0.0108 (0.0149)	MaskDICELoss 0.0999 (0.0482)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 307 is less than current step: 499. Dropping entry: {'train/loss': 0.276391320489347, 'train/ce_loss': 0.05059814453125, 'train/seg_cls_loss': 0.0008022308349609375, 'train/kl_loss': 0.00285797119140625, 'train/mask_bce_loss': 0.014888603379949928, 'train/mask_dice_loss': 0.048174522910267116, 'train/mask_loss': 0.06306312680244446, 'metrics/total_secs_per_batch': 48.54074263572693, 'metrics/data_secs_per_batch': 20.716438460350037, '_timestamp': 1741704885.5558128}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 307 is less than current step: 499. Dropping entry: {'train/lr': 0.0002905421686746988, '_timestamp': 1741704885.5568311}).
Epoch: [1][309/500]	Time 48.314 (48.314)	Loss 0.4614 (0.4197)	CeLoss 0.0461 (0.0404)	SegCLSLoss 0.0031 (0.0020)	KLLoss 0.0034 (0.0039)	MaskLoss 0.1133 (0.1082)	MaskBCELoss 0.0214 (0.0293)	MaskDICELoss 0.0919 (0.0790)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 308 is less than current step: 499. Dropping entry: {'train/loss': 0.4196668118238449, 'train/ce_loss': 0.04036865234375, 'train/seg_cls_loss': 0.001967620849609375, 'train/kl_loss': 0.003850555419921875, 'train/mask_bce_loss': 0.029253720794804393, 'train/mask_dice_loss': 0.07897148244082927, 'train/mask_loss': 0.10822520218789577, 'metrics/total_secs_per_batch': 48.314032316207886, 'metrics/data_secs_per_batch': 21.752764892578124, '_timestamp': 1741704933.8695762}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 308 is less than current step: 499. Dropping entry: {'train/lr': 0.0002905301204819277, '_timestamp': 1741704933.8704717}).
Epoch: [1][310/500]	Time 51.715 (51.715)	Loss 0.4777 (0.4096)	CeLoss 0.0320 (0.0521)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0029 (0.0032)	MaskLoss 0.1218 (0.0998)	MaskBCELoss 0.0225 (0.0227)	MaskDICELoss 0.0993 (0.0771)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 309 is less than current step: 499. Dropping entry: {'train/loss': 0.40963641107082366, 'train/ce_loss': 0.05211181640625, 'train/seg_cls_loss': 0.0010990142822265626, 'train/kl_loss': 0.003246307373046875, 'train/mask_bce_loss': 0.02267902148887515, 'train/mask_dice_loss': 0.07709009908139705, 'train/mask_loss': 0.09976911880075931, 'metrics/total_secs_per_batch': 51.714797496795654, 'metrics/data_secs_per_batch': 22.64966776371002, '_timestamp': 1741704985.5832734}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 309 is less than current step: 499. Dropping entry: {'train/lr': 0.00029050602409638553, '_timestamp': 1741704985.58351}).
Epoch: [1][311/500]	Time 48.791 (48.791)	Loss 0.4819 (0.3325)	CeLoss 0.0256 (0.0455)	SegCLSLoss 0.0003 (0.0015)	KLLoss 0.0078 (0.0031)	MaskLoss 0.1373 (0.0855)	MaskBCELoss 0.0505 (0.0294)	MaskDICELoss 0.0869 (0.0561)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 310 is less than current step: 499. Dropping entry: {'train/loss': 0.33254039362072946, 'train/ce_loss': 0.045458984375, 'train/seg_cls_loss': 0.0015201568603515625, 'train/kl_loss': 0.00305633544921875, 'train/mask_bce_loss': 0.02937959018163383, 'train/mask_dice_loss': 0.056135731749236584, 'train/mask_loss': 0.085515321418643, 'metrics/total_secs_per_batch': 48.790923833847046, 'metrics/data_secs_per_batch': 20.50186653137207, '_timestamp': 1741705034.3742242}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 310 is less than current step: 499. Dropping entry: {'train/lr': 0.00029049397590361444, '_timestamp': 1741705034.3744996}).
Epoch: [1][312/500]	Time 47.470 (47.470)	Loss 0.0516 (0.2842)	CeLoss 0.0515 (0.0502)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0682)	MaskBCELoss 0.0000 (0.0211)	MaskDICELoss 0.0000 (0.0472)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 311 is less than current step: 499. Dropping entry: {'train/loss': 0.28424275275319816, 'train/ce_loss': 0.05015869140625, 'train/seg_cls_loss': 0.0010980606079101563, 'train/kl_loss': 0.00270538330078125, 'train/mask_bce_loss': 0.021081815753132106, 'train/mask_dice_loss': 0.04715308248996734, 'train/mask_loss': 0.0682348981499672, 'metrics/total_secs_per_batch': 47.47032928466797, 'metrics/data_secs_per_batch': 21.011579608917238, '_timestamp': 1741705081.8445582}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 311 is less than current step: 499. Dropping entry: {'train/lr': 0.00029048192771084335, '_timestamp': 1741705081.8448277}).
Epoch: [1][313/500]	Time 47.593 (47.593)	Loss 0.3655 (0.3791)	CeLoss 0.0669 (0.0344)	SegCLSLoss 0.0028 (0.0022)	KLLoss 0.0032 (0.0027)	MaskLoss 0.0896 (0.0987)	MaskBCELoss 0.0323 (0.0269)	MaskDICELoss 0.0574 (0.0718)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 312 is less than current step: 499. Dropping entry: {'train/loss': 0.37912122830748557, 'train/ce_loss': 0.0343505859375, 'train/seg_cls_loss': 0.002183341979980469, 'train/kl_loss': 0.00267333984375, 'train/mask_bce_loss': 0.026901005278341474, 'train/mask_dice_loss': 0.07180099636316299, 'train/mask_loss': 0.09870200157165528, 'metrics/total_secs_per_batch': 47.593356132507324, 'metrics/data_secs_per_batch': 21.37845721244812, '_timestamp': 1741705129.4381013}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 312 is less than current step: 499. Dropping entry: {'train/lr': 0.00029046987951807226, '_timestamp': 1741705129.438389}).
Epoch: [1][314/500]	Time 52.635 (52.635)	Loss 0.4320 (0.3132)	CeLoss 0.0203 (0.0475)	SegCLSLoss 0.0022 (0.0007)	KLLoss 0.0033 (0.0024)	MaskLoss 0.1296 (0.0731)	MaskBCELoss 0.0554 (0.0147)	MaskDICELoss 0.0741 (0.0584)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 313 is less than current step: 499. Dropping entry: {'train/loss': 0.31317788641899824, 'train/ce_loss': 0.0474609375, 'train/seg_cls_loss': 0.0007053375244140625, 'train/kl_loss': 0.002365875244140625, 'train/mask_bce_loss': 0.01466148007893935, 'train/mask_dice_loss': 0.05844908393919468, 'train/mask_loss': 0.07311056479811669, 'metrics/total_secs_per_batch': 52.63496541976929, 'metrics/data_secs_per_batch': 24.8132572889328, '_timestamp': 1741705182.0729063}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 313 is less than current step: 499. Dropping entry: {'train/lr': 0.0002904578313253012, '_timestamp': 1741705182.0731795}).
Epoch: [1][315/500]	Time 49.007 (49.007)	Loss 0.4411 (0.3525)	CeLoss 0.0342 (0.0515)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0029 (0.0027)	MaskLoss 0.1024 (0.0915)	MaskBCELoss 0.0031 (0.0341)	MaskDICELoss 0.0993 (0.0574)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 314 is less than current step: 499. Dropping entry: {'train/loss': 0.35252251513302324, 'train/ce_loss': 0.05150146484375, 'train/seg_cls_loss': 0.0010593414306640625, 'train/kl_loss': 0.00266876220703125, 'train/mask_bce_loss': 0.03413411912042648, 'train/mask_dice_loss': 0.0574063403531909, 'train/mask_loss': 0.09154046215116977, 'metrics/total_secs_per_batch': 49.00733828544617, 'metrics/data_secs_per_batch': 20.174093627929686, '_timestamp': 1741705231.0803866}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 314 is less than current step: 499. Dropping entry: {'train/lr': 0.0002904457831325301, '_timestamp': 1741705231.0806792}).
Epoch: [1][316/500]	Time 48.409 (48.409)	Loss 0.2098 (0.3585)	CeLoss 0.0508 (0.0401)	SegCLSLoss 0.0011 (0.0021)	KLLoss 0.0049 (0.0043)	MaskLoss 0.0460 (0.0914)	MaskBCELoss 0.0153 (0.0262)	MaskDICELoss 0.0307 (0.0652)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 315 is less than current step: 499. Dropping entry: {'train/loss': 0.35850192308425904, 'train/ce_loss': 0.040118408203125, 'train/seg_cls_loss': 0.00213623046875, 'train/kl_loss': 0.0043121337890625, 'train/mask_bce_loss': 0.026193525921553374, 'train/mask_dice_loss': 0.06515664681792259, 'train/mask_loss': 0.09135017320513725, 'metrics/total_secs_per_batch': 48.409343004226685, 'metrics/data_secs_per_batch': 22.33736057281494, '_timestamp': 1741705279.4897292}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 315 is less than current step: 499. Dropping entry: {'train/lr': 0.000290433734939759, '_timestamp': 1741705279.4900215}).
Epoch: [1][317/500]	Time 46.820 (46.820)	Loss 0.4064 (0.3429)	CeLoss 0.0232 (0.0314)	SegCLSLoss 0.0041 (0.0015)	KLLoss 0.0035 (0.0032)	MaskLoss 0.0973 (0.0881)	MaskBCELoss 0.0058 (0.0225)	MaskDICELoss 0.0915 (0.0656)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 316 is less than current step: 499. Dropping entry: {'train/loss': 0.342949865758419, 'train/ce_loss': 0.03135986328125, 'train/seg_cls_loss': 0.0014919281005859376, 'train/kl_loss': 0.00319671630859375, 'train/mask_bce_loss': 0.02250481112860143, 'train/mask_dice_loss': 0.06564472895115614, 'train/mask_loss': 0.0881495401263237, 'metrics/total_secs_per_batch': 46.820348262786865, 'metrics/data_secs_per_batch': 21.96001696586609, '_timestamp': 1741705326.3099384}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 316 is less than current step: 499. Dropping entry: {'train/lr': 0.0002904216867469879, '_timestamp': 1741705326.3102064}).
Epoch: [1][318/500]	Time 50.331 (50.331)	Loss 0.6131 (0.3778)	CeLoss 0.0237 (0.0390)	SegCLSLoss 0.0037 (0.0013)	KLLoss 0.0030 (0.0026)	MaskLoss 0.1943 (0.0927)	MaskBCELoss 0.0963 (0.0176)	MaskDICELoss 0.0981 (0.0751)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 317 is less than current step: 499. Dropping entry: {'train/loss': 0.3777528066188097, 'train/ce_loss': 0.03902587890625, 'train/seg_cls_loss': 0.001346588134765625, 'train/kl_loss': 0.00257568359375, 'train/mask_bce_loss': 0.017559218185488133, 'train/mask_dice_loss': 0.07510683489963413, 'train/mask_loss': 0.09266605284065008, 'metrics/total_secs_per_batch': 50.33148908615112, 'metrics/data_secs_per_batch': 23.79113459587097, '_timestamp': 1741705376.641442}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 317 is less than current step: 499. Dropping entry: {'train/lr': 0.0002904096385542168, '_timestamp': 1741705376.6417184}).
Epoch: [1][319/500]	Time 44.240 (44.240)	Loss 0.3889 (0.3936)	CeLoss 0.0723 (0.0464)	SegCLSLoss 0.0037 (0.0019)	KLLoss 0.0026 (0.0036)	MaskLoss 0.1017 (0.0957)	MaskBCELoss 0.0474 (0.0200)	MaskDICELoss 0.0543 (0.0757)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 318 is less than current step: 499. Dropping entry: {'train/loss': 0.3935850754380226, 'train/ce_loss': 0.04637451171875, 'train/seg_cls_loss': 0.0018819808959960938, 'train/kl_loss': 0.00362548828125, 'train/mask_bce_loss': 0.019960081670433283, 'train/mask_dice_loss': 0.07569650001823902, 'train/mask_loss': 0.09565658099018037, 'metrics/total_secs_per_batch': 44.240217447280884, 'metrics/data_secs_per_batch': 20.982834219932556, '_timestamp': 1741705420.881644}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 318 is less than current step: 499. Dropping entry: {'train/lr': 0.00029039759036144573, '_timestamp': 1741705420.881913}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 319 is less than current step: 499. Dropping entry: {'train/loss': 0.4158469095826149, 'train/ce_loss': 0.0515869140625, 'train/seg_cls_loss': 0.001369476318359375, 'train/kl_loss': 0.0032073974609375, 'train/mask_bce_loss': 0.03085543812485412, 'train/mask_dice_loss': 0.07466437793336808, 'train/mask_loss': 0.10551981572061778, 'metrics/total_secs_per_batch': 43.10316491127014, 'metrics/data_secs_per_batch': 17.42975287437439, '_timestamp': 1741705463.9847925}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 319 is less than current step: 499. Dropping entry: {'train/lr': 0.0002903734939759036, '_timestamp': 1741705463.9850292}).
Epoch: [1][320/500]	Time 43.103 (43.103)	Loss 0.5064 (0.4158)	CeLoss 0.0251 (0.0516)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0024 (0.0032)	MaskLoss 0.1457 (0.1055)	MaskBCELoss 0.0522 (0.0309)	MaskDICELoss 0.0935 (0.0747)
Epoch: [1][321/500]	Time 47.889 (47.889)	Loss 0.4318 (0.3682)	CeLoss 0.0210 (0.0246)	SegCLSLoss 0.0013 (0.0016)	KLLoss 0.0037 (0.0029)	MaskLoss 0.1032 (0.0924)	MaskBCELoss 0.0032 (0.0148)	MaskDICELoss 0.1000 (0.0776)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 320 is less than current step: 499. Dropping entry: {'train/loss': 0.3681536132469773, 'train/ce_loss': 0.0246337890625, 'train/seg_cls_loss': 0.001628875732421875, 'train/kl_loss': 0.002874755859375, 'train/mask_bce_loss': 0.014824927982408554, 'train/mask_dice_loss': 0.0775531843304634, 'train/mask_loss': 0.09237811341881752, 'metrics/total_secs_per_batch': 47.88851571083069, 'metrics/data_secs_per_batch': 20.62589564323425, '_timestamp': 1741705511.873341}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 320 is less than current step: 499. Dropping entry: {'train/lr': 0.0002903614457831325, '_timestamp': 1741705511.873612}).
Epoch: [1][322/500]	Time 52.291 (52.291)	Loss 0.4662 (0.3833)	CeLoss 0.0474 (0.0347)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0024 (0.0034)	MaskLoss 0.1081 (0.1085)	MaskBCELoss 0.0081 (0.0447)	MaskDICELoss 0.1000 (0.0638)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 321 is less than current step: 499. Dropping entry: {'train/loss': 0.38328728564083575, 'train/ce_loss': 0.03465576171875, 'train/seg_cls_loss': 0.0010240554809570312, 'train/kl_loss': 0.0034393310546875, 'train/mask_bce_loss': 0.04466006625443697, 'train/mask_dice_loss': 0.06383358342573046, 'train/mask_loss': 0.10849365126341581, 'metrics/total_secs_per_batch': 52.29096436500549, 'metrics/data_secs_per_batch': 22.769567680358886, '_timestamp': 1741705564.165652}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 321 is less than current step: 499. Dropping entry: {'train/lr': 0.0002903493975903614, '_timestamp': 1741705564.1666424}).
Epoch: [1][323/500]	Time 52.706 (52.706)	Loss 0.0516 (0.2966)	CeLoss 0.0515 (0.0497)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0732)	MaskBCELoss 0.0000 (0.0249)	MaskDICELoss 0.0000 (0.0483)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 322 is less than current step: 499. Dropping entry: {'train/loss': 0.29655641280114653, 'train/ce_loss': 0.04970703125, 'train/seg_cls_loss': 0.0010473251342773438, 'train/kl_loss': 0.00321807861328125, 'train/mask_bce_loss': 0.024942336743697523, 'train/mask_dice_loss': 0.04830367635004222, 'train/mask_loss': 0.07324601383879781, 'metrics/total_secs_per_batch': 52.705740451812744, 'metrics/data_secs_per_batch': 23.436023449897768, '_timestamp': 1741705616.8711002}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 322 is less than current step: 499. Dropping entry: {'train/lr': 0.00029033734939759034, '_timestamp': 1741705616.8720045}).
Epoch: [1][324/500]	Time 42.109 (42.109)	Loss 0.4036 (0.4100)	CeLoss 0.0884 (0.0517)	SegCLSLoss 0.0025 (0.0016)	KLLoss 0.0028 (0.0027)	MaskLoss 0.1130 (0.1127)	MaskBCELoss 0.0702 (0.0481)	MaskDICELoss 0.0427 (0.0646)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 323 is less than current step: 499. Dropping entry: {'train/loss': 0.40999988913536073, 'train/ce_loss': 0.05166015625, 'train/seg_cls_loss': 0.0016155242919921875, 'train/kl_loss': 0.002738189697265625, 'train/mask_bce_loss': 0.04811901287175715, 'train/mask_dice_loss': 0.06462210454046727, 'train/mask_loss': 0.11274111792445182, 'metrics/total_secs_per_batch': 42.10937213897705, 'metrics/data_secs_per_batch': 18.7256596326828, '_timestamp': 1741705658.980638}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 323 is less than current step: 499. Dropping entry: {'train/lr': 0.00029032530120481925, '_timestamp': 1741705658.9816306}).
Epoch: [1][325/500]	Time 45.777 (45.777)	Loss 0.4314 (0.4025)	CeLoss 0.0240 (0.0480)	SegCLSLoss 0.0006 (0.0022)	KLLoss 0.0023 (0.0033)	MaskLoss 0.1027 (0.0976)	MaskBCELoss 0.0031 (0.0201)	MaskDICELoss 0.0996 (0.0775)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 324 is less than current step: 499. Dropping entry: {'train/loss': 0.40252414643764495, 'train/ce_loss': 0.04801025390625, 'train/seg_cls_loss': 0.0021991729736328125, 'train/kl_loss': 0.003265380859375, 'train/mask_bce_loss': 0.020075116609223186, 'train/mask_dice_loss': 0.07748801019042731, 'train/mask_loss': 0.09756312817335129, 'metrics/total_secs_per_batch': 45.777019739151, 'metrics/data_secs_per_batch': 20.159772062301634, '_timestamp': 1741705704.757467}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 324 is less than current step: 499. Dropping entry: {'train/lr': 0.00029031325301204816, '_timestamp': 1741705704.7584188}).
Epoch: [1][326/500]	Time 49.307 (49.307)	Loss 0.4312 (0.3794)	CeLoss 0.0476 (0.0580)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0045 (0.0033)	MaskLoss 0.1006 (0.0920)	MaskBCELoss 0.0118 (0.0253)	MaskDICELoss 0.0888 (0.0667)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 325 is less than current step: 499. Dropping entry: {'train/loss': 0.3794152125716209, 'train/ce_loss': 0.057958984375, 'train/seg_cls_loss': 0.0016826629638671876, 'train/kl_loss': 0.0032867431640625, 'train/mask_bce_loss': 0.02533006409648806, 'train/mask_dice_loss': 0.066666309395805, 'train/mask_loss': 0.09199637272395193, 'metrics/total_secs_per_batch': 49.307459592819214, 'metrics/data_secs_per_batch': 21.26636004447937, '_timestamp': 1741705754.0641582}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 325 is less than current step: 499. Dropping entry: {'train/lr': 0.00029030120481927707, '_timestamp': 1741705754.064617}).
Epoch: [1][327/500]	Time 48.183 (48.183)	Loss 0.4650 (0.3187)	CeLoss 0.0240 (0.0249)	SegCLSLoss 0.0027 (0.0026)	KLLoss 0.0024 (0.0045)	MaskLoss 0.1202 (0.0834)	MaskBCELoss 0.0219 (0.0228)	MaskDICELoss 0.0984 (0.0606)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 326 is less than current step: 499. Dropping entry: {'train/loss': 0.3186801694333553, 'train/ce_loss': 0.024920654296875, 'train/seg_cls_loss': 0.0025920867919921875, 'train/kl_loss': 0.0045166015625, 'train/mask_bce_loss': 0.0227883405983448, 'train/mask_dice_loss': 0.06059276536107063, 'train/mask_loss': 0.0833811054006219, 'metrics/total_secs_per_batch': 48.182671546936035, 'metrics/data_secs_per_batch': 21.55415141582489, '_timestamp': 1741705802.2471216}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 326 is less than current step: 499. Dropping entry: {'train/lr': 0.000290289156626506, '_timestamp': 1741705802.2476618}).
Epoch: [1][328/500]	Time 44.716 (44.716)	Loss 0.5266 (0.4561)	CeLoss 0.0232 (0.0443)	SegCLSLoss 0.0022 (0.0022)	KLLoss 0.0053 (0.0036)	MaskLoss 0.1510 (0.1190)	MaskBCELoss 0.0535 (0.0345)	MaskDICELoss 0.0975 (0.0845)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 327 is less than current step: 499. Dropping entry: {'train/loss': 0.4560771256685257, 'train/ce_loss': 0.04434814453125, 'train/seg_cls_loss': 0.0021938323974609376, 'train/kl_loss': 0.0035919189453125, 'train/mask_bce_loss': 0.034476367151364685, 'train/mask_dice_loss': 0.0845105905085802, 'train/mask_loss': 0.1189869575202465, 'metrics/total_secs_per_batch': 44.7158784866333, 'metrics/data_secs_per_batch': 20.11611602306366, '_timestamp': 1741705846.9637403}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 327 is less than current step: 499. Dropping entry: {'train/lr': 0.0002902771084337349, '_timestamp': 1741705846.964444}).
Epoch: [1][329/500]	Time 51.392 (51.392)	Loss 0.4029 (0.4033)	CeLoss 0.0415 (0.0521)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0028 (0.0044)	MaskLoss 0.1166 (0.0954)	MaskBCELoss 0.0540 (0.0177)	MaskDICELoss 0.0626 (0.0777)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 328 is less than current step: 499. Dropping entry: {'train/loss': 0.4033214509487152, 'train/ce_loss': 0.05211181640625, 'train/seg_cls_loss': 0.00118255615234375, 'train/kl_loss': 0.00435943603515625, 'train/mask_bce_loss': 0.0176863543340005, 'train/mask_dice_loss': 0.07772449161857367, 'train/mask_loss': 0.09541084766387939, 'metrics/total_secs_per_batch': 51.39235973358154, 'metrics/data_secs_per_batch': 23.425027537345887, '_timestamp': 1741705898.3550355}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 328 is less than current step: 499. Dropping entry: {'train/lr': 0.00029026506024096386, '_timestamp': 1741705898.3553452}).
Epoch: [1][330/500]	Time 49.759 (49.759)	Loss 0.4345 (0.3666)	CeLoss 0.0168 (0.0378)	SegCLSLoss 0.0008 (0.0009)	KLLoss 0.0031 (0.0030)	MaskLoss 0.1071 (0.0952)	MaskBCELoss 0.0071 (0.0277)	MaskDICELoss 0.1000 (0.0675)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 329 is less than current step: 499. Dropping entry: {'train/loss': 0.36659400165081024, 'train/ce_loss': 0.03782958984375, 'train/seg_cls_loss': 0.000923919677734375, 'train/kl_loss': 0.00302276611328125, 'train/mask_bce_loss': 0.027744055399671196, 'train/mask_dice_loss': 0.0674615316092968, 'train/mask_loss': 0.09520558565855027, 'metrics/total_secs_per_batch': 49.75864791870117, 'metrics/data_secs_per_batch': 23.705678081512453, '_timestamp': 1741705948.113576}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 329 is less than current step: 499. Dropping entry: {'train/lr': 0.0002902409638554217, '_timestamp': 1741705948.1138139}).
Epoch: [1][331/500]	Time 51.585 (51.585)	Loss 0.5839 (0.4041)	CeLoss 0.0752 (0.0533)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0037 (0.0030)	MaskLoss 0.1525 (0.1004)	MaskBCELoss 0.0526 (0.0272)	MaskDICELoss 0.1000 (0.0733)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 330 is less than current step: 499. Dropping entry: {'train/loss': 0.40405317954719067, 'train/ce_loss': 0.0533203125, 'train/seg_cls_loss': 0.0006931304931640625, 'train/kl_loss': 0.0029571533203125, 'train/mask_bce_loss': 0.027152233850210906, 'train/mask_dice_loss': 0.07328190151602029, 'train/mask_loss': 0.10043413676321507, 'metrics/total_secs_per_batch': 51.58459949493408, 'metrics/data_secs_per_batch': 22.44988670349121, '_timestamp': 1741705999.6983502}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 330 is less than current step: 499. Dropping entry: {'train/lr': 0.0002902289156626506, '_timestamp': 1741705999.6987975}).
Epoch: [1][332/500]	Time 49.989 (49.989)	Loss 0.5102 (0.3308)	CeLoss 0.0488 (0.0454)	SegCLSLoss 0.0005 (0.0019)	KLLoss 0.0049 (0.0027)	MaskLoss 0.1289 (0.0776)	MaskBCELoss 0.0296 (0.0142)	MaskDICELoss 0.0993 (0.0634)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 331 is less than current step: 499. Dropping entry: {'train/loss': 0.3308369530364871, 'train/ce_loss': 0.04539794921875, 'train/seg_cls_loss': 0.001891326904296875, 'train/kl_loss': 0.00267333984375, 'train/mask_bce_loss': 0.014202461531385779, 'train/mask_dice_loss': 0.06337167862802744, 'train/mask_loss': 0.07757413890212775, 'metrics/total_secs_per_batch': 49.98872923851013, 'metrics/data_secs_per_batch': 21.50929672718048, '_timestamp': 1741706049.687812}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 331 is less than current step: 499. Dropping entry: {'train/lr': 0.0002902168674698795, '_timestamp': 1741706049.6885495}).
Epoch: [1][333/500]	Time 44.840 (44.840)	Loss 0.0924 (0.3136)	CeLoss 0.0410 (0.0536)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0039 (0.0029)	MaskLoss 0.0122 (0.0783)	MaskBCELoss 0.0007 (0.0282)	MaskDICELoss 0.0115 (0.0501)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 332 is less than current step: 499. Dropping entry: {'train/loss': 0.313594888150692, 'train/ce_loss': 0.053564453125, 'train/seg_cls_loss': 0.0007547378540039062, 'train/kl_loss': 0.002925872802734375, 'train/mask_bce_loss': 0.028224227973259984, 'train/mask_dice_loss': 0.05009715370833874, 'train/mask_loss': 0.07832138119265437, 'metrics/total_secs_per_batch': 44.83985185623169, 'metrics/data_secs_per_batch': 19.794905829429627, '_timestamp': 1741706094.52711}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 332 is less than current step: 499. Dropping entry: {'train/lr': 0.0002902048192771084, '_timestamp': 1741706094.5276122}).
Epoch: [1][334/500]	Time 45.295 (45.295)	Loss 0.0420 (0.3162)	CeLoss 0.0420 (0.0410)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0776)	MaskBCELoss 0.0000 (0.0190)	MaskDICELoss 0.0000 (0.0586)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 333 is less than current step: 499. Dropping entry: {'train/loss': 0.3161730244755745, 'train/ce_loss': 0.04097900390625, 'train/seg_cls_loss': 0.000788116455078125, 'train/kl_loss': 0.00237884521484375, 'train/mask_bce_loss': 0.01897660115500912, 'train/mask_dice_loss': 0.058617453277111056, 'train/mask_loss': 0.07759405430406333, 'metrics/total_secs_per_batch': 45.29464602470398, 'metrics/data_secs_per_batch': 20.73028697967529, '_timestamp': 1741706139.8221016}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 333 is less than current step: 499. Dropping entry: {'train/lr': 0.0002901927710843373, '_timestamp': 1741706139.822741}).
Epoch: [1][335/500]	Time 47.563 (47.563)	Loss 0.4656 (0.3306)	CeLoss 0.0752 (0.0475)	SegCLSLoss 0.0020 (0.0017)	KLLoss 0.0034 (0.0033)	MaskLoss 0.1032 (0.0777)	MaskBCELoss 0.0134 (0.0160)	MaskDICELoss 0.0898 (0.0617)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 334 is less than current step: 499. Dropping entry: {'train/loss': 0.3306251855567098, 'train/ce_loss': 0.047509765625, 'train/seg_cls_loss': 0.001702880859375, 'train/kl_loss': 0.00334320068359375, 'train/mask_bce_loss': 0.015954754722770303, 'train/mask_dice_loss': 0.06173702511005104, 'train/mask_loss': 0.07769177807494998, 'metrics/total_secs_per_batch': 47.562938928604126, 'metrics/data_secs_per_batch': 20.06159873008728, '_timestamp': 1741706187.3845413}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 334 is less than current step: 499. Dropping entry: {'train/lr': 0.00029018072289156623, '_timestamp': 1741706187.3848467}).
Epoch: [1][336/500]	Time 45.104 (45.104)	Loss 0.1786 (0.4271)	CeLoss 0.0237 (0.0492)	SegCLSLoss 0.0014 (0.0015)	KLLoss 0.0036 (0.0031)	MaskLoss 0.0387 (0.1031)	MaskBCELoss 0.0022 (0.0192)	MaskDICELoss 0.0366 (0.0839)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 335 is less than current step: 499. Dropping entry: {'train/loss': 0.42709706723690033, 'train/ce_loss': 0.049169921875, 'train/seg_cls_loss': 0.0014951705932617187, 'train/kl_loss': 0.00309600830078125, 'train/mask_bce_loss': 0.019237030192743986, 'train/mask_dice_loss': 0.08389891423285008, 'train/mask_loss': 0.10313594415783882, 'metrics/total_secs_per_batch': 45.10424304008484, 'metrics/data_secs_per_batch': 20.992846894264222, '_timestamp': 1741706232.4886892}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 335 is less than current step: 499. Dropping entry: {'train/lr': 0.00029016867469879514, '_timestamp': 1741706232.4890957}).
Epoch: [1][337/500]	Time 47.761 (47.761)	Loss 0.3726 (0.3532)	CeLoss 0.0635 (0.0513)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0024 (0.0028)	MaskLoss 0.0813 (0.0855)	MaskBCELoss 0.0093 (0.0217)	MaskDICELoss 0.0720 (0.0638)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 336 is less than current step: 499. Dropping entry: {'train/loss': 0.35320048853755, 'train/ce_loss': 0.0513427734375, 'train/seg_cls_loss': 0.0010223388671875, 'train/kl_loss': 0.002819061279296875, 'train/mask_bce_loss': 0.02168521728599444, 'train/mask_dice_loss': 0.06377587400493212, 'train/mask_loss': 0.08546109230956063, 'metrics/total_secs_per_batch': 47.76136636734009, 'metrics/data_secs_per_batch': 21.772175884246828, '_timestamp': 1741706280.250044}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 336 is less than current step: 499. Dropping entry: {'train/lr': 0.00029015662650602405, '_timestamp': 1741706280.2503164}).
Epoch: [1][338/500]	Time 47.606 (47.606)	Loss 0.4546 (0.4161)	CeLoss 0.0206 (0.0547)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0034 (0.0032)	MaskLoss 0.1151 (0.0956)	MaskBCELoss 0.0151 (0.0124)	MaskDICELoss 0.1000 (0.0832)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 337 is less than current step: 499. Dropping entry: {'train/loss': 0.41609962061047556, 'train/ce_loss': 0.05469970703125, 'train/seg_cls_loss': 0.00133514404296875, 'train/kl_loss': 0.003154754638671875, 'train/mask_bce_loss': 0.012424008804373443, 'train/mask_dice_loss': 0.08317910903133452, 'train/mask_loss': 0.09560311799868941, 'metrics/total_secs_per_batch': 47.60566449165344, 'metrics/data_secs_per_batch': 21.527493357658386, '_timestamp': 1741706327.8556924}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 337 is less than current step: 499. Dropping entry: {'train/lr': 0.00029014457831325296, '_timestamp': 1741706327.8560884}).
Epoch: [1][339/500]	Time 41.768 (41.768)	Loss 0.3661 (0.3865)	CeLoss 0.0413 (0.0611)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0032 (0.0029)	MaskLoss 0.0868 (0.0964)	MaskBCELoss 0.0129 (0.0318)	MaskDICELoss 0.0739 (0.0646)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 338 is less than current step: 499. Dropping entry: {'train/loss': 0.3864507630467415, 'train/ce_loss': 0.0611328125, 'train/seg_cls_loss': 0.0007913589477539062, 'train/kl_loss': 0.00287933349609375, 'train/mask_bce_loss': 0.03181437910534442, 'train/mask_dice_loss': 0.06462883912026882, 'train/mask_loss': 0.09644321743398905, 'metrics/total_secs_per_batch': 41.76838660240173, 'metrics/data_secs_per_batch': 17.273507022857665, '_timestamp': 1741706369.6241195}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 338 is less than current step: 499. Dropping entry: {'train/lr': 0.0002901325301204819, '_timestamp': 1741706369.6245298}).
Epoch: [1][340/500]	Time 47.370 (47.370)	Loss 0.0622 (0.3984)	CeLoss 0.0435 (0.0452)	SegCLSLoss 0.0005 (0.0024)	KLLoss 0.0056 (0.0041)	MaskLoss 0.0051 (0.0985)	MaskBCELoss 0.0037 (0.0231)	MaskDICELoss 0.0014 (0.0754)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 339 is less than current step: 499. Dropping entry: {'train/loss': 0.3983829338103533, 'train/ce_loss': 0.04517822265625, 'train/seg_cls_loss': 0.002384376525878906, 'train/kl_loss': 0.0041107177734375, 'train/mask_bce_loss': 0.023121952824294568, 'train/mask_dice_loss': 0.07542000971734523, 'train/mask_loss': 0.09854196361266077, 'metrics/total_secs_per_batch': 47.37047219276428, 'metrics/data_secs_per_batch': 22.43202669620514, '_timestamp': 1741706416.9945743}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 339 is less than current step: 499. Dropping entry: {'train/lr': 0.00029010843373493975, '_timestamp': 1741706416.9949546}).
Epoch: [1][341/500]	Time 49.215 (49.215)	Loss 0.0421 (0.4063)	CeLoss 0.0190 (0.0438)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0052 (0.0034)	MaskLoss 0.0064 (0.1068)	MaskBCELoss 0.0042 (0.0344)	MaskDICELoss 0.0022 (0.0724)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 340 is less than current step: 499. Dropping entry: {'train/loss': 0.40630822721868753, 'train/ce_loss': 0.04378662109375, 'train/seg_cls_loss': 0.0013607025146484375, 'train/kl_loss': 0.00338897705078125, 'train/mask_bce_loss': 0.034367872966686266, 'train/mask_dice_loss': 0.07243511171545833, 'train/mask_loss': 0.10680298428051174, 'metrics/total_secs_per_batch': 49.21545672416687, 'metrics/data_secs_per_batch': 23.035932779312134, '_timestamp': 1741706466.2101183}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 340 is less than current step: 499. Dropping entry: {'train/lr': 0.00029009638554216866, '_timestamp': 1741706466.2105486}).
Epoch: [1][342/500]	Time 52.070 (52.070)	Loss 0.3633 (0.3567)	CeLoss 0.0266 (0.0390)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0033 (0.0037)	MaskLoss 0.0919 (0.0880)	MaskBCELoss 0.0176 (0.0194)	MaskDICELoss 0.0743 (0.0686)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 341 is less than current step: 499. Dropping entry: {'train/loss': 0.35668923109769823, 'train/ce_loss': 0.03902587890625, 'train/seg_cls_loss': 0.0013963699340820313, 'train/kl_loss': 0.00365447998046875, 'train/mask_bce_loss': 0.01944662055466324, 'train/mask_dice_loss': 0.06858962327241898, 'train/mask_loss': 0.08803624287247658, 'metrics/total_secs_per_batch': 52.06952786445618, 'metrics/data_secs_per_batch': 23.340200996398927, '_timestamp': 1741706518.2796936}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 341 is less than current step: 499. Dropping entry: {'train/lr': 0.00029008433734939757, '_timestamp': 1741706518.2799876}).
Epoch: [1][343/500]	Time 48.844 (48.844)	Loss 0.0387 (0.3897)	CeLoss 0.0386 (0.0472)	SegCLSLoss 0.0000 (0.0016)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.1028)	MaskBCELoss 0.0000 (0.0364)	MaskDICELoss 0.0000 (0.0665)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 342 is less than current step: 499. Dropping entry: {'train/loss': 0.3897401962429285, 'train/ce_loss': 0.04722900390625, 'train/seg_cls_loss': 0.0016193389892578125, 'train/kl_loss': 0.003173828125, 'train/mask_bce_loss': 0.03635002565570176, 'train/mask_dice_loss': 0.0664524171501398, 'train/mask_loss': 0.10280243903398514, 'metrics/total_secs_per_batch': 48.84366250038147, 'metrics/data_secs_per_batch': 21.2128066778183, '_timestamp': 1741706567.1233878}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 342 is less than current step: 499. Dropping entry: {'train/lr': 0.0002900722891566265, '_timestamp': 1741706567.1238737}).
Epoch: [1][344/500]	Time 47.786 (47.786)	Loss 0.4585 (0.4389)	CeLoss 0.0240 (0.0532)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0023 (0.0032)	MaskLoss 0.1157 (0.1039)	MaskBCELoss 0.0159 (0.0169)	MaskDICELoss 0.0999 (0.0870)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 343 is less than current step: 499. Dropping entry: {'train/loss': 0.4388977974653244, 'train/ce_loss': 0.05323486328125, 'train/seg_cls_loss': 0.001470947265625, 'train/kl_loss': 0.0031646728515625, 'train/mask_bce_loss': 0.016897895827423782, 'train/mask_dice_loss': 0.08698839135468006, 'train/mask_loss': 0.10388628542423248, 'metrics/total_secs_per_batch': 47.78613996505737, 'metrics/data_secs_per_batch': 23.806383991241454, '_timestamp': 1741706614.9100795}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 343 is less than current step: 499. Dropping entry: {'train/lr': 0.0002900602409638554, '_timestamp': 1741706614.9105263}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 344 is less than current step: 499. Dropping entry: {'train/loss': 0.3020518057048321, 'train/ce_loss': 0.04310302734375, 'train/seg_cls_loss': 0.0010829925537109374, 'train/kl_loss': 0.0024295806884765624, 'train/mask_bce_loss': 0.012840702512767166, 'train/mask_dice_loss': 0.057581369578838346, 'train/mask_loss': 0.0704220712184906, 'metrics/total_secs_per_batch': 50.495909214019775, 'metrics/data_secs_per_batch': 23.252315497398378, '_timestamp': 1741706665.4075565}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 344 is less than current step: 499. Dropping entry: {'train/lr': 0.0002900481927710843, '_timestamp': 1741706665.4089372}).
Epoch: [1][345/500]	Time 50.496 (50.496)	Loss 0.4333 (0.3021)	CeLoss 0.0242 (0.0431)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0041 (0.0024)	MaskLoss 0.1023 (0.0704)	MaskBCELoss 0.0026 (0.0128)	MaskDICELoss 0.0997 (0.0576)
Epoch: [1][346/500]	Time 52.464 (52.464)	Loss 0.0574 (0.2648)	CeLoss 0.0206 (0.0288)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0023 (0.0021)	MaskLoss 0.0100 (0.0648)	MaskBCELoss 0.0030 (0.0128)	MaskDICELoss 0.0070 (0.0520)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 345 is less than current step: 499. Dropping entry: {'train/loss': 0.2647683210670948, 'train/ce_loss': 0.02882080078125, 'train/seg_cls_loss': 0.000774383544921875, 'train/kl_loss': 0.0020751953125, 'train/mask_bce_loss': 0.01276173172518611, 'train/mask_dice_loss': 0.05199138792231679, 'train/mask_loss': 0.06475311908870936, 'metrics/total_secs_per_batch': 52.46381187438965, 'metrics/data_secs_per_batch': 22.803149771690368, '_timestamp': 1741706717.8692813}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 345 is less than current step: 499. Dropping entry: {'train/lr': 0.0002900361445783132, '_timestamp': 1741706717.8695874}).
Epoch: [1][347/500]	Time 47.043 (47.043)	Loss 0.4229 (0.3712)	CeLoss 0.0237 (0.0348)	SegCLSLoss 0.0012 (0.0021)	KLLoss 0.0038 (0.0037)	MaskLoss 0.1010 (0.0917)	MaskBCELoss 0.0046 (0.0177)	MaskDICELoss 0.0964 (0.0740)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 346 is less than current step: 499. Dropping entry: {'train/loss': 0.37117673456668854, 'train/ce_loss': 0.0347900390625, 'train/seg_cls_loss': 0.002142333984375, 'train/kl_loss': 0.00372161865234375, 'train/mask_bce_loss': 0.017704448592849076, 'train/mask_dice_loss': 0.07404449619352818, 'train/mask_loss': 0.09174894466996193, 'metrics/total_secs_per_batch': 47.04318380355835, 'metrics/data_secs_per_batch': 21.268220639228822, '_timestamp': 1741706764.9127777}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 346 is less than current step: 499. Dropping entry: {'train/lr': 0.0002900240963855421, '_timestamp': 1741706764.9133594}).
Epoch: [1][348/500]	Time 46.369 (46.369)	Loss 0.3958 (0.3473)	CeLoss 0.0579 (0.0448)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0034 (0.0040)	MaskLoss 0.0917 (0.0878)	MaskBCELoss 0.0166 (0.0267)	MaskDICELoss 0.0751 (0.0611)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 347 is less than current step: 499. Dropping entry: {'train/loss': 0.3472592536360025, 'train/ce_loss': 0.044793701171875, 'train/seg_cls_loss': 0.001445770263671875, 'train/kl_loss': 0.00397491455078125, 'train/mask_bce_loss': 0.026692807418294252, 'train/mask_dice_loss': 0.061085597751662134, 'train/mask_loss': 0.08777840402908624, 'metrics/total_secs_per_batch': 46.36932301521301, 'metrics/data_secs_per_batch': 20.72027716636658, '_timestamp': 1741706811.2821624}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 347 is less than current step: 499. Dropping entry: {'train/lr': 0.00029001204819277104, '_timestamp': 1741706811.282535}).
Epoch: [1][349/500]	Time 45.333 (45.333)	Loss 0.1501 (0.3431)	CeLoss 0.0645 (0.0461)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0037 (0.0031)	MaskLoss 0.0280 (0.0805)	MaskBCELoss 0.0153 (0.0144)	MaskDICELoss 0.0127 (0.0661)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 348 is less than current step: 499. Dropping entry: {'train/loss': 0.34311550818383696, 'train/ce_loss': 0.0460693359375, 'train/seg_cls_loss': 0.001155853271484375, 'train/kl_loss': 0.0031280517578125, 'train/mask_bce_loss': 0.014383293082937598, 'train/mask_dice_loss': 0.06613605786114932, 'train/mask_loss': 0.08051935015246273, 'metrics/total_secs_per_batch': 45.33253192901611, 'metrics/data_secs_per_batch': 20.28258364200592, '_timestamp': 1741706856.6144648}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 348 is less than current step: 499. Dropping entry: {'train/lr': 0.00029, '_timestamp': 1741706856.6148047}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 349 is less than current step: 499. Dropping entry: {'train/loss': 0.36714879870414735, 'train/ce_loss': 0.0379638671875, 'train/seg_cls_loss': 0.0013017654418945312, 'train/kl_loss': 0.002175140380859375, 'train/mask_bce_loss': 0.01728166940738447, 'train/mask_dice_loss': 0.07294128611683845, 'train/mask_loss': 0.09022295475006104, 'metrics/total_secs_per_batch': 48.804938554763794, 'metrics/data_secs_per_batch': 22.44478495121002, '_timestamp': 1741706905.4194796}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 349 is less than current step: 499. Dropping entry: {'train/lr': 0.0002899759036144578, '_timestamp': 1741706905.4197526}).
Epoch: [1][350/500]	Time 48.805 (48.805)	Loss 0.0273 (0.3671)	CeLoss 0.0273 (0.0380)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0022)	MaskLoss 0.0000 (0.0902)	MaskBCELoss 0.0000 (0.0173)	MaskDICELoss 0.0000 (0.0729)
Epoch: [1][351/500]	Time 52.368 (52.368)	Loss 0.5619 (0.4007)	CeLoss 0.0234 (0.0368)	SegCLSLoss 0.0046 (0.0017)	KLLoss 0.0031 (0.0032)	MaskLoss 0.1679 (0.1009)	MaskBCELoss 0.0694 (0.0220)	MaskDICELoss 0.0985 (0.0790)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 350 is less than current step: 499. Dropping entry: {'train/loss': 0.40073734652251003, 'train/ce_loss': 0.03677978515625, 'train/seg_cls_loss': 0.0016834259033203125, 'train/kl_loss': 0.00321502685546875, 'train/mask_bce_loss': 0.021950219431892036, 'train/mask_dice_loss': 0.0789992656558752, 'train/mask_loss': 0.10094948634505271, 'metrics/total_secs_per_batch': 52.3683123588562, 'metrics/data_secs_per_batch': 24.100345921516418, '_timestamp': 1741706957.78882}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 350 is less than current step: 499. Dropping entry: {'train/lr': 0.00028996385542168673, '_timestamp': 1741706957.7899518}).
Epoch: [1][352/500]	Time 47.858 (47.858)	Loss 0.0569 (0.2379)	CeLoss 0.0260 (0.0368)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0067 (0.0023)	MaskLoss 0.0083 (0.0546)	MaskBCELoss 0.0047 (0.0100)	MaskDICELoss 0.0036 (0.0446)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 351 is less than current step: 499. Dropping entry: {'train/loss': 0.23789357710629702, 'train/ce_loss': 0.03675537109375, 'train/seg_cls_loss': 0.0011569976806640625, 'train/kl_loss': 0.00228271484375, 'train/mask_bce_loss': 0.010006590513512492, 'train/mask_dice_loss': 0.044562874175608155, 'train/mask_loss': 0.054569464176893234, 'metrics/total_secs_per_batch': 47.857752323150635, 'metrics/data_secs_per_batch': 21.76651527881622, '_timestamp': 1741707005.6470072}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 351 is less than current step: 499. Dropping entry: {'train/lr': 0.00028995180722891564, '_timestamp': 1741707005.6482828}).
Epoch: [1][353/500]	Time 42.705 (42.705)	Loss 0.0714 (0.3565)	CeLoss 0.0432 (0.0480)	SegCLSLoss 0.0005 (0.0020)	KLLoss 0.0068 (0.0041)	MaskLoss 0.0081 (0.0857)	MaskBCELoss 0.0055 (0.0196)	MaskDICELoss 0.0026 (0.0661)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 352 is less than current step: 499. Dropping entry: {'train/loss': 0.356537177413702, 'train/ce_loss': 0.0479736328125, 'train/seg_cls_loss': 0.0019969940185546875, 'train/kl_loss': 0.004052734375, 'train/mask_bce_loss': 0.019603718002326787, 'train/mask_dice_loss': 0.06607559963595122, 'train/mask_loss': 0.08567931838333606, 'metrics/total_secs_per_batch': 42.70529079437256, 'metrics/data_secs_per_batch': 19.07359571456909, '_timestamp': 1741707048.3518825}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 352 is less than current step: 499. Dropping entry: {'train/lr': 0.00028993975903614456, '_timestamp': 1741707048.3526416}).
Epoch: [1][354/500]	Time 49.091 (49.091)	Loss 0.4956 (0.4535)	CeLoss 0.0718 (0.0518)	SegCLSLoss 0.0032 (0.0015)	KLLoss 0.0044 (0.0039)	MaskLoss 0.1416 (0.1076)	MaskBCELoss 0.0744 (0.0167)	MaskDICELoss 0.0673 (0.0909)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 353 is less than current step: 499. Dropping entry: {'train/loss': 0.45345623791217804, 'train/ce_loss': 0.05181884765625, 'train/seg_cls_loss': 0.001546478271484375, 'train/kl_loss': 0.00390777587890625, 'train/mask_bce_loss': 0.016745125176385045, 'train/mask_dice_loss': 0.09087040424346923, 'train/mask_loss': 0.10761552825570106, 'metrics/total_secs_per_batch': 49.09056115150452, 'metrics/data_secs_per_batch': 22.314922833442687, '_timestamp': 1741707097.441635}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 353 is less than current step: 499. Dropping entry: {'train/lr': 0.00028992771084337347, '_timestamp': 1741707097.4421122}).
Epoch: [1][355/500]	Time 50.475 (50.475)	Loss 0.4170 (0.2651)	CeLoss 0.0231 (0.0347)	SegCLSLoss 0.0026 (0.0014)	KLLoss 0.0034 (0.0033)	MaskLoss 0.1061 (0.0636)	MaskBCELoss 0.0177 (0.0140)	MaskDICELoss 0.0885 (0.0496)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 354 is less than current step: 499. Dropping entry: {'train/loss': 0.26507749743759634, 'train/ce_loss': 0.03465576171875, 'train/seg_cls_loss': 0.001406097412109375, 'train/kl_loss': 0.0032562255859375, 'train/mask_bce_loss': 0.01395540895173326, 'train/mask_dice_loss': 0.04962370176799595, 'train/mask_loss': 0.06357911005616187, 'metrics/total_secs_per_batch': 50.47466063499451, 'metrics/data_secs_per_batch': 22.303782057762145, '_timestamp': 1741707147.9161165}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 354 is less than current step: 499. Dropping entry: {'train/lr': 0.0002899156626506024, '_timestamp': 1741707147.9164317}).
Epoch: [1][356/500]	Time 44.017 (44.017)	Loss 0.3360 (0.3136)	CeLoss 0.0214 (0.0526)	SegCLSLoss 0.0026 (0.0013)	KLLoss 0.0026 (0.0030)	MaskLoss 0.0867 (0.0704)	MaskBCELoss 0.0180 (0.0122)	MaskDICELoss 0.0687 (0.0582)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 355 is less than current step: 499. Dropping entry: {'train/loss': 0.31361749209463596, 'train/ce_loss': 0.05260009765625, 'train/seg_cls_loss': 0.001305389404296875, 'train/kl_loss': 0.0030059814453125, 'train/mask_bce_loss': 0.012211813073372468, 'train/mask_dice_loss': 0.05821643667295575, 'train/mask_loss': 0.07042825128883123, 'metrics/total_secs_per_batch': 44.01694846153259, 'metrics/data_secs_per_batch': 20.24367756843567, '_timestamp': 1741707191.932849}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 355 is less than current step: 499. Dropping entry: {'train/lr': 0.0002899036144578313, '_timestamp': 1741707191.9333017}).
Epoch: [1][357/500]	Time 49.976 (49.976)	Loss 0.3997 (0.3826)	CeLoss 0.0236 (0.0432)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0029 (0.0029)	MaskLoss 0.0947 (0.0881)	MaskBCELoss 0.0032 (0.0082)	MaskDICELoss 0.0916 (0.0799)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 356 is less than current step: 499. Dropping entry: {'train/loss': 0.3826241664588451, 'train/ce_loss': 0.04315185546875, 'train/seg_cls_loss': 0.001293182373046875, 'train/kl_loss': 0.00285491943359375, 'train/mask_bce_loss': 0.008161868283059448, 'train/mask_dice_loss': 0.07992715947329998, 'train/mask_loss': 0.08808902651071548, 'metrics/total_secs_per_batch': 49.97560143470764, 'metrics/data_secs_per_batch': 22.741110801696777, '_timestamp': 1741707241.9089026}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 356 is less than current step: 499. Dropping entry: {'train/lr': 0.0002898915662650602, '_timestamp': 1741707241.9094813}).
Epoch: [1][358/500]	Time 50.089 (50.089)	Loss 0.3342 (0.3773)	CeLoss 0.0515 (0.0394)	SegCLSLoss 0.0016 (0.0022)	KLLoss 0.0018 (0.0030)	MaskLoss 0.0919 (0.0957)	MaskBCELoss 0.0439 (0.0246)	MaskDICELoss 0.0480 (0.0711)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 357 is less than current step: 499. Dropping entry: {'train/loss': 0.3773043915629387, 'train/ce_loss': 0.03944091796875, 'train/seg_cls_loss': 0.0022457122802734377, 'train/kl_loss': 0.0029998779296875, 'train/mask_bce_loss': 0.02463317707879469, 'train/mask_dice_loss': 0.07111595459282398, 'train/mask_loss': 0.09574913084506989, 'metrics/total_secs_per_batch': 50.08888483047485, 'metrics/data_secs_per_batch': 20.419014549255373, '_timestamp': 1741707291.9975898}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 357 is less than current step: 499. Dropping entry: {'train/lr': 0.0002898795180722891, '_timestamp': 1741707291.997935}).
Epoch: [1][359/500]	Time 50.974 (50.974)	Loss 0.4304 (0.3313)	CeLoss 0.0261 (0.0323)	SegCLSLoss 0.0021 (0.0016)	KLLoss 0.0036 (0.0037)	MaskLoss 0.1012 (0.0849)	MaskBCELoss 0.0025 (0.0226)	MaskDICELoss 0.0987 (0.0624)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 358 is less than current step: 499. Dropping entry: {'train/loss': 0.3313380438834429, 'train/ce_loss': 0.0322509765625, 'train/seg_cls_loss': 0.00158538818359375, 'train/kl_loss': 0.0037353515625, 'train/mask_bce_loss': 0.022557381819933654, 'train/mask_dice_loss': 0.062361484253779055, 'train/mask_loss': 0.08491886667907238, 'metrics/total_secs_per_batch': 50.97366809844971, 'metrics/data_secs_per_batch': 21.54967908859253, '_timestamp': 1741707342.9711733}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 358 is less than current step: 499. Dropping entry: {'train/lr': 0.000289867469879518, '_timestamp': 1741707342.9714887}).
Epoch: [1][360/500]	Time 48.134 (48.134)	Loss 0.2703 (0.3959)	CeLoss 0.0187 (0.0443)	SegCLSLoss 0.0012 (0.0017)	KLLoss 0.0042 (0.0029)	MaskLoss 0.0702 (0.0952)	MaskBCELoss 0.0169 (0.0166)	MaskDICELoss 0.0533 (0.0786)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 359 is less than current step: 499. Dropping entry: {'train/loss': 0.39587168395519257, 'train/ce_loss': 0.0443359375, 'train/seg_cls_loss': 0.0017429351806640624, 'train/kl_loss': 0.00292816162109375, 'train/mask_bce_loss': 0.016599624295486136, 'train/mask_dice_loss': 0.0786319762468338, 'train/mask_loss': 0.09523159973323345, 'metrics/total_secs_per_batch': 48.13407588005066, 'metrics/data_secs_per_batch': 22.112849473953247, '_timestamp': 1741707391.1060772}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 359 is less than current step: 499. Dropping entry: {'train/lr': 0.0002898433734939759, '_timestamp': 1741707391.1070251}).
Epoch: [1][361/500]	Time 46.007 (46.007)	Loss 0.0331 (0.3002)	CeLoss 0.0201 (0.0349)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0050 (0.0037)	MaskLoss 0.0028 (0.0691)	MaskBCELoss 0.0018 (0.0077)	MaskDICELoss 0.0010 (0.0615)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 360 is less than current step: 499. Dropping entry: {'train/loss': 0.3002490058541298, 'train/ce_loss': 0.03486328125, 'train/seg_cls_loss': 0.0010974884033203125, 'train/kl_loss': 0.00365142822265625, 'train/mask_bce_loss': 0.007654613727936521, 'train/mask_dice_loss': 0.06147420026827603, 'train/mask_loss': 0.06912881371099502, 'metrics/total_secs_per_batch': 46.00696802139282, 'metrics/data_secs_per_batch': 21.68877730369568, '_timestamp': 1741707437.113694}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 360 is less than current step: 499. Dropping entry: {'train/lr': 0.0002898313253012048, '_timestamp': 1741707437.1148348}).
Epoch: [1][362/500]	Time 42.260 (42.260)	Loss 0.4705 (0.3307)	CeLoss 0.0488 (0.0434)	SegCLSLoss 0.0028 (0.0015)	KLLoss 0.0028 (0.0033)	MaskLoss 0.1088 (0.0782)	MaskBCELoss 0.0089 (0.0147)	MaskDICELoss 0.0999 (0.0634)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 361 is less than current step: 499. Dropping entry: {'train/loss': 0.33066937513649464, 'train/ce_loss': 0.043408203125, 'train/seg_cls_loss': 0.0014911651611328124, 'train/kl_loss': 0.003336334228515625, 'train/mask_bce_loss': 0.014746609353460371, 'train/mask_dice_loss': 0.06342880597803742, 'train/mask_loss': 0.07817541519179941, 'metrics/total_secs_per_batch': 42.26010322570801, 'metrics/data_secs_per_batch': 20.090186047554017, '_timestamp': 1741707479.3741844}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 361 is less than current step: 499. Dropping entry: {'train/lr': 0.0002898192771084337, '_timestamp': 1741707479.3756301}).
Epoch: [1][363/500]	Time 53.172 (53.172)	Loss 0.4738 (0.3216)	CeLoss 0.0261 (0.0329)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0027 (0.0032)	MaskLoss 0.1271 (0.0781)	MaskBCELoss 0.0321 (0.0138)	MaskDICELoss 0.0950 (0.0643)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 362 is less than current step: 499. Dropping entry: {'train/loss': 0.32159543987363576, 'train/ce_loss': 0.03292236328125, 'train/seg_cls_loss': 0.00139617919921875, 'train/kl_loss': 0.003179931640625, 'train/mask_bce_loss': 0.013791980734094978, 'train/mask_dice_loss': 0.06428411975502968, 'train/mask_loss': 0.0780760996043682, 'metrics/total_secs_per_batch': 53.17220735549927, 'metrics/data_secs_per_batch': 25.480573463439942, '_timestamp': 1741707532.5445392}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 362 is less than current step: 499. Dropping entry: {'train/lr': 0.00028980722891566263, '_timestamp': 1741707532.5450664}).
Epoch: [1][364/500]	Time 45.457 (45.457)	Loss 0.4299 (0.4237)	CeLoss 0.0181 (0.0529)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0034 (0.0039)	MaskLoss 0.1038 (0.1055)	MaskBCELoss 0.0038 (0.0278)	MaskDICELoss 0.1000 (0.0777)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 363 is less than current step: 499. Dropping entry: {'train/loss': 0.4237450286746025, 'train/ce_loss': 0.05291748046875, 'train/seg_cls_loss': 0.0011089324951171875, 'train/kl_loss': 0.00389404296875, 'train/mask_bce_loss': 0.02782865894259885, 'train/mask_dice_loss': 0.07766157425940037, 'train/mask_loss': 0.10549023449420929, 'metrics/total_secs_per_batch': 45.45733428001404, 'metrics/data_secs_per_batch': 20.467075395584107, '_timestamp': 1741707578.001943}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 363 is less than current step: 499. Dropping entry: {'train/lr': 0.00028979518072289154, '_timestamp': 1741707578.0024788}).
Epoch: [1][365/500]	Time 52.884 (52.884)	Loss 0.3179 (0.3844)	CeLoss 0.0688 (0.0406)	SegCLSLoss 0.0009 (0.0020)	KLLoss 0.0042 (0.0042)	MaskLoss 0.0692 (0.0969)	MaskBCELoss 0.0161 (0.0245)	MaskDICELoss 0.0531 (0.0724)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 364 is less than current step: 499. Dropping entry: {'train/loss': 0.3843775700777769, 'train/ce_loss': 0.04058837890625, 'train/seg_cls_loss': 0.0020391464233398436, 'train/kl_loss': 0.0042327880859375, 'train/mask_bce_loss': 0.024488886108156294, 'train/mask_dice_loss': 0.07240219421219081, 'train/mask_loss': 0.09689107956364751, 'metrics/total_secs_per_batch': 52.88407230377197, 'metrics/data_secs_per_batch': 22.983930230140686, '_timestamp': 1741707630.8862796}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 364 is less than current step: 499. Dropping entry: {'train/lr': 0.00028978313253012045, '_timestamp': 1741707630.8866627}).
Epoch: [1][366/500]	Time 44.147 (44.147)	Loss 0.3050 (0.3933)	CeLoss 0.0552 (0.0456)	SegCLSLoss 0.0007 (0.0018)	KLLoss 0.0046 (0.0036)	MaskLoss 0.0755 (0.0984)	MaskBCELoss 0.0286 (0.0253)	MaskDICELoss 0.0469 (0.0732)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 365 is less than current step: 499. Dropping entry: {'train/loss': 0.39325663447380066, 'train/ce_loss': 0.0455810546875, 'train/seg_cls_loss': 0.0018474578857421875, 'train/kl_loss': 0.00359649658203125, 'train/mask_bce_loss': 0.025252073997398837, 'train/mask_dice_loss': 0.07315394170582294, 'train/mask_loss': 0.09840601533651352, 'metrics/total_secs_per_batch': 44.146705627441406, 'metrics/data_secs_per_batch': 19.738193893432616, '_timestamp': 1741707675.0325356}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 365 is less than current step: 499. Dropping entry: {'train/lr': 0.00028977108433734936, '_timestamp': 1741707675.032829}).
Epoch: [1][367/500]	Time 50.439 (50.439)	Loss 0.2483 (0.3838)	CeLoss 0.0776 (0.0477)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0039 (0.0032)	MaskLoss 0.0449 (0.0912)	MaskBCELoss 0.0066 (0.0163)	MaskDICELoss 0.0383 (0.0749)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 366 is less than current step: 499. Dropping entry: {'train/loss': 0.38381524980068205, 'train/ce_loss': 0.04766845703125, 'train/seg_cls_loss': 0.0012325286865234376, 'train/kl_loss': 0.003244781494140625, 'train/mask_bce_loss': 0.016327993106096984, 'train/mask_dice_loss': 0.07492116559296846, 'train/mask_loss': 0.09124915972352028, 'metrics/total_secs_per_batch': 50.4386785030365, 'metrics/data_secs_per_batch': 23.89099986553192, '_timestamp': 1741707725.4716897}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 366 is less than current step: 499. Dropping entry: {'train/lr': 0.00028975903614457827, '_timestamp': 1741707725.4723213}).
Epoch: [1][368/500]	Time 53.611 (53.611)	Loss 0.3868 (0.3596)	CeLoss 0.0195 (0.0379)	SegCLSLoss 0.0010 (0.0008)	KLLoss 0.0021 (0.0030)	MaskLoss 0.0960 (0.0873)	MaskBCELoss 0.0096 (0.0154)	MaskDICELoss 0.0864 (0.0719)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 367 is less than current step: 499. Dropping entry: {'train/loss': 0.3595897801220417, 'train/ce_loss': 0.037890625, 'train/seg_cls_loss': 0.0007829666137695312, 'train/kl_loss': 0.003009033203125, 'train/mask_bce_loss': 0.015423189417924732, 'train/mask_dice_loss': 0.0718709085136652, 'train/mask_loss': 0.08729409798979759, 'metrics/total_secs_per_batch': 53.61085224151611, 'metrics/data_secs_per_batch': 24.65555944442749, '_timestamp': 1741707779.0833547}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 367 is less than current step: 499. Dropping entry: {'train/lr': 0.0002897469879518072, '_timestamp': 1741707779.0844238}).
Epoch: [1][369/500]	Time 47.994 (47.994)	Loss 0.4346 (0.3474)	CeLoss 0.0214 (0.0361)	SegCLSLoss 0.0022 (0.0008)	KLLoss 0.0051 (0.0028)	MaskLoss 0.1051 (0.0886)	MaskBCELoss 0.0067 (0.0231)	MaskDICELoss 0.0984 (0.0655)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 368 is less than current step: 499. Dropping entry: {'train/loss': 0.34740756209939716, 'train/ce_loss': 0.03614501953125, 'train/seg_cls_loss': 0.000848388671875, 'train/kl_loss': 0.00275421142578125, 'train/mask_bce_loss': 0.023134630266577007, 'train/mask_dice_loss': 0.06545547395944595, 'train/mask_loss': 0.08859010115265846, 'metrics/total_secs_per_batch': 47.99366354942322, 'metrics/data_secs_per_batch': 21.70149450302124, '_timestamp': 1741707827.0770788}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 368 is less than current step: 499. Dropping entry: {'train/lr': 0.00028973493975903615, '_timestamp': 1741707827.0780919}).
Epoch: [1][370/500]	Time 50.791 (50.791)	Loss 0.5561 (0.3663)	CeLoss 0.0334 (0.0490)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0048 (0.0033)	MaskLoss 0.1636 (0.0884)	MaskBCELoss 0.0685 (0.0200)	MaskDICELoss 0.0952 (0.0684)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 369 is less than current step: 499. Dropping entry: {'train/loss': 0.36625456884503366, 'train/ce_loss': 0.049017333984375, 'train/seg_cls_loss': 0.000839996337890625, 'train/kl_loss': 0.00330810546875, 'train/mask_bce_loss': 0.02002297822618857, 'train/mask_dice_loss': 0.068397855758667, 'train/mask_loss': 0.0884208345785737, 'metrics/total_secs_per_batch': 50.791260957717896, 'metrics/data_secs_per_batch': 21.716503953933717, '_timestamp': 1741707877.8670812}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 369 is less than current step: 499. Dropping entry: {'train/lr': 0.00028971084337349397, '_timestamp': 1741707877.8673556}).
Epoch: [1][371/500]	Time 43.380 (43.380)	Loss 0.2151 (0.3833)	CeLoss 0.0635 (0.0518)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0063 (0.0036)	MaskLoss 0.0468 (0.0997)	MaskBCELoss 0.0211 (0.0357)	MaskDICELoss 0.0257 (0.0640)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 370 is less than current step: 499. Dropping entry: {'train/loss': 0.38334493450820445, 'train/ce_loss': 0.05179443359375, 'train/seg_cls_loss': 0.0010766983032226562, 'train/kl_loss': 0.0035858154296875, 'train/mask_bce_loss': 0.03569658059859648, 'train/mask_dice_loss': 0.06401821598410606, 'train/mask_loss': 0.09971479736268521, 'metrics/total_secs_per_batch': 43.379958152770996, 'metrics/data_secs_per_batch': 19.59711434841156, '_timestamp': 1741707921.2478807}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 370 is less than current step: 499. Dropping entry: {'train/lr': 0.0002896987951807229, '_timestamp': 1741707921.2488322}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 371 is less than current step: 499. Dropping entry: {'train/loss': 0.36996195986866953, 'train/ce_loss': 0.0524658203125, 'train/seg_cls_loss': 0.0016363143920898437, 'train/kl_loss': 0.003192138671875, 'train/mask_bce_loss': 0.025225159511319362, 'train/mask_dice_loss': 0.06575681485701353, 'train/mask_loss': 0.09098197412677109, 'metrics/total_secs_per_batch': 49.280301094055176, 'metrics/data_secs_per_batch': 22.348348903656007, '_timestamp': 1741707970.5277526}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 371 is less than current step: 499. Dropping entry: {'train/lr': 0.0002896867469879518, '_timestamp': 1741707970.5283756}).
Epoch: [1][372/500]	Time 49.280 (49.280)	Loss 0.3555 (0.3700)	CeLoss 0.0242 (0.0525)	SegCLSLoss 0.0039 (0.0016)	KLLoss 0.0028 (0.0032)	MaskLoss 0.0933 (0.0910)	MaskBCELoss 0.0232 (0.0252)	MaskDICELoss 0.0700 (0.0658)
Epoch: [1][373/500]	Time 49.410 (49.410)	Loss 0.5349 (0.3324)	CeLoss 0.0522 (0.0491)	SegCLSLoss 0.0003 (0.0016)	KLLoss 0.0081 (0.0040)	MaskLoss 0.1375 (0.0801)	MaskBCELoss 0.0378 (0.0210)	MaskDICELoss 0.0997 (0.0591)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 372 is less than current step: 499. Dropping entry: {'train/loss': 0.33237868659198283, 'train/ce_loss': 0.04913330078125, 'train/seg_cls_loss': 0.0015947341918945313, 'train/kl_loss': 0.0040130615234375, 'train/mask_bce_loss': 0.021012608800083397, 'train/mask_dice_loss': 0.05911668762564659, 'train/mask_loss': 0.08012929665856064, 'metrics/total_secs_per_batch': 49.41043949127197, 'metrics/data_secs_per_batch': 23.26687934398651, '_timestamp': 1741708019.9384477}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 372 is less than current step: 499. Dropping entry: {'train/lr': 0.0002896746987951807, '_timestamp': 1741708019.9391422}).
Epoch: [1][374/500]	Time 45.076 (45.076)	Loss 0.2764 (0.3771)	CeLoss 0.0610 (0.0414)	SegCLSLoss 0.0029 (0.0013)	KLLoss 0.0024 (0.0035)	MaskLoss 0.0575 (0.0974)	MaskBCELoss 0.0091 (0.0290)	MaskDICELoss 0.0483 (0.0684)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 373 is less than current step: 499. Dropping entry: {'train/loss': 0.3770523965358734, 'train/ce_loss': 0.04144287109375, 'train/seg_cls_loss': 0.0013427734375, 'train/kl_loss': 0.0034637451171875, 'train/mask_bce_loss': 0.02901283618994057, 'train/mask_dice_loss': 0.0683601975440979, 'train/mask_loss': 0.09737303461879492, 'metrics/total_secs_per_batch': 45.07560205459595, 'metrics/data_secs_per_batch': 20.133457088470458, '_timestamp': 1741708065.0137773}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 373 is less than current step: 499. Dropping entry: {'train/lr': 0.0002896626506024096, '_timestamp': 1741708065.0144384}).
Epoch: [1][375/500]	Time 49.792 (49.792)	Loss 0.4492 (0.3477)	CeLoss 0.0229 (0.0545)	SegCLSLoss 0.0025 (0.0014)	KLLoss 0.0033 (0.0028)	MaskLoss 0.1108 (0.0759)	MaskBCELoss 0.0108 (0.0069)	MaskDICELoss 0.1000 (0.0690)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 374 is less than current step: 499. Dropping entry: {'train/loss': 0.3476570833474398, 'train/ce_loss': 0.0544677734375, 'train/seg_cls_loss': 0.001352691650390625, 'train/kl_loss': 0.002825164794921875, 'train/mask_bce_loss': 0.006931153952609748, 'train/mask_dice_loss': 0.0689711538143456, 'train/mask_loss': 0.07590230666100979, 'metrics/total_secs_per_batch': 49.79150605201721, 'metrics/data_secs_per_batch': 23.0920259475708, '_timestamp': 1741708114.8050365}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 374 is less than current step: 499. Dropping entry: {'train/lr': 0.0002896506024096385, '_timestamp': 1741708114.8053677}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 375 is less than current step: 499. Dropping entry: {'train/loss': 0.33978310227394104, 'train/ce_loss': 0.037384033203125, 'train/seg_cls_loss': 0.0013483047485351562, 'train/kl_loss': 0.0036102294921875, 'train/mask_bce_loss': 0.025430493149906398, 'train/mask_dice_loss': 0.06181793079013005, 'train/mask_loss': 0.08724842295050621, 'metrics/total_secs_per_batch': 50.107452630996704, 'metrics/data_secs_per_batch': 23.89532904624939, '_timestamp': 1741708164.912519}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 375 is less than current step: 499. Dropping entry: {'train/lr': 0.00028963855421686743, '_timestamp': 1741708164.9128613}).
Epoch: [1][376/500]	Time 50.107 (50.107)	Loss 0.0954 (0.3398)	CeLoss 0.0791 (0.0374)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0046 (0.0036)	MaskLoss 0.0040 (0.0872)	MaskBCELoss 0.0023 (0.0254)	MaskDICELoss 0.0017 (0.0618)
Epoch: [1][377/500]	Time 51.212 (51.212)	Loss 0.5127 (0.3602)	CeLoss 0.1006 (0.0441)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0033 (0.0023)	MaskLoss 0.1107 (0.0815)	MaskBCELoss 0.0171 (0.0064)	MaskDICELoss 0.0937 (0.0751)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 376 is less than current step: 499. Dropping entry: {'train/loss': 0.360212860442698, 'train/ce_loss': 0.0441162109375, 'train/seg_cls_loss': 0.0011932373046875, 'train/kl_loss': 0.002288818359375, 'train/mask_bce_loss': 0.006359596364200115, 'train/mask_dice_loss': 0.07513757646083832, 'train/mask_loss': 0.08149717301130295, 'metrics/total_secs_per_batch': 51.21225166320801, 'metrics/data_secs_per_batch': 23.455083680152892, '_timestamp': 1741708216.1269798}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 376 is less than current step: 499. Dropping entry: {'train/lr': 0.00028962650602409634, '_timestamp': 1741708216.1285279}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 377 is less than current step: 499. Dropping entry: {'train/loss': 0.36004210598766806, 'train/ce_loss': 0.034381103515625, 'train/seg_cls_loss': 0.001618194580078125, 'train/kl_loss': 0.00317840576171875, 'train/mask_bce_loss': 0.027042070194147526, 'train/mask_dice_loss': 0.06688499897718429, 'train/mask_loss': 0.09392707124352455, 'metrics/total_secs_per_batch': 68.77186799049377, 'metrics/data_secs_per_batch': 26.239469122886657, '_timestamp': 1741708284.8966775}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 377 is less than current step: 499. Dropping entry: {'train/lr': 0.00028961445783132526, '_timestamp': 1741708284.8969834}).
Epoch: [1][378/500]	Time 68.772 (68.772)	Loss 0.4612 (0.3600)	CeLoss 0.0135 (0.0344)	SegCLSLoss 0.0016 (0.0016)	KLLoss 0.0032 (0.0032)	MaskLoss 0.1447 (0.0939)	MaskBCELoss 0.0674 (0.0270)	MaskDICELoss 0.0773 (0.0669)
Epoch: [1][379/500]	Time 77.627 (77.627)	Loss 0.2271 (0.3891)	CeLoss 0.0598 (0.0397)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0039 (0.0035)	MaskLoss 0.0506 (0.0934)	MaskBCELoss 0.0196 (0.0143)	MaskDICELoss 0.0310 (0.0792)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 378 is less than current step: 499. Dropping entry: {'train/loss': 0.38905020505189897, 'train/ce_loss': 0.03968505859375, 'train/seg_cls_loss': 0.00137786865234375, 'train/kl_loss': 0.00346221923828125, 'train/mask_bce_loss': 0.014268796425312757, 'train/mask_dice_loss': 0.07917112223803997, 'train/mask_loss': 0.09343991763889789, 'metrics/total_secs_per_batch': 77.62690854072571, 'metrics/data_secs_per_batch': 34.05306897163391, '_timestamp': 1741708362.5235403}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 378 is less than current step: 499. Dropping entry: {'train/lr': 0.00028960240963855417, '_timestamp': 1741708362.52383}).
Epoch: [1][380/500]	Time 70.619 (70.619)	Loss 0.2480 (0.3805)	CeLoss 0.0260 (0.0447)	SegCLSLoss 0.0029 (0.0019)	KLLoss 0.0025 (0.0038)	MaskLoss 0.0630 (0.0937)	MaskBCELoss 0.0170 (0.0219)	MaskDICELoss 0.0460 (0.0718)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 379 is less than current step: 499. Dropping entry: {'train/loss': 0.38045441955327985, 'train/ce_loss': 0.044677734375, 'train/seg_cls_loss': 0.001869964599609375, 'train/kl_loss': 0.00378570556640625, 'train/mask_bce_loss': 0.02189976886147633, 'train/mask_dice_loss': 0.07179555804468692, 'train/mask_loss': 0.09369532754644752, 'metrics/total_secs_per_batch': 70.61918354034424, 'metrics/data_secs_per_batch': 32.00896418094635, '_timestamp': 1741708433.1426606}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 379 is less than current step: 499. Dropping entry: {'train/lr': 0.000289578313253012, '_timestamp': 1741708433.142902}).
Epoch: [1][381/500]	Time 72.943 (72.943)	Loss 0.4505 (0.4831)	CeLoss 0.0811 (0.0496)	SegCLSLoss 0.0016 (0.0017)	KLLoss 0.0059 (0.0034)	MaskLoss 0.1019 (0.1266)	MaskBCELoss 0.0225 (0.0385)	MaskDICELoss 0.0794 (0.0881)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 380 is less than current step: 499. Dropping entry: {'train/loss': 0.48310004770755766, 'train/ce_loss': 0.049560546875, 'train/seg_cls_loss': 0.0016607284545898438, 'train/kl_loss': 0.0033660888671875, 'train/mask_bce_loss': 0.03849604488350451, 'train/mask_dice_loss': 0.08807483911514283, 'train/mask_loss': 0.12657088562846183, 'metrics/total_secs_per_batch': 72.9432942867279, 'metrics/data_secs_per_batch': 33.314952635765074, '_timestamp': 1741708506.0862048}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 380 is less than current step: 499. Dropping entry: {'train/lr': 0.00028956626506024095, '_timestamp': 1741708506.0865068}).
Epoch: [1][382/500]	Time 71.683 (71.683)	Loss 0.4666 (0.3747)	CeLoss 0.0513 (0.0402)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0034 (0.0029)	MaskLoss 0.1060 (0.0934)	MaskBCELoss 0.0061 (0.0213)	MaskDICELoss 0.0998 (0.0721)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 381 is less than current step: 499. Dropping entry: {'train/loss': 0.3747312806546688, 'train/ce_loss': 0.0402099609375, 'train/seg_cls_loss': 0.0009668350219726562, 'train/kl_loss': 0.00291290283203125, 'train/mask_bce_loss': 0.02127019949257374, 'train/mask_dice_loss': 0.07211998729035259, 'train/mask_loss': 0.09339018519967794, 'metrics/total_secs_per_batch': 71.68267154693604, 'metrics/data_secs_per_batch': 32.37719442844391, '_timestamp': 1741708577.7689025}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 381 is less than current step: 499. Dropping entry: {'train/lr': 0.00028955421686746986, '_timestamp': 1741708577.7693198}).
Epoch: [1][383/500]	Time 77.039 (77.039)	Loss 0.4052 (0.3316)	CeLoss 0.0222 (0.0396)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0024 (0.0034)	MaskLoss 0.0985 (0.0870)	MaskBCELoss 0.0070 (0.0300)	MaskDICELoss 0.0915 (0.0570)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 382 is less than current step: 499. Dropping entry: {'train/loss': 0.3315618662163615, 'train/ce_loss': 0.03958740234375, 'train/seg_cls_loss': 0.0008024215698242187, 'train/kl_loss': 0.00341796875, 'train/mask_bce_loss': 0.029987146146595478, 'train/mask_dice_loss': 0.057027753256261346, 'train/mask_loss': 0.08701489958912134, 'metrics/total_secs_per_batch': 77.039475440979, 'metrics/data_secs_per_batch': 34.1724946975708, '_timestamp': 1741708654.8081734}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 382 is less than current step: 499. Dropping entry: {'train/lr': 0.0002895421686746988, '_timestamp': 1741708654.8084738}).
Epoch: [1][384/500]	Time 73.557 (73.557)	Loss 0.0770 (0.4002)	CeLoss 0.0281 (0.0452)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0025 (0.0036)	MaskLoss 0.0131 (0.1032)	MaskBCELoss 0.0033 (0.0311)	MaskDICELoss 0.0098 (0.0721)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 383 is less than current step: 499. Dropping entry: {'train/loss': 0.40021606907248497, 'train/ce_loss': 0.0452392578125, 'train/seg_cls_loss': 0.001351165771484375, 'train/kl_loss': 0.00361175537109375, 'train/mask_bce_loss': 0.031127004767768085, 'train/mask_dice_loss': 0.07210770137608051, 'train/mask_loss': 0.1032347060739994, 'metrics/total_secs_per_batch': 73.55732321739197, 'metrics/data_secs_per_batch': 32.8989116191864, '_timestamp': 1741708728.3656805}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 383 is less than current step: 499. Dropping entry: {'train/lr': 0.0002895301204819277, '_timestamp': 1741708728.3659728}).
Epoch: [1][385/500]	Time 75.096 (75.096)	Loss 0.4210 (0.3569)	CeLoss 0.0210 (0.0367)	SegCLSLoss 0.0013 (0.0016)	KLLoss 0.0029 (0.0028)	MaskLoss 0.1012 (0.0892)	MaskBCELoss 0.0042 (0.0202)	MaskDICELoss 0.0970 (0.0690)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 384 is less than current step: 499. Dropping entry: {'train/loss': 0.35690263733267785, 'train/ce_loss': 0.0367431640625, 'train/seg_cls_loss': 0.0016424179077148438, 'train/kl_loss': 0.0027557373046875, 'train/mask_bce_loss': 0.02017942073289305, 'train/mask_dice_loss': 0.0690407344372943, 'train/mask_loss': 0.08922015517018736, 'metrics/total_secs_per_batch': 75.09601950645447, 'metrics/data_secs_per_batch': 33.456134748458865, '_timestamp': 1741708803.4615676}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 384 is less than current step: 499. Dropping entry: {'train/lr': 0.0002895180722891566, '_timestamp': 1741708803.4620597}).
Epoch: [1][386/500]	Time 76.378 (76.378)	Loss 0.2337 (0.4071)	CeLoss 0.1016 (0.0522)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0019 (0.0032)	MaskLoss 0.0481 (0.1026)	MaskBCELoss 0.0309 (0.0297)	MaskDICELoss 0.0172 (0.0729)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 385 is less than current step: 499. Dropping entry: {'train/loss': 0.4070685006678104, 'train/ce_loss': 0.052215576171875, 'train/seg_cls_loss': 0.000978851318359375, 'train/kl_loss': 0.003244781494140625, 'train/mask_bce_loss': 0.029670398426242174, 'train/mask_dice_loss': 0.07294755000621081, 'train/mask_loss': 0.10261794738471508, 'metrics/total_secs_per_batch': 76.37817883491516, 'metrics/data_secs_per_batch': 35.77738444805145, '_timestamp': 1741708879.8402357}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 385 is less than current step: 499. Dropping entry: {'train/lr': 0.0002895060240963855, '_timestamp': 1741708879.840932}).
Epoch: [1][387/500]	Time 71.611 (71.611)	Loss 0.2997 (0.3539)	CeLoss 0.0654 (0.0492)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0029 (0.0037)	MaskLoss 0.0704 (0.0831)	MaskBCELoss 0.0252 (0.0161)	MaskDICELoss 0.0452 (0.0671)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 386 is less than current step: 499. Dropping entry: {'train/loss': 0.3538581818342209, 'train/ce_loss': 0.04920654296875, 'train/seg_cls_loss': 0.00106353759765625, 'train/kl_loss': 0.0037384033203125, 'train/mask_bce_loss': 0.01607166852336377, 'train/mask_dice_loss': 0.06707422016188502, 'train/mask_loss': 0.08314589001238346, 'metrics/total_secs_per_batch': 71.61095356941223, 'metrics/data_secs_per_batch': 31.43233025074005, '_timestamp': 1741708951.4506469}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 386 is less than current step: 499. Dropping entry: {'train/lr': 0.0002894939759036144, '_timestamp': 1741708951.4509525}).
Epoch: [1][388/500]	Time 72.428 (72.428)	Loss 0.4216 (0.3210)	CeLoss 0.0242 (0.0343)	SegCLSLoss 0.0043 (0.0014)	KLLoss 0.0033 (0.0029)	MaskLoss 0.1087 (0.0811)	MaskBCELoss 0.0214 (0.0206)	MaskDICELoss 0.0873 (0.0605)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 387 is less than current step: 499. Dropping entry: {'train/loss': 0.32097860984504223, 'train/ce_loss': 0.034283447265625, 'train/seg_cls_loss': 0.001386547088623047, 'train/kl_loss': 0.00287017822265625, 'train/mask_bce_loss': 0.02060002873186022, 'train/mask_dice_loss': 0.06047686450183391, 'train/mask_loss': 0.08107689507305622, 'metrics/total_secs_per_batch': 72.42793393135071, 'metrics/data_secs_per_batch': 32.78284687995911, '_timestamp': 1741709023.8788502}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 387 is less than current step: 499. Dropping entry: {'train/lr': 0.00028948192771084333, '_timestamp': 1741709023.8791885}).
Epoch: [1][389/500]	Time 72.190 (72.190)	Loss 0.4567 (0.3364)	CeLoss 0.0493 (0.0392)	SegCLSLoss 0.0019 (0.0008)	KLLoss 0.0034 (0.0026)	MaskLoss 0.1022 (0.0845)	MaskBCELoss 0.0029 (0.0220)	MaskDICELoss 0.0994 (0.0626)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 388 is less than current step: 499. Dropping entry: {'train/loss': 0.3364494565874338, 'train/ce_loss': 0.0391845703125, 'train/seg_cls_loss': 0.0008436203002929688, 'train/kl_loss': 0.00259246826171875, 'train/mask_bce_loss': 0.02196591258980334, 'train/mask_dice_loss': 0.06258253455162048, 'train/mask_loss': 0.08454844914376736, 'metrics/total_secs_per_batch': 72.19005131721497, 'metrics/data_secs_per_batch': 33.23344969749451, '_timestamp': 1741709096.0689476}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 388 is less than current step: 499. Dropping entry: {'train/lr': 0.0002894698795180723, '_timestamp': 1741709096.0695782}).
Epoch: [1][390/500]	Time 74.963 (74.963)	Loss 0.4283 (0.3508)	CeLoss 0.0248 (0.0314)	SegCLSLoss 0.0024 (0.0019)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1000 (0.0846)	MaskBCELoss 0.0006 (0.0115)	MaskDICELoss 0.0995 (0.0730)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 389 is less than current step: 499. Dropping entry: {'train/loss': 0.35075995735824106, 'train/ce_loss': 0.0313720703125, 'train/seg_cls_loss': 0.0019256591796875, 'train/kl_loss': 0.0031982421875, 'train/mask_bce_loss': 0.011537809495348484, 'train/mask_dice_loss': 0.07304168976843357, 'train/mask_loss': 0.08457949864678085, 'metrics/total_secs_per_batch': 74.96285843849182, 'metrics/data_secs_per_batch': 34.73782923221588, '_timestamp': 1741709171.0316913}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 389 is less than current step: 499. Dropping entry: {'train/lr': 0.0002894457831325301, '_timestamp': 1741709171.03201}).
Epoch: [1][391/500]	Time 79.203 (79.203)	Loss 0.1564 (0.3247)	CeLoss 0.0226 (0.0463)	SegCLSLoss 0.0047 (0.0014)	KLLoss 0.0029 (0.0032)	MaskLoss 0.0410 (0.0796)	MaskBCELoss 0.0177 (0.0220)	MaskDICELoss 0.0233 (0.0576)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 390 is less than current step: 499. Dropping entry: {'train/loss': 0.3247380185872316, 'train/ce_loss': 0.0463134765625, 'train/seg_cls_loss': 0.0013702392578125, 'train/kl_loss': 0.0032470703125, 'train/mask_bce_loss': 0.022006418625824153, 'train/mask_dice_loss': 0.057617819495499135, 'train/mask_loss': 0.07962423842400312, 'metrics/total_secs_per_batch': 79.20339870452881, 'metrics/data_secs_per_batch': 36.73958978652954, '_timestamp': 1741709250.2356384}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 390 is less than current step: 499. Dropping entry: {'train/lr': 0.000289433734939759, '_timestamp': 1741709250.2359626}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 391 is less than current step: 499. Dropping entry: {'train/loss': 0.46411730349063873, 'train/ce_loss': 0.0463623046875, 'train/seg_cls_loss': 0.0013731002807617187, 'train/kl_loss': 0.00304107666015625, 'train/mask_bce_loss': 0.027017120411619543, 'train/mask_dice_loss': 0.08998414203524589, 'train/mask_loss': 0.117001261562109, 'metrics/total_secs_per_batch': 75.4565978050232, 'metrics/data_secs_per_batch': 32.97397065162659, '_timestamp': 1741709325.6919014}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 391 is less than current step: 499. Dropping entry: {'train/lr': 0.00028942168674698794, '_timestamp': 1741709325.692446}).
Epoch: [1][392/500]	Time 75.457 (75.457)	Loss 0.4503 (0.4641)	CeLoss 0.0267 (0.0464)	SegCLSLoss 0.0025 (0.0014)	KLLoss 0.0029 (0.0030)	MaskLoss 0.1154 (0.1170)	MaskBCELoss 0.0211 (0.0270)	MaskDICELoss 0.0943 (0.0900)
Epoch: [1][393/500]	Time 82.415 (82.415)	Loss 0.2398 (0.2863)	CeLoss 0.0547 (0.0393)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0028 (0.0024)	MaskLoss 0.0583 (0.0727)	MaskBCELoss 0.0255 (0.0233)	MaskDICELoss 0.0327 (0.0494)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 392 is less than current step: 499. Dropping entry: {'train/loss': 0.28634381107985973, 'train/ce_loss': 0.039306640625, 'train/seg_cls_loss': 0.0008638381958007812, 'train/kl_loss': 0.002361297607421875, 'train/mask_bce_loss': 0.023303308256436138, 'train/mask_dice_loss': 0.049394750013016166, 'train/mask_loss': 0.07269805697724223, 'metrics/total_secs_per_batch': 82.41514611244202, 'metrics/data_secs_per_batch': 35.80919075012207, '_timestamp': 1741709408.1093438}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 392 is less than current step: 499. Dropping entry: {'train/lr': 0.00028940963855421685, '_timestamp': 1741709408.1098146}).
Epoch: [1][394/500]	Time 76.804 (76.804)	Loss 0.1080 (0.3402)	CeLoss 0.0242 (0.0469)	SegCLSLoss 0.0011 (0.0010)	KLLoss 0.0023 (0.0030)	MaskLoss 0.0216 (0.0835)	MaskBCELoss 0.0027 (0.0222)	MaskDICELoss 0.0189 (0.0614)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 393 is less than current step: 499. Dropping entry: {'train/loss': 0.34017956629395485, 'train/ce_loss': 0.04691162109375, 'train/seg_cls_loss': 0.0009759902954101562, 'train/kl_loss': 0.003022003173828125, 'train/mask_bce_loss': 0.022162349591962994, 'train/mask_dice_loss': 0.06137094320729375, 'train/mask_loss': 0.08353329226374626, 'metrics/total_secs_per_batch': 76.80395746231079, 'metrics/data_secs_per_batch': 34.49464640617371, '_timestamp': 1741709484.910663}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 393 is less than current step: 499. Dropping entry: {'train/lr': 0.00028939759036144576, '_timestamp': 1741709484.9111931}).
Epoch: [1][395/500]	Time 75.918 (75.918)	Loss 0.2445 (0.4092)	CeLoss 0.0240 (0.0416)	SegCLSLoss 0.0015 (0.0019)	KLLoss 0.0031 (0.0036)	MaskLoss 0.0611 (0.0992)	MaskBCELoss 0.0139 (0.0168)	MaskDICELoss 0.0472 (0.0824)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 394 is less than current step: 499. Dropping entry: {'train/loss': 0.40923804640769956, 'train/ce_loss': 0.04161376953125, 'train/seg_cls_loss': 0.001873016357421875, 'train/kl_loss': 0.003586578369140625, 'train/mask_bce_loss': 0.01678952411748469, 'train/mask_dice_loss': 0.08236689660698175, 'train/mask_loss': 0.0991564217954874, 'metrics/total_secs_per_batch': 75.91813325881958, 'metrics/data_secs_per_batch': 34.556899070739746, '_timestamp': 1741709560.8288796}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 394 is less than current step: 499. Dropping entry: {'train/lr': 0.00028938554216867467, '_timestamp': 1741709560.829463}).
Epoch: [1][396/500]	Time 83.664 (83.664)	Loss 0.4272 (0.4405)	CeLoss 0.0250 (0.0566)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0032 (0.0028)	MaskLoss 0.1000 (0.1028)	MaskBCELoss 0.0007 (0.0153)	MaskDICELoss 0.0993 (0.0875)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 395 is less than current step: 499. Dropping entry: {'train/loss': 0.44050870537757875, 'train/ce_loss': 0.05662841796875, 'train/seg_cls_loss': 0.0010677337646484374, 'train/kl_loss': 0.00275421142578125, 'train/mask_bce_loss': 0.015325447492068633, 'train/mask_dice_loss': 0.08749863412231207, 'train/mask_loss': 0.10282407812774182, 'metrics/total_secs_per_batch': 83.6643455028534, 'metrics/data_secs_per_batch': 39.15690000057221, '_timestamp': 1741709644.4932787}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 395 is less than current step: 499. Dropping entry: {'train/lr': 0.0002893734939759036, '_timestamp': 1741709644.4936104}).
Epoch: [1][397/500]	Time 70.492 (70.492)	Loss 0.2615 (0.3042)	CeLoss 0.0593 (0.0329)	SegCLSLoss 0.0010 (0.0025)	KLLoss 0.0023 (0.0027)	MaskLoss 0.0636 (0.0791)	MaskBCELoss 0.0276 (0.0244)	MaskDICELoss 0.0361 (0.0546)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 396 is less than current step: 499. Dropping entry: {'train/loss': 0.30423085801303384, 'train/ce_loss': 0.0328857421875, 'train/seg_cls_loss': 0.0025485992431640626, 'train/kl_loss': 0.0026519775390625, 'train/mask_bce_loss': 0.024427978252060712, 'train/mask_dice_loss': 0.054644505679607394, 'train/mask_loss': 0.07907248428091407, 'metrics/total_secs_per_batch': 70.49217796325684, 'metrics/data_secs_per_batch': 32.69163873195648, '_timestamp': 1741709714.9857163}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 396 is less than current step: 499. Dropping entry: {'train/lr': 0.0002893614457831325, '_timestamp': 1741709714.9862227}).
Epoch: [1][398/500]	Time 77.575 (77.575)	Loss 0.2769 (0.4295)	CeLoss 0.0266 (0.0589)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0042 (0.0032)	MaskLoss 0.0741 (0.1027)	MaskBCELoss 0.0252 (0.0219)	MaskDICELoss 0.0489 (0.0808)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 397 is less than current step: 499. Dropping entry: {'train/loss': 0.42953833341598513, 'train/ce_loss': 0.0588623046875, 'train/seg_cls_loss': 0.0010967254638671875, 'train/kl_loss': 0.003150177001953125, 'train/mask_bce_loss': 0.021894711023196577, 'train/mask_dice_loss': 0.08081222511827946, 'train/mask_loss': 0.10270693823695183, 'metrics/total_secs_per_batch': 77.57452511787415, 'metrics/data_secs_per_batch': 36.30538966655731, '_timestamp': 1741709792.5600452}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 397 is less than current step: 499. Dropping entry: {'train/lr': 0.0002893493975903614, '_timestamp': 1741709792.5607054}).
Epoch: [1][399/500]	Time 74.639 (74.639)	Loss 0.4299 (0.3561)	CeLoss 0.0175 (0.0378)	SegCLSLoss 0.0011 (0.0020)	KLLoss 0.0041 (0.0026)	MaskLoss 0.1051 (0.0855)	MaskBCELoss 0.0062 (0.0138)	MaskDICELoss 0.0989 (0.0718)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 398 is less than current step: 499. Dropping entry: {'train/loss': 0.3560566458851099, 'train/ce_loss': 0.037841796875, 'train/seg_cls_loss': 0.001967620849609375, 'train/kl_loss': 0.002603912353515625, 'train/mask_bce_loss': 0.013784024096094073, 'train/mask_dice_loss': 0.07176082096993923, 'train/mask_loss': 0.0855448454618454, 'metrics/total_secs_per_batch': 74.63890504837036, 'metrics/data_secs_per_batch': 33.475508546829225, '_timestamp': 1741709867.199036}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 398 is less than current step: 499. Dropping entry: {'train/lr': 0.0002893373493975903, '_timestamp': 1741709867.1996536}).
[2025-03-11 11:19:00,674] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[0.0002893253012048192], mom=[(0.9, 0.95)]
[2025-03-11 11:19:00,684] [INFO] [timer.py:215:stop] epoch=0/micro_step=900/global_step=90, RunningAvgSamplesPerSec=0.8201491586887011, CurrSamplesPerSec=0.5633895480532255, MemAllocated=58.52GB, MaxMemAllocated=74.15GB
Epoch: [1][400/500]	Time 73.487 (73.487)	Loss 0.3886 (0.3247)	CeLoss 0.1025 (0.0399)	SegCLSLoss 0.0008 (0.0034)	KLLoss 0.0052 (0.0027)	MaskLoss 0.0931 (0.0863)	MaskBCELoss 0.0458 (0.0323)	MaskDICELoss 0.0473 (0.0539)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 399 is less than current step: 499. Dropping entry: {'train/loss': 0.3246762428432703, 'train/ce_loss': 0.039892578125, 'train/seg_cls_loss': 0.0034008026123046875, 'train/kl_loss': 0.002728271484375, 'train/mask_bce_loss': 0.03233113163150847, 'train/mask_dice_loss': 0.0539243923034519, 'train/mask_loss': 0.08625552337616682, 'metrics/total_secs_per_batch': 73.48674464225769, 'metrics/data_secs_per_batch': 31.990085744857787, '_timestamp': 1741709940.685308}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 399 is less than current step: 499. Dropping entry: {'train/lr': 0.00028931325301204813, '_timestamp': 1741709940.685719}).
Epoch: [1][401/500]	Time 80.390 (80.390)	Loss 0.4466 (0.3532)	CeLoss 0.0520 (0.0413)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0031 (0.0018)	MaskLoss 0.0998 (0.0833)	MaskBCELoss 0.0042 (0.0119)	MaskDICELoss 0.0956 (0.0714)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 400 is less than current step: 499. Dropping entry: {'train/loss': 0.3532077010720968, 'train/ce_loss': 0.04132080078125, 'train/seg_cls_loss': 0.0011651992797851562, 'train/kl_loss': 0.00178375244140625, 'train/mask_bce_loss': 0.01188094071112573, 'train/mask_dice_loss': 0.07143616061657668, 'train/mask_loss': 0.08331710137426854, 'metrics/total_secs_per_batch': 80.39018607139587, 'metrics/data_secs_per_batch': 35.996132135391235, '_timestamp': 1741710021.0757835}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 400 is less than current step: 499. Dropping entry: {'train/lr': 0.0002893012048192771, '_timestamp': 1741710021.0762985}).
Epoch: [1][402/500]	Time 79.718 (79.718)	Loss 0.0200 (0.3545)	CeLoss 0.0200 (0.0370)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0887)	MaskBCELoss 0.0000 (0.0203)	MaskDICELoss 0.0000 (0.0685)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 401 is less than current step: 499. Dropping entry: {'train/loss': 0.3544894378632307, 'train/ce_loss': 0.0370361328125, 'train/seg_cls_loss': 0.0012651443481445312, 'train/kl_loss': 0.002436065673828125, 'train/mask_bce_loss': 0.02026357190916315, 'train/mask_dice_loss': 0.06848080828785896, 'train/mask_loss': 0.08874437967315316, 'metrics/total_secs_per_batch': 79.71818423271179, 'metrics/data_secs_per_batch': 34.53394184112549, '_timestamp': 1741710100.7942436}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 401 is less than current step: 499. Dropping entry: {'train/lr': 0.000289289156626506, '_timestamp': 1741710100.7948403}).
Epoch: [1][403/500]	Time 71.420 (71.420)	Loss 0.3244 (0.3803)	CeLoss 0.0535 (0.0491)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0034 (0.0028)	MaskLoss 0.0765 (0.0965)	MaskBCELoss 0.0196 (0.0292)	MaskDICELoss 0.0568 (0.0674)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 402 is less than current step: 499. Dropping entry: {'train/loss': 0.3803424283862114, 'train/ce_loss': 0.04906005859375, 'train/seg_cls_loss': 0.00138397216796875, 'train/kl_loss': 0.002771759033203125, 'train/mask_bce_loss': 0.029181764810346067, 'train/mask_dice_loss': 0.0673599581234157, 'train/mask_loss': 0.09654172249138356, 'metrics/total_secs_per_batch': 71.42023754119873, 'metrics/data_secs_per_batch': 32.4758229970932, '_timestamp': 1741710172.214194}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 402 is less than current step: 499. Dropping entry: {'train/lr': 0.0002892771084337349, '_timestamp': 1741710172.2144752}).
Epoch: [1][404/500]	Time 77.081 (77.081)	Loss 0.3097 (0.3211)	CeLoss 0.0128 (0.0335)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0042 (0.0021)	MaskLoss 0.1043 (0.0824)	MaskBCELoss 0.0626 (0.0225)	MaskDICELoss 0.0418 (0.0600)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 403 is less than current step: 499. Dropping entry: {'train/loss': 0.3211016828194261, 'train/ce_loss': 0.033544921875, 'train/seg_cls_loss': 0.001280975341796875, 'train/kl_loss': 0.002093505859375, 'train/mask_bce_loss': 0.02247231835499406, 'train/mask_dice_loss': 0.05997187718749046, 'train/mask_loss': 0.08244419321417809, 'metrics/total_secs_per_batch': 77.08060121536255, 'metrics/data_secs_per_batch': 36.067976760864255, '_timestamp': 1741710249.2948358}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 403 is less than current step: 499. Dropping entry: {'train/lr': 0.00028926506024096383, '_timestamp': 1741710249.2951565}).
Epoch: [1][405/500]	Time 73.847 (73.847)	Loss 0.5319 (0.4336)	CeLoss 0.0508 (0.0395)	SegCLSLoss 0.0031 (0.0019)	KLLoss 0.0035 (0.0026)	MaskLoss 0.1412 (0.1071)	MaskBCELoss 0.0444 (0.0189)	MaskDICELoss 0.0968 (0.0882)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 404 is less than current step: 499. Dropping entry: {'train/loss': 0.43364195674657824, 'train/ce_loss': 0.039501953125, 'train/seg_cls_loss': 0.001902008056640625, 'train/kl_loss': 0.002625274658203125, 'train/mask_bce_loss': 0.01889580019051209, 'train/mask_dice_loss': 0.08819110542535782, 'train/mask_loss': 0.10708690658211709, 'metrics/total_secs_per_batch': 73.84657096862793, 'metrics/data_secs_per_batch': 31.71209852695465, '_timestamp': 1741710323.1413896}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 404 is less than current step: 499. Dropping entry: {'train/lr': 0.00028925301204819274, '_timestamp': 1741710323.141841}).
Epoch: [1][406/500]	Time 72.862 (72.862)	Loss 0.4771 (0.3094)	CeLoss 0.0732 (0.0372)	SegCLSLoss 0.0031 (0.0014)	KLLoss 0.0020 (0.0020)	MaskLoss 0.1010 (0.0778)	MaskBCELoss 0.0016 (0.0208)	MaskDICELoss 0.0993 (0.0570)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 405 is less than current step: 499. Dropping entry: {'train/loss': 0.30942990677431226, 'train/ce_loss': 0.03720703125, 'train/seg_cls_loss': 0.0013713836669921875, 'train/kl_loss': 0.002039337158203125, 'train/mask_bce_loss': 0.020793761732056736, 'train/mask_dice_loss': 0.05698256772011519, 'train/mask_loss': 0.07777632996439934, 'metrics/total_secs_per_batch': 72.86212682723999, 'metrics/data_secs_per_batch': 33.253657937049866, '_timestamp': 1741710396.0042713}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 405 is less than current step: 499. Dropping entry: {'train/lr': 0.00028924096385542165, '_timestamp': 1741710396.005003}).
Epoch: [1][407/500]	Time 85.011 (85.011)	Loss 0.4522 (0.3695)	CeLoss 0.0474 (0.0419)	SegCLSLoss 0.0020 (0.0014)	KLLoss 0.0020 (0.0028)	MaskLoss 0.1019 (0.0903)	MaskBCELoss 0.0029 (0.0185)	MaskDICELoss 0.0990 (0.0718)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 406 is less than current step: 499. Dropping entry: {'train/loss': 0.36951090693473815, 'train/ce_loss': 0.041943359375, 'train/seg_cls_loss': 0.0013957977294921874, 'train/kl_loss': 0.00276641845703125, 'train/mask_bce_loss': 0.01852105581201613, 'train/mask_dice_loss': 0.07175001250579953, 'train/mask_loss': 0.09027106985449791, 'metrics/total_secs_per_batch': 85.01103138923645, 'metrics/data_secs_per_batch': 35.98810467720032, '_timestamp': 1741710481.0148785}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 406 is less than current step: 499. Dropping entry: {'train/lr': 0.00028922891566265056, '_timestamp': 1741710481.0152824}).
Epoch: [1][408/500]	Time 71.887 (71.887)	Loss 0.2916 (0.4201)	CeLoss 0.0170 (0.0334)	SegCLSLoss 0.0058 (0.0031)	KLLoss 0.0028 (0.0030)	MaskLoss 0.0933 (0.1083)	MaskBCELoss 0.0523 (0.0256)	MaskDICELoss 0.0411 (0.0828)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 407 is less than current step: 499. Dropping entry: {'train/loss': 0.42008964717388153, 'train/ce_loss': 0.03336181640625, 'train/seg_cls_loss': 0.00307159423828125, 'train/kl_loss': 0.00301361083984375, 'train/mask_bce_loss': 0.02556212084600702, 'train/mask_dice_loss': 0.08277113698422908, 'train/mask_loss': 0.10833325684070587, 'metrics/total_secs_per_batch': 71.8865430355072, 'metrics/data_secs_per_batch': 32.785968971252444, '_timestamp': 1741710552.9010947}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 407 is less than current step: 499. Dropping entry: {'train/lr': 0.0002892168674698795, '_timestamp': 1741710552.9013789}).
Epoch: [1][409/500]	Time 73.445 (73.445)	Loss 0.3827 (0.3409)	CeLoss 0.0227 (0.0429)	SegCLSLoss 0.0022 (0.0015)	KLLoss 0.0017 (0.0022)	MaskLoss 0.1006 (0.0809)	MaskBCELoss 0.0226 (0.0143)	MaskDICELoss 0.0781 (0.0666)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 408 is less than current step: 499. Dropping entry: {'train/loss': 0.3408677872270346, 'train/ce_loss': 0.04285888671875, 'train/seg_cls_loss': 0.0014623641967773438, 'train/kl_loss': 0.002188873291015625, 'train/mask_bce_loss': 0.014314802491571754, 'train/mask_dice_loss': 0.06663376726210117, 'train/mask_loss': 0.0809485673904419, 'metrics/total_secs_per_batch': 73.44465970993042, 'metrics/data_secs_per_batch': 33.23160033226013, '_timestamp': 1741710626.3459866}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 408 is less than current step: 499. Dropping entry: {'train/lr': 0.00028920481927710844, '_timestamp': 1741710626.346314}).
Epoch: [1][410/500]	Time 75.246 (75.246)	Loss 0.4005 (0.3889)	CeLoss 0.0219 (0.0401)	SegCLSLoss 0.0024 (0.0019)	KLLoss 0.0023 (0.0029)	MaskLoss 0.0943 (0.0942)	MaskBCELoss 0.0010 (0.0159)	MaskDICELoss 0.0933 (0.0783)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 409 is less than current step: 499. Dropping entry: {'train/loss': 0.3889133378863335, 'train/ce_loss': 0.04005126953125, 'train/seg_cls_loss': 0.001892852783203125, 'train/kl_loss': 0.00294647216796875, 'train/mask_bce_loss': 0.015882383711868897, 'train/mask_dice_loss': 0.07830081563442945, 'train/mask_loss': 0.09418319836258889, 'metrics/total_secs_per_batch': 75.24649024009705, 'metrics/data_secs_per_batch': 34.25757513046265, '_timestamp': 1741710701.5922658}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 409 is less than current step: 499. Dropping entry: {'train/lr': 0.00028918072289156626, '_timestamp': 1741710701.5925431}).
Epoch: [1][411/500]	Time 72.288 (72.288)	Loss 0.4804 (0.3727)	CeLoss 0.0535 (0.0403)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0028 (0.0026)	MaskLoss 0.1139 (0.0887)	MaskBCELoss 0.0159 (0.0128)	MaskDICELoss 0.0980 (0.0759)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 410 is less than current step: 499. Dropping entry: {'train/loss': 0.3726685419678688, 'train/ce_loss': 0.0402587890625, 'train/seg_cls_loss': 0.001049041748046875, 'train/kl_loss': 0.00262451171875, 'train/mask_bce_loss': 0.012761390791274608, 'train/mask_dice_loss': 0.07594659440219402, 'train/mask_loss': 0.08870798647403717, 'metrics/total_secs_per_batch': 72.28818655014038, 'metrics/data_secs_per_batch': 31.717640256881715, '_timestamp': 1741710773.880735}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 410 is less than current step: 499. Dropping entry: {'train/lr': 0.00028916867469879517, '_timestamp': 1741710773.8813565}).
Epoch: [1][412/500]	Time 72.431 (72.431)	Loss 0.3876 (0.3684)	CeLoss 0.0203 (0.0376)	SegCLSLoss 0.0048 (0.0014)	KLLoss 0.0027 (0.0024)	MaskLoss 0.1010 (0.0902)	MaskBCELoss 0.0208 (0.0166)	MaskDICELoss 0.0802 (0.0736)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 411 is less than current step: 499. Dropping entry: {'train/loss': 0.3684337057173252, 'train/ce_loss': 0.03758544921875, 'train/seg_cls_loss': 0.001440715789794922, 'train/kl_loss': 0.002437591552734375, 'train/mask_bce_loss': 0.016613023728132247, 'train/mask_dice_loss': 0.07362613398581744, 'train/mask_loss': 0.09023915864527225, 'metrics/total_secs_per_batch': 72.43097376823425, 'metrics/data_secs_per_batch': 32.32962336540222, '_timestamp': 1741710846.31147}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 411 is less than current step: 499. Dropping entry: {'train/lr': 0.0002891566265060241, '_timestamp': 1741710846.3117828}).
Epoch: [1][413/500]	Time 71.224 (71.224)	Loss 0.2889 (0.3594)	CeLoss 0.0222 (0.0405)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0023 (0.0023)	MaskLoss 0.0974 (0.0926)	MaskBCELoss 0.0630 (0.0272)	MaskDICELoss 0.0344 (0.0654)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 412 is less than current step: 499. Dropping entry: {'train/loss': 0.3594212312251329, 'train/ce_loss': 0.0405029296875, 'train/seg_cls_loss': 0.0013353347778320313, 'train/kl_loss': 0.002268218994140625, 'train/mask_bce_loss': 0.027245919534470885, 'train/mask_dice_loss': 0.0653729721903801, 'train/mask_loss': 0.09261889308691025, 'metrics/total_secs_per_batch': 71.22431492805481, 'metrics/data_secs_per_batch': 31.820083737373352, '_timestamp': 1741710917.5358648}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 412 is less than current step: 499. Dropping entry: {'train/lr': 0.000289144578313253, '_timestamp': 1741710917.536166}).
Epoch: [1][414/500]	Time 73.036 (73.036)	Loss 0.2606 (0.3625)	CeLoss 0.0723 (0.0448)	SegCLSLoss 0.0005 (0.0017)	KLLoss 0.0029 (0.0017)	MaskLoss 0.0613 (0.0866)	MaskBCELoss 0.0300 (0.0157)	MaskDICELoss 0.0313 (0.0709)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 413 is less than current step: 499. Dropping entry: {'train/loss': 0.3624538189731538, 'train/ce_loss': 0.04481201171875, 'train/seg_cls_loss': 0.001711273193359375, 'train/kl_loss': 0.00172119140625, 'train/mask_bce_loss': 0.015683339070528747, 'train/mask_dice_loss': 0.07091143317520618, 'train/mask_loss': 0.08659477122128009, 'metrics/total_secs_per_batch': 73.03622150421143, 'metrics/data_secs_per_batch': 34.489079642295835, '_timestamp': 1741710990.5732377}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 413 is less than current step: 499. Dropping entry: {'train/lr': 0.0002891325301204819, '_timestamp': 1741710990.5742435}).
Epoch: [1][415/500]	Time 76.762 (76.762)	Loss 0.4397 (0.4169)	CeLoss 0.0208 (0.0401)	SegCLSLoss 0.0010 (0.0023)	KLLoss 0.0018 (0.0026)	MaskLoss 0.1084 (0.1108)	MaskBCELoss 0.0084 (0.0350)	MaskDICELoss 0.1000 (0.0757)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 414 is less than current step: 499. Dropping entry: {'train/loss': 0.41688157320022584, 'train/ce_loss': 0.04014892578125, 'train/seg_cls_loss': 0.0023059844970703125, 'train/kl_loss': 0.002628326416015625, 'train/mask_bce_loss': 0.035033338936045766, 'train/mask_dice_loss': 0.07572960369288921, 'train/mask_loss': 0.11076294220983982, 'metrics/total_secs_per_batch': 76.76181840896606, 'metrics/data_secs_per_batch': 34.0610511302948, '_timestamp': 1741711067.3352334}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 414 is less than current step: 499. Dropping entry: {'train/lr': 0.0002891204819277108, '_timestamp': 1741711067.3359025}).
Epoch: [1][416/500]	Time 74.851 (74.851)	Loss 0.3705 (0.3453)	CeLoss 0.0415 (0.0409)	SegCLSLoss 0.0009 (0.0019)	KLLoss 0.0041 (0.0023)	MaskLoss 0.0922 (0.0799)	MaskBCELoss 0.0222 (0.0092)	MaskDICELoss 0.0700 (0.0707)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 415 is less than current step: 499. Dropping entry: {'train/loss': 0.34534943401813506, 'train/ce_loss': 0.0409423828125, 'train/seg_cls_loss': 0.0019239425659179688, 'train/kl_loss': 0.002313995361328125, 'train/mask_bce_loss': 0.009184766086400486, 'train/mask_dice_loss': 0.0706866255030036, 'train/mask_loss': 0.07987139113247395, 'metrics/total_secs_per_batch': 74.85131406784058, 'metrics/data_secs_per_batch': 34.13310589790344, '_timestamp': 1741711142.1885586}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 415 is less than current step: 499. Dropping entry: {'train/lr': 0.0002891084337349397, '_timestamp': 1741711142.1905878}).
Epoch: [1][417/500]	Time 75.583 (75.583)	Loss 0.2934 (0.4243)	CeLoss 0.0267 (0.0449)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0024 (0.0029)	MaskLoss 0.0940 (0.1149)	MaskBCELoss 0.0561 (0.0417)	MaskDICELoss 0.0379 (0.0732)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 416 is less than current step: 499. Dropping entry: {'train/loss': 0.4242583900690079, 'train/ce_loss': 0.04486083984375, 'train/seg_cls_loss': 0.000978851318359375, 'train/kl_loss': 0.002867889404296875, 'train/mask_bce_loss': 0.04167923415079713, 'train/mask_dice_loss': 0.07318152338266373, 'train/mask_loss': 0.11486075967550277, 'metrics/total_secs_per_batch': 75.58332347869873, 'metrics/data_secs_per_batch': 35.50355243682861, '_timestamp': 1741711217.768673}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 416 is less than current step: 499. Dropping entry: {'train/lr': 0.00028909638554216864, '_timestamp': 1741711217.769002}).
Epoch: [1][418/500]	Time 81.074 (81.074)	Loss 0.4436 (0.3843)	CeLoss 0.0267 (0.0342)	SegCLSLoss 0.0016 (0.0016)	KLLoss 0.0019 (0.0018)	MaskLoss 0.1075 (0.1047)	MaskBCELoss 0.0078 (0.0356)	MaskDICELoss 0.0997 (0.0691)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 417 is less than current step: 499. Dropping entry: {'train/loss': 0.3843108778819442, 'train/ce_loss': 0.03424072265625, 'train/seg_cls_loss': 0.0015575408935546875, 'train/kl_loss': 0.0018035888671875, 'train/mask_bce_loss': 0.03562481871340424, 'train/mask_dice_loss': 0.06907585635781288, 'train/mask_loss': 0.10470067374408246, 'metrics/total_secs_per_batch': 81.0741810798645, 'metrics/data_secs_per_batch': 37.10453805923462, '_timestamp': 1741711298.8427927}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 417 is less than current step: 499. Dropping entry: {'train/lr': 0.00028908433734939755, '_timestamp': 1741711298.843254}).
Epoch: [1][419/500]	Time 82.170 (82.170)	Loss 0.3647 (0.3232)	CeLoss 0.0223 (0.0349)	SegCLSLoss 0.0020 (0.0011)	KLLoss 0.0016 (0.0025)	MaskLoss 0.0956 (0.0804)	MaskBCELoss 0.0213 (0.0182)	MaskDICELoss 0.0743 (0.0622)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 418 is less than current step: 499. Dropping entry: {'train/loss': 0.32316602356731894, 'train/ce_loss': 0.03489990234375, 'train/seg_cls_loss': 0.0011266708374023438, 'train/kl_loss': 0.002541351318359375, 'train/mask_bce_loss': 0.018247353145852685, 'train/mask_dice_loss': 0.062158552929759026, 'train/mask_loss': 0.08040590770542622, 'metrics/total_secs_per_batch': 82.17023777961731, 'metrics/data_secs_per_batch': 36.54099423885346, '_timestamp': 1741711381.0134933}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 418 is less than current step: 499. Dropping entry: {'train/lr': 0.00028907228915662646, '_timestamp': 1741711381.0141551}).
Epoch: [1][420/500]	Time 72.043 (72.043)	Loss 0.3536 (0.4059)	CeLoss 0.0825 (0.0615)	SegCLSLoss 0.0027 (0.0014)	KLLoss 0.0023 (0.0027)	MaskLoss 0.0708 (0.0939)	MaskBCELoss 0.0078 (0.0172)	MaskDICELoss 0.0630 (0.0767)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 419 is less than current step: 499. Dropping entry: {'train/loss': 0.4059478133916855, 'train/ce_loss': 0.0614501953125, 'train/seg_cls_loss': 0.00143585205078125, 'train/kl_loss': 0.002738189697265625, 'train/mask_bce_loss': 0.017230016735265963, 'train/mask_dice_loss': 0.07666589058935643, 'train/mask_loss': 0.09389590658247471, 'metrics/total_secs_per_batch': 72.04271626472473, 'metrics/data_secs_per_batch': 32.86265354156494, '_timestamp': 1741711453.0556884}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 419 is less than current step: 499. Dropping entry: {'train/lr': 0.0002890481927710843, '_timestamp': 1741711453.0559397}).
Epoch: [1][421/500]	Time 74.289 (74.289)	Loss 0.2782 (0.3585)	CeLoss 0.0825 (0.0418)	SegCLSLoss 0.0013 (0.0023)	KLLoss 0.0041 (0.0022)	MaskLoss 0.0618 (0.0900)	MaskBCELoss 0.0281 (0.0234)	MaskDICELoss 0.0337 (0.0666)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 420 is less than current step: 499. Dropping entry: {'train/loss': 0.3585129989311099, 'train/ce_loss': 0.041845703125, 'train/seg_cls_loss': 0.0023237228393554687, 'train/kl_loss': 0.002182769775390625, 'train/mask_bce_loss': 0.023350045969709753, 'train/mask_dice_loss': 0.06664951536804438, 'train/mask_loss': 0.08999955952167511, 'metrics/total_secs_per_batch': 74.28919315338135, 'metrics/data_secs_per_batch': 35.241739416122435, '_timestamp': 1741711527.346021}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 420 is less than current step: 499. Dropping entry: {'train/lr': 0.0002890361445783132, '_timestamp': 1741711527.346998}).
Epoch: [1][422/500]	Time 72.153 (72.153)	Loss 0.4792 (0.3364)	CeLoss 0.0540 (0.0357)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0030 (0.0023)	MaskLoss 0.1131 (0.0822)	MaskBCELoss 0.0153 (0.0154)	MaskDICELoss 0.0978 (0.0668)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 421 is less than current step: 499. Dropping entry: {'train/loss': 0.33644930347800256, 'train/ce_loss': 0.03568115234375, 'train/seg_cls_loss': 0.0010829925537109374, 'train/kl_loss': 0.00231781005859375, 'train/mask_bce_loss': 0.015373742929659784, 'train/mask_dice_loss': 0.06680631190538407, 'train/mask_loss': 0.08218005569651723, 'metrics/total_secs_per_batch': 72.15270447731018, 'metrics/data_secs_per_batch': 32.62341215610504, '_timestamp': 1741711599.4976969}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 421 is less than current step: 499. Dropping entry: {'train/lr': 0.00028902409638554216, '_timestamp': 1741711599.4979963}).
Epoch: [1][423/500]	Time 81.226 (81.226)	Loss 0.3785 (0.3761)	CeLoss 0.0349 (0.0369)	SegCLSLoss 0.0009 (0.0022)	KLLoss 0.0013 (0.0017)	MaskLoss 0.1100 (0.0938)	MaskBCELoss 0.0492 (0.0194)	MaskDICELoss 0.0608 (0.0744)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 422 is less than current step: 499. Dropping entry: {'train/loss': 0.376100305095315, 'train/ce_loss': 0.0368896484375, 'train/seg_cls_loss': 0.0021944046020507812, 'train/kl_loss': 0.00166473388671875, 'train/mask_bce_loss': 0.019438021979294718, 'train/mask_dice_loss': 0.07438419088721275, 'train/mask_loss': 0.09382221382111311, 'metrics/total_secs_per_batch': 81.22565531730652, 'metrics/data_secs_per_batch': 38.65321180820465, '_timestamp': 1741711680.7244737}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 422 is less than current step: 499. Dropping entry: {'train/lr': 0.00028901204819277107, '_timestamp': 1741711680.7256567}).
Epoch: [1][424/500]	Time 76.940 (76.940)	Loss 0.4635 (0.4198)	CeLoss 0.0713 (0.0471)	SegCLSLoss 0.0024 (0.0015)	KLLoss 0.0025 (0.0027)	MaskLoss 0.1327 (0.1006)	MaskBCELoss 0.0710 (0.0166)	MaskDICELoss 0.0617 (0.0840)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 423 is less than current step: 499. Dropping entry: {'train/loss': 0.4198253035545349, 'train/ce_loss': 0.0470947265625, 'train/seg_cls_loss': 0.0014837265014648437, 'train/kl_loss': 0.0027252197265625, 'train/mask_bce_loss': 0.016580837883520872, 'train/mask_dice_loss': 0.08403406953439116, 'train/mask_loss': 0.10061490684747695, 'metrics/total_secs_per_batch': 76.9396436214447, 'metrics/data_secs_per_batch': 35.67954285144806, '_timestamp': 1741711757.66467}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 423 is less than current step: 499. Dropping entry: {'train/lr': 0.000289, '_timestamp': 1741711757.6660273}).
Epoch: [1][425/500]	Time 73.979 (73.979)	Loss 0.2068 (0.2701)	CeLoss 0.0967 (0.0535)	SegCLSLoss 0.0004 (0.0026)	KLLoss 0.0042 (0.0027)	MaskLoss 0.0325 (0.0641)	MaskBCELoss 0.0124 (0.0219)	MaskDICELoss 0.0201 (0.0422)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 424 is less than current step: 499. Dropping entry: {'train/loss': 0.2701147608458996, 'train/ce_loss': 0.053533935546875, 'train/seg_cls_loss': 0.0026300430297851564, 'train/kl_loss': 0.002691650390625, 'train/mask_bce_loss': 0.021862111624795944, 'train/mask_dice_loss': 0.04220066145062447, 'train/mask_loss': 0.06406277380883693, 'metrics/total_secs_per_batch': 73.97891235351562, 'metrics/data_secs_per_batch': 33.03691835403443, '_timestamp': 1741711831.6426525}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 424 is less than current step: 499. Dropping entry: {'train/lr': 0.0002889879518072289, '_timestamp': 1741711831.6432912}).
Epoch: [1][426/500]	Time 72.179 (72.179)	Loss 0.1270 (0.3130)	CeLoss 0.0889 (0.0489)	SegCLSLoss 0.0006 (0.0014)	KLLoss 0.0024 (0.0023)	MaskLoss 0.0114 (0.0722)	MaskBCELoss 0.0053 (0.0139)	MaskDICELoss 0.0062 (0.0583)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 425 is less than current step: 499. Dropping entry: {'train/loss': 0.31299923788756134, 'train/ce_loss': 0.0488525390625, 'train/seg_cls_loss': 0.0013788223266601562, 'train/kl_loss': 0.002298736572265625, 'train/mask_bce_loss': 0.01385698956437409, 'train/mask_dice_loss': 0.05833303295075894, 'train/mask_loss': 0.07219002144411206, 'metrics/total_secs_per_batch': 72.17941379547119, 'metrics/data_secs_per_batch': 32.835014247894286, '_timestamp': 1741711903.8212974}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 425 is less than current step: 499. Dropping entry: {'train/lr': 0.0002889759036144578, '_timestamp': 1741711903.8216155}).
Epoch: [1][427/500]	Time 74.417 (74.417)	Loss 0.4861 (0.3891)	CeLoss 0.0713 (0.0512)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0018 (0.0028)	MaskLoss 0.1129 (0.0940)	MaskBCELoss 0.0199 (0.0208)	MaskDICELoss 0.0930 (0.0732)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 426 is less than current step: 499. Dropping entry: {'train/loss': 0.3890577137470245, 'train/ce_loss': 0.05120849609375, 'train/seg_cls_loss': 0.0012971878051757813, 'train/kl_loss': 0.002817535400390625, 'train/mask_bce_loss': 0.020754692927584983, 'train/mask_dice_loss': 0.07320544198155403, 'train/mask_loss': 0.09396013431251049, 'metrics/total_secs_per_batch': 74.41694116592407, 'metrics/data_secs_per_batch': 32.562179756164554, '_timestamp': 1741711978.2382343}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 426 is less than current step: 499. Dropping entry: {'train/lr': 0.0002889638554216867, '_timestamp': 1741711978.2385526}).
Epoch: [1][428/500]	Time 76.019 (76.019)	Loss 0.4504 (0.3848)	CeLoss 0.0364 (0.0491)	SegCLSLoss 0.0020 (0.0017)	KLLoss 0.0016 (0.0026)	MaskLoss 0.1087 (0.0936)	MaskBCELoss 0.0116 (0.0211)	MaskDICELoss 0.0971 (0.0725)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 427 is less than current step: 499. Dropping entry: {'train/loss': 0.38478008657693863, 'train/ce_loss': 0.04908447265625, 'train/seg_cls_loss': 0.0016529083251953125, 'train/kl_loss': 0.0026336669921875, 'train/mask_bce_loss': 0.021083777360036037, 'train/mask_dice_loss': 0.07250860221683979, 'train/mask_loss': 0.09359237775206566, 'metrics/total_secs_per_batch': 76.01907753944397, 'metrics/data_secs_per_batch': 34.12574706077576, '_timestamp': 1741712054.2585893}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 427 is less than current step: 499. Dropping entry: {'train/lr': 0.0002889518072289156, '_timestamp': 1741712054.2592595}).
Epoch: [1][429/500]	Time 71.099 (71.099)	Loss 0.1767 (0.3435)	CeLoss 0.0815 (0.0441)	SegCLSLoss 0.0003 (0.0032)	KLLoss 0.0041 (0.0026)	MaskLoss 0.0307 (0.0845)	MaskBCELoss 0.0158 (0.0213)	MaskDICELoss 0.0149 (0.0631)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 428 is less than current step: 499. Dropping entry: {'train/loss': 0.3434744283556938, 'train/ce_loss': 0.0441162109375, 'train/seg_cls_loss': 0.0031620025634765624, 'train/kl_loss': 0.0026397705078125, 'train/mask_bce_loss': 0.021342772617936136, 'train/mask_dice_loss': 0.06311226021498442, 'train/mask_loss': 0.08445503227412701, 'metrics/total_secs_per_batch': 71.0987617969513, 'metrics/data_secs_per_batch': 31.966490983963013, '_timestamp': 1741712125.356308}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 428 is less than current step: 499. Dropping entry: {'train/lr': 0.00028893975903614453, '_timestamp': 1741712125.3566246}).
Epoch: [1][430/500]	Time 73.801 (73.801)	Loss 0.4436 (0.3652)	CeLoss 0.0250 (0.0468)	SegCLSLoss 0.0030 (0.0014)	KLLoss 0.0018 (0.0022)	MaskLoss 0.1092 (0.0899)	MaskBCELoss 0.0107 (0.0221)	MaskDICELoss 0.0985 (0.0678)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 429 is less than current step: 499. Dropping entry: {'train/loss': 0.3651500023901463, 'train/ce_loss': 0.04678955078125, 'train/seg_cls_loss': 0.0014019012451171875, 'train/kl_loss': 0.00215911865234375, 'train/mask_bce_loss': 0.022062111436389385, 'train/mask_dice_loss': 0.06783701162785291, 'train/mask_loss': 0.08989912383258343, 'metrics/total_secs_per_batch': 73.80088090896606, 'metrics/data_secs_per_batch': 34.38476958274841, '_timestamp': 1741712199.157117}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 429 is less than current step: 499. Dropping entry: {'train/lr': 0.0002889156626506024, '_timestamp': 1741712199.1574228}).
Epoch: [1][431/500]	Time 78.872 (78.872)	Loss 0.5775 (0.3485)	CeLoss 0.0591 (0.0570)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0026 (0.0022)	MaskLoss 0.1595 (0.0831)	MaskBCELoss 0.0614 (0.0219)	MaskDICELoss 0.0982 (0.0612)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 430 is less than current step: 499. Dropping entry: {'train/loss': 0.348482177965343, 'train/ce_loss': 0.056982421875, 'train/seg_cls_loss': 0.0011371612548828126, 'train/kl_loss': 0.002228546142578125, 'train/mask_bce_loss': 0.02192367296665907, 'train/mask_dice_loss': 0.06117335520684719, 'train/mask_loss': 0.08309702835977077, 'metrics/total_secs_per_batch': 78.87157201766968, 'metrics/data_secs_per_batch': 34.492266392707826, '_timestamp': 1741712278.0290327}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 430 is less than current step: 499. Dropping entry: {'train/lr': 0.0002889036144578313, '_timestamp': 1741712278.0295715}).
Epoch: [1][432/500]	Time 75.816 (75.816)	Loss 0.4392 (0.4335)	CeLoss 0.0732 (0.0415)	SegCLSLoss 0.0029 (0.0015)	KLLoss 0.0027 (0.0026)	MaskLoss 0.1065 (0.1089)	MaskBCELoss 0.0322 (0.0234)	MaskDICELoss 0.0744 (0.0854)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 431 is less than current step: 499. Dropping entry: {'train/loss': 0.43352256119251253, 'train/ce_loss': 0.04154052734375, 'train/seg_cls_loss': 0.001523590087890625, 'train/kl_loss': 0.002646636962890625, 'train/mask_bce_loss': 0.02342821399215609, 'train/mask_dice_loss': 0.08544094767421484, 'train/mask_loss': 0.10886916108429431, 'metrics/total_secs_per_batch': 75.8164496421814, 'metrics/data_secs_per_batch': 32.72151563167572, '_timestamp': 1741712353.8451588}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 431 is less than current step: 499. Dropping entry: {'train/lr': 0.00028889156626506023, '_timestamp': 1741712353.8457592}).
Epoch: [1][433/500]	Time 71.811 (71.811)	Loss 0.3853 (0.4516)	CeLoss 0.0222 (0.0491)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0019 (0.0023)	MaskLoss 0.0956 (0.1143)	MaskBCELoss 0.0107 (0.0289)	MaskDICELoss 0.0849 (0.0854)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 432 is less than current step: 499. Dropping entry: {'train/loss': 0.45158830285072327, 'train/ce_loss': 0.0491455078125, 'train/seg_cls_loss': 0.001435089111328125, 'train/kl_loss': 0.00233154296875, 'train/mask_bce_loss': 0.028862825827673078, 'train/mask_dice_loss': 0.08540169820189476, 'train/mask_loss': 0.11426452323794364, 'metrics/total_secs_per_batch': 71.81089425086975, 'metrics/data_secs_per_batch': 31.755259656906127, '_timestamp': 1741712425.6561303}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 432 is less than current step: 499. Dropping entry: {'train/lr': 0.00028887951807228914, '_timestamp': 1741712425.6564684}).
Epoch: [1][434/500]	Time 74.550 (74.550)	Loss 0.1747 (0.2952)	CeLoss 0.0688 (0.0371)	SegCLSLoss 0.0008 (0.0021)	KLLoss 0.0015 (0.0019)	MaskLoss 0.0288 (0.0723)	MaskBCELoss 0.0056 (0.0170)	MaskDICELoss 0.0232 (0.0553)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 433 is less than current step: 499. Dropping entry: {'train/loss': 0.295229787286371, 'train/ce_loss': 0.037109375, 'train/seg_cls_loss': 0.002072906494140625, 'train/kl_loss': 0.001934814453125, 'train/mask_bce_loss': 0.017040938744321464, 'train/mask_dice_loss': 0.05527476938441396, 'train/mask_loss': 0.07231570780277252, 'metrics/total_secs_per_batch': 74.55035018920898, 'metrics/data_secs_per_batch': 33.19210274219513, '_timestamp': 1741712500.2064748}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 433 is less than current step: 499. Dropping entry: {'train/lr': 0.00028886746987951805, '_timestamp': 1741712500.20692}).
Epoch: [1][435/500]	Time 70.654 (70.654)	Loss 0.5367 (0.4264)	CeLoss 0.0247 (0.0634)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0055 (0.0027)	MaskLoss 0.1988 (0.1078)	MaskBCELoss 0.1444 (0.0356)	MaskDICELoss 0.0543 (0.0722)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 434 is less than current step: 499. Dropping entry: {'train/loss': 0.42643644772469996, 'train/ce_loss': 0.0633544921875, 'train/seg_cls_loss': 0.0012775421142578124, 'train/kl_loss': 0.002663421630859375, 'train/mask_bce_loss': 0.035590746882371606, 'train/mask_dice_loss': 0.07216334715485573, 'train/mask_loss': 0.10775409564375878, 'metrics/total_secs_per_batch': 70.65436339378357, 'metrics/data_secs_per_batch': 32.26419584751129, '_timestamp': 1741712570.8606977}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 434 is less than current step: 499. Dropping entry: {'train/lr': 0.00028885542168674696, '_timestamp': 1741712570.8611312}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 435 is less than current step: 499. Dropping entry: {'train/loss': 0.389620690792799, 'train/ce_loss': 0.04864501953125, 'train/seg_cls_loss': 0.0012792587280273438, 'train/kl_loss': 0.002472686767578125, 'train/mask_bce_loss': 0.018181584494595882, 'train/mask_dice_loss': 0.07536760270595551, 'train/mask_loss': 0.09354918710887432, 'metrics/total_secs_per_batch': 79.9706027507782, 'metrics/data_secs_per_batch': 36.71063604354858, '_timestamp': 1741712650.831224}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 435 is less than current step: 499. Dropping entry: {'train/lr': 0.00028884337349397587, '_timestamp': 1741712650.8314931}).
Epoch: [1][436/500]	Time 79.971 (79.971)	Loss 0.4824 (0.3896)	CeLoss 0.0786 (0.0486)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0042 (0.0025)	MaskLoss 0.1012 (0.0935)	MaskBCELoss 0.0029 (0.0182)	MaskDICELoss 0.0984 (0.0754)
Epoch: [1][437/500]	Time 71.468 (71.468)	Loss 0.1363 (0.2937)	CeLoss 0.0593 (0.0518)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0015 (0.0021)	MaskLoss 0.0209 (0.0692)	MaskBCELoss 0.0044 (0.0190)	MaskDICELoss 0.0165 (0.0502)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 436 is less than current step: 499. Dropping entry: {'train/loss': 0.2936541516333818, 'train/ce_loss': 0.05177001953125, 'train/seg_cls_loss': 0.001636505126953125, 'train/kl_loss': 0.00205230712890625, 'train/mask_bce_loss': 0.019032359053380788, 'train/mask_dice_loss': 0.05021571796387434, 'train/mask_loss': 0.06924807727336883, 'metrics/total_secs_per_batch': 71.46839785575867, 'metrics/data_secs_per_batch': 32.55663235187531, '_timestamp': 1741712722.2996247}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 436 is less than current step: 499. Dropping entry: {'train/lr': 0.0002888313253012048, '_timestamp': 1741712722.3000727}).
Epoch: [1][438/500]	Time 73.424 (73.424)	Loss 0.4607 (0.4087)	CeLoss 0.0271 (0.0485)	SegCLSLoss 0.0021 (0.0014)	KLLoss 0.0016 (0.0021)	MaskLoss 0.1170 (0.0983)	MaskBCELoss 0.0186 (0.0178)	MaskDICELoss 0.0985 (0.0805)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 437 is less than current step: 499. Dropping entry: {'train/loss': 0.40874663442373277, 'train/ce_loss': 0.0484619140625, 'train/seg_cls_loss': 0.0014133453369140625, 'train/kl_loss': 0.00212554931640625, 'train/mask_bce_loss': 0.017821239912882446, 'train/mask_dice_loss': 0.08046842161566019, 'train/mask_loss': 0.09828966110944748, 'metrics/total_secs_per_batch': 73.423832654953, 'metrics/data_secs_per_batch': 32.33517029285431, '_timestamp': 1741712795.7237322}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 437 is less than current step: 499. Dropping entry: {'train/lr': 0.0002888192771084337, '_timestamp': 1741712795.724251}).
Epoch: [1][439/500]	Time 73.148 (73.148)	Loss 0.4808 (0.3567)	CeLoss 0.0767 (0.0447)	SegCLSLoss 0.0019 (0.0018)	KLLoss 0.0018 (0.0022)	MaskLoss 0.1027 (0.0903)	MaskBCELoss 0.0047 (0.0261)	MaskDICELoss 0.0980 (0.0642)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 438 is less than current step: 499. Dropping entry: {'train/loss': 0.35669451477006076, 'train/ce_loss': 0.044708251953125, 'train/seg_cls_loss': 0.0017709732055664062, 'train/kl_loss': 0.00218505859375, 'train/mask_bce_loss': 0.026098399376496672, 'train/mask_dice_loss': 0.06418595109134913, 'train/mask_loss': 0.09028435125946999, 'metrics/total_secs_per_batch': 73.1478624343872, 'metrics/data_secs_per_batch': 32.54224073886871, '_timestamp': 1741712868.8713474}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 438 is less than current step: 499. Dropping entry: {'train/lr': 0.0002888072289156626, '_timestamp': 1741712868.8716333}).
Epoch: [1][440/500]	Time 83.083 (83.083)	Loss 0.4517 (0.3533)	CeLoss 0.0208 (0.0343)	SegCLSLoss 0.0076 (0.0018)	KLLoss 0.0017 (0.0020)	MaskLoss 0.1251 (0.0913)	MaskBCELoss 0.0375 (0.0246)	MaskDICELoss 0.0876 (0.0667)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 439 is less than current step: 499. Dropping entry: {'train/loss': 0.3533380340784788, 'train/ce_loss': 0.034326171875, 'train/seg_cls_loss': 0.0018360137939453125, 'train/kl_loss': 0.00200958251953125, 'train/mask_bce_loss': 0.024617151287384332, 'train/mask_dice_loss': 0.06669487887993455, 'train/mask_loss': 0.09131202949211001, 'metrics/total_secs_per_batch': 83.08282542228699, 'metrics/data_secs_per_batch': 34.921893620491026, '_timestamp': 1741712951.9542725}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 439 is less than current step: 499. Dropping entry: {'train/lr': 0.0002887831325301204, '_timestamp': 1741712951.954529}).
Epoch: [1][441/500]	Time 75.222 (75.222)	Loss 0.4594 (0.4169)	CeLoss 0.0216 (0.0519)	SegCLSLoss 0.0029 (0.0012)	KLLoss 0.0019 (0.0022)	MaskLoss 0.1195 (0.0979)	MaskBCELoss 0.0217 (0.0146)	MaskDICELoss 0.0978 (0.0833)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 440 is less than current step: 499. Dropping entry: {'train/loss': 0.41689290553331376, 'train/ce_loss': 0.05186767578125, 'train/seg_cls_loss': 0.0011945724487304687, 'train/kl_loss': 0.00220489501953125, 'train/mask_bce_loss': 0.01458601919002831, 'train/mask_dice_loss': 0.08328275606036187, 'train/mask_loss': 0.09786877557635307, 'metrics/total_secs_per_batch': 75.22177529335022, 'metrics/data_secs_per_batch': 34.638339614868165, '_timestamp': 1741713027.176195}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 440 is less than current step: 499. Dropping entry: {'train/lr': 0.00028877108433734934, '_timestamp': 1741713027.1765244}).
Epoch: [1][442/500]	Time 82.557 (82.557)	Loss 0.0926 (0.3369)	CeLoss 0.0654 (0.0376)	SegCLSLoss 0.0003 (0.0006)	KLLoss 0.0027 (0.0017)	MaskLoss 0.0087 (0.0795)	MaskBCELoss 0.0050 (0.0103)	MaskDICELoss 0.0036 (0.0692)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 441 is less than current step: 499. Dropping entry: {'train/loss': 0.33693217635154726, 'train/ce_loss': 0.037646484375, 'train/seg_cls_loss': 0.0006465911865234375, 'train/kl_loss': 0.001657867431640625, 'train/mask_bce_loss': 0.010290639812592418, 'train/mask_dice_loss': 0.06919514702167362, 'train/mask_loss': 0.07948578856885433, 'metrics/total_secs_per_batch': 82.55670189857483, 'metrics/data_secs_per_batch': 35.66067197322845, '_timestamp': 1741713109.7331622}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 441 is less than current step: 499. Dropping entry: {'train/lr': 0.0002887590361445783, '_timestamp': 1741713109.7338386}).
Epoch: [1][443/500]	Time 79.920 (79.920)	Loss 0.4198 (0.3798)	CeLoss 0.0347 (0.0395)	SegCLSLoss 0.0017 (0.0021)	KLLoss 0.0030 (0.0020)	MaskLoss 0.0961 (0.0944)	MaskBCELoss 0.0015 (0.0203)	MaskDICELoss 0.0946 (0.0742)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 442 is less than current step: 499. Dropping entry: {'train/loss': 0.37977440655231476, 'train/ce_loss': 0.0395263671875, 'train/seg_cls_loss': 0.0020549774169921877, 'train/kl_loss': 0.002017974853515625, 'train/mask_bce_loss': 0.02026756377890706, 'train/mask_dice_loss': 0.07416528882458806, 'train/mask_loss': 0.09443285223096609, 'metrics/total_secs_per_batch': 79.92040228843689, 'metrics/data_secs_per_batch': 36.07917168140411, '_timestamp': 1741713189.6531668}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 442 is less than current step: 499. Dropping entry: {'train/lr': 0.0002887469879518072, '_timestamp': 1741713189.6534622}).
Epoch: [1][444/500]	Time 81.077 (81.077)	Loss 0.2242 (0.3434)	CeLoss 0.0300 (0.0498)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0019 (0.0021)	MaskLoss 0.0585 (0.0852)	MaskBCELoss 0.0210 (0.0250)	MaskDICELoss 0.0374 (0.0602)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 443 is less than current step: 499. Dropping entry: {'train/loss': 0.34340948760509493, 'train/ce_loss': 0.04984130859375, 'train/seg_cls_loss': 0.0012416839599609375, 'train/kl_loss': 0.002094268798828125, 'train/mask_bce_loss': 0.025037634139880537, 'train/mask_dice_loss': 0.060193903651088475, 'train/mask_loss': 0.08523153755813836, 'metrics/total_secs_per_batch': 81.07717418670654, 'metrics/data_secs_per_batch': 33.62590887546539, '_timestamp': 1741713270.7328272}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 443 is less than current step: 499. Dropping entry: {'train/lr': 0.0002887349397590361, '_timestamp': 1741713270.7342012}).
Epoch: [1][445/500]	Time 75.570 (75.570)	Loss 0.1111 (0.3083)	CeLoss 0.0254 (0.0440)	SegCLSLoss 0.0010 (0.0008)	KLLoss 0.0018 (0.0020)	MaskLoss 0.0261 (0.0768)	MaskBCELoss 0.0105 (0.0227)	MaskDICELoss 0.0156 (0.0541)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 444 is less than current step: 499. Dropping entry: {'train/loss': 0.30825294125825164, 'train/ce_loss': 0.043994140625, 'train/seg_cls_loss': 0.00078582763671875, 'train/kl_loss': 0.002031707763671875, 'train/mask_bce_loss': 0.02271557142958045, 'train/mask_dice_loss': 0.054099003039300445, 'train/mask_loss': 0.076814572699368, 'metrics/total_secs_per_batch': 75.57044959068298, 'metrics/data_secs_per_batch': 32.40337090492248, '_timestamp': 1741713346.3017797}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 444 is less than current step: 499. Dropping entry: {'train/lr': 0.00028872289156626503, '_timestamp': 1741713346.3029857}).
Epoch: [1][446/500]	Time 73.419 (73.419)	Loss 0.4791 (0.4220)	CeLoss 0.1162 (0.0473)	SegCLSLoss 0.0017 (0.0013)	KLLoss 0.0023 (0.0024)	MaskLoss 0.1091 (0.1015)	MaskBCELoss 0.0384 (0.0173)	MaskDICELoss 0.0707 (0.0843)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 445 is less than current step: 499. Dropping entry: {'train/loss': 0.4220282196998596, 'train/ce_loss': 0.047314453125, 'train/seg_cls_loss': 0.00132904052734375, 'train/kl_loss': 0.002447509765625, 'train/mask_bce_loss': 0.017254536971449852, 'train/mask_dice_loss': 0.08426259793341159, 'train/mask_loss': 0.10151713602244854, 'metrics/total_secs_per_batch': 73.41930508613586, 'metrics/data_secs_per_batch': 35.23212053775787, '_timestamp': 1741713419.7199545}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 445 is less than current step: 499. Dropping entry: {'train/lr': 0.00028871084337349394, '_timestamp': 1741713419.720218}).
Epoch: [1][447/500]	Time 77.835 (77.835)	Loss 0.4877 (0.3653)	CeLoss 0.0654 (0.0407)	SegCLSLoss 0.0012 (0.0007)	KLLoss 0.0022 (0.0021)	MaskLoss 0.1112 (0.0852)	MaskBCELoss 0.0125 (0.0093)	MaskDICELoss 0.0987 (0.0759)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 446 is less than current step: 499. Dropping entry: {'train/loss': 0.36526981834322214, 'train/ce_loss': 0.0407470703125, 'train/seg_cls_loss': 0.0007205963134765625, 'train/kl_loss': 0.00205078125, 'train/mask_bce_loss': 0.009323126124218106, 'train/mask_dice_loss': 0.07586487606167794, 'train/mask_loss': 0.08518800139427185, 'metrics/total_secs_per_batch': 77.83487248420715, 'metrics/data_secs_per_batch': 35.92895448207855, '_timestamp': 1741713497.5558088}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 446 is less than current step: 499. Dropping entry: {'train/lr': 0.00028869879518072286, '_timestamp': 1741713497.5566947}).
Epoch: [1][448/500]	Time 79.912 (79.912)	Loss 0.2929 (0.3900)	CeLoss 0.0437 (0.0508)	SegCLSLoss 0.0022 (0.0019)	KLLoss 0.0022 (0.0024)	MaskLoss 0.0723 (0.1012)	MaskBCELoss 0.0217 (0.0345)	MaskDICELoss 0.0506 (0.0667)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 447 is less than current step: 499. Dropping entry: {'train/loss': 0.3900097534060478, 'train/ce_loss': 0.05081787109375, 'train/seg_cls_loss': 0.0019191741943359376, 'train/kl_loss': 0.002434539794921875, 'train/mask_bce_loss': 0.034459416836034505, 'train/mask_dice_loss': 0.06673757210373879, 'train/mask_loss': 0.10119699090719222, 'metrics/total_secs_per_batch': 79.91218304634094, 'metrics/data_secs_per_batch': 36.23254547119141, '_timestamp': 1741713577.4681728}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 447 is less than current step: 499. Dropping entry: {'train/lr': 0.00028868674698795177, '_timestamp': 1741713577.4694176}).
Epoch: [1][449/500]	Time 72.004 (72.004)	Loss 0.0145 (0.2946)	CeLoss 0.0145 (0.0332)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0747)	MaskBCELoss 0.0000 (0.0200)	MaskDICELoss 0.0000 (0.0548)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 448 is less than current step: 499. Dropping entry: {'train/loss': 0.29457026431336997, 'train/ce_loss': 0.033184814453125, 'train/seg_cls_loss': 0.00096435546875, 'train/kl_loss': 0.001897430419921875, 'train/mask_bce_loss': 0.019950858550146222, 'train/mask_dice_loss': 0.05477065332233906, 'train/mask_loss': 0.07472151033580303, 'metrics/total_secs_per_batch': 72.00363993644714, 'metrics/data_secs_per_batch': 31.42031455039978, '_timestamp': 1741713649.470773}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 448 is less than current step: 499. Dropping entry: {'train/lr': 0.0002886746987951807, '_timestamp': 1741713649.4710357}).
Epoch: [1][450/500]	Time 75.143 (75.143)	Loss 0.3726 (0.3032)	CeLoss 0.0256 (0.0440)	SegCLSLoss 0.0053 (0.0014)	KLLoss 0.0030 (0.0025)	MaskLoss 0.1024 (0.0754)	MaskBCELoss 0.0342 (0.0228)	MaskDICELoss 0.0682 (0.0526)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 449 is less than current step: 499. Dropping entry: {'train/loss': 0.303187296167016, 'train/ce_loss': 0.04398193359375, 'train/seg_cls_loss': 0.0013967514038085937, 'train/kl_loss': 0.00247039794921875, 'train/mask_bce_loss': 0.02278386913239956, 'train/mask_dice_loss': 0.05261045517399907, 'train/mask_loss': 0.07539432607591152, 'metrics/total_secs_per_batch': 75.14283037185669, 'metrics/data_secs_per_batch': 34.061115407943724, '_timestamp': 1741713724.6135304}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 449 is less than current step: 499. Dropping entry: {'train/lr': 0.00028865060240963855, '_timestamp': 1741713724.613772}).
Epoch: [1][451/500]	Time 70.251 (70.251)	Loss 0.0131 (0.2857)	CeLoss 0.0131 (0.0476)	SegCLSLoss 0.0000 (0.0017)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0656)	MaskBCELoss 0.0000 (0.0136)	MaskDICELoss 0.0000 (0.0520)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 450 is less than current step: 499. Dropping entry: {'train/loss': 0.2857444739900529, 'train/ce_loss': 0.04764404296875, 'train/seg_cls_loss': 0.0016651153564453125, 'train/kl_loss': 0.00198211669921875, 'train/mask_bce_loss': 0.013639389094896615, 'train/mask_dice_loss': 0.05197970494627953, 'train/mask_loss': 0.06561909541487694, 'metrics/total_secs_per_batch': 70.25127220153809, 'metrics/data_secs_per_batch': 30.476323795318603, '_timestamp': 1741713794.865183}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 450 is less than current step: 499. Dropping entry: {'train/lr': 0.00028863855421686746, '_timestamp': 1741713794.8657787}).
Epoch: [1][452/500]	Time 88.978 (88.978)	Loss 0.2505 (0.2301)	CeLoss 0.0226 (0.0339)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0016 (0.0012)	MaskLoss 0.0672 (0.0529)	MaskBCELoss 0.0215 (0.0085)	MaskDICELoss 0.0458 (0.0444)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 451 is less than current step: 499. Dropping entry: {'train/loss': 0.230096797645092, 'train/ce_loss': 0.0338623046875, 'train/seg_cls_loss': 0.0007688522338867188, 'train/kl_loss': 0.001212310791015625, 'train/mask_bce_loss': 0.008466963330283761, 'train/mask_dice_loss': 0.044430853053927424, 'train/mask_loss': 0.052897817082703115, 'metrics/total_secs_per_batch': 88.97843980789185, 'metrics/data_secs_per_batch': 39.459860396385196, '_timestamp': 1741713883.844122}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 451 is less than current step: 499. Dropping entry: {'train/lr': 0.0002886265060240964, '_timestamp': 1741713883.8447957}).
Epoch: [1][453/500]	Time 69.200 (69.200)	Loss 0.5302 (0.3932)	CeLoss 0.0254 (0.0365)	SegCLSLoss 0.0023 (0.0015)	KLLoss 0.0017 (0.0019)	MaskLoss 0.1561 (0.1004)	MaskBCELoss 0.0611 (0.0238)	MaskDICELoss 0.0949 (0.0766)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 452 is less than current step: 499. Dropping entry: {'train/loss': 0.3932228431105614, 'train/ce_loss': 0.0365234375, 'train/seg_cls_loss': 0.0015331268310546874, 'train/kl_loss': 0.001947021484375, 'train/mask_bce_loss': 0.023811943526379765, 'train/mask_dice_loss': 0.07660237476229667, 'train/mask_loss': 0.10041432045400142, 'metrics/total_secs_per_batch': 69.20040798187256, 'metrics/data_secs_per_batch': 31.31710903644562, '_timestamp': 1741713953.0440586}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 452 is less than current step: 499. Dropping entry: {'train/lr': 0.0002886144578313253, '_timestamp': 1741713953.0446355}).
Epoch: [1][454/500]	Time 80.202 (80.202)	Loss 0.4003 (0.4016)	CeLoss 0.0225 (0.0564)	SegCLSLoss 0.0031 (0.0009)	KLLoss 0.0027 (0.0022)	MaskLoss 0.0979 (0.0949)	MaskBCELoss 0.0090 (0.0186)	MaskDICELoss 0.0889 (0.0763)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 453 is less than current step: 499. Dropping entry: {'train/loss': 0.40164706073701384, 'train/ce_loss': 0.0564453125, 'train/seg_cls_loss': 0.0008523941040039062, 'train/kl_loss': 0.00220489501953125, 'train/mask_bce_loss': 0.018574930331669747, 'train/mask_dice_loss': 0.07634158357977867, 'train/mask_loss': 0.09491651505231857, 'metrics/total_secs_per_batch': 80.20212078094482, 'metrics/data_secs_per_batch': 36.42043154239654, '_timestamp': 1741714033.2477336}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 453 is less than current step: 499. Dropping entry: {'train/lr': 0.0002886024096385542, '_timestamp': 1741714033.249007}).
Epoch: [1][455/500]	Time 80.062 (80.062)	Loss 0.0156 (0.3154)	CeLoss 0.0156 (0.0490)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0022)	MaskLoss 0.0000 (0.0720)	MaskBCELoss 0.0000 (0.0122)	MaskDICELoss 0.0000 (0.0598)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 454 is less than current step: 499. Dropping entry: {'train/loss': 0.315385296754539, 'train/ce_loss': 0.0489990234375, 'train/seg_cls_loss': 0.0010507583618164062, 'train/kl_loss': 0.00218963623046875, 'train/mask_bce_loss': 0.012152171530760824, 'train/mask_dice_loss': 0.05983810871839523, 'train/mask_loss': 0.07199028246104718, 'metrics/total_secs_per_batch': 80.0622308254242, 'metrics/data_secs_per_batch': 35.811611604690555, '_timestamp': 1741714113.308144}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 454 is less than current step: 499. Dropping entry: {'train/lr': 0.0002885903614457831, '_timestamp': 1741714113.308482}).
Epoch: [1][456/500]	Time 68.690 (68.690)	Loss 0.4535 (0.4207)	CeLoss 0.0459 (0.0419)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0017 (0.0022)	MaskLoss 0.1028 (0.1063)	MaskBCELoss 0.0028 (0.0246)	MaskDICELoss 0.1000 (0.0817)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 455 is less than current step: 499. Dropping entry: {'train/loss': 0.42071193605661394, 'train/ce_loss': 0.0418701171875, 'train/seg_cls_loss': 0.0014156341552734376, 'train/kl_loss': 0.002222442626953125, 'train/mask_bce_loss': 0.024578162957914172, 'train/mask_dice_loss': 0.08168528825044633, 'train/mask_loss': 0.10626345202326774, 'metrics/total_secs_per_batch': 68.69034028053284, 'metrics/data_secs_per_batch': 29.897143769264222, '_timestamp': 1741714182.0006564}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 455 is less than current step: 499. Dropping entry: {'train/lr': 0.000288578313253012, '_timestamp': 1741714182.0022566}).
Epoch: [1][457/500]	Time 75.034 (75.034)	Loss 0.2783 (0.3395)	CeLoss 0.0688 (0.0397)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0024 (0.0019)	MaskLoss 0.0569 (0.0856)	MaskBCELoss 0.0106 (0.0226)	MaskDICELoss 0.0463 (0.0630)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 456 is less than current step: 499. Dropping entry: {'train/loss': 0.33946693418547513, 'train/ce_loss': 0.039739990234375, 'train/seg_cls_loss': 0.0013591766357421875, 'train/kl_loss': 0.001882171630859375, 'train/mask_bce_loss': 0.022594237211160363, 'train/mask_dice_loss': 0.06300076507031918, 'train/mask_loss': 0.08559500202536582, 'metrics/total_secs_per_batch': 75.03432393074036, 'metrics/data_secs_per_batch': 34.86114122867584, '_timestamp': 1741714257.0330358}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 456 is less than current step: 499. Dropping entry: {'train/lr': 0.00028856626506024093, '_timestamp': 1741714257.0333655}).
Epoch: [1][458/500]	Time 77.053 (77.053)	Loss 0.4315 (0.3664)	CeLoss 0.0247 (0.0356)	SegCLSLoss 0.0024 (0.0018)	KLLoss 0.0024 (0.0022)	MaskLoss 0.1036 (0.0911)	MaskBCELoss 0.0056 (0.0183)	MaskDICELoss 0.0980 (0.0728)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 457 is less than current step: 499. Dropping entry: {'train/loss': 0.36644346080720425, 'train/ce_loss': 0.035595703125, 'train/seg_cls_loss': 0.0017948150634765625, 'train/kl_loss': 0.0022308349609375, 'train/mask_bce_loss': 0.018333297892240807, 'train/mask_dice_loss': 0.07276404178701341, 'train/mask_loss': 0.09109733887016773, 'metrics/total_secs_per_batch': 77.0533754825592, 'metrics/data_secs_per_batch': 35.13286116123199, '_timestamp': 1741714334.0866435}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 457 is less than current step: 499. Dropping entry: {'train/lr': 0.00028855421686746984, '_timestamp': 1741714334.0872514}).
Epoch: [1][459/500]	Time 78.279 (78.279)	Loss 0.4310 (0.2944)	CeLoss 0.0199 (0.0556)	SegCLSLoss 0.0035 (0.0010)	KLLoss 0.0020 (0.0021)	MaskLoss 0.1063 (0.0682)	MaskBCELoss 0.0089 (0.0182)	MaskDICELoss 0.0974 (0.0500)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 458 is less than current step: 499. Dropping entry: {'train/loss': 0.2943810110911727, 'train/ce_loss': 0.05562744140625, 'train/seg_cls_loss': 0.0009771347045898437, 'train/kl_loss': 0.002126312255859375, 'train/mask_bce_loss': 0.018188276188448073, 'train/mask_dice_loss': 0.04996498264372349, 'train/mask_loss': 0.0681532584130764, 'metrics/total_secs_per_batch': 78.27907609939575, 'metrics/data_secs_per_batch': 37.39018874168396, '_timestamp': 1741714412.365297}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 458 is less than current step: 499. Dropping entry: {'train/lr': 0.00028854216867469875, '_timestamp': 1741714412.3655705}).
Epoch: [1][460/500]	Time 77.587 (77.587)	Loss 0.4380 (0.3383)	CeLoss 0.0286 (0.0490)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0029 (0.0023)	MaskLoss 0.1031 (0.0763)	MaskBCELoss 0.0031 (0.0094)	MaskDICELoss 0.1000 (0.0669)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 459 is less than current step: 499. Dropping entry: {'train/loss': 0.33827318996191025, 'train/ce_loss': 0.0489990234375, 'train/seg_cls_loss': 0.0013370513916015625, 'train/kl_loss': 0.002292633056640625, 'train/mask_bce_loss': 0.00939342046622187, 'train/mask_dice_loss': 0.06687842514365912, 'train/mask_loss': 0.07627184651792049, 'metrics/total_secs_per_batch': 77.58714938163757, 'metrics/data_secs_per_batch': 34.969686627388, '_timestamp': 1741714489.9532638}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 459 is less than current step: 499. Dropping entry: {'train/lr': 0.00028851807228915657, '_timestamp': 1741714489.9537928}).
Epoch: [1][461/500]	Time 74.060 (74.060)	Loss 0.4771 (0.3618)	CeLoss 0.0688 (0.0618)	SegCLSLoss 0.0012 (0.0015)	KLLoss 0.0034 (0.0026)	MaskLoss 0.1022 (0.0831)	MaskBCELoss 0.0024 (0.0179)	MaskDICELoss 0.0998 (0.0652)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 460 is less than current step: 499. Dropping entry: {'train/loss': 0.36176629886031153, 'train/ce_loss': 0.06180419921875, 'train/seg_cls_loss': 0.0015193939208984375, 'train/kl_loss': 0.00264129638671875, 'train/mask_bce_loss': 0.017886719456873833, 'train/mask_dice_loss': 0.06520182695239782, 'train/mask_loss': 0.08308854643255473, 'metrics/total_secs_per_batch': 74.06038117408752, 'metrics/data_secs_per_batch': 33.07398457527161, '_timestamp': 1741714564.0130346}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 460 is less than current step: 499. Dropping entry: {'train/lr': 0.0002885060240963855, '_timestamp': 1741714564.0135753}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 461 is less than current step: 499. Dropping entry: {'train/loss': 0.33362388275563715, 'train/ce_loss': 0.0402587890625, 'train/seg_cls_loss': 0.0010885238647460938, 'train/kl_loss': 0.00229949951171875, 'train/mask_bce_loss': 0.017325783136766405, 'train/mask_dice_loss': 0.06398624265566469, 'train/mask_loss': 0.08131202571094036, 'metrics/total_secs_per_batch': 77.21293044090271, 'metrics/data_secs_per_batch': 34.32137913703919, '_timestamp': 1741714641.226916}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 461 is less than current step: 499. Dropping entry: {'train/lr': 0.0002884939759036144, '_timestamp': 1741714641.227557}).
Epoch: [1][462/500]	Time 77.213 (77.213)	Loss 0.4832 (0.3336)	CeLoss 0.0771 (0.0403)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0030 (0.0023)	MaskLoss 0.1016 (0.0813)	MaskBCELoss 0.0016 (0.0173)	MaskDICELoss 0.1000 (0.0640)
Epoch: [1][463/500]	Time 79.199 (79.199)	Loss 0.2400 (0.3220)	CeLoss 0.0835 (0.0354)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0022 (0.0023)	MaskLoss 0.0530 (0.0836)	MaskBCELoss 0.0291 (0.0253)	MaskDICELoss 0.0238 (0.0583)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 462 is less than current step: 499. Dropping entry: {'train/loss': 0.3219645943492651, 'train/ce_loss': 0.0353515625, 'train/seg_cls_loss': 0.001255035400390625, 'train/kl_loss': 0.002349853515625, 'train/mask_bce_loss': 0.02528971794527024, 'train/mask_dice_loss': 0.05826132725924253, 'train/mask_loss': 0.08355104513466358, 'metrics/total_secs_per_batch': 79.19901609420776, 'metrics/data_secs_per_batch': 37.15674102306366, '_timestamp': 1741714720.4248786}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 462 is less than current step: 499. Dropping entry: {'train/lr': 0.00028848192771084336, '_timestamp': 1741714720.4251842}).
Epoch: [1][464/500]	Time 72.516 (72.516)	Loss 0.2544 (0.3905)	CeLoss 0.0635 (0.0390)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0021 (0.0024)	MaskLoss 0.0642 (0.0976)	MaskBCELoss 0.0340 (0.0209)	MaskDICELoss 0.0302 (0.0767)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 463 is less than current step: 499. Dropping entry: {'train/loss': 0.3904898889362812, 'train/ce_loss': 0.03897705078125, 'train/seg_cls_loss': 0.000992584228515625, 'train/kl_loss': 0.002414703369140625, 'train/mask_bce_loss': 0.020868555502966048, 'train/mask_dice_loss': 0.07672920841723681, 'train/mask_loss': 0.09759776294231415, 'metrics/total_secs_per_batch': 72.51617336273193, 'metrics/data_secs_per_batch': 32.848631620407104, '_timestamp': 1741714792.943118}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 463 is less than current step: 499. Dropping entry: {'train/lr': 0.00028846987951807227, '_timestamp': 1741714792.9445488}).
Epoch: [1][465/500]	Time 79.062 (79.062)	Loss 0.4441 (0.3509)	CeLoss 0.0151 (0.0388)	SegCLSLoss 0.0020 (0.0017)	KLLoss 0.0023 (0.0024)	MaskLoss 0.1183 (0.0864)	MaskBCELoss 0.0237 (0.0184)	MaskDICELoss 0.0945 (0.0680)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 464 is less than current step: 499. Dropping entry: {'train/loss': 0.3509157560765743, 'train/ce_loss': 0.03880615234375, 'train/seg_cls_loss': 0.00174407958984375, 'train/kl_loss': 0.002420806884765625, 'train/mask_bce_loss': 0.018386681389529258, 'train/mask_dice_loss': 0.06801069686189294, 'train/mask_loss': 0.08639737833291292, 'metrics/total_secs_per_batch': 79.0617184638977, 'metrics/data_secs_per_batch': 33.77796838283539, '_timestamp': 1741714872.0036094}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 464 is less than current step: 499. Dropping entry: {'train/lr': 0.0002884578313253012, '_timestamp': 1741714872.0046208}).
Epoch: [1][466/500]	Time 80.318 (80.318)	Loss 0.1691 (0.3516)	CeLoss 0.0825 (0.0568)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0020 (0.0021)	MaskLoss 0.0261 (0.0813)	MaskBCELoss 0.0100 (0.0166)	MaskDICELoss 0.0161 (0.0648)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 465 is less than current step: 499. Dropping entry: {'train/loss': 0.35163840651512146, 'train/ce_loss': 0.05675048828125, 'train/seg_cls_loss': 0.001090240478515625, 'train/kl_loss': 0.00208892822265625, 'train/mask_bce_loss': 0.016588154307100922, 'train/mask_dice_loss': 0.06475712433457374, 'train/mask_loss': 0.08134527932852506, 'metrics/total_secs_per_batch': 80.3176097869873, 'metrics/data_secs_per_batch': 35.750659227371216, '_timestamp': 1741714952.3207202}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 465 is less than current step: 499. Dropping entry: {'train/lr': 0.0002884457831325301, '_timestamp': 1741714952.3210633}).
Epoch: [1][467/500]	Time 78.149 (78.149)	Loss 0.4175 (0.4264)	CeLoss 0.0508 (0.0526)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0018 (0.0023)	MaskLoss 0.1011 (0.1054)	MaskBCELoss 0.0200 (0.0254)	MaskDICELoss 0.0811 (0.0800)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 466 is less than current step: 499. Dropping entry: {'train/loss': 0.4264323949813843, 'train/ce_loss': 0.0525634765625, 'train/seg_cls_loss': 0.0017345428466796875, 'train/kl_loss': 0.002252960205078125, 'train/mask_bce_loss': 0.02538966143038124, 'train/mask_dice_loss': 0.07999481186270714, 'train/mask_loss': 0.1053844727575779, 'metrics/total_secs_per_batch': 78.14898037910461, 'metrics/data_secs_per_batch': 32.807332730293275, '_timestamp': 1741715030.469555}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 466 is less than current step: 499. Dropping entry: {'train/lr': 0.000288433734939759, '_timestamp': 1741715030.4700632}).
Epoch: [1][468/500]	Time 75.113 (75.113)	Loss 0.0946 (0.2771)	CeLoss 0.0432 (0.0349)	SegCLSLoss 0.0005 (0.0019)	KLLoss 0.0025 (0.0022)	MaskLoss 0.0163 (0.0692)	MaskBCELoss 0.0083 (0.0189)	MaskDICELoss 0.0080 (0.0503)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 467 is less than current step: 499. Dropping entry: {'train/loss': 0.27708920976147056, 'train/ce_loss': 0.034869384765625, 'train/seg_cls_loss': 0.0019475936889648438, 'train/kl_loss': 0.00224761962890625, 'train/mask_bce_loss': 0.018888292054180057, 'train/mask_dice_loss': 0.0503103339811787, 'train/mask_loss': 0.06919862502254545, 'metrics/total_secs_per_batch': 75.11261510848999, 'metrics/data_secs_per_batch': 32.34242634773254, '_timestamp': 1741715105.5823643}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 467 is less than current step: 499. Dropping entry: {'train/lr': 0.0002884216867469879, '_timestamp': 1741715105.5828037}).
Epoch: [1][469/500]	Time 79.868 (79.868)	Loss 0.4330 (0.2627)	CeLoss 0.0281 (0.0418)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0023 (0.0019)	MaskLoss 0.1011 (0.0584)	MaskBCELoss 0.0011 (0.0077)	MaskDICELoss 0.1000 (0.0508)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 468 is less than current step: 499. Dropping entry: {'train/loss': 0.2627213385887444, 'train/ce_loss': 0.041827392578125, 'train/seg_cls_loss': 0.0010625839233398438, 'train/kl_loss': 0.001868438720703125, 'train/mask_bce_loss': 0.0076639396167593075, 'train/mask_dice_loss': 0.05076438137330115, 'train/mask_loss': 0.05842832000926137, 'metrics/total_secs_per_batch': 79.8678548336029, 'metrics/data_secs_per_batch': 33.57456676959991, '_timestamp': 1741715185.4500577}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 468 is less than current step: 499. Dropping entry: {'train/lr': 0.0002884096385542168, '_timestamp': 1741715185.4505315}).
Epoch: [1][470/500]	Time 78.813 (78.813)	Loss 0.2203 (0.2459)	CeLoss 0.0527 (0.0442)	SegCLSLoss 0.0017 (0.0009)	KLLoss 0.0020 (0.0019)	MaskLoss 0.0476 (0.0580)	MaskBCELoss 0.0128 (0.0163)	MaskDICELoss 0.0348 (0.0417)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 469 is less than current step: 499. Dropping entry: {'train/loss': 0.24592224108055233, 'train/ce_loss': 0.04420166015625, 'train/seg_cls_loss': 0.0008632659912109375, 'train/kl_loss': 0.001898193359375, 'train/mask_bce_loss': 0.016273267474025487, 'train/mask_dice_loss': 0.04172039031982422, 'train/mask_loss': 0.05799365863204002, 'metrics/total_secs_per_batch': 78.81270027160645, 'metrics/data_secs_per_batch': 36.51991078853607, '_timestamp': 1741715264.2628062}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 469 is less than current step: 499. Dropping entry: {'train/lr': 0.0002883855421686747, '_timestamp': 1741715264.2630928}).
Epoch: [1][471/500]	Time 79.867 (79.867)	Loss 0.4849 (0.3259)	CeLoss 0.0762 (0.0314)	SegCLSLoss 0.0014 (0.0018)	KLLoss 0.0025 (0.0024)	MaskLoss 0.1028 (0.0843)	MaskBCELoss 0.0028 (0.0230)	MaskDICELoss 0.1000 (0.0613)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 470 is less than current step: 499. Dropping entry: {'train/loss': 0.3258727561682463, 'train/ce_loss': 0.0314208984375, 'train/seg_cls_loss': 0.0018245697021484375, 'train/kl_loss': 0.00239715576171875, 'train/mask_bce_loss': 0.022950741369277237, 'train/mask_dice_loss': 0.06132094468921423, 'train/mask_loss': 0.08427168242633343, 'metrics/total_secs_per_batch': 79.86654877662659, 'metrics/data_secs_per_batch': 35.72503597736359, '_timestamp': 1741715344.1295335}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 470 is less than current step: 499. Dropping entry: {'train/lr': 0.0002883734939759036, '_timestamp': 1741715344.129907}).
Epoch: [1][472/500]	Time 83.210 (83.210)	Loss 0.2458 (0.3356)	CeLoss 0.0786 (0.0565)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0019 (0.0020)	MaskLoss 0.0439 (0.0743)	MaskBCELoss 0.0053 (0.0103)	MaskDICELoss 0.0386 (0.0639)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 471 is less than current step: 499. Dropping entry: {'train/loss': 0.33564421720802784, 'train/ce_loss': 0.056494140625, 'train/seg_cls_loss': 0.0014698028564453125, 'train/kl_loss': 0.002033233642578125, 'train/mask_bce_loss': 0.010331327753374354, 'train/mask_dice_loss': 0.06392117077484727, 'train/mask_loss': 0.07425250122323632, 'metrics/total_secs_per_batch': 83.20998406410217, 'metrics/data_secs_per_batch': 35.42358660697937, '_timestamp': 1741715427.3393714}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 471 is less than current step: 499. Dropping entry: {'train/lr': 0.0002883614457831325, '_timestamp': 1741715427.3397205}).
Epoch: [1][473/500]	Time 70.761 (70.761)	Loss 0.4968 (0.4459)	CeLoss 0.0598 (0.0553)	SegCLSLoss 0.0021 (0.0012)	KLLoss 0.0014 (0.0021)	MaskLoss 0.1266 (0.1170)	MaskBCELoss 0.0359 (0.0401)	MaskDICELoss 0.0908 (0.0769)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 472 is less than current step: 499. Dropping entry: {'train/loss': 0.445859868824482, 'train/ce_loss': 0.055322265625, 'train/seg_cls_loss': 0.0011976242065429687, 'train/kl_loss': 0.0021331787109375, 'train/mask_bce_loss': 0.040143154584802686, 'train/mask_dice_loss': 0.0768963173031807, 'train/mask_loss': 0.11703947260975837, 'metrics/total_secs_per_batch': 70.76093053817749, 'metrics/data_secs_per_batch': 32.0298849105835, '_timestamp': 1741715498.100238}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 472 is less than current step: 499. Dropping entry: {'train/lr': 0.00028834939759036143, '_timestamp': 1741715498.1005368}).
Epoch: [1][474/500]	Time 77.633 (77.633)	Loss 0.4779 (0.3175)	CeLoss 0.0693 (0.0421)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0028 (0.0019)	MaskLoss 0.1069 (0.0784)	MaskBCELoss 0.0111 (0.0204)	MaskDICELoss 0.0959 (0.0580)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 473 is less than current step: 499. Dropping entry: {'train/loss': 0.31747441086918116, 'train/ce_loss': 0.04212646484375, 'train/seg_cls_loss': 0.001323699951171875, 'train/kl_loss': 0.0018707275390625, 'train/mask_bce_loss': 0.02043979330919683, 'train/mask_dice_loss': 0.05798415653407574, 'train/mask_loss': 0.07842394858598709, 'metrics/total_secs_per_batch': 77.63298559188843, 'metrics/data_secs_per_batch': 35.77122683525086, '_timestamp': 1741715575.7332242}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 473 is less than current step: 499. Dropping entry: {'train/lr': 0.00028833734939759034, '_timestamp': 1741715575.733527}).
Epoch: [1][475/500]	Time 75.926 (75.926)	Loss 0.2411 (0.2981)	CeLoss 0.0339 (0.0498)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0027 (0.0024)	MaskLoss 0.0634 (0.0661)	MaskBCELoss 0.0247 (0.0095)	MaskDICELoss 0.0386 (0.0566)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 474 is less than current step: 499. Dropping entry: {'train/loss': 0.2981026083230972, 'train/ce_loss': 0.04984130859375, 'train/seg_cls_loss': 0.0008275985717773437, 'train/kl_loss': 0.002436065673828125, 'train/mask_bce_loss': 0.009534856167738326, 'train/mask_dice_loss': 0.056577071896754205, 'train/mask_loss': 0.06611192733980716, 'metrics/total_secs_per_batch': 75.92582321166992, 'metrics/data_secs_per_batch': 33.115050959587094, '_timestamp': 1741715651.6592116}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 474 is less than current step: 499. Dropping entry: {'train/lr': 0.00028832530120481925, '_timestamp': 1741715651.6597993}).
Epoch: [1][476/500]	Time 74.890 (74.890)	Loss 0.3705 (0.3442)	CeLoss 0.0295 (0.0511)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0028 (0.0025)	MaskLoss 0.1064 (0.0812)	MaskBCELoss 0.0441 (0.0173)	MaskDICELoss 0.0623 (0.0638)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 475 is less than current step: 499. Dropping entry: {'train/loss': 0.3442161552608013, 'train/ce_loss': 0.051080322265625, 'train/seg_cls_loss': 0.0011302947998046875, 'train/kl_loss': 0.0024822235107421877, 'train/mask_bce_loss': 0.017330722894985228, 'train/mask_dice_loss': 0.06384863751009107, 'train/mask_loss': 0.0811793607659638, 'metrics/total_secs_per_batch': 74.88961505889893, 'metrics/data_secs_per_batch': 33.2545645236969, '_timestamp': 1741715726.5485563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 475 is less than current step: 499. Dropping entry: {'train/lr': 0.00028831325301204816, '_timestamp': 1741715726.5488586}).
Epoch: [1][477/500]	Time 72.615 (72.615)	Loss 0.3688 (0.3530)	CeLoss 0.0248 (0.0394)	SegCLSLoss 0.0007 (0.0025)	KLLoss 0.0012 (0.0024)	MaskLoss 0.1085 (0.0868)	MaskBCELoss 0.0458 (0.0186)	MaskDICELoss 0.0627 (0.0682)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 476 is less than current step: 499. Dropping entry: {'train/loss': 0.3529963918030262, 'train/ce_loss': 0.0393798828125, 'train/seg_cls_loss': 0.0024646759033203126, 'train/kl_loss': 0.00241851806640625, 'train/mask_bce_loss': 0.018642188096418977, 'train/mask_dice_loss': 0.06817116811871529, 'train/mask_loss': 0.08681335654109716, 'metrics/total_secs_per_batch': 72.61453533172607, 'metrics/data_secs_per_batch': 32.18175296783447, '_timestamp': 1741715799.1635096}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 476 is less than current step: 499. Dropping entry: {'train/lr': 0.0002883012048192771, '_timestamp': 1741715799.163943}).
Epoch: [1][478/500]	Time 76.204 (76.204)	Loss 0.4886 (0.4263)	CeLoss 0.0791 (0.0533)	SegCLSLoss 0.0020 (0.0017)	KLLoss 0.0018 (0.0021)	MaskLoss 0.1033 (0.1054)	MaskBCELoss 0.0033 (0.0258)	MaskDICELoss 0.1000 (0.0796)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 477 is less than current step: 499. Dropping entry: {'train/loss': 0.42631988525390624, 'train/ce_loss': 0.05333251953125, 'train/seg_cls_loss': 0.0017459869384765625, 'train/kl_loss': 0.002072906494140625, 'train/mask_bce_loss': 0.02582575937267393, 'train/mask_dice_loss': 0.07956552710384131, 'train/mask_loss': 0.10539128854870797, 'metrics/total_secs_per_batch': 76.20429706573486, 'metrics/data_secs_per_batch': 33.72846829891205, '_timestamp': 1741715875.367782}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 477 is less than current step: 499. Dropping entry: {'train/lr': 0.000288289156626506, '_timestamp': 1741715875.368118}).
Epoch: [1][479/500]	Time 73.161 (73.161)	Loss 0.4071 (0.3286)	CeLoss 0.0249 (0.0377)	SegCLSLoss 0.0063 (0.0018)	KLLoss 0.0051 (0.0026)	MaskLoss 0.1101 (0.0806)	MaskBCELoss 0.0332 (0.0175)	MaskDICELoss 0.0769 (0.0631)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 478 is less than current step: 499. Dropping entry: {'train/loss': 0.32856066934764383, 'train/ce_loss': 0.0377197265625, 'train/seg_cls_loss': 0.0017971038818359376, 'train/kl_loss': 0.0026458740234375, 'train/mask_bce_loss': 0.017527303006500006, 'train/mask_dice_loss': 0.06305180718190968, 'train/mask_loss': 0.08057911107316613, 'metrics/total_secs_per_batch': 73.1614990234375, 'metrics/data_secs_per_batch': 33.07778496742249, '_timestamp': 1741715948.5290668}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 478 is less than current step: 499. Dropping entry: {'train/lr': 0.0002882771084337349, '_timestamp': 1741715948.5293949}).
Epoch: [1][480/500]	Time 63.356 (63.356)	Loss 0.3474 (0.3392)	CeLoss 0.0635 (0.0416)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0030 (0.0027)	MaskLoss 0.0754 (0.0846)	MaskBCELoss 0.0108 (0.0221)	MaskDICELoss 0.0646 (0.0626)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 479 is less than current step: 499. Dropping entry: {'train/loss': 0.33919734358787534, 'train/ce_loss': 0.0416015625, 'train/seg_cls_loss': 0.0008481979370117187, 'train/kl_loss': 0.002736663818359375, 'train/mask_bce_loss': 0.022055437741801142, 'train/mask_dice_loss': 0.06256311871111393, 'train/mask_loss': 0.0846185578033328, 'metrics/total_secs_per_batch': 63.35608124732971, 'metrics/data_secs_per_batch': 33.09767637252808, '_timestamp': 1741716011.8862703}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 479 is less than current step: 499. Dropping entry: {'train/lr': 0.0002882530120481927, '_timestamp': 1741716011.887249}).
Epoch: [1][481/500]	Time 69.369 (69.369)	Loss 0.4750 (0.3414)	CeLoss 0.0625 (0.0458)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0028 (0.0020)	MaskLoss 0.1047 (0.0776)	MaskBCELoss 0.0047 (0.0086)	MaskDICELoss 0.1000 (0.0690)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 480 is less than current step: 499. Dropping entry: {'train/loss': 0.34138373769819735, 'train/ce_loss': 0.045849609375, 'train/seg_cls_loss': 0.0007007598876953125, 'train/kl_loss': 0.001984405517578125, 'train/mask_bce_loss': 0.008597767946776002, 'train/mask_dice_loss': 0.06900115292519331, 'train/mask_loss': 0.07759892009198666, 'metrics/total_secs_per_batch': 69.36921763420105, 'metrics/data_secs_per_batch': 25.935851168632507, '_timestamp': 1741716081.254572}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 480 is less than current step: 499. Dropping entry: {'train/lr': 0.00028824096385542163, '_timestamp': 1741716081.2550068}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 481 is less than current step: 499. Dropping entry: {'train/loss': 0.30763357486575843, 'train/ce_loss': 0.04678955078125, 'train/seg_cls_loss': 0.0010480880737304688, 'train/kl_loss': 0.00250396728515625, 'train/mask_bce_loss': 0.026799996936460957, 'train/mask_dice_loss': 0.051071873190812765, 'train/mask_loss': 0.07787186787463725, 'metrics/total_secs_per_batch': 79.58829283714294, 'metrics/data_secs_per_batch': 33.20070788860321, '_timestamp': 1741716160.8427913}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 481 is less than current step: 499. Dropping entry: {'train/lr': 0.00028822891566265054, '_timestamp': 1741716160.843119}).
Epoch: [1][482/500]	Time 79.588 (79.588)	Loss 0.6625 (0.3076)	CeLoss 0.0771 (0.0468)	SegCLSLoss 0.0011 (0.0010)	KLLoss 0.0032 (0.0025)	MaskLoss 0.1959 (0.0779)	MaskBCELoss 0.1008 (0.0268)	MaskDICELoss 0.0951 (0.0511)
Epoch: [1][483/500]	Time 55.185 (55.185)	Loss 0.4094 (0.3833)	CeLoss 0.0212 (0.0285)	SegCLSLoss 0.0022 (0.0020)	KLLoss 0.0034 (0.0022)	MaskLoss 0.0977 (0.1003)	MaskBCELoss 0.0035 (0.0247)	MaskDICELoss 0.0941 (0.0755)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 482 is less than current step: 499. Dropping entry: {'train/loss': 0.38329332061111926, 'train/ce_loss': 0.02845458984375, 'train/seg_cls_loss': 0.0020032882690429687, 'train/kl_loss': 0.00218048095703125, 'train/mask_bce_loss': 0.02474929897580296, 'train/mask_dice_loss': 0.07554096840322018, 'train/mask_loss': 0.10029026791453362, 'metrics/total_secs_per_batch': 55.18535780906677, 'metrics/data_secs_per_batch': 24.124208855628968, '_timestamp': 1741716216.0296357}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 482 is less than current step: 499. Dropping entry: {'train/lr': 0.0002882168674698795, '_timestamp': 1741716216.0306053}).
Epoch: [1][484/500]	Time 62.976 (62.976)	Loss 0.5358 (0.3194)	CeLoss 0.0654 (0.0419)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0030 (0.0015)	MaskLoss 0.1342 (0.0755)	MaskBCELoss 0.0351 (0.0134)	MaskDICELoss 0.0991 (0.0622)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 483 is less than current step: 499. Dropping entry: {'train/loss': 0.3194318755529821, 'train/ce_loss': 0.041925048828125, 'train/seg_cls_loss': 0.0009319305419921875, 'train/kl_loss': 0.001537322998046875, 'train/mask_bce_loss': 0.013358685025013983, 'train/mask_dice_loss': 0.06218985840678215, 'train/mask_loss': 0.07554854229092597, 'metrics/total_secs_per_batch': 62.975863218307495, 'metrics/data_secs_per_batch': 31.40630736351013, '_timestamp': 1741716279.003821}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 483 is less than current step: 499. Dropping entry: {'train/lr': 0.0002882048192771084, '_timestamp': 1741716279.0041928}).
Epoch: [1][485/500]	Time 59.908 (59.908)	Loss 0.4607 (0.3716)	CeLoss 0.0515 (0.0497)	SegCLSLoss 0.0008 (0.0009)	KLLoss 0.0014 (0.0021)	MaskLoss 0.1043 (0.0895)	MaskBCELoss 0.0048 (0.0193)	MaskDICELoss 0.0995 (0.0702)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 484 is less than current step: 499. Dropping entry: {'train/loss': 0.3716043919324875, 'train/ce_loss': 0.04971923828125, 'train/seg_cls_loss': 0.00090179443359375, 'train/kl_loss': 0.002093505859375, 'train/mask_bce_loss': 0.019307535456027834, 'train/mask_dice_loss': 0.07018580758012831, 'train/mask_loss': 0.08949334211647511, 'metrics/total_secs_per_batch': 59.90794062614441, 'metrics/data_secs_per_batch': 28.541893911361694, '_timestamp': 1741716338.9132261}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 484 is less than current step: 499. Dropping entry: {'train/lr': 0.0002881927710843373, '_timestamp': 1741716338.9135947}).
Epoch: [1][486/500]	Time 50.244 (50.244)	Loss 0.4449 (0.3794)	CeLoss 0.0206 (0.0413)	SegCLSLoss 0.0021 (0.0014)	KLLoss 0.0033 (0.0023)	MaskLoss 0.1207 (0.0932)	MaskBCELoss 0.0314 (0.0187)	MaskDICELoss 0.0893 (0.0744)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 485 is less than current step: 499. Dropping entry: {'train/loss': 0.37941542491316793, 'train/ce_loss': 0.04132080078125, 'train/seg_cls_loss': 0.0014293670654296875, 'train/kl_loss': 0.00234832763671875, 'train/mask_bce_loss': 0.018745783972553907, 'train/mask_dice_loss': 0.07440674686804413, 'train/mask_loss': 0.0931525282561779, 'metrics/total_secs_per_batch': 50.24433422088623, 'metrics/data_secs_per_batch': 22.150932717323304, '_timestamp': 1741716389.1563568}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 485 is less than current step: 499. Dropping entry: {'train/lr': 0.00028818072289156624, '_timestamp': 1741716389.1569352}).
Epoch: [1][487/500]	Time 44.974 (44.974)	Loss 0.0162 (0.2744)	CeLoss 0.0162 (0.0534)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0017)	MaskLoss 0.0000 (0.0671)	MaskBCELoss 0.0000 (0.0248)	MaskDICELoss 0.0000 (0.0423)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 486 is less than current step: 499. Dropping entry: {'train/loss': 0.2743704801425338, 'train/ce_loss': 0.05340576171875, 'train/seg_cls_loss': 0.0008119583129882812, 'train/kl_loss': 0.001651763916015625, 'train/mask_bce_loss': 0.02484331917949021, 'train/mask_dice_loss': 0.04227691907435656, 'train/mask_loss': 0.06712023727595806, 'metrics/total_secs_per_batch': 44.973942279815674, 'metrics/data_secs_per_batch': 19.953539109230043, '_timestamp': 1741716434.1301966}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 486 is less than current step: 499. Dropping entry: {'train/lr': 0.00028816867469879515, '_timestamp': 1741716434.1306713}).
Epoch: [1][488/500]	Time 50.744 (50.744)	Loss 0.3880 (0.3568)	CeLoss 0.0547 (0.0420)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0042 (0.0030)	MaskLoss 0.1122 (0.0922)	MaskBCELoss 0.0600 (0.0288)	MaskDICELoss 0.0523 (0.0634)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 487 is less than current step: 499. Dropping entry: {'train/loss': 0.35680186897516253, 'train/ce_loss': 0.04197998046875, 'train/seg_cls_loss': 0.0010370254516601563, 'train/kl_loss': 0.003018951416015625, 'train/mask_bce_loss': 0.028764588525518775, 'train/mask_dice_loss': 0.06344854338094592, 'train/mask_loss': 0.09221313055604696, 'metrics/total_secs_per_batch': 50.744428873062134, 'metrics/data_secs_per_batch': 21.826350855827332, '_timestamp': 1741716484.8757331}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 487 is less than current step: 499. Dropping entry: {'train/lr': 0.00028815662650602406, '_timestamp': 1741716484.8767288}).
Epoch: [1][489/500]	Time 48.304 (48.304)	Loss 0.2397 (0.2837)	CeLoss 0.0369 (0.0430)	SegCLSLoss 0.0066 (0.0016)	KLLoss 0.0023 (0.0019)	MaskLoss 0.0663 (0.0710)	MaskBCELoss 0.0340 (0.0230)	MaskDICELoss 0.0323 (0.0480)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 488 is less than current step: 499. Dropping entry: {'train/loss': 0.28374172691255806, 'train/ce_loss': 0.043017578125, 'train/seg_cls_loss': 0.0015777587890625, 'train/kl_loss': 0.00189666748046875, 'train/mask_bce_loss': 0.022971334308385848, 'train/mask_dice_loss': 0.04801421985030174, 'train/mask_loss': 0.0709855530411005, 'metrics/total_secs_per_batch': 48.30399680137634, 'metrics/data_secs_per_batch': 21.340063858032227, '_timestamp': 1741716533.1796112}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 488 is less than current step: 499. Dropping entry: {'train/lr': 0.00028814457831325297, '_timestamp': 1741716533.1805432}).
Epoch: [1][490/500]	Time 45.783 (45.783)	Loss 0.4142 (0.3952)	CeLoss 0.0693 (0.0480)	SegCLSLoss 0.0017 (0.0016)	KLLoss 0.0020 (0.0021)	MaskLoss 0.1190 (0.0952)	MaskBCELoss 0.0669 (0.0182)	MaskDICELoss 0.0522 (0.0770)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 489 is less than current step: 499. Dropping entry: {'train/loss': 0.395156417042017, 'train/ce_loss': 0.04798583984375, 'train/seg_cls_loss': 0.001575469970703125, 'train/kl_loss': 0.00212554931640625, 'train/mask_bce_loss': 0.018191266735084356, 'train/mask_dice_loss': 0.07697862801142037, 'train/mask_loss': 0.09516989598050714, 'metrics/total_secs_per_batch': 45.78292202949524, 'metrics/data_secs_per_batch': 19.84307768344879, '_timestamp': 1741716578.9637425}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 489 is less than current step: 499. Dropping entry: {'train/lr': 0.00028812048192771085, '_timestamp': 1741716578.964058}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 490 is less than current step: 499. Dropping entry: {'train/loss': 0.313978205062449, 'train/ce_loss': 0.02869873046875, 'train/seg_cls_loss': 0.0013856887817382812, 'train/kl_loss': 0.002074432373046875, 'train/mask_bce_loss': 0.02199854189530015, 'train/mask_dice_loss': 0.05963639346882701, 'train/mask_loss': 0.08163493387401104, 'metrics/total_secs_per_batch': 47.35855746269226, 'metrics/data_secs_per_batch': 19.806611251831054, '_timestamp': 1741716626.320002}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 490 is less than current step: 499. Dropping entry: {'train/lr': 0.00028810843373493976, '_timestamp': 1741716626.320446}).
Epoch: [1][491/500]	Time 47.359 (47.359)	Loss 0.0188 (0.3140)	CeLoss 0.0188 (0.0287)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0816)	MaskBCELoss 0.0000 (0.0220)	MaskDICELoss 0.0000 (0.0596)
Epoch: [1][492/500]	Time 50.459 (50.459)	Loss 0.4328 (0.4425)	CeLoss 0.0212 (0.0422)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0026 (0.0021)	MaskLoss 0.1056 (0.1169)	MaskBCELoss 0.0071 (0.0351)	MaskDICELoss 0.0985 (0.0818)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 491 is less than current step: 499. Dropping entry: {'train/loss': 0.442453533411026, 'train/ce_loss': 0.0421630859375, 'train/seg_cls_loss': 0.001264190673828125, 'train/kl_loss': 0.002101898193359375, 'train/mask_bce_loss': 0.035130853136070075, 'train/mask_dice_loss': 0.08180039525032043, 'train/mask_loss': 0.11693124920129776, 'metrics/total_secs_per_batch': 50.45917868614197, 'metrics/data_secs_per_batch': 21.765704011917116, '_timestamp': 1741716676.779106}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 491 is less than current step: 499. Dropping entry: {'train/lr': 0.00028809638554216867, '_timestamp': 1741716676.779532}).
Epoch: [1][493/500]	Time 51.641 (51.641)	Loss 0.0566 (0.2874)	CeLoss 0.0566 (0.0425)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0694)	MaskBCELoss 0.0000 (0.0175)	MaskDICELoss 0.0000 (0.0519)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 492 is less than current step: 499. Dropping entry: {'train/loss': 0.2874353057704866, 'train/ce_loss': 0.0425048828125, 'train/seg_cls_loss': 0.0007314682006835938, 'train/kl_loss': 0.00185089111328125, 'train/mask_bce_loss': 0.017536099045537414, 'train/mask_dice_loss': 0.05188960507512093, 'train/mask_loss': 0.0694257065653801, 'metrics/total_secs_per_batch': 51.64076852798462, 'metrics/data_secs_per_batch': 22.53601005077362, '_timestamp': 1741716728.4212146}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 492 is less than current step: 499. Dropping entry: {'train/lr': 0.0002880843373493976, '_timestamp': 1741716728.4219484}).
Epoch: [1][494/500]	Time 50.249 (50.249)	Loss 0.0735 (0.2782)	CeLoss 0.0540 (0.0382)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0035 (0.0023)	MaskLoss 0.0050 (0.0706)	MaskBCELoss 0.0020 (0.0226)	MaskDICELoss 0.0030 (0.0480)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 493 is less than current step: 499. Dropping entry: {'train/loss': 0.2782154427841306, 'train/ce_loss': 0.0382080078125, 'train/seg_cls_loss': 0.0014209747314453125, 'train/kl_loss': 0.00225372314453125, 'train/mask_bce_loss': 0.022604110953398048, 'train/mask_dice_loss': 0.04796860150527209, 'train/mask_loss': 0.07057271185331046, 'metrics/total_secs_per_batch': 50.248947620391846, 'metrics/data_secs_per_batch': 22.809073328971863, '_timestamp': 1741716778.6698878}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 493 is less than current step: 499. Dropping entry: {'train/lr': 0.0002880722891566265, '_timestamp': 1741716778.6709442}).
Epoch: [1][495/500]	Time 48.048 (48.048)	Loss 0.4148 (0.3991)	CeLoss 0.0386 (0.0513)	SegCLSLoss 0.0011 (0.0018)	KLLoss 0.0029 (0.0026)	MaskLoss 0.1223 (0.1064)	MaskBCELoss 0.0583 (0.0407)	MaskDICELoss 0.0640 (0.0657)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 494 is less than current step: 499. Dropping entry: {'train/loss': 0.39910057932138443, 'train/ce_loss': 0.05126953125, 'train/seg_cls_loss': 0.001792144775390625, 'train/kl_loss': 0.00258941650390625, 'train/mask_bce_loss': 0.04068098249845207, 'train/mask_dice_loss': 0.06573836440220475, 'train/mask_loss': 0.10641934722661972, 'metrics/total_secs_per_batch': 48.04831337928772, 'metrics/data_secs_per_batch': 20.77898108959198, '_timestamp': 1741716826.7183652}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 494 is less than current step: 499. Dropping entry: {'train/lr': 0.0002880602409638554, '_timestamp': 1741716826.7194254}).
Epoch: [1][496/500]	Time 48.097 (48.097)	Loss 0.8234 (0.4364)	CeLoss 0.0972 (0.0469)	SegCLSLoss 0.0011 (0.0010)	KLLoss 0.0019 (0.0020)	MaskLoss 0.2652 (0.1101)	MaskBCELoss 0.1685 (0.0267)	MaskDICELoss 0.0967 (0.0834)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 495 is less than current step: 499. Dropping entry: {'train/loss': 0.4364024270325899, 'train/ce_loss': 0.046875, 'train/seg_cls_loss': 0.0010265350341796876, 'train/kl_loss': 0.002002716064453125, 'train/mask_bce_loss': 0.026681256073061377, 'train/mask_dice_loss': 0.08342965468764305, 'train/mask_loss': 0.11011091247200966, 'metrics/total_secs_per_batch': 48.09678101539612, 'metrics/data_secs_per_batch': 22.61058964729309, '_timestamp': 1741716874.8147476}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 495 is less than current step: 499. Dropping entry: {'train/lr': 0.0002880481927710843, '_timestamp': 1741716874.815548}).
Epoch: [1][497/500]	Time 49.275 (49.275)	Loss 0.1769 (0.3579)	CeLoss 0.0247 (0.0361)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0021 (0.0026)	MaskLoss 0.0553 (0.0926)	MaskBCELoss 0.0359 (0.0259)	MaskDICELoss 0.0194 (0.0667)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 496 is less than current step: 499. Dropping entry: {'train/loss': 0.35793939922004936, 'train/ce_loss': 0.036138916015625, 'train/seg_cls_loss': 0.0014225006103515624, 'train/kl_loss': 0.0025909423828125, 'train/mask_bce_loss': 0.02588783230166882, 'train/mask_dice_loss': 0.06669474244117737, 'train/mask_loss': 0.0925825759768486, 'metrics/total_secs_per_batch': 49.274885177612305, 'metrics/data_secs_per_batch': 21.221179366111755, '_timestamp': 1741716924.088898}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 496 is less than current step: 499. Dropping entry: {'train/lr': 0.0002880361445783132, '_timestamp': 1741716924.0891638}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 497 is less than current step: 499. Dropping entry: {'train/loss': 0.31681078374385835, 'train/ce_loss': 0.0410400390625, 'train/seg_cls_loss': 0.001592254638671875, 'train/kl_loss': 0.002407073974609375, 'train/mask_bce_loss': 0.01188181615434587, 'train/mask_dice_loss': 0.062190010119229554, 'train/mask_loss': 0.07407182715833187, 'metrics/total_secs_per_batch': 47.84205889701843, 'metrics/data_secs_per_batch': 20.793716430664062, '_timestamp': 1741716971.9314873}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 497 is less than current step: 499. Dropping entry: {'train/lr': 0.00028802409638554213, '_timestamp': 1741716971.9320536}).
Epoch: [1][498/500]	Time 47.842 (47.842)	Loss 0.1883 (0.3168)	CeLoss 0.0209 (0.0410)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0016 (0.0024)	MaskLoss 0.0439 (0.0741)	MaskBCELoss 0.0051 (0.0119)	MaskDICELoss 0.0388 (0.0622)
Epoch: [1][499/500]	Time 50.178 (50.178)	Loss 0.2042 (0.3993)	CeLoss 0.0251 (0.0428)	SegCLSLoss 0.0023 (0.0009)	KLLoss 0.0013 (0.0027)	MaskLoss 0.0478 (0.1033)	MaskBCELoss 0.0073 (0.0299)	MaskDICELoss 0.0405 (0.0734)
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 498 is less than current step: 499. Dropping entry: {'train/loss': 0.3993273377418518, 'train/ce_loss': 0.0427978515625, 'train/seg_cls_loss': 0.0009141921997070313, 'train/kl_loss': 0.00273895263671875, 'train/mask_bce_loss': 0.02994040190242231, 'train/mask_dice_loss': 0.07335528451949358, 'train/mask_loss': 0.10329568684101105, 'metrics/total_secs_per_batch': 50.178359508514404, 'metrics/data_secs_per_batch': 23.6367506980896, '_timestamp': 1741717022.109694}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 498 is less than current step: 499. Dropping entry: {'train/lr': 0.00028801204819277104, '_timestamp': 1741717022.1100569}).
  0%|                                                                                                                                                              | 0/200 [00:00<?, ?it/s]
[2025-03-11 13:17:55,347] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[0.00028799999999999995], mom=[(0.9, 0.95)]
[2025-03-11 13:17:55,359] [INFO] [timer.py:215:stop] epoch=0/micro_step=1000/global_step=100, RunningAvgSamplesPerSec=0.7813667582713971, CurrSamplesPerSec=0.7655652115219361, MemAllocated=60.24GB, MaxMemAllocated=74.15GB


































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:07<00:00,  2.95it/s]
giou: 0.2542, ciou: 0.2220
[2025-03-11 13:19:10,153] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 499. Dropping entry: {'val/giou': 0.2541801333427429, 'val/ciou': 0.2219816893339157, '_timestamp': 1741717143.2479513}).
[2025-03-11 13:19:54,454] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step100/mp_rank_00_model_states.pt
[2025-03-11 13:19:54,455] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step100/mp_rank_00_model_states.pt...
[2025-03-11 13:24:55,906] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step100/mp_rank_00_model_states.pt.
[2025-03-11 13:24:58,330] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-11 13:25:12,807] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-11 13:25:12,889] [INFO] [engine.py:3244:_save_zero_checkpoint] zero checkpoint saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-11 13:25:12,890] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
Epoch: [2][  1/500]	Time 75.337 (75.337)	Loss 0.3415 (0.3915)	CeLoss 0.0295 (0.0438)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0035 (0.0023)	MaskLoss 0.1017 (0.0973)	MaskBCELoss 0.0493 (0.0223)	MaskDICELoss 0.0524 (0.0751)
Epoch: [2][  2/500]	Time 70.542 (70.542)	Loss 0.5022 (0.3548)	CeLoss 0.0737 (0.0437)	SegCLSLoss 0.0020 (0.0022)	KLLoss 0.0023 (0.0019)	MaskLoss 0.1181 (0.0886)	MaskBCELoss 0.0237 (0.0232)	MaskDICELoss 0.0944 (0.0654)
Epoch: [2][  3/500]	Time 74.768 (74.768)	Loss 0.1196 (0.3791)	CeLoss 0.0240 (0.0543)	SegCLSLoss 0.0012 (0.0017)	KLLoss 0.0014 (0.0020)	MaskLoss 0.0340 (0.0946)	MaskBCELoss 0.0211 (0.0282)	MaskDICELoss 0.0129 (0.0664)
Epoch: [2][  4/500]	Time 73.666 (73.666)	Loss 0.4263 (0.3712)	CeLoss 0.0177 (0.0298)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0035 (0.0027)	MaskLoss 0.1025 (0.1004)	MaskBCELoss 0.0027 (0.0318)	MaskDICELoss 0.0998 (0.0686)
Epoch: [2][  5/500]	Time 78.044 (78.044)	Loss 0.4623 (0.3183)	CeLoss 0.0420 (0.0347)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0027 (0.0023)	MaskLoss 0.1155 (0.0768)	MaskBCELoss 0.0225 (0.0132)	MaskDICELoss 0.0931 (0.0636)
Epoch: [2][  6/500]	Time 75.209 (75.209)	Loss 0.2699 (0.3481)	CeLoss 0.0625 (0.0484)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0031 (0.0025)	MaskLoss 0.0720 (0.0843)	MaskBCELoss 0.0421 (0.0202)	MaskDICELoss 0.0300 (0.0641)
Epoch: [2][  7/500]	Time 79.964 (79.964)	Loss 0.4986 (0.4112)	CeLoss 0.0344 (0.0422)	SegCLSLoss 0.0002 (0.0010)	KLLoss 0.0029 (0.0025)	MaskLoss 0.1389 (0.1052)	MaskBCELoss 0.0472 (0.0275)	MaskDICELoss 0.0917 (0.0777)
Epoch: [2][  8/500]	Time 72.373 (72.373)	Loss 0.4706 (0.3686)	CeLoss 0.0742 (0.0517)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0022 (0.0023)	MaskLoss 0.1013 (0.0862)	MaskBCELoss 0.0060 (0.0154)	MaskDICELoss 0.0953 (0.0708)
Epoch: [2][  9/500]	Time 74.567 (74.567)	Loss 0.3780 (0.4361)	CeLoss 0.0204 (0.0483)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0031 (0.0030)	MaskLoss 0.0952 (0.1146)	MaskBCELoss 0.0136 (0.0371)	MaskDICELoss 0.0817 (0.0775)
Epoch: [2][ 10/500]	Time 74.984 (74.984)	Loss 0.4096 (0.3100)	CeLoss 0.0540 (0.0406)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0019 (0.0023)	MaskLoss 0.0909 (0.0801)	MaskBCELoss 0.0052 (0.0270)	MaskDICELoss 0.0858 (0.0532)
Epoch: [2][ 11/500]	Time 71.730 (71.730)	Loss 0.4271 (0.3238)	CeLoss 0.0266 (0.0319)	SegCLSLoss 0.0013 (0.0020)	KLLoss 0.0022 (0.0022)	MaskLoss 0.1007 (0.0783)	MaskBCELoss 0.0026 (0.0122)	MaskDICELoss 0.0982 (0.0661)
Epoch: [2][ 12/500]	Time 80.623 (80.623)	Loss 0.2351 (0.4416)	CeLoss 0.0322 (0.0527)	SegCLSLoss 0.0009 (0.0009)	KLLoss 0.0020 (0.0023)	MaskLoss 0.0708 (0.1116)	MaskBCELoss 0.0414 (0.0302)	MaskDICELoss 0.0294 (0.0814)
Epoch: [2][ 13/500]	Time 81.390 (81.390)	Loss 0.4755 (0.4359)	CeLoss 0.0674 (0.0466)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0023 (0.0027)	MaskLoss 0.1026 (0.1085)	MaskBCELoss 0.0026 (0.0241)	MaskDICELoss 0.1000 (0.0844)
Epoch: [2][ 14/500]	Time 71.597 (71.597)	Loss 0.7965 (0.4518)	CeLoss 0.0264 (0.0373)	SegCLSLoss 0.0013 (0.0014)	KLLoss 0.0020 (0.0019)	MaskLoss 0.2932 (0.1196)	MaskBCELoss 0.2027 (0.0334)	MaskDICELoss 0.0906 (0.0863)
Epoch: [2][ 15/500]	Time 74.206 (74.206)	Loss 0.4634 (0.4543)	CeLoss 0.0515 (0.0617)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0018 (0.0027)	MaskLoss 0.1178 (0.1091)	MaskBCELoss 0.0309 (0.0235)	MaskDICELoss 0.0869 (0.0856)
Epoch: [2][ 16/500]	Time 74.559 (74.559)	Loss 0.4788 (0.3834)	CeLoss 0.0674 (0.0470)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0027 (0.0023)	MaskLoss 0.1083 (0.0900)	MaskBCELoss 0.0123 (0.0132)	MaskDICELoss 0.0960 (0.0768)
Epoch: [2][ 17/500]	Time 72.466 (72.466)	Loss 0.2566 (0.3161)	CeLoss 0.0239 (0.0269)	SegCLSLoss 0.0020 (0.0020)	KLLoss 0.0031 (0.0027)	MaskLoss 0.0648 (0.0793)	MaskBCELoss 0.0152 (0.0158)	MaskDICELoss 0.0496 (0.0635)
Epoch: [2][ 18/500]	Time 75.068 (75.068)	Loss 0.3648 (0.3757)	CeLoss 0.0216 (0.0515)	SegCLSLoss 0.0031 (0.0019)	KLLoss 0.0028 (0.0026)	MaskLoss 0.0897 (0.0961)	MaskBCELoss 0.0100 (0.0319)	MaskDICELoss 0.0797 (0.0642)
Epoch: [2][ 19/500]	Time 80.936 (80.936)	Loss 0.4697 (0.3315)	CeLoss 0.0593 (0.0498)	SegCLSLoss 0.0008 (0.0015)	KLLoss 0.0033 (0.0024)	MaskLoss 0.1051 (0.0760)	MaskBCELoss 0.0068 (0.0127)	MaskDICELoss 0.0983 (0.0633)
Epoch: [2][ 20/500]	Time 75.496 (75.496)	Loss 0.4310 (0.3498)	CeLoss 0.0216 (0.0392)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0022 (0.0028)	MaskLoss 0.1033 (0.0866)	MaskBCELoss 0.0034 (0.0197)	MaskDICELoss 0.0999 (0.0670)
Epoch: [2][ 21/500]	Time 70.445 (70.445)	Loss 0.4728 (0.3536)	CeLoss 0.0640 (0.0433)	SegCLSLoss 0.0017 (0.0017)	KLLoss 0.0021 (0.0020)	MaskLoss 0.1056 (0.0893)	MaskBCELoss 0.0083 (0.0250)	MaskDICELoss 0.0974 (0.0643)
Epoch: [2][ 22/500]	Time 72.291 (72.291)	Loss 0.4331 (0.4479)	CeLoss 0.0251 (0.0491)	SegCLSLoss 0.0012 (0.0017)	KLLoss 0.0030 (0.0027)	MaskLoss 0.1022 (0.1160)	MaskBCELoss 0.0022 (0.0344)	MaskDICELoss 0.1000 (0.0816)
Epoch: [2][ 23/500]	Time 76.357 (76.357)	Loss 0.4146 (0.3779)	CeLoss 0.0231 (0.0499)	SegCLSLoss 0.0066 (0.0013)	KLLoss 0.0045 (0.0029)	MaskLoss 0.1185 (0.0972)	MaskBCELoss 0.0451 (0.0321)	MaskDICELoss 0.0734 (0.0650)
Epoch: [2][ 24/500]	Time 78.128 (78.128)	Loss 0.0494 (0.3804)	CeLoss 0.0493 (0.0510)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0956)	MaskBCELoss 0.0000 (0.0277)	MaskDICELoss 0.0000 (0.0679)
Epoch: [2][ 25/500]	Time 71.677 (71.677)	Loss 0.3550 (0.4230)	CeLoss 0.0359 (0.0357)	SegCLSLoss 0.0042 (0.0026)	KLLoss 0.0033 (0.0026)	MaskLoss 0.0884 (0.1050)	MaskBCELoss 0.0201 (0.0183)	MaskDICELoss 0.0684 (0.0867)
Epoch: [2][ 26/500]	Time 81.539 (81.539)	Loss 0.1779 (0.3412)	CeLoss 0.0454 (0.0379)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0041 (0.0026)	MaskLoss 0.0441 (0.0783)	MaskBCELoss 0.0241 (0.0065)	MaskDICELoss 0.0201 (0.0717)
Epoch: [2][ 27/500]	Time 73.672 (73.672)	Loss 0.4920 (0.4003)	CeLoss 0.0903 (0.0422)	SegCLSLoss 0.0028 (0.0018)	KLLoss 0.0038 (0.0029)	MaskLoss 0.1114 (0.1014)	MaskBCELoss 0.0247 (0.0257)	MaskDICELoss 0.0867 (0.0757)
Epoch: [2][ 28/500]	Time 83.513 (83.513)	Loss 0.4466 (0.3499)	CeLoss 0.0233 (0.0432)	SegCLSLoss 0.0025 (0.0013)	KLLoss 0.0029 (0.0026)	MaskLoss 0.1099 (0.0816)	MaskBCELoss 0.0102 (0.0114)	MaskDICELoss 0.0997 (0.0702)
Epoch: [2][ 29/500]	Time 71.505 (71.505)	Loss 0.3895 (0.3775)	CeLoss 0.0239 (0.0339)	SegCLSLoss 0.0017 (0.0016)	KLLoss 0.0023 (0.0025)	MaskLoss 0.1005 (0.0943)	MaskBCELoss 0.0199 (0.0184)	MaskDICELoss 0.0807 (0.0759)
Epoch: [2][ 30/500]	Time 71.415 (71.415)	Loss 0.4094 (0.3332)	CeLoss 0.0233 (0.0367)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0022 (0.0020)	MaskLoss 0.0964 (0.0787)	MaskBCELoss 0.0012 (0.0105)	MaskDICELoss 0.0953 (0.0683)
Epoch: [2][ 31/500]	Time 74.251 (74.251)	Loss 0.0277 (0.3822)	CeLoss 0.0277 (0.0529)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0022)	MaskLoss 0.0000 (0.0939)	MaskBCELoss 0.0000 (0.0245)	MaskDICELoss 0.0000 (0.0694)
Epoch: [2][ 32/500]	Time 80.672 (80.672)	Loss 0.4263 (0.3731)	CeLoss 0.0540 (0.0493)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0021 (0.0021)	MaskLoss 0.0994 (0.0861)	MaskBCELoss 0.0140 (0.0116)	MaskDICELoss 0.0854 (0.0745)
Epoch: [2][ 33/500]	Time 72.192 (72.192)	Loss 0.4339 (0.3307)	CeLoss 0.0535 (0.0559)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0040 (0.0029)	MaskLoss 0.1112 (0.0816)	MaskBCELoss 0.0344 (0.0276)	MaskDICELoss 0.0768 (0.0540)
Epoch: [2][ 34/500]	Time 79.090 (79.090)	Loss 0.2706 (0.3248)	CeLoss 0.0781 (0.0345)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0018 (0.0021)	MaskLoss 0.0683 (0.0793)	MaskBCELoss 0.0416 (0.0148)	MaskDICELoss 0.0267 (0.0645)
Epoch: [2][ 35/500]	Time 78.788 (78.788)	Loss 0.3971 (0.2920)	CeLoss 0.0610 (0.0367)	SegCLSLoss 0.0040 (0.0014)	KLLoss 0.0026 (0.0022)	MaskLoss 0.0998 (0.0691)	MaskBCELoss 0.0340 (0.0119)	MaskDICELoss 0.0659 (0.0571)
Epoch: [2][ 36/500]	Time 81.707 (81.707)	Loss 0.3704 (0.4662)	CeLoss 0.0630 (0.0547)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0028 (0.0027)	MaskLoss 0.0767 (0.1224)	MaskBCELoss 0.0010 (0.0406)	MaskDICELoss 0.0757 (0.0818)
Epoch: [2][ 37/500]	Time 78.173 (78.173)	Loss 0.4150 (0.2897)	CeLoss 0.0270 (0.0428)	SegCLSLoss 0.0011 (0.0017)	KLLoss 0.0027 (0.0024)	MaskLoss 0.1027 (0.0726)	MaskBCELoss 0.0129 (0.0235)	MaskDICELoss 0.0897 (0.0492)
Epoch: [2][ 38/500]	Time 67.941 (67.941)	Loss 0.3496 (0.3843)	CeLoss 0.0286 (0.0553)	SegCLSLoss 0.0018 (0.0017)	KLLoss 0.0006 (0.0022)	MaskLoss 0.0807 (0.0893)	MaskBCELoss 0.0017 (0.0156)	MaskDICELoss 0.0790 (0.0737)
Epoch: [2][ 39/500]	Time 87.100 (87.100)	Loss 0.4290 (0.4438)	CeLoss 0.0261 (0.0444)	SegCLSLoss 0.0015 (0.0019)	KLLoss 0.0017 (0.0029)	MaskLoss 0.1025 (0.1126)	MaskBCELoss 0.0048 (0.0275)	MaskDICELoss 0.0977 (0.0851)
Epoch: [2][ 40/500]	Time 79.189 (79.189)	Loss 0.4131 (0.3204)	CeLoss 0.0388 (0.0383)	SegCLSLoss 0.0006 (0.0022)	KLLoss 0.0013 (0.0024)	MaskLoss 0.0947 (0.0748)	MaskBCELoss 0.0032 (0.0102)	MaskDICELoss 0.0915 (0.0645)
Epoch: [2][ 41/500]	Time 78.434 (78.434)	Loss 0.4905 (0.3973)	CeLoss 0.0515 (0.0381)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0023 (0.0019)	MaskLoss 0.1238 (0.0941)	MaskBCELoss 0.0295 (0.0098)	MaskDICELoss 0.0943 (0.0843)
Epoch: [2][ 42/500]	Time 80.286 (80.286)	Loss 0.2367 (0.3860)	CeLoss 0.0243 (0.0414)	SegCLSLoss 0.0011 (0.0017)	KLLoss 0.0036 (0.0026)	MaskLoss 0.0730 (0.0959)	MaskBCELoss 0.0420 (0.0212)	MaskDICELoss 0.0311 (0.0747)
Epoch: [2][ 43/500]	Time 78.114 (78.114)	Loss 0.4707 (0.4310)	CeLoss 0.0559 (0.0575)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0070 (0.0027)	MaskLoss 0.1078 (0.1004)	MaskBCELoss 0.0116 (0.0156)	MaskDICELoss 0.0961 (0.0848)
Epoch: [2][ 44/500]	Time 65.364 (65.364)	Loss 0.1981 (0.3885)	CeLoss 0.0535 (0.0576)	SegCLSLoss 0.0004 (0.0018)	KLLoss 0.0019 (0.0024)	MaskLoss 0.0528 (0.0909)	MaskBCELoss 0.0343 (0.0180)	MaskDICELoss 0.0185 (0.0729)
Epoch: [2][ 45/500]	Time 75.626 (75.626)	Loss 0.4179 (0.3906)	CeLoss 0.0232 (0.0468)	SegCLSLoss 0.0033 (0.0016)	KLLoss 0.0024 (0.0023)	MaskLoss 0.1020 (0.0897)	MaskBCELoss 0.0088 (0.0091)	MaskDICELoss 0.0932 (0.0806)
Epoch: [2][ 46/500]	Time 75.169 (75.169)	Loss 0.1946 (0.3923)	CeLoss 0.0408 (0.0525)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0021 (0.0022)	MaskLoss 0.0458 (0.0920)	MaskBCELoss 0.0158 (0.0156)	MaskDICELoss 0.0300 (0.0765)
Epoch: [2][ 47/500]	Time 74.804 (74.804)	Loss 0.3560 (0.3761)	CeLoss 0.0227 (0.0483)	SegCLSLoss 0.0015 (0.0017)	KLLoss 0.0025 (0.0024)	MaskLoss 0.0978 (0.1045)	MaskBCELoss 0.0307 (0.0468)	MaskDICELoss 0.0671 (0.0577)
Epoch: [2][ 48/500]	Time 71.202 (71.202)	Loss 0.0443 (0.2535)	CeLoss 0.0444 (0.0389)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0634)	MaskBCELoss 0.0000 (0.0208)	MaskDICELoss 0.0000 (0.0426)
Epoch: [2][ 49/500]	Time 75.077 (75.077)	Loss 0.1862 (0.3099)	CeLoss 0.0209 (0.0268)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0054 (0.0019)	MaskLoss 0.0449 (0.0827)	MaskBCELoss 0.0101 (0.0251)	MaskDICELoss 0.0348 (0.0576)
Epoch: [2][ 50/500]	Time 74.292 (74.292)	Loss 0.3549 (0.3195)	CeLoss 0.0300 (0.0476)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0043 (0.0021)	MaskLoss 0.0934 (0.0772)	MaskBCELoss 0.0267 (0.0197)	MaskDICELoss 0.0667 (0.0575)
Epoch: [2][ 51/500]	Time 78.462 (78.462)	Loss 0.1214 (0.3753)	CeLoss 0.0571 (0.0437)	SegCLSLoss 0.0004 (0.0015)	KLLoss 0.0040 (0.0031)	MaskLoss 0.0210 (0.0974)	MaskBCELoss 0.0120 (0.0308)	MaskDICELoss 0.0090 (0.0666)
Epoch: [2][ 52/500]	Time 85.198 (85.198)	Loss 0.4629 (0.3263)	CeLoss 0.0474 (0.0475)	SegCLSLoss 0.0007 (0.0008)	KLLoss 0.0029 (0.0026)	MaskLoss 0.1116 (0.0750)	MaskBCELoss 0.0171 (0.0123)	MaskDICELoss 0.0945 (0.0628)
Epoch: [2][ 53/500]	Time 75.863 (75.863)	Loss 0.4557 (0.3474)	CeLoss 0.0649 (0.0438)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0023 (0.0028)	MaskLoss 0.1002 (0.0841)	MaskBCELoss 0.0061 (0.0182)	MaskDICELoss 0.0941 (0.0659)
Epoch: [2][ 54/500]	Time 77.911 (77.911)	Loss 0.5413 (0.3652)	CeLoss 0.0850 (0.0415)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0050 (0.0026)	MaskLoss 0.1266 (0.0951)	MaskBCELoss 0.0276 (0.0298)	MaskDICELoss 0.0991 (0.0653)
Epoch: [2][ 55/500]	Time 72.630 (72.630)	Loss 0.1472 (0.3373)	CeLoss 0.0287 (0.0401)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0020 (0.0020)	MaskLoss 0.0367 (0.0868)	MaskBCELoss 0.0152 (0.0262)	MaskDICELoss 0.0215 (0.0606)
Epoch: [2][ 56/500]	Time 77.920 (77.920)	Loss 0.3799 (0.3913)	CeLoss 0.0276 (0.0327)	SegCLSLoss 0.0016 (0.0019)	KLLoss 0.0017 (0.0024)	MaskLoss 0.1164 (0.1080)	MaskBCELoss 0.0578 (0.0382)	MaskDICELoss 0.0585 (0.0697)
Epoch: [2][ 57/500]	Time 76.062 (76.062)	Loss 0.3566 (0.4390)	CeLoss 0.0122 (0.0383)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0023 (0.0026)	MaskLoss 0.0882 (0.1088)	MaskBCELoss 0.0056 (0.0188)	MaskDICELoss 0.0826 (0.0900)
Epoch: [2][ 58/500]	Time 79.261 (79.261)	Loss 0.4307 (0.3479)	CeLoss 0.0271 (0.0273)	SegCLSLoss 0.0037 (0.0020)	KLLoss 0.0025 (0.0023)	MaskLoss 0.1041 (0.0976)	MaskBCELoss 0.0086 (0.0366)	MaskDICELoss 0.0955 (0.0610)
Epoch: [2][ 59/500]	Time 69.855 (69.855)	Loss 0.4620 (0.4005)	CeLoss 0.0226 (0.0435)	SegCLSLoss 0.0019 (0.0021)	KLLoss 0.0023 (0.0022)	MaskLoss 0.1202 (0.0935)	MaskBCELoss 0.0223 (0.0100)	MaskDICELoss 0.0978 (0.0835)
Epoch: [2][ 60/500]	Time 72.374 (72.374)	Loss 0.4855 (0.3189)	CeLoss 0.0554 (0.0397)	SegCLSLoss 0.0006 (0.0023)	KLLoss 0.0015 (0.0025)	MaskLoss 0.1149 (0.0752)	MaskBCELoss 0.0159 (0.0127)	MaskDICELoss 0.0991 (0.0626)
Epoch: [2][ 61/500]	Time 74.299 (74.299)	Loss 0.4034 (0.3446)	CeLoss 0.0238 (0.0409)	SegCLSLoss 0.0035 (0.0018)	KLLoss 0.0025 (0.0020)	MaskLoss 0.1000 (0.0832)	MaskBCELoss 0.0124 (0.0161)	MaskDICELoss 0.0876 (0.0671)
Epoch: [2][ 62/500]	Time 73.258 (73.258)	Loss 0.3909 (0.3189)	CeLoss 0.0258 (0.0387)	SegCLSLoss 0.0021 (0.0016)	KLLoss 0.0036 (0.0027)	MaskLoss 0.0924 (0.0749)	MaskBCELoss 0.0046 (0.0114)	MaskDICELoss 0.0878 (0.0635)
Epoch: [2][ 63/500]	Time 76.041 (76.041)	Loss 0.3569 (0.2933)	CeLoss 0.0635 (0.0458)	SegCLSLoss 0.0021 (0.0014)	KLLoss 0.0027 (0.0021)	MaskLoss 0.0836 (0.0681)	MaskBCELoss 0.0225 (0.0138)	MaskDICELoss 0.0611 (0.0543)
Epoch: [2][ 64/500]	Time 76.336 (76.336)	Loss 0.4254 (0.3304)	CeLoss 0.0201 (0.0388)	SegCLSLoss 0.0024 (0.0013)	KLLoss 0.0021 (0.0024)	MaskLoss 0.1058 (0.0784)	MaskBCELoss 0.0107 (0.0126)	MaskDICELoss 0.0952 (0.0658)
Epoch: [2][ 65/500]	Time 75.432 (75.432)	Loss 0.4496 (0.2999)	CeLoss 0.0461 (0.0568)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0036 (0.0026)	MaskLoss 0.1248 (0.0705)	MaskBCELoss 0.0498 (0.0210)	MaskDICELoss 0.0750 (0.0495)
Epoch: [2][ 66/500]	Time 78.433 (78.433)	Loss 0.4402 (0.4028)	CeLoss 0.0247 (0.0288)	SegCLSLoss 0.0025 (0.0017)	KLLoss 0.0031 (0.0028)	MaskLoss 0.1172 (0.1010)	MaskBCELoss 0.0288 (0.0168)	MaskDICELoss 0.0884 (0.0842)
Epoch: [2][ 67/500]	Time 69.278 (69.278)	Loss 0.5090 (0.3667)	CeLoss 0.0270 (0.0568)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0021 (0.0024)	MaskLoss 0.1591 (0.0890)	MaskBCELoss 0.0785 (0.0246)	MaskDICELoss 0.0806 (0.0644)
Epoch: [2][ 68/500]	Time 74.821 (74.821)	Loss 0.3329 (0.3865)	CeLoss 0.0244 (0.0410)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0020 (0.0025)	MaskLoss 0.0955 (0.0960)	MaskBCELoss 0.0382 (0.0208)	MaskDICELoss 0.0573 (0.0751)
Epoch: [2][ 69/500]	Time 75.238 (75.238)	Loss 0.3839 (0.3636)	CeLoss 0.0767 (0.0495)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0040 (0.0022)	MaskLoss 0.0914 (0.0910)	MaskBCELoss 0.0313 (0.0263)	MaskDICELoss 0.0601 (0.0646)
Epoch: [2][ 70/500]	Time 75.154 (75.154)	Loss 0.3610 (0.3960)	CeLoss 0.0208 (0.0517)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0019 (0.0026)	MaskLoss 0.0901 (0.0966)	MaskBCELoss 0.0113 (0.0227)	MaskDICELoss 0.0788 (0.0739)
Epoch: [2][ 71/500]	Time 71.648 (71.648)	Loss 0.4280 (0.3220)	CeLoss 0.0248 (0.0351)	SegCLSLoss 0.0033 (0.0016)	KLLoss 0.0028 (0.0021)	MaskLoss 0.1010 (0.0791)	MaskBCELoss 0.0027 (0.0162)	MaskDICELoss 0.0983 (0.0629)
Epoch: [2][ 72/500]	Time 72.908 (72.908)	Loss 0.4127 (0.3676)	CeLoss 0.0254 (0.0394)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0025 (0.0022)	MaskLoss 0.0985 (0.0902)	MaskBCELoss 0.0050 (0.0176)	MaskDICELoss 0.0935 (0.0726)
Epoch: [2][ 73/500]	Time 79.043 (79.043)	Loss 0.2993 (0.3232)	CeLoss 0.0874 (0.0439)	SegCLSLoss 0.0006 (0.0019)	KLLoss 0.0039 (0.0027)	MaskLoss 0.0578 (0.0744)	MaskBCELoss 0.0119 (0.0110)	MaskDICELoss 0.0459 (0.0633)
Epoch: [2][ 74/500]	Time 72.321 (72.321)	Loss 0.2177 (0.2600)	CeLoss 0.0574 (0.0351)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0019 (0.0018)	MaskLoss 0.0491 (0.0655)	MaskBCELoss 0.0191 (0.0197)	MaskDICELoss 0.0299 (0.0458)
Epoch: [2][ 75/500]	Time 76.065 (76.065)	Loss 0.4259 (0.4628)	CeLoss 0.0251 (0.0491)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0022 (0.0026)	MaskLoss 0.1031 (0.1105)	MaskBCELoss 0.0073 (0.0158)	MaskDICELoss 0.0958 (0.0947)
Epoch: [2][ 76/500]	Time 79.246 (79.246)	Loss 0.4563 (0.3767)	CeLoss 0.0747 (0.0420)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0043 (0.0028)	MaskLoss 0.1063 (0.0940)	MaskBCELoss 0.0240 (0.0225)	MaskDICELoss 0.0823 (0.0716)
Epoch: [2][ 77/500]	Time 71.216 (71.216)	Loss 0.4510 (0.2902)	CeLoss 0.0471 (0.0368)	SegCLSLoss 0.0029 (0.0017)	KLLoss 0.0028 (0.0022)	MaskLoss 0.1183 (0.0702)	MaskBCELoss 0.0366 (0.0151)	MaskDICELoss 0.0816 (0.0550)
Epoch: [2][ 78/500]	Time 75.783 (75.783)	Loss 0.2755 (0.3581)	CeLoss 0.0620 (0.0472)	SegCLSLoss 0.0010 (0.0019)	KLLoss 0.0019 (0.0030)	MaskLoss 0.0637 (0.0844)	MaskBCELoss 0.0219 (0.0152)	MaskDICELoss 0.0418 (0.0691)
Epoch: [2][ 79/500]	Time 84.763 (84.763)	Loss 0.3148 (0.3270)	CeLoss 0.0601 (0.0481)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0022 (0.0025)	MaskLoss 0.0841 (0.0821)	MaskBCELoss 0.0423 (0.0263)	MaskDICELoss 0.0418 (0.0557)
Epoch: [2][ 80/500]	Time 75.451 (75.451)	Loss 0.1115 (0.2857)	CeLoss 0.0215 (0.0386)	SegCLSLoss 0.0042 (0.0016)	KLLoss 0.0020 (0.0024)	MaskLoss 0.0240 (0.0643)	MaskBCELoss 0.0051 (0.0067)	MaskDICELoss 0.0189 (0.0576)
Epoch: [2][ 81/500]	Time 77.960 (77.960)	Loss 0.1422 (0.3583)	CeLoss 0.0444 (0.0374)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0031 (0.0023)	MaskLoss 0.0303 (0.0864)	MaskBCELoss 0.0135 (0.0137)	MaskDICELoss 0.0169 (0.0726)
Epoch: [2][ 82/500]	Time 67.182 (67.182)	Loss 0.0992 (0.3269)	CeLoss 0.0991 (0.0503)	SegCLSLoss 0.0000 (0.0020)	KLLoss 0.0000 (0.0025)	MaskLoss 0.0000 (0.0786)	MaskBCELoss 0.0000 (0.0206)	MaskDICELoss 0.0000 (0.0580)
Epoch: [2][ 83/500]	Time 71.875 (71.875)	Loss 0.3970 (0.3902)	CeLoss 0.0215 (0.0450)	SegCLSLoss 0.0042 (0.0015)	KLLoss 0.0022 (0.0027)	MaskLoss 0.0962 (0.0910)	MaskBCELoss 0.0068 (0.0112)	MaskDICELoss 0.0894 (0.0798)
Epoch: [2][ 84/500]	Time 74.794 (74.794)	Loss 0.4768 (0.3041)	CeLoss 0.0254 (0.0346)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0038 (0.0026)	MaskLoss 0.1278 (0.0799)	MaskBCELoss 0.0322 (0.0265)	MaskDICELoss 0.0956 (0.0534)
Epoch: [2][ 85/500]	Time 77.543 (77.543)	Loss 1.0678 (0.4274)	CeLoss 0.0986 (0.0398)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0024 (0.0022)	MaskLoss 0.3903 (0.1162)	MaskBCELoss 0.2975 (0.0400)	MaskDICELoss 0.0928 (0.0762)
Epoch: [2][ 86/500]	Time 74.290 (74.290)	Loss 0.0171 (0.2692)	CeLoss 0.0171 (0.0283)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0022)	MaskLoss 0.0000 (0.0675)	MaskBCELoss 0.0000 (0.0160)	MaskDICELoss 0.0000 (0.0515)
Epoch: [2][ 87/500]	Time 76.008 (76.008)	Loss 0.4476 (0.3315)	CeLoss 0.1123 (0.0443)	SegCLSLoss 0.0004 (0.0017)	KLLoss 0.0053 (0.0019)	MaskLoss 0.0988 (0.0759)	MaskBCELoss 0.0327 (0.0095)	MaskDICELoss 0.0660 (0.0664)
Epoch: [2][ 88/500]	Time 78.814 (78.814)	Loss 0.5826 (0.3648)	CeLoss 0.0649 (0.0399)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0033 (0.0028)	MaskLoss 0.1603 (0.0905)	MaskBCELoss 0.0636 (0.0203)	MaskDICELoss 0.0968 (0.0702)
Epoch: [2][ 89/500]	Time 87.111 (87.111)	Loss 0.5080 (0.3929)	CeLoss 0.0693 (0.0473)	SegCLSLoss 0.0013 (0.0014)	KLLoss 0.0033 (0.0031)	MaskLoss 0.1210 (0.0946)	MaskBCELoss 0.0246 (0.0182)	MaskDICELoss 0.0964 (0.0764)
Epoch: [2][ 90/500]	Time 71.727 (71.727)	Loss 0.5252 (0.3939)	CeLoss 0.0232 (0.0382)	SegCLSLoss 0.0033 (0.0014)	KLLoss 0.0023 (0.0025)	MaskLoss 0.1502 (0.1212)	MaskBCELoss 0.0514 (0.0663)	MaskDICELoss 0.0988 (0.0550)
Epoch: [2][ 91/500]	Time 78.738 (78.738)	Loss 0.3490 (0.3104)	CeLoss 0.0168 (0.0302)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0015 (0.0021)	MaskLoss 0.0855 (0.0778)	MaskBCELoss 0.0060 (0.0169)	MaskDICELoss 0.0795 (0.0609)
Epoch: [2][ 92/500]	Time 81.555 (81.555)	Loss 0.1338 (0.3151)	CeLoss 0.0732 (0.0398)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0034 (0.0020)	MaskLoss 0.0194 (0.0811)	MaskBCELoss 0.0105 (0.0258)	MaskDICELoss 0.0089 (0.0552)
Epoch: [2][ 93/500]	Time 78.494 (78.494)	Loss 0.2446 (0.3425)	CeLoss 0.0247 (0.0442)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0025 (0.0026)	MaskLoss 0.0718 (0.0838)	MaskBCELoss 0.0352 (0.0200)	MaskDICELoss 0.0366 (0.0638)
Epoch: [2][ 94/500]	Time 75.336 (75.336)	Loss 0.0297 (0.3355)	CeLoss 0.0297 (0.0391)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0829)	MaskBCELoss 0.0000 (0.0193)	MaskDICELoss 0.0000 (0.0636)
Epoch: [2][ 95/500]	Time 73.214 (73.214)	Loss 0.3960 (0.3736)	CeLoss 0.0483 (0.0427)	SegCLSLoss 0.0022 (0.0023)	KLLoss 0.0026 (0.0031)	MaskLoss 0.1015 (0.0977)	MaskBCELoss 0.0310 (0.0321)	MaskDICELoss 0.0705 (0.0656)
Epoch: [2][ 96/500]	Time 80.330 (80.330)	Loss 0.3789 (0.2735)	CeLoss 0.0264 (0.0394)	SegCLSLoss 0.0019 (0.0008)	KLLoss 0.0015 (0.0016)	MaskLoss 0.1041 (0.0611)	MaskBCELoss 0.0333 (0.0062)	MaskDICELoss 0.0708 (0.0549)
Epoch: [2][ 97/500]	Time 78.597 (78.597)	Loss 0.3933 (0.3528)	CeLoss 0.0620 (0.0549)	SegCLSLoss 0.0009 (0.0017)	KLLoss 0.0017 (0.0030)	MaskLoss 0.1018 (0.0863)	MaskBCELoss 0.0389 (0.0256)	MaskDICELoss 0.0628 (0.0607)
Epoch: [2][ 98/500]	Time 70.575 (70.575)	Loss 0.4509 (0.4102)	CeLoss 0.0231 (0.0388)	SegCLSLoss 0.0043 (0.0017)	KLLoss 0.0019 (0.0030)	MaskLoss 0.1142 (0.1041)	MaskBCELoss 0.0166 (0.0244)	MaskDICELoss 0.0976 (0.0796)
Epoch: [2][ 99/500]	Time 76.781 (76.781)	Loss 0.1970 (0.3899)	CeLoss 0.0247 (0.0448)	SegCLSLoss 0.0011 (0.0018)	KLLoss 0.0015 (0.0030)	MaskLoss 0.0587 (0.0982)	MaskBCELoss 0.0322 (0.0259)	MaskDICELoss 0.0264 (0.0723)
[2025-03-11 15:31:39,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[0.00028668674698795177], mom=[(0.9, 0.95)]
[2025-03-11 15:31:39,437] [INFO] [timer.py:215:stop] epoch=0/micro_step=1100/global_step=110, RunningAvgSamplesPerSec=0.7467141216028795, CurrSamplesPerSec=0.4828625614444916, MemAllocated=59.55GB, MaxMemAllocated=74.71GB
Epoch: [2][100/500]	Time 77.774 (77.774)	Loss 0.1241 (0.3439)	CeLoss 0.0200 (0.0340)	SegCLSLoss 0.0013 (0.0018)	KLLoss 0.0036 (0.0031)	MaskLoss 0.0331 (0.0867)	MaskBCELoss 0.0162 (0.0204)	MaskDICELoss 0.0168 (0.0663)
Epoch: [2][101/500]	Time 77.300 (77.300)	Loss 0.4878 (0.3313)	CeLoss 0.0825 (0.0559)	SegCLSLoss 0.0008 (0.0007)	KLLoss 0.0026 (0.0024)	MaskLoss 0.1014 (0.0766)	MaskBCELoss 0.0016 (0.0169)	MaskDICELoss 0.0998 (0.0597)
Epoch: [2][102/500]	Time 75.133 (75.133)	Loss 0.4808 (0.4014)	CeLoss 0.0591 (0.0576)	SegCLSLoss 0.0009 (0.0017)	KLLoss 0.0021 (0.0028)	MaskLoss 0.1526 (0.1064)	MaskBCELoss 0.0954 (0.0428)	MaskDICELoss 0.0571 (0.0636)
Epoch: [2][103/500]	Time 71.954 (71.954)	Loss 0.4394 (0.4549)	CeLoss 0.0201 (0.0430)	SegCLSLoss 0.0036 (0.0019)	KLLoss 0.0034 (0.0029)	MaskLoss 0.1104 (0.1278)	MaskBCELoss 0.0137 (0.0517)	MaskDICELoss 0.0967 (0.0762)
Epoch: [2][104/500]	Time 73.659 (73.659)	Loss 0.4265 (0.3099)	CeLoss 0.0674 (0.0381)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0030 (0.0031)	MaskLoss 0.1066 (0.0822)	MaskBCELoss 0.0357 (0.0304)	MaskDICELoss 0.0709 (0.0518)
Epoch: [2][105/500]	Time 79.486 (79.486)	Loss 0.4846 (0.4451)	CeLoss 0.0762 (0.0487)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0026 (0.0027)	MaskLoss 0.1028 (0.1165)	MaskBCELoss 0.0031 (0.0364)	MaskDICELoss 0.0997 (0.0800)
Epoch: [2][106/500]	Time 77.700 (77.700)	Loss 0.4678 (0.3462)	CeLoss 0.0214 (0.0302)	SegCLSLoss 0.0034 (0.0017)	KLLoss 0.0027 (0.0026)	MaskLoss 0.1214 (0.0894)	MaskBCELoss 0.0218 (0.0225)	MaskDICELoss 0.0996 (0.0669)
Epoch: [2][107/500]	Time 79.777 (79.777)	Loss 0.4932 (0.4035)	CeLoss 0.0126 (0.0495)	SegCLSLoss 0.0036 (0.0015)	KLLoss 0.0030 (0.0030)	MaskLoss 0.1384 (0.0944)	MaskBCELoss 0.0389 (0.0137)	MaskDICELoss 0.0995 (0.0807)
Epoch: [2][108/500]	Time 76.065 (76.065)	Loss 0.4060 (0.3630)	CeLoss 0.0396 (0.0525)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0024 (0.0031)	MaskLoss 0.0943 (0.0842)	MaskBCELoss 0.0068 (0.0151)	MaskDICELoss 0.0875 (0.0691)
Epoch: [2][109/500]	Time 71.079 (71.079)	Loss 0.2211 (0.3844)	CeLoss 0.0723 (0.0467)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0034 (0.0032)	MaskLoss 0.0473 (0.0949)	MaskBCELoss 0.0222 (0.0228)	MaskDICELoss 0.0251 (0.0721)
Epoch: [2][110/500]	Time 71.760 (71.760)	Loss 0.4082 (0.3669)	CeLoss 0.0248 (0.0338)	SegCLSLoss 0.0028 (0.0017)	KLLoss 0.0022 (0.0032)	MaskLoss 0.0979 (0.1044)	MaskBCELoss 0.0059 (0.0442)	MaskDICELoss 0.0920 (0.0602)
Epoch: [2][111/500]	Time 71.120 (71.120)	Loss 0.0753 (0.3477)	CeLoss 0.0654 (0.0443)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0046 (0.0039)	MaskLoss 0.0016 (0.0858)	MaskBCELoss 0.0008 (0.0222)	MaskDICELoss 0.0008 (0.0636)
Epoch: [2][112/500]	Time 74.380 (74.380)	Loss 0.5259 (0.3886)	CeLoss 0.1055 (0.0520)	SegCLSLoss 0.0017 (0.0014)	KLLoss 0.0030 (0.0031)	MaskLoss 0.1083 (0.0935)	MaskBCELoss 0.0083 (0.0206)	MaskDICELoss 0.1000 (0.0729)
Epoch: [2][113/500]	Time 77.352 (77.352)	Loss 0.6661 (0.3442)	CeLoss 0.0166 (0.0349)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0026 (0.0030)	MaskLoss 0.2263 (0.0909)	MaskBCELoss 0.1291 (0.0289)	MaskDICELoss 0.0971 (0.0620)
Epoch: [2][114/500]	Time 79.585 (79.585)	Loss 0.4100 (0.3104)	CeLoss 0.0312 (0.0406)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0039 (0.0032)	MaskLoss 0.1015 (0.0787)	MaskBCELoss 0.0156 (0.0242)	MaskDICELoss 0.0859 (0.0544)
Epoch: [2][115/500]	Time 73.825 (73.825)	Loss 0.1039 (0.4017)	CeLoss 0.0649 (0.0446)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0051 (0.0036)	MaskLoss 0.0109 (0.1008)	MaskBCELoss 0.0050 (0.0254)	MaskDICELoss 0.0059 (0.0755)
Epoch: [2][116/500]	Time 75.154 (75.154)	Loss 0.3983 (0.3420)	CeLoss 0.0415 (0.0539)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0026 (0.0037)	MaskLoss 0.0908 (0.0826)	MaskBCELoss 0.0045 (0.0232)	MaskDICELoss 0.0863 (0.0594)
Epoch: [2][117/500]	Time 76.841 (76.841)	Loss 0.2462 (0.3577)	CeLoss 0.0248 (0.0480)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0027 (0.0038)	MaskLoss 0.0905 (0.0969)	MaskBCELoss 0.0720 (0.0412)	MaskDICELoss 0.0185 (0.0557)
Epoch: [2][118/500]	Time 80.131 (80.131)	Loss 0.4433 (0.3543)	CeLoss 0.0337 (0.0397)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0018 (0.0034)	MaskLoss 0.1038 (0.0895)	MaskBCELoss 0.0039 (0.0238)	MaskDICELoss 0.1000 (0.0658)
Epoch: [2][119/500]	Time 72.929 (72.929)	Loss 0.3315 (0.4051)	CeLoss 0.0591 (0.0409)	SegCLSLoss 0.0026 (0.0020)	KLLoss 0.0012 (0.0027)	MaskLoss 0.0997 (0.1057)	MaskBCELoss 0.0644 (0.0311)	MaskDICELoss 0.0353 (0.0746)
Epoch: [2][120/500]	Time 80.176 (80.176)	Loss 0.2728 (0.3172)	CeLoss 0.0204 (0.0528)	SegCLSLoss 0.0033 (0.0012)	KLLoss 0.0034 (0.0034)	MaskLoss 0.0710 (0.0702)	MaskBCELoss 0.0183 (0.0103)	MaskDICELoss 0.0526 (0.0600)
Epoch: [2][121/500]	Time 72.626 (72.626)	Loss 0.0398 (0.3665)	CeLoss 0.0238 (0.0389)	SegCLSLoss 0.0008 (0.0017)	KLLoss 0.0025 (0.0032)	MaskLoss 0.0046 (0.0947)	MaskBCELoss 0.0028 (0.0276)	MaskDICELoss 0.0019 (0.0671)
Epoch: [2][122/500]	Time 76.047 (76.047)	Loss 0.4538 (0.3771)	CeLoss 0.0299 (0.0422)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0045 (0.0035)	MaskLoss 0.1101 (0.0944)	MaskBCELoss 0.0105 (0.0235)	MaskDICELoss 0.0996 (0.0710)
Epoch: [2][123/500]	Time 79.033 (79.033)	Loss 0.4579 (0.3620)	CeLoss 0.0432 (0.0381)	SegCLSLoss 0.0006 (0.0019)	KLLoss 0.0035 (0.0032)	MaskLoss 0.1108 (0.0878)	MaskBCELoss 0.0161 (0.0157)	MaskDICELoss 0.0947 (0.0721)
Epoch: [2][124/500]	Time 75.088 (75.088)	Loss 0.0377 (0.3593)	CeLoss 0.0376 (0.0498)	SegCLSLoss 0.0000 (0.0022)	KLLoss 0.0000 (0.0040)	MaskLoss 0.0000 (0.0866)	MaskBCELoss 0.0000 (0.0211)	MaskDICELoss 0.0000 (0.0656)
Epoch: [2][125/500]	Time 75.483 (75.483)	Loss 0.4910 (0.4150)	CeLoss 0.0096 (0.0423)	SegCLSLoss 0.0029 (0.0014)	KLLoss 0.0035 (0.0028)	MaskLoss 0.1416 (0.1044)	MaskBCELoss 0.0451 (0.0242)	MaskDICELoss 0.0966 (0.0802)
Epoch: [2][126/500]	Time 73.651 (73.651)	Loss 0.4148 (0.3811)	CeLoss 0.0225 (0.0444)	SegCLSLoss 0.0027 (0.0019)	KLLoss 0.0039 (0.0032)	MaskLoss 0.0988 (0.0881)	MaskBCELoss 0.0040 (0.0099)	MaskDICELoss 0.0948 (0.0782)
Epoch: [2][127/500]	Time 79.228 (79.228)	Loss 0.4874 (0.3369)	CeLoss 0.0610 (0.0526)	SegCLSLoss 0.0006 (0.0014)	KLLoss 0.0017 (0.0039)	MaskLoss 0.1129 (0.0795)	MaskBCELoss 0.0136 (0.0192)	MaskDICELoss 0.0993 (0.0603)
Epoch: [2][128/500]	Time 72.427 (72.427)	Loss 0.1491 (0.3060)	CeLoss 0.0242 (0.0413)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0052 (0.0029)	MaskLoss 0.0424 (0.0725)	MaskBCELoss 0.0251 (0.0144)	MaskDICELoss 0.0173 (0.0581)
Epoch: [2][129/500]	Time 74.638 (74.638)	Loss 0.3237 (0.3030)	CeLoss 0.0598 (0.0583)	SegCLSLoss 0.0002 (0.0008)	KLLoss 0.0055 (0.0040)	MaskLoss 0.0739 (0.0670)	MaskBCELoss 0.0186 (0.0139)	MaskDICELoss 0.0553 (0.0531)
Epoch: [2][130/500]	Time 72.899 (72.899)	Loss 0.5110 (0.3217)	CeLoss 0.0718 (0.0380)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0049 (0.0044)	MaskLoss 0.1170 (0.0771)	MaskBCELoss 0.0171 (0.0150)	MaskDICELoss 0.0999 (0.0621)
Epoch: [2][131/500]	Time 74.752 (74.752)	Loss 0.2420 (0.2935)	CeLoss 0.0216 (0.0334)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0035 (0.0031)	MaskLoss 0.0684 (0.0776)	MaskBCELoss 0.0284 (0.0269)	MaskDICELoss 0.0399 (0.0506)
Epoch: [2][132/500]	Time 71.798 (71.798)	Loss 0.4160 (0.4426)	CeLoss 0.0310 (0.0436)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0032 (0.0031)	MaskLoss 0.0973 (0.1116)	MaskBCELoss 0.0038 (0.0255)	MaskDICELoss 0.0935 (0.0861)
Epoch: [2][133/500]	Time 79.701 (79.701)	Loss 0.3174 (0.3199)	CeLoss 0.0247 (0.0287)	SegCLSLoss 0.0015 (0.0010)	KLLoss 0.0033 (0.0028)	MaskLoss 0.0739 (0.0791)	MaskBCELoss 0.0034 (0.0142)	MaskDICELoss 0.0705 (0.0649)
Epoch: [2][134/500]	Time 78.445 (78.445)	Loss 0.4318 (0.4047)	CeLoss 0.0256 (0.0395)	SegCLSLoss 0.0021 (0.0013)	KLLoss 0.0043 (0.0037)	MaskLoss 0.1005 (0.1020)	MaskBCELoss 0.0005 (0.0236)	MaskDICELoss 0.1000 (0.0785)
Epoch: [2][135/500]	Time 76.193 (76.193)	Loss 0.0312 (0.2865)	CeLoss 0.0312 (0.0455)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0681)	MaskBCELoss 0.0000 (0.0172)	MaskDICELoss 0.0000 (0.0509)
Epoch: [2][136/500]	Time 74.963 (74.963)	Loss 0.3341 (0.3424)	CeLoss 0.0405 (0.0378)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0039 (0.0037)	MaskLoss 0.0774 (0.0816)	MaskBCELoss 0.0103 (0.0131)	MaskDICELoss 0.0671 (0.0685)
Epoch: [2][137/500]	Time 71.472 (71.472)	Loss 0.3213 (0.2943)	CeLoss 0.0240 (0.0464)	SegCLSLoss 0.0033 (0.0014)	KLLoss 0.0030 (0.0040)	MaskLoss 0.0798 (0.0761)	MaskBCELoss 0.0133 (0.0305)	MaskDICELoss 0.0665 (0.0456)
Epoch: [2][138/500]	Time 74.954 (74.954)	Loss 0.0828 (0.3703)	CeLoss 0.0306 (0.0414)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0057 (0.0037)	MaskLoss 0.0164 (0.0875)	MaskBCELoss 0.0098 (0.0128)	MaskDICELoss 0.0066 (0.0747)
Epoch: [2][139/500]	Time 73.136 (73.136)	Loss 0.1142 (0.3733)	CeLoss 0.0142 (0.0499)	SegCLSLoss 0.0006 (0.0014)	KLLoss 0.0036 (0.0034)	MaskLoss 0.0336 (0.0868)	MaskBCELoss 0.0192 (0.0139)	MaskDICELoss 0.0144 (0.0729)
Epoch: [2][140/500]	Time 78.557 (78.557)	Loss 0.2508 (0.2758)	CeLoss 0.0640 (0.0436)	SegCLSLoss 0.0006 (0.0023)	KLLoss 0.0043 (0.0032)	MaskLoss 0.0574 (0.0643)	MaskBCELoss 0.0238 (0.0147)	MaskDICELoss 0.0336 (0.0496)
Epoch: [2][141/500]	Time 70.401 (70.401)	Loss 0.0793 (0.3693)	CeLoss 0.0232 (0.0523)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0037 (0.0031)	MaskLoss 0.0202 (0.0932)	MaskBCELoss 0.0145 (0.0297)	MaskDICELoss 0.0058 (0.0635)
Epoch: [2][142/500]	Time 73.258 (73.258)	Loss 0.5123 (0.3653)	CeLoss 0.0227 (0.0488)	SegCLSLoss 0.0039 (0.0012)	KLLoss 0.0062 (0.0033)	MaskLoss 0.1438 (0.0931)	MaskBCELoss 0.0469 (0.0300)	MaskDICELoss 0.0969 (0.0631)
Epoch: [2][143/500]	Time 70.754 (70.754)	Loss 0.3960 (0.3160)	CeLoss 0.0286 (0.0343)	SegCLSLoss 0.0015 (0.0014)	KLLoss 0.0045 (0.0030)	MaskLoss 0.0910 (0.0777)	MaskBCELoss 0.0008 (0.0165)	MaskDICELoss 0.0901 (0.0613)
Epoch: [2][144/500]	Time 74.394 (74.394)	Loss 0.0385 (0.3375)	CeLoss 0.0386 (0.0438)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0861)	MaskBCELoss 0.0000 (0.0272)	MaskDICELoss 0.0000 (0.0589)
Epoch: [2][145/500]	Time 74.107 (74.107)	Loss 0.1285 (0.2834)	CeLoss 0.0258 (0.0424)	SegCLSLoss 0.0015 (0.0019)	KLLoss 0.0024 (0.0024)	MaskLoss 0.0305 (0.0703)	MaskBCELoss 0.0112 (0.0218)	MaskDICELoss 0.0193 (0.0485)
Epoch: [2][146/500]	Time 75.705 (75.705)	Loss 0.2347 (0.3746)	CeLoss 0.0167 (0.0486)	SegCLSLoss 0.0015 (0.0010)	KLLoss 0.0045 (0.0034)	MaskLoss 0.0535 (0.0876)	MaskBCELoss 0.0006 (0.0140)	MaskDICELoss 0.0529 (0.0735)
Epoch: [2][147/500]	Time 75.683 (75.683)	Loss 0.4819 (0.3913)	CeLoss 0.0256 (0.0334)	SegCLSLoss 0.0008 (0.0018)	KLLoss 0.0038 (0.0029)	MaskLoss 0.1795 (0.1034)	MaskBCELoss 0.1329 (0.0297)	MaskDICELoss 0.0466 (0.0737)
Epoch: [2][148/500]	Time 75.773 (75.773)	Loss 0.1945 (0.3273)	CeLoss 0.0388 (0.0447)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0039 (0.0031)	MaskLoss 0.0496 (0.0806)	MaskBCELoss 0.0234 (0.0217)	MaskDICELoss 0.0262 (0.0589)
Epoch: [2][149/500]	Time 75.179 (75.179)	Loss 0.4193 (0.3850)	CeLoss 0.0225 (0.0380)	SegCLSLoss 0.0030 (0.0012)	KLLoss 0.0041 (0.0032)	MaskLoss 0.1075 (0.0974)	MaskBCELoss 0.0193 (0.0232)	MaskDICELoss 0.0882 (0.0742)
Epoch: [2][150/500]	Time 77.530 (77.530)	Loss 0.3999 (0.4635)	CeLoss 0.0277 (0.0634)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0032 (0.0033)	MaskLoss 0.0930 (0.1062)	MaskBCELoss 0.0017 (0.0144)	MaskDICELoss 0.0913 (0.0918)
Epoch: [2][151/500]	Time 76.177 (76.177)	Loss 0.4512 (0.3741)	CeLoss 0.0243 (0.0372)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0037 (0.0033)	MaskLoss 0.1118 (0.0970)	MaskBCELoss 0.0125 (0.0276)	MaskDICELoss 0.0993 (0.0694)
Epoch: [2][152/500]	Time 78.281 (78.281)	Loss 0.0471 (0.3288)	CeLoss 0.0471 (0.0581)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.0803)	MaskBCELoss 0.0000 (0.0272)	MaskDICELoss 0.0000 (0.0531)
Epoch: [2][153/500]	Time 76.783 (76.783)	Loss 0.3000 (0.3399)	CeLoss 0.0757 (0.0387)	SegCLSLoss 0.0066 (0.0022)	KLLoss 0.0030 (0.0034)	MaskLoss 0.0702 (0.0794)	MaskBCELoss 0.0314 (0.0105)	MaskDICELoss 0.0388 (0.0689)
Epoch: [2][154/500]	Time 74.113 (74.113)	Loss 0.4757 (0.3371)	CeLoss 0.0204 (0.0401)	SegCLSLoss 0.0095 (0.0020)	KLLoss 0.0030 (0.0034)	MaskLoss 0.1305 (0.0801)	MaskBCELoss 0.0373 (0.0138)	MaskDICELoss 0.0932 (0.0663)
Epoch: [2][155/500]	Time 76.710 (76.710)	Loss 0.3383 (0.3156)	CeLoss 0.0547 (0.0599)	SegCLSLoss 0.0008 (0.0008)	KLLoss 0.0031 (0.0038)	MaskLoss 0.0764 (0.0755)	MaskBCELoss 0.0128 (0.0253)	MaskDICELoss 0.0636 (0.0502)
Epoch: [2][156/500]	Time 70.298 (70.298)	Loss 0.2926 (0.3583)	CeLoss 0.0645 (0.0428)	SegCLSLoss 0.0041 (0.0020)	KLLoss 0.0040 (0.0039)	MaskLoss 0.0717 (0.0882)	MaskBCELoss 0.0322 (0.0212)	MaskDICELoss 0.0395 (0.0671)
Epoch: [2][157/500]	Time 74.715 (74.715)	Loss 0.0497 (0.4298)	CeLoss 0.0226 (0.0426)	SegCLSLoss 0.0008 (0.0018)	KLLoss 0.0069 (0.0036)	MaskLoss 0.0066 (0.1167)	MaskBCELoss 0.0033 (0.0420)	MaskDICELoss 0.0033 (0.0747)
Epoch: [2][158/500]	Time 78.471 (78.471)	Loss 0.4422 (0.2699)	CeLoss 0.0200 (0.0507)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0034 (0.0026)	MaskLoss 0.1100 (0.0591)	MaskBCELoss 0.0110 (0.0102)	MaskDICELoss 0.0991 (0.0489)
Epoch: [2][159/500]	Time 71.762 (71.762)	Loss 0.3871 (0.4129)	CeLoss 0.0669 (0.0411)	SegCLSLoss 0.0020 (0.0026)	KLLoss 0.0046 (0.0037)	MaskLoss 0.1004 (0.1029)	MaskBCELoss 0.0436 (0.0224)	MaskDICELoss 0.0568 (0.0805)
Epoch: [2][160/500]	Time 74.443 (74.443)	Loss 0.3517 (0.3329)	CeLoss 0.0791 (0.0563)	SegCLSLoss 0.0002 (0.0013)	KLLoss 0.0058 (0.0041)	MaskLoss 0.0965 (0.0882)	MaskBCELoss 0.0597 (0.0404)	MaskDICELoss 0.0368 (0.0478)
Epoch: [2][161/500]	Time 74.435 (74.435)	Loss 0.1395 (0.3407)	CeLoss 0.0649 (0.0514)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0034 (0.0033)	MaskLoss 0.0197 (0.0796)	MaskBCELoss 0.0041 (0.0164)	MaskDICELoss 0.0157 (0.0632)
Epoch: [2][162/500]	Time 74.319 (74.319)	Loss 0.1842 (0.3361)	CeLoss 0.0669 (0.0407)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0025 (0.0033)	MaskLoss 0.0357 (0.0814)	MaskBCELoss 0.0142 (0.0172)	MaskDICELoss 0.0215 (0.0643)
Epoch: [2][163/500]	Time 73.931 (73.931)	Loss 0.5052 (0.3870)	CeLoss 0.0962 (0.0422)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0041 (0.0037)	MaskLoss 0.1026 (0.0906)	MaskBCELoss 0.0030 (0.0110)	MaskDICELoss 0.0996 (0.0796)
Epoch: [2][164/500]	Time 76.178 (76.178)	Loss 0.4497 (0.3483)	CeLoss 0.0332 (0.0387)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0017 (0.0028)	MaskLoss 0.1073 (0.0853)	MaskBCELoss 0.0074 (0.0175)	MaskDICELoss 0.0999 (0.0678)
Epoch: [2][165/500]	Time 74.762 (74.762)	Loss 0.3145 (0.2842)	CeLoss 0.0159 (0.0374)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0026 (0.0025)	MaskLoss 0.0757 (0.0702)	MaskBCELoss 0.0035 (0.0185)	MaskDICELoss 0.0722 (0.0517)
Epoch: [2][166/500]	Time 76.041 (76.041)	Loss 0.2719 (0.3752)	CeLoss 0.0845 (0.0391)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0024 (0.0032)	MaskLoss 0.0626 (0.1141)	MaskBCELoss 0.0327 (0.0621)	MaskDICELoss 0.0299 (0.0521)
Epoch: [2][167/500]	Time 79.962 (79.962)	Loss 0.3508 (0.3349)	CeLoss 0.0217 (0.0406)	SegCLSLoss 0.0023 (0.0014)	KLLoss 0.0026 (0.0040)	MaskLoss 0.0947 (0.0882)	MaskBCELoss 0.0269 (0.0318)	MaskDICELoss 0.0679 (0.0565)
Epoch: [2][168/500]	Time 74.903 (74.903)	Loss 0.4806 (0.3907)	CeLoss 0.0645 (0.0574)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0039 (0.0029)	MaskLoss 0.1070 (0.0914)	MaskBCELoss 0.0081 (0.0179)	MaskDICELoss 0.0989 (0.0736)
Epoch: [2][169/500]	Time 85.702 (85.702)	Loss 0.2645 (0.3923)	CeLoss 0.0247 (0.0397)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0058 (0.0040)	MaskLoss 0.0768 (0.1062)	MaskBCELoss 0.0369 (0.0385)	MaskDICELoss 0.0399 (0.0677)
Epoch: [2][170/500]	Time 74.795 (74.795)	Loss 0.2376 (0.3174)	CeLoss 0.0347 (0.0385)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0035 (0.0041)	MaskLoss 0.0602 (0.0827)	MaskBCELoss 0.0209 (0.0282)	MaskDICELoss 0.0393 (0.0544)
Epoch: [2][171/500]	Time 72.467 (72.467)	Loss 0.4346 (0.4266)	CeLoss 0.0214 (0.0346)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0031 (0.0045)	MaskLoss 0.1048 (0.1047)	MaskBCELoss 0.0049 (0.0160)	MaskDICELoss 0.1000 (0.0887)
Epoch: [2][172/500]	Time 78.719 (78.719)	Loss 0.4020 (0.3809)	CeLoss 0.0981 (0.0498)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0032 (0.0029)	MaskLoss 0.0781 (0.0918)	MaskBCELoss 0.0060 (0.0198)	MaskDICELoss 0.0721 (0.0720)
Epoch: [2][173/500]	Time 78.261 (78.261)	Loss 0.2566 (0.3366)	CeLoss 0.0742 (0.0425)	SegCLSLoss 0.0009 (0.0018)	KLLoss 0.0023 (0.0035)	MaskLoss 0.0592 (0.0857)	MaskBCELoss 0.0285 (0.0265)	MaskDICELoss 0.0306 (0.0591)
Epoch: [2][174/500]	Time 82.371 (82.371)	Loss 0.4466 (0.3778)	CeLoss 0.0366 (0.0467)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0025 (0.0033)	MaskLoss 0.1037 (0.0901)	MaskBCELoss 0.0037 (0.0166)	MaskDICELoss 0.1000 (0.0735)
Epoch: [2][175/500]	Time 74.503 (74.503)	Loss 0.4613 (0.3597)	CeLoss 0.0220 (0.0433)	SegCLSLoss 0.0020 (0.0024)	KLLoss 0.0035 (0.0033)	MaskLoss 0.1368 (0.0960)	MaskBCELoss 0.0562 (0.0362)	MaskDICELoss 0.0806 (0.0599)
Epoch: [2][176/500]	Time 78.882 (78.882)	Loss 0.4774 (0.4408)	CeLoss 0.0664 (0.0399)	SegCLSLoss 0.0010 (0.0022)	KLLoss 0.0021 (0.0037)	MaskLoss 0.1043 (0.1086)	MaskBCELoss 0.0043 (0.0191)	MaskDICELoss 0.1000 (0.0895)
Epoch: [2][177/500]	Time 74.846 (74.846)	Loss 0.4217 (0.3192)	CeLoss 0.0256 (0.0352)	SegCLSLoss 0.0023 (0.0023)	KLLoss 0.0033 (0.0033)	MaskLoss 0.0993 (0.0776)	MaskBCELoss 0.0028 (0.0153)	MaskDICELoss 0.0965 (0.0623)
Epoch: [2][178/500]	Time 71.351 (71.351)	Loss 0.4713 (0.2975)	CeLoss 0.0610 (0.0536)	SegCLSLoss 0.0012 (0.0010)	KLLoss 0.0030 (0.0032)	MaskLoss 0.1033 (0.0690)	MaskBCELoss 0.0034 (0.0181)	MaskDICELoss 0.0999 (0.0510)
Epoch: [2][179/500]	Time 73.165 (73.165)	Loss 0.0120 (0.3317)	CeLoss 0.0120 (0.0405)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0771)	MaskBCELoss 0.0000 (0.0102)	MaskDICELoss 0.0000 (0.0669)
Epoch: [2][180/500]	Time 79.919 (79.919)	Loss 0.0972 (0.3262)	CeLoss 0.0613 (0.0464)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0030 (0.0032)	MaskLoss 0.0108 (0.0766)	MaskBCELoss 0.0054 (0.0152)	MaskDICELoss 0.0054 (0.0614)
Epoch: [2][181/500]	Time 82.208 (82.208)	Loss 0.3629 (0.2425)	CeLoss 0.0254 (0.0470)	SegCLSLoss 0.0016 (0.0010)	KLLoss 0.0023 (0.0022)	MaskLoss 0.0960 (0.0572)	MaskBCELoss 0.0248 (0.0179)	MaskDICELoss 0.0712 (0.0393)
Epoch: [2][182/500]	Time 76.023 (76.023)	Loss 0.4353 (0.3976)	CeLoss 0.0244 (0.0488)	SegCLSLoss 0.0037 (0.0017)	KLLoss 0.0052 (0.0036)	MaskLoss 0.1021 (0.0933)	MaskBCELoss 0.0023 (0.0144)	MaskDICELoss 0.0998 (0.0788)
Epoch: [2][183/500]	Time 76.947 (76.947)	Loss 0.1399 (0.3578)	CeLoss 0.0203 (0.0394)	SegCLSLoss 0.0020 (0.0014)	KLLoss 0.0029 (0.0029)	MaskLoss 0.0362 (0.0871)	MaskBCELoss 0.0145 (0.0168)	MaskDICELoss 0.0217 (0.0703)
Epoch: [2][184/500]	Time 72.571 (72.571)	Loss 0.4697 (0.3790)	CeLoss 0.0227 (0.0395)	SegCLSLoss 0.0030 (0.0014)	KLLoss 0.0034 (0.0033)	MaskLoss 0.1268 (0.0966)	MaskBCELoss 0.0326 (0.0254)	MaskDICELoss 0.0942 (0.0712)
Epoch: [2][185/500]	Time 72.991 (72.991)	Loss 0.4441 (0.3793)	CeLoss 0.0229 (0.0336)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0033 (0.0040)	MaskLoss 0.1139 (0.0955)	MaskBCELoss 0.0192 (0.0206)	MaskDICELoss 0.0947 (0.0749)
Epoch: [2][186/500]	Time 76.724 (76.724)	Loss 0.6132 (0.3701)	CeLoss 0.0674 (0.0427)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0040 (0.0037)	MaskLoss 0.1713 (0.0914)	MaskBCELoss 0.0718 (0.0212)	MaskDICELoss 0.0996 (0.0702)
Epoch: [2][187/500]	Time 78.088 (78.088)	Loss 0.4351 (0.3247)	CeLoss 0.0237 (0.0615)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0029 (0.0030)	MaskLoss 0.1039 (0.0734)	MaskBCELoss 0.0039 (0.0170)	MaskDICELoss 0.1000 (0.0564)
Epoch: [2][188/500]	Time 71.912 (71.912)	Loss 0.5262 (0.3809)	CeLoss 0.0732 (0.0459)	SegCLSLoss 0.0030 (0.0017)	KLLoss 0.0034 (0.0033)	MaskLoss 0.1259 (0.0960)	MaskBCELoss 0.0277 (0.0266)	MaskDICELoss 0.0982 (0.0694)
Epoch: [2][189/500]	Time 81.709 (81.709)	Loss 0.4361 (0.4391)	CeLoss 0.0206 (0.0426)	SegCLSLoss 0.0006 (0.0014)	KLLoss 0.0030 (0.0041)	MaskLoss 0.1074 (0.1122)	MaskBCELoss 0.0088 (0.0285)	MaskDICELoss 0.0987 (0.0836)
Epoch: [2][190/500]	Time 68.764 (68.764)	Loss 0.0275 (0.3363)	CeLoss 0.0276 (0.0553)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0853)	MaskBCELoss 0.0000 (0.0321)	MaskDICELoss 0.0000 (0.0533)
Epoch: [2][191/500]	Time 73.072 (73.072)	Loss 0.1210 (0.3235)	CeLoss 0.0215 (0.0278)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0024 (0.0033)	MaskLoss 0.0355 (0.0800)	MaskBCELoss 0.0229 (0.0141)	MaskDICELoss 0.0127 (0.0659)
Epoch: [2][192/500]	Time 76.976 (76.976)	Loss 0.1959 (0.3816)	CeLoss 0.0222 (0.0348)	SegCLSLoss 0.0012 (0.0020)	KLLoss 0.0034 (0.0031)	MaskLoss 0.0532 (0.0933)	MaskBCELoss 0.0216 (0.0151)	MaskDICELoss 0.0316 (0.0781)
Epoch: [2][193/500]	Time 78.595 (78.595)	Loss 0.4892 (0.3501)	CeLoss 0.0669 (0.0457)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0040 (0.0033)	MaskLoss 0.1280 (0.0815)	MaskBCELoss 0.0470 (0.0128)	MaskDICELoss 0.0810 (0.0687)
Epoch: [2][194/500]	Time 82.589 (82.589)	Loss 0.4819 (0.3807)	CeLoss 0.0225 (0.0329)	SegCLSLoss 0.0017 (0.0010)	KLLoss 0.0057 (0.0036)	MaskLoss 0.1472 (0.0942)	MaskBCELoss 0.0679 (0.0166)	MaskDICELoss 0.0792 (0.0776)
Epoch: [2][195/500]	Time 73.495 (73.495)	Loss 0.3125 (0.3133)	CeLoss 0.0498 (0.0424)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0030 (0.0025)	MaskLoss 0.0661 (0.0854)	MaskBCELoss 0.0025 (0.0369)	MaskDICELoss 0.0636 (0.0485)
Epoch: [2][196/500]	Time 72.953 (72.953)	Loss 0.4161 (0.2665)	CeLoss 0.0187 (0.0390)	SegCLSLoss 0.0036 (0.0018)	KLLoss 0.0044 (0.0038)	MaskLoss 0.1028 (0.0642)	MaskBCELoss 0.0099 (0.0171)	MaskDICELoss 0.0929 (0.0471)
Epoch: [2][197/500]	Time 78.383 (78.383)	Loss 0.4972 (0.3740)	CeLoss 0.0825 (0.0403)	SegCLSLoss 0.0018 (0.0020)	KLLoss 0.0018 (0.0036)	MaskLoss 0.1060 (0.0966)	MaskBCELoss 0.0060 (0.0286)	MaskDICELoss 0.1000 (0.0680)
Epoch: [2][198/500]	Time 77.685 (77.685)	Loss 0.3384 (0.4736)	CeLoss 0.0286 (0.0420)	SegCLSLoss 0.0013 (0.0018)	KLLoss 0.0060 (0.0038)	MaskLoss 0.0898 (0.1250)	MaskBCELoss 0.0280 (0.0365)	MaskDICELoss 0.0618 (0.0884)
Epoch: [2][199/500]	Time 81.846 (81.846)	Loss 0.0436 (0.3887)	CeLoss 0.0435 (0.0479)	SegCLSLoss 0.0000 (0.0016)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0970)	MaskBCELoss 0.0000 (0.0255)	MaskDICELoss 0.0000 (0.0714)
[2025-03-11 17:37:57,595] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[0.0002853614457831325], mom=[(0.9, 0.95)]
[2025-03-11 17:37:57,605] [INFO] [timer.py:215:stop] epoch=0/micro_step=1200/global_step=120, RunningAvgSamplesPerSec=0.7221532235415477, CurrSamplesPerSec=0.5463954697614873, MemAllocated=59.63GB, MaxMemAllocated=74.71GB
Epoch: [2][200/500]	Time 80.089 (80.089)	Loss 0.5162 (0.2859)	CeLoss 0.0879 (0.0374)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0024 (0.0025)	MaskLoss 0.1222 (0.0676)	MaskBCELoss 0.0317 (0.0127)	MaskDICELoss 0.0905 (0.0550)
Epoch: [2][201/500]	Time 76.166 (76.166)	Loss 0.3283 (0.3703)	CeLoss 0.0771 (0.0525)	SegCLSLoss 0.0014 (0.0011)	KLLoss 0.0017 (0.0043)	MaskLoss 0.0773 (0.0922)	MaskBCELoss 0.0300 (0.0279)	MaskDICELoss 0.0472 (0.0643)
Epoch: [2][202/500]	Time 75.971 (75.971)	Loss 0.3734 (0.3646)	CeLoss 0.0757 (0.0371)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0028 (0.0042)	MaskLoss 0.0760 (0.0888)	MaskBCELoss 0.0049 (0.0162)	MaskDICELoss 0.0711 (0.0726)
Epoch: [2][203/500]	Time 76.117 (76.117)	Loss 0.0555 (0.3046)	CeLoss 0.0554 (0.0358)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0750)	MaskBCELoss 0.0000 (0.0178)	MaskDICELoss 0.0000 (0.0572)
Epoch: [2][204/500]	Time 72.451 (72.451)	Loss 0.3079 (0.2986)	CeLoss 0.0659 (0.0397)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0046 (0.0026)	MaskLoss 0.0727 (0.0720)	MaskBCELoss 0.0271 (0.0160)	MaskDICELoss 0.0457 (0.0560)
Epoch: [2][205/500]	Time 74.422 (74.422)	Loss 0.4358 (0.4335)	CeLoss 0.0215 (0.0383)	SegCLSLoss 0.0016 (0.0018)	KLLoss 0.0026 (0.0034)	MaskLoss 0.1069 (0.1095)	MaskBCELoss 0.0084 (0.0234)	MaskDICELoss 0.0985 (0.0861)
Epoch: [2][206/500]	Time 77.384 (77.384)	Loss 0.4221 (0.3661)	CeLoss 0.0713 (0.0620)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0018 (0.0028)	MaskLoss 0.0891 (0.0788)	MaskBCELoss 0.0039 (0.0073)	MaskDICELoss 0.0852 (0.0715)
Epoch: [2][207/500]	Time 79.959 (79.959)	Loss 0.4685 (0.3676)	CeLoss 0.0515 (0.0366)	SegCLSLoss 0.0020 (0.0013)	KLLoss 0.0024 (0.0030)	MaskLoss 0.1093 (0.0898)	MaskBCELoss 0.0120 (0.0158)	MaskDICELoss 0.0974 (0.0740)
Epoch: [2][208/500]	Time 73.750 (73.750)	Loss 0.5032 (0.3820)	CeLoss 0.0903 (0.0479)	SegCLSLoss 0.0028 (0.0016)	KLLoss 0.0022 (0.0029)	MaskLoss 0.1175 (0.0909)	MaskBCELoss 0.0304 (0.0166)	MaskDICELoss 0.0870 (0.0743)
Epoch: [2][209/500]	Time 77.208 (77.208)	Loss 0.4625 (0.2814)	CeLoss 0.0474 (0.0339)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0028 (0.0024)	MaskLoss 0.1061 (0.0664)	MaskBCELoss 0.0063 (0.0105)	MaskDICELoss 0.0998 (0.0559)
Epoch: [2][210/500]	Time 72.890 (72.890)	Loss 0.4753 (0.3348)	CeLoss 0.0781 (0.0359)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0021 (0.0030)	MaskLoss 0.0993 (0.0879)	MaskBCELoss 0.0013 (0.0282)	MaskDICELoss 0.0981 (0.0597)
Epoch: [2][211/500]	Time 76.053 (76.053)	Loss 0.0912 (0.3143)	CeLoss 0.0222 (0.0342)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0040 (0.0035)	MaskLoss 0.0216 (0.0814)	MaskBCELoss 0.0110 (0.0250)	MaskDICELoss 0.0107 (0.0565)
Epoch: [2][212/500]	Time 76.325 (76.325)	Loss 0.3356 (0.3947)	CeLoss 0.0535 (0.0533)	SegCLSLoss 0.0016 (0.0016)	KLLoss 0.0025 (0.0040)	MaskLoss 0.0780 (0.0947)	MaskBCELoss 0.0168 (0.0212)	MaskDICELoss 0.0613 (0.0736)
Epoch: [2][213/500]	Time 72.953 (72.953)	Loss 0.3708 (0.4004)	CeLoss 0.0425 (0.0619)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0033 (0.0035)	MaskLoss 0.0868 (0.0932)	MaskBCELoss 0.0112 (0.0192)	MaskDICELoss 0.0756 (0.0740)
Epoch: [2][214/500]	Time 77.001 (77.001)	Loss 0.1326 (0.3861)	CeLoss 0.0747 (0.0402)	SegCLSLoss 0.0008 (0.0015)	KLLoss 0.0036 (0.0033)	MaskLoss 0.0183 (0.0925)	MaskBCELoss 0.0095 (0.0141)	MaskDICELoss 0.0088 (0.0784)
Epoch: [2][215/500]	Time 76.380 (76.380)	Loss 0.4177 (0.4657)	CeLoss 0.0542 (0.0468)	SegCLSLoss 0.0007 (0.0021)	KLLoss 0.0020 (0.0034)	MaskLoss 0.0912 (0.1144)	MaskBCELoss 0.0018 (0.0216)	MaskDICELoss 0.0894 (0.0928)
Epoch: [2][216/500]	Time 74.248 (74.248)	Loss 0.4286 (0.3166)	CeLoss 0.0232 (0.0500)	SegCLSLoss 0.0039 (0.0013)	KLLoss 0.0021 (0.0025)	MaskLoss 0.1040 (0.0717)	MaskBCELoss 0.0075 (0.0116)	MaskDICELoss 0.0966 (0.0600)
Epoch: [2][217/500]	Time 73.924 (73.924)	Loss 0.3777 (0.3441)	CeLoss 0.1162 (0.0588)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0031 (0.0037)	MaskLoss 0.0877 (0.0825)	MaskBCELoss 0.0466 (0.0245)	MaskDICELoss 0.0410 (0.0579)
Epoch: [2][218/500]	Time 78.077 (78.077)	Loss 0.3058 (0.3647)	CeLoss 0.0250 (0.0434)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0028 (0.0048)	MaskLoss 0.0810 (0.0921)	MaskBCELoss 0.0233 (0.0261)	MaskDICELoss 0.0577 (0.0660)
Epoch: [2][219/500]	Time 76.101 (76.101)	Loss 0.4381 (0.4040)	CeLoss 0.0381 (0.0579)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0030 (0.0032)	MaskLoss 0.1001 (0.0954)	MaskBCELoss 0.0020 (0.0196)	MaskDICELoss 0.0981 (0.0757)
Epoch: [2][220/500]	Time 82.306 (82.306)	Loss 0.4421 (0.3063)	CeLoss 0.0291 (0.0428)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0042 (0.0032)	MaskLoss 0.1057 (0.0709)	MaskBCELoss 0.0073 (0.0119)	MaskDICELoss 0.0984 (0.0590)
Epoch: [2][221/500]	Time 80.282 (80.282)	Loss 0.1888 (0.3234)	CeLoss 0.0210 (0.0389)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0021 (0.0033)	MaskLoss 0.0449 (0.0812)	MaskBCELoss 0.0070 (0.0220)	MaskDICELoss 0.0378 (0.0592)
Epoch: [2][222/500]	Time 87.706 (87.706)	Loss 0.3297 (0.3732)	CeLoss 0.0479 (0.0558)	SegCLSLoss 0.0022 (0.0011)	KLLoss 0.0042 (0.0036)	MaskLoss 0.0762 (0.0849)	MaskBCELoss 0.0142 (0.0133)	MaskDICELoss 0.0620 (0.0716)
Epoch: [2][223/500]	Time 77.858 (77.858)	Loss 0.4604 (0.3924)	CeLoss 0.0527 (0.0435)	SegCLSLoss 0.0033 (0.0015)	KLLoss 0.0022 (0.0037)	MaskLoss 0.1030 (0.0934)	MaskBCELoss 0.0039 (0.0145)	MaskDICELoss 0.0991 (0.0789)
Epoch: [2][224/500]	Time 72.193 (72.193)	Loss 0.4305 (0.3539)	CeLoss 0.0254 (0.0462)	SegCLSLoss 0.0029 (0.0015)	KLLoss 0.0032 (0.0037)	MaskLoss 0.1008 (0.0826)	MaskBCELoss 0.0013 (0.0136)	MaskDICELoss 0.0995 (0.0690)
Epoch: [2][225/500]	Time 73.846 (73.846)	Loss 0.4434 (0.3273)	CeLoss 0.0593 (0.0539)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0035 (0.0034)	MaskLoss 0.0975 (0.0728)	MaskBCELoss 0.0052 (0.0108)	MaskDICELoss 0.0923 (0.0620)
Epoch: [2][226/500]	Time 78.258 (78.258)	Loss 0.4968 (0.3555)	CeLoss 0.0547 (0.0435)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0034 (0.0029)	MaskLoss 0.1288 (0.0834)	MaskBCELoss 0.0385 (0.0125)	MaskDICELoss 0.0903 (0.0709)
Epoch: [2][227/500]	Time 76.158 (76.158)	Loss 0.4168 (0.3643)	CeLoss 0.0171 (0.0456)	SegCLSLoss 0.0038 (0.0020)	KLLoss 0.0030 (0.0034)	MaskLoss 0.1105 (0.0912)	MaskBCELoss 0.0237 (0.0252)	MaskDICELoss 0.0868 (0.0660)
Epoch: [2][228/500]	Time 85.941 (85.941)	Loss 0.3030 (0.3175)	CeLoss 0.0454 (0.0356)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0015 (0.0028)	MaskLoss 0.0818 (0.0805)	MaskBCELoss 0.0359 (0.0219)	MaskDICELoss 0.0459 (0.0586)
Epoch: [2][229/500]	Time 83.053 (83.053)	Loss 0.0178 (0.3619)	CeLoss 0.0178 (0.0480)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0883)	MaskBCELoss 0.0000 (0.0216)	MaskDICELoss 0.0000 (0.0667)
Epoch: [2][230/500]	Time 77.910 (77.910)	Loss 0.4175 (0.3840)	CeLoss 0.0208 (0.0429)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0046 (0.0041)	MaskLoss 0.0982 (0.0933)	MaskBCELoss 0.0008 (0.0184)	MaskDICELoss 0.0974 (0.0749)
Epoch: [2][231/500]	Time 76.659 (76.659)	Loss 0.4427 (0.4047)	CeLoss 0.0248 (0.0366)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0032 (0.0038)	MaskLoss 0.1076 (0.1099)	MaskBCELoss 0.0083 (0.0380)	MaskDICELoss 0.0994 (0.0719)
Epoch: [2][232/500]	Time 77.838 (77.838)	Loss 0.4950 (0.3833)	CeLoss 0.0713 (0.0580)	SegCLSLoss 0.0011 (0.0008)	KLLoss 0.0044 (0.0042)	MaskLoss 0.1130 (0.0924)	MaskBCELoss 0.0166 (0.0244)	MaskDICELoss 0.0964 (0.0680)
Epoch: [2][233/500]	Time 73.943 (73.943)	Loss 0.0374 (0.2692)	CeLoss 0.0197 (0.0406)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0046 (0.0041)	MaskLoss 0.0037 (0.0682)	MaskBCELoss 0.0013 (0.0244)	MaskDICELoss 0.0024 (0.0438)
Epoch: [2][234/500]	Time 75.599 (75.599)	Loss 0.4317 (0.4042)	CeLoss 0.0204 (0.0470)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0031 (0.0034)	MaskLoss 0.1040 (0.0981)	MaskBCELoss 0.0042 (0.0196)	MaskDICELoss 0.0998 (0.0785)
Epoch: [2][235/500]	Time 77.949 (77.949)	Loss 0.3590 (0.4150)	CeLoss 0.0339 (0.0507)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0026 (0.0038)	MaskLoss 0.0848 (0.1029)	MaskBCELoss 0.0084 (0.0258)	MaskDICELoss 0.0764 (0.0771)
Epoch: [2][236/500]	Time 80.257 (80.257)	Loss 0.4258 (0.3119)	CeLoss 0.0221 (0.0328)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0038 (0.0033)	MaskLoss 0.1004 (0.0818)	MaskBCELoss 0.0012 (0.0260)	MaskDICELoss 0.0992 (0.0558)
Epoch: [2][237/500]	Time 72.173 (72.173)	Loss 0.2064 (0.3075)	CeLoss 0.0444 (0.0535)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0039 (0.0031)	MaskLoss 0.0538 (0.0713)	MaskBCELoss 0.0287 (0.0175)	MaskDICELoss 0.0251 (0.0538)
Epoch: [2][238/500]	Time 79.728 (79.728)	Loss 0.5197 (0.3962)	CeLoss 0.0664 (0.0467)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0041 (0.0029)	MaskLoss 0.1370 (0.0951)	MaskBCELoss 0.0497 (0.0173)	MaskDICELoss 0.0873 (0.0778)
Epoch: [2][239/500]	Time 75.837 (75.837)	Loss 0.4870 (0.3378)	CeLoss 0.0815 (0.0523)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0044 (0.0035)	MaskLoss 0.1003 (0.0741)	MaskBCELoss 0.0004 (0.0076)	MaskDICELoss 0.1000 (0.0665)
Epoch: [2][240/500]	Time 85.715 (85.715)	Loss 0.2854 (0.3440)	CeLoss 0.0183 (0.0380)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0028 (0.0036)	MaskLoss 0.0885 (0.0860)	MaskBCELoss 0.0449 (0.0211)	MaskDICELoss 0.0435 (0.0650)
Epoch: [2][241/500]	Time 71.677 (71.677)	Loss 0.3274 (0.3475)	CeLoss 0.0237 (0.0417)	SegCLSLoss 0.0036 (0.0014)	KLLoss 0.0034 (0.0041)	MaskLoss 0.0750 (0.0853)	MaskBCELoss 0.0007 (0.0201)	MaskDICELoss 0.0743 (0.0652)
Epoch: [2][242/500]	Time 73.461 (73.461)	Loss 0.4632 (0.4261)	CeLoss 0.0581 (0.0489)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0033 (0.0029)	MaskLoss 0.1009 (0.1080)	MaskBCELoss 0.0010 (0.0292)	MaskDICELoss 0.0998 (0.0788)
Epoch: [2][243/500]	Time 72.293 (72.293)	Loss 0.3560 (0.2917)	CeLoss 0.0234 (0.0418)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0023 (0.0034)	MaskLoss 0.0848 (0.0725)	MaskBCELoss 0.0048 (0.0221)	MaskDICELoss 0.0800 (0.0504)
Epoch: [2][244/500]	Time 76.207 (76.207)	Loss 0.4394 (0.3306)	CeLoss 0.0188 (0.0302)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0036 (0.0033)	MaskLoss 0.1129 (0.0810)	MaskBCELoss 0.0174 (0.0138)	MaskDICELoss 0.0955 (0.0672)
Epoch: [2][245/500]	Time 79.811 (79.811)	Loss 0.4516 (0.3717)	CeLoss 0.0214 (0.0427)	SegCLSLoss 0.0023 (0.0013)	KLLoss 0.0036 (0.0033)	MaskLoss 0.1127 (0.0949)	MaskBCELoss 0.0128 (0.0273)	MaskDICELoss 0.1000 (0.0676)
Epoch: [2][246/500]	Time 72.548 (72.548)	Loss 0.3775 (0.4180)	CeLoss 0.0339 (0.0620)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0028 (0.0033)	MaskLoss 0.0892 (0.0959)	MaskBCELoss 0.0083 (0.0158)	MaskDICELoss 0.0810 (0.0801)
Epoch: [2][247/500]	Time 83.999 (83.999)	Loss 0.4365 (0.4070)	CeLoss 0.0214 (0.0479)	SegCLSLoss 0.0030 (0.0015)	KLLoss 0.0023 (0.0032)	MaskLoss 0.1065 (0.1003)	MaskBCELoss 0.0073 (0.0231)	MaskDICELoss 0.0992 (0.0772)
Epoch: [2][248/500]	Time 73.418 (73.418)	Loss 0.3568 (0.3332)	CeLoss 0.0295 (0.0332)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0029 (0.0032)	MaskLoss 0.0986 (0.0862)	MaskBCELoss 0.0353 (0.0241)	MaskDICELoss 0.0633 (0.0620)
Epoch: [2][249/500]	Time 71.948 (71.948)	Loss 0.4364 (0.4006)	CeLoss 0.0237 (0.0529)	SegCLSLoss 0.0041 (0.0015)	KLLoss 0.0030 (0.0031)	MaskLoss 0.1121 (0.0946)	MaskBCELoss 0.0204 (0.0173)	MaskDICELoss 0.0917 (0.0773)
Epoch: [2][250/500]	Time 79.101 (79.101)	Loss 0.2516 (0.3499)	CeLoss 0.0432 (0.0472)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0050 (0.0037)	MaskLoss 0.0543 (0.0796)	MaskBCELoss 0.0070 (0.0100)	MaskDICELoss 0.0472 (0.0696)
Epoch: [2][251/500]	Time 71.420 (71.420)	Loss 0.0361 (0.2470)	CeLoss 0.0361 (0.0461)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0569)	MaskBCELoss 0.0000 (0.0154)	MaskDICELoss 0.0000 (0.0415)
Epoch: [2][252/500]	Time 73.046 (73.046)	Loss 0.4495 (0.3335)	CeLoss 0.0415 (0.0329)	SegCLSLoss 0.0008 (0.0015)	KLLoss 0.0046 (0.0029)	MaskLoss 0.1024 (0.0835)	MaskBCELoss 0.0034 (0.0186)	MaskDICELoss 0.0990 (0.0649)
Epoch: [2][253/500]	Time 81.517 (81.517)	Loss 0.2198 (0.3369)	CeLoss 0.0693 (0.0361)	SegCLSLoss 0.0018 (0.0019)	KLLoss 0.0040 (0.0029)	MaskLoss 0.0386 (0.0805)	MaskBCELoss 0.0044 (0.0126)	MaskDICELoss 0.0342 (0.0679)
Epoch: [2][254/500]	Time 71.989 (71.989)	Loss 0.0377 (0.3162)	CeLoss 0.0376 (0.0370)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0787)	MaskBCELoss 0.0000 (0.0196)	MaskDICELoss 0.0000 (0.0591)
Epoch: [2][255/500]	Time 80.104 (80.104)	Loss 0.4963 (0.4021)	CeLoss 0.0776 (0.0429)	SegCLSLoss 0.0016 (0.0017)	KLLoss 0.0057 (0.0033)	MaskLoss 0.1068 (0.0982)	MaskBCELoss 0.0076 (0.0189)	MaskDICELoss 0.0992 (0.0793)
Epoch: [2][256/500]	Time 78.194 (78.194)	Loss 0.2724 (0.3271)	CeLoss 0.0579 (0.0363)	SegCLSLoss 0.0008 (0.0007)	KLLoss 0.0042 (0.0035)	MaskLoss 0.0553 (0.0815)	MaskBCELoss 0.0057 (0.0194)	MaskDICELoss 0.0496 (0.0621)
Epoch: [2][257/500]	Time 76.445 (76.445)	Loss 0.4266 (0.3884)	CeLoss 0.0586 (0.0599)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0021 (0.0027)	MaskLoss 0.1072 (0.0891)	MaskBCELoss 0.0316 (0.0155)	MaskDICELoss 0.0756 (0.0736)
Epoch: [2][258/500]	Time 74.039 (74.039)	Loss 0.5276 (0.3683)	CeLoss 0.0835 (0.0369)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0026 (0.0030)	MaskLoss 0.1577 (0.0924)	MaskBCELoss 0.0949 (0.0209)	MaskDICELoss 0.0628 (0.0715)
Epoch: [2][259/500]	Time 75.395 (75.395)	Loss 0.2964 (0.3584)	CeLoss 0.0238 (0.0485)	SegCLSLoss 0.0010 (0.0008)	KLLoss 0.0028 (0.0033)	MaskLoss 0.0880 (0.0860)	MaskBCELoss 0.0414 (0.0188)	MaskDICELoss 0.0466 (0.0671)
Epoch: [2][260/500]	Time 79.480 (79.480)	Loss 0.4695 (0.3153)	CeLoss 0.0654 (0.0503)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0049 (0.0033)	MaskLoss 0.1044 (0.0719)	MaskBCELoss 0.0093 (0.0131)	MaskDICELoss 0.0950 (0.0588)
Epoch: [2][261/500]	Time 78.852 (78.852)	Loss 0.4102 (0.3903)	CeLoss 0.0266 (0.0367)	SegCLSLoss 0.0028 (0.0014)	KLLoss 0.0037 (0.0036)	MaskLoss 0.1081 (0.0998)	MaskBCELoss 0.0269 (0.0249)	MaskDICELoss 0.0812 (0.0749)
Epoch: [2][262/500]	Time 77.753 (77.753)	Loss 0.0706 (0.3558)	CeLoss 0.0124 (0.0396)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0030 (0.0031)	MaskLoss 0.0194 (0.0877)	MaskBCELoss 0.0113 (0.0190)	MaskDICELoss 0.0081 (0.0687)
Epoch: [2][263/500]	Time 75.044 (75.044)	Loss 0.4898 (0.3966)	CeLoss 0.0133 (0.0479)	SegCLSLoss 0.0025 (0.0018)	KLLoss 0.0024 (0.0032)	MaskLoss 0.1375 (0.0987)	MaskBCELoss 0.0387 (0.0251)	MaskDICELoss 0.0989 (0.0736)
Epoch: [2][264/500]	Time 80.959 (80.959)	Loss 0.4548 (0.3240)	CeLoss 0.0242 (0.0409)	SegCLSLoss 0.0024 (0.0009)	KLLoss 0.0031 (0.0032)	MaskLoss 0.1219 (0.0768)	MaskBCELoss 0.0307 (0.0140)	MaskDICELoss 0.0912 (0.0629)
Epoch: [2][265/500]	Time 78.444 (78.444)	Loss 0.2337 (0.3328)	CeLoss 0.0535 (0.0506)	SegCLSLoss 0.0002 (0.0028)	KLLoss 0.0028 (0.0031)	MaskLoss 0.0483 (0.0816)	MaskBCELoss 0.0078 (0.0244)	MaskDICELoss 0.0405 (0.0572)
Epoch: [2][266/500]	Time 76.887 (76.887)	Loss 0.3349 (0.3782)	CeLoss 0.0140 (0.0405)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0036 (0.0032)	MaskLoss 0.0874 (0.0952)	MaskBCELoss 0.0167 (0.0236)	MaskDICELoss 0.0708 (0.0717)
Epoch: [2][267/500]	Time 77.059 (77.059)	Loss 0.1569 (0.2827)	CeLoss 0.0425 (0.0476)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0024 (0.0025)	MaskLoss 0.0438 (0.0674)	MaskBCELoss 0.0316 (0.0188)	MaskDICELoss 0.0122 (0.0487)
Epoch: [2][268/500]	Time 75.739 (75.739)	Loss 0.4288 (0.3849)	CeLoss 0.0276 (0.0483)	SegCLSLoss 0.0029 (0.0021)	KLLoss 0.0036 (0.0035)	MaskLoss 0.1098 (0.0949)	MaskBCELoss 0.0215 (0.0237)	MaskDICELoss 0.0884 (0.0711)
Epoch: [2][269/500]	Time 80.230 (80.230)	Loss 0.1297 (0.3395)	CeLoss 0.0415 (0.0539)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0026 (0.0030)	MaskLoss 0.0315 (0.0835)	MaskBCELoss 0.0201 (0.0260)	MaskDICELoss 0.0114 (0.0575)
Epoch: [2][270/500]	Time 73.233 (73.233)	Loss 0.2713 (0.3148)	CeLoss 0.0713 (0.0501)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0032 (0.0019)	MaskLoss 0.0627 (0.0736)	MaskBCELoss 0.0271 (0.0159)	MaskDICELoss 0.0356 (0.0576)
Epoch: [2][271/500]	Time 76.216 (76.216)	Loss 0.4405 (0.3972)	CeLoss 0.0270 (0.0416)	SegCLSLoss 0.0019 (0.0013)	KLLoss 0.0038 (0.0030)	MaskLoss 0.1047 (0.0971)	MaskBCELoss 0.0050 (0.0183)	MaskDICELoss 0.0997 (0.0788)
Epoch: [2][272/500]	Time 72.473 (72.473)	Loss 0.1173 (0.3324)	CeLoss 0.0718 (0.0575)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0031 (0.0031)	MaskLoss 0.0138 (0.0804)	MaskBCELoss 0.0067 (0.0252)	MaskDICELoss 0.0071 (0.0552)
Epoch: [2][273/500]	Time 83.369 (83.369)	Loss 0.4653 (0.2859)	CeLoss 0.0131 (0.0373)	SegCLSLoss 0.0008 (0.0008)	KLLoss 0.0032 (0.0028)	MaskLoss 0.1290 (0.0696)	MaskBCELoss 0.0336 (0.0166)	MaskDICELoss 0.0954 (0.0531)
Epoch: [2][274/500]	Time 76.436 (76.436)	Loss 0.4305 (0.2459)	CeLoss 0.0225 (0.0361)	SegCLSLoss 0.0055 (0.0020)	KLLoss 0.0025 (0.0029)	MaskLoss 0.1121 (0.0572)	MaskBCELoss 0.0228 (0.0114)	MaskDICELoss 0.0893 (0.0458)
Epoch: [2][275/500]	Time 81.528 (81.528)	Loss 0.4806 (0.3155)	CeLoss 0.0243 (0.0409)	SegCLSLoss 0.0057 (0.0011)	KLLoss 0.0049 (0.0029)	MaskLoss 0.1262 (0.0853)	MaskBCELoss 0.0280 (0.0350)	MaskDICELoss 0.0981 (0.0503)
Epoch: [2][276/500]	Time 74.142 (74.142)	Loss 0.1378 (0.3495)	CeLoss 0.0181 (0.0424)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0021 (0.0032)	MaskLoss 0.0326 (0.0870)	MaskBCELoss 0.0065 (0.0224)	MaskDICELoss 0.0262 (0.0646)
Epoch: [2][277/500]	Time 82.868 (82.868)	Loss 0.4477 (0.3036)	CeLoss 0.0347 (0.0327)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0033 (0.0029)	MaskLoss 0.1069 (0.0719)	MaskBCELoss 0.0090 (0.0100)	MaskDICELoss 0.0978 (0.0619)
Epoch: [2][278/500]	Time 76.517 (76.517)	Loss 0.4662 (0.4085)	CeLoss 0.0598 (0.0380)	SegCLSLoss 0.0012 (0.0010)	KLLoss 0.0031 (0.0027)	MaskLoss 0.1023 (0.1017)	MaskBCELoss 0.0033 (0.0197)	MaskDICELoss 0.0990 (0.0820)
Epoch: [2][279/500]	Time 74.934 (74.934)	Loss 0.1249 (0.2672)	CeLoss 0.0222 (0.0439)	SegCLSLoss 0.0056 (0.0018)	KLLoss 0.0031 (0.0030)	MaskLoss 0.0292 (0.0614)	MaskBCELoss 0.0100 (0.0132)	MaskDICELoss 0.0192 (0.0482)
Epoch: [2][280/500]	Time 81.011 (81.011)	Loss 0.4914 (0.3803)	CeLoss 0.0703 (0.0440)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0026 (0.0032)	MaskLoss 0.1106 (0.0944)	MaskBCELoss 0.0121 (0.0225)	MaskDICELoss 0.0985 (0.0719)
Epoch: [2][281/500]	Time 72.880 (72.880)	Loss 0.4244 (0.3144)	CeLoss 0.0219 (0.0369)	SegCLSLoss 0.0012 (0.0021)	KLLoss 0.0033 (0.0031)	MaskLoss 0.1058 (0.0747)	MaskBCELoss 0.0123 (0.0127)	MaskDICELoss 0.0935 (0.0620)
Epoch: [2][282/500]	Time 81.785 (81.785)	Loss 0.3806 (0.3187)	CeLoss 0.0635 (0.0452)	SegCLSLoss 0.0023 (0.0017)	KLLoss 0.0016 (0.0029)	MaskLoss 0.0939 (0.0774)	MaskBCELoss 0.0307 (0.0199)	MaskDICELoss 0.0632 (0.0575)
Epoch: [2][283/500]	Time 79.154 (79.154)	Loss 0.5231 (0.3953)	CeLoss 0.0825 (0.0420)	SegCLSLoss 0.0023 (0.0016)	KLLoss 0.0029 (0.0023)	MaskLoss 0.1211 (0.0935)	MaskBCELoss 0.0238 (0.0119)	MaskDICELoss 0.0973 (0.0816)
Epoch: [2][284/500]	Time 74.663 (74.663)	Loss 0.5297 (0.3590)	CeLoss 0.0305 (0.0471)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0044 (0.0032)	MaskLoss 0.1553 (0.0894)	MaskBCELoss 0.0633 (0.0247)	MaskDICELoss 0.0920 (0.0647)
Epoch: [2][285/500]	Time 72.618 (72.618)	Loss 0.4359 (0.3841)	CeLoss 0.0520 (0.0418)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0035 (0.0034)	MaskLoss 0.0966 (0.1011)	MaskBCELoss 0.0029 (0.0330)	MaskDICELoss 0.0936 (0.0681)
Epoch: [2][286/500]	Time 76.096 (76.096)	Loss 0.3745 (0.4068)	CeLoss 0.0435 (0.0475)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0043 (0.0029)	MaskLoss 0.0894 (0.0975)	MaskBCELoss 0.0154 (0.0171)	MaskDICELoss 0.0740 (0.0804)
Epoch: [2][287/500]	Time 77.580 (77.580)	Loss 0.4413 (0.4334)	CeLoss 0.0635 (0.0606)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0068 (0.0044)	MaskLoss 0.1317 (0.1051)	MaskBCELoss 0.0780 (0.0262)	MaskDICELoss 0.0537 (0.0789)
Epoch: [2][288/500]	Time 77.052 (77.052)	Loss 0.0491 (0.3534)	CeLoss 0.0273 (0.0449)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0030 (0.0031)	MaskLoss 0.0052 (0.0868)	MaskBCELoss 0.0014 (0.0213)	MaskDICELoss 0.0039 (0.0656)
Epoch: [2][289/500]	Time 77.205 (77.205)	Loss 0.1008 (0.2904)	CeLoss 0.0791 (0.0345)	SegCLSLoss 0.0002 (0.0011)	KLLoss 0.0042 (0.0029)	MaskLoss 0.0052 (0.0687)	MaskBCELoss 0.0018 (0.0113)	MaskDICELoss 0.0034 (0.0575)
Epoch: [2][290/500]	Time 73.400 (73.400)	Loss 0.2303 (0.4261)	CeLoss 0.0796 (0.0522)	SegCLSLoss 0.0010 (0.0015)	KLLoss 0.0026 (0.0027)	MaskLoss 0.0408 (0.1176)	MaskBCELoss 0.0080 (0.0499)	MaskDICELoss 0.0329 (0.0677)
Epoch: [2][291/500]	Time 80.293 (80.293)	Loss 0.1435 (0.2975)	CeLoss 0.0520 (0.0338)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0033 (0.0030)	MaskLoss 0.0285 (0.0716)	MaskBCELoss 0.0129 (0.0131)	MaskDICELoss 0.0155 (0.0586)
Epoch: [2][292/500]	Time 84.507 (84.507)	Loss 0.1937 (0.3344)	CeLoss 0.0164 (0.0444)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0024 (0.0025)	MaskLoss 0.0603 (0.0837)	MaskBCELoss 0.0333 (0.0240)	MaskDICELoss 0.0269 (0.0597)
Epoch: [2][293/500]	Time 80.359 (80.359)	Loss 0.1581 (0.2939)	CeLoss 0.0610 (0.0385)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0026 (0.0034)	MaskLoss 0.0269 (0.0810)	MaskBCELoss 0.0068 (0.0363)	MaskDICELoss 0.0201 (0.0447)
Epoch: [2][294/500]	Time 72.495 (72.495)	Loss 0.5169 (0.4144)	CeLoss 0.0933 (0.0636)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0030 (0.0030)	MaskLoss 0.1110 (0.0929)	MaskBCELoss 0.0122 (0.0122)	MaskDICELoss 0.0988 (0.0806)
Epoch: [2][295/500]	Time 80.423 (80.423)	Loss 0.5463 (0.3497)	CeLoss 0.0591 (0.0435)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0044 (0.0033)	MaskLoss 0.1428 (0.0862)	MaskBCELoss 0.0441 (0.0211)	MaskDICELoss 0.0987 (0.0651)
Epoch: [2][296/500]	Time 75.339 (75.339)	Loss 0.4027 (0.3904)	CeLoss 0.0231 (0.0423)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0033 (0.0036)	MaskLoss 0.0955 (0.0927)	MaskBCELoss 0.0031 (0.0135)	MaskDICELoss 0.0924 (0.0792)
Epoch: [2][297/500]	Time 83.170 (83.170)	Loss 0.0189 (0.3629)	CeLoss 0.0189 (0.0550)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0025)	MaskLoss 0.0000 (0.0945)	MaskBCELoss 0.0000 (0.0366)	MaskDICELoss 0.0000 (0.0579)
Epoch: [2][298/500]	Time 75.288 (75.288)	Loss 0.4725 (0.3811)	CeLoss 0.0645 (0.0494)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0042 (0.0035)	MaskLoss 0.1266 (0.0921)	MaskBCELoss 0.0515 (0.0203)	MaskDICELoss 0.0751 (0.0718)
Epoch: [2][299/500]	Time 77.700 (77.700)	Loss 0.5634 (0.4146)	CeLoss 0.0542 (0.0389)	SegCLSLoss 0.0005 (0.0023)	KLLoss 0.0030 (0.0028)	MaskLoss 0.1569 (0.1056)	MaskBCELoss 0.0609 (0.0254)	MaskDICELoss 0.0960 (0.0802)
[2025-03-11 19:46:27,892] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[0.00028403614457831323], mom=[(0.9, 0.95)]
[2025-03-11 19:46:27,903] [INFO] [timer.py:215:stop] epoch=0/micro_step=1300/global_step=130, RunningAvgSamplesPerSec=0.7002602516384637, CurrSamplesPerSec=0.5073966712624131, MemAllocated=60.08GB, MaxMemAllocated=74.71GB
Epoch: [2][300/500]	Time 79.915 (79.915)	Loss 0.2065 (0.2697)	CeLoss 0.0212 (0.0331)	SegCLSLoss 0.0014 (0.0016)	KLLoss 0.0047 (0.0026)	MaskLoss 0.0487 (0.0685)	MaskBCELoss 0.0076 (0.0203)	MaskDICELoss 0.0411 (0.0481)
Epoch: [2][301/500]	Time 73.054 (73.054)	Loss 0.4144 (0.4036)	CeLoss 0.0444 (0.0551)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0030 (0.0033)	MaskLoss 0.1339 (0.0983)	MaskBCELoss 0.0844 (0.0243)	MaskDICELoss 0.0495 (0.0740)
Epoch: [2][302/500]	Time 79.107 (79.107)	Loss 0.4100 (0.3711)	CeLoss 0.0378 (0.0483)	SegCLSLoss 0.0015 (0.0014)	KLLoss 0.0020 (0.0026)	MaskLoss 0.0964 (0.0894)	MaskBCELoss 0.0081 (0.0190)	MaskDICELoss 0.0883 (0.0704)
Epoch: [2][303/500]	Time 80.573 (80.573)	Loss 0.0801 (0.2079)	CeLoss 0.0503 (0.0314)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0033 (0.0026)	MaskLoss 0.0092 (0.0488)	MaskBCELoss 0.0053 (0.0109)	MaskDICELoss 0.0039 (0.0379)
Epoch: [2][304/500]	Time 73.096 (73.096)	Loss 0.6157 (0.2538)	CeLoss 0.0581 (0.0429)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0037 (0.0022)	MaskLoss 0.1802 (0.0611)	MaskBCELoss 0.0836 (0.0180)	MaskDICELoss 0.0966 (0.0431)
Epoch: [2][305/500]	Time 86.126 (86.126)	Loss 0.4001 (0.3863)	CeLoss 0.0228 (0.0404)	SegCLSLoss 0.0020 (0.0015)	KLLoss 0.0033 (0.0033)	MaskLoss 0.1044 (0.1034)	MaskBCELoss 0.0224 (0.0358)	MaskDICELoss 0.0820 (0.0676)
Epoch: [2][306/500]	Time 77.660 (77.660)	Loss 0.4665 (0.3211)	CeLoss 0.0128 (0.0520)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0030 (0.0024)	MaskLoss 0.1381 (0.0769)	MaskBCELoss 0.0510 (0.0207)	MaskDICELoss 0.0871 (0.0562)
Epoch: [2][307/500]	Time 76.612 (76.612)	Loss 0.3340 (0.2988)	CeLoss 0.0240 (0.0374)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0022 (0.0027)	MaskLoss 0.0847 (0.0728)	MaskBCELoss 0.0158 (0.0165)	MaskDICELoss 0.0689 (0.0563)
Epoch: [2][308/500]	Time 82.292 (82.292)	Loss 0.4338 (0.3431)	CeLoss 0.0145 (0.0417)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0028 (0.0026)	MaskLoss 0.1108 (0.0860)	MaskBCELoss 0.0135 (0.0230)	MaskDICELoss 0.0973 (0.0630)
Epoch: [2][309/500]	Time 77.377 (77.377)	Loss 0.4193 (0.3595)	CeLoss 0.0277 (0.0523)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0035 (0.0029)	MaskLoss 0.1097 (0.0860)	MaskBCELoss 0.0257 (0.0202)	MaskDICELoss 0.0840 (0.0658)
Epoch: [2][310/500]	Time 83.817 (83.817)	Loss 0.4645 (0.3530)	CeLoss 0.0535 (0.0415)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0031 (0.0036)	MaskLoss 0.1044 (0.0841)	MaskBCELoss 0.0053 (0.0146)	MaskDICELoss 0.0991 (0.0695)
Epoch: [2][311/500]	Time 71.676 (71.676)	Loss 0.4534 (0.3013)	CeLoss 0.0198 (0.0431)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0023 (0.0021)	MaskLoss 0.1158 (0.0710)	MaskBCELoss 0.0162 (0.0143)	MaskDICELoss 0.0995 (0.0567)
Epoch: [2][312/500]	Time 72.853 (72.853)	Loss 0.4600 (0.2599)	CeLoss 0.0815 (0.0428)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0041 (0.0027)	MaskLoss 0.0978 (0.0634)	MaskBCELoss 0.0085 (0.0199)	MaskDICELoss 0.0892 (0.0435)
Epoch: [2][313/500]	Time 84.489 (84.489)	Loss 0.2054 (0.3344)	CeLoss 0.0610 (0.0323)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0036 (0.0024)	MaskLoss 0.0367 (0.0787)	MaskBCELoss 0.0029 (0.0078)	MaskDICELoss 0.0338 (0.0709)
Epoch: [2][314/500]	Time 86.880 (86.880)	Loss 0.2785 (0.3242)	CeLoss 0.0243 (0.0463)	SegCLSLoss 0.0021 (0.0012)	KLLoss 0.0027 (0.0024)	MaskLoss 0.0730 (0.0742)	MaskBCELoss 0.0209 (0.0109)	MaskDICELoss 0.0521 (0.0633)
Epoch: [2][315/500]	Time 80.521 (80.521)	Loss 0.4455 (0.3979)	CeLoss 0.0295 (0.0454)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0033 (0.0029)	MaskLoss 0.1082 (0.0930)	MaskBCELoss 0.0102 (0.0114)	MaskDICELoss 0.0980 (0.0816)
Epoch: [2][316/500]	Time 90.107 (90.107)	Loss 0.2293 (0.2603)	CeLoss 0.0160 (0.0359)	SegCLSLoss 0.0012 (0.0006)	KLLoss 0.0031 (0.0028)	MaskLoss 0.0687 (0.0630)	MaskBCELoss 0.0327 (0.0153)	MaskDICELoss 0.0360 (0.0477)
Epoch: [2][317/500]	Time 80.912 (80.912)	Loss 0.4118 (0.3953)	CeLoss 0.0664 (0.0388)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0052 (0.0032)	MaskLoss 0.1015 (0.1014)	MaskBCELoss 0.0329 (0.0263)	MaskDICELoss 0.0686 (0.0751)
Epoch: [2][318/500]	Time 72.350 (72.350)	Loss 0.4575 (0.2868)	CeLoss 0.0415 (0.0411)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0021 (0.0024)	MaskLoss 0.1097 (0.0685)	MaskBCELoss 0.0128 (0.0157)	MaskDICELoss 0.0969 (0.0528)
Epoch: [2][319/500]	Time 80.912 (80.912)	Loss 0.4408 (0.3375)	CeLoss 0.0454 (0.0398)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0022 (0.0024)	MaskLoss 0.1012 (0.0793)	MaskBCELoss 0.0061 (0.0113)	MaskDICELoss 0.0951 (0.0680)
Epoch: [2][320/500]	Time 76.800 (76.800)	Loss 0.4305 (0.3077)	CeLoss 0.0232 (0.0484)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0027 (0.0031)	MaskLoss 0.1146 (0.0771)	MaskBCELoss 0.0272 (0.0263)	MaskDICELoss 0.0874 (0.0508)
Epoch: [2][321/500]	Time 78.889 (78.889)	Loss 0.4246 (0.3524)	CeLoss 0.0405 (0.0297)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0028 (0.0024)	MaskLoss 0.0967 (0.0849)	MaskBCELoss 0.0028 (0.0098)	MaskDICELoss 0.0938 (0.0751)
Epoch: [2][322/500]	Time 83.631 (83.631)	Loss 0.3866 (0.3673)	CeLoss 0.0306 (0.0451)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0024 (0.0026)	MaskLoss 0.0887 (0.0875)	MaskBCELoss 0.0009 (0.0155)	MaskDICELoss 0.0878 (0.0720)
Epoch: [2][323/500]	Time 80.515 (80.515)	Loss 0.4272 (0.4144)	CeLoss 0.0203 (0.0481)	SegCLSLoss 0.0024 (0.0013)	KLLoss 0.0023 (0.0023)	MaskLoss 0.1018 (0.1094)	MaskBCELoss 0.0019 (0.0372)	MaskDICELoss 0.0999 (0.0722)
Epoch: [2][324/500]	Time 82.544 (82.544)	Loss 0.2413 (0.3726)	CeLoss 0.0256 (0.0339)	SegCLSLoss 0.0020 (0.0018)	KLLoss 0.0035 (0.0029)	MaskLoss 0.0570 (0.0978)	MaskBCELoss 0.0085 (0.0282)	MaskDICELoss 0.0486 (0.0697)
Epoch: [2][325/500]	Time 77.012 (77.012)	Loss 0.4093 (0.3729)	CeLoss 0.0172 (0.0318)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0030 (0.0024)	MaskLoss 0.1028 (0.0993)	MaskBCELoss 0.0112 (0.0296)	MaskDICELoss 0.0916 (0.0697)
Epoch: [2][326/500]	Time 82.969 (82.969)	Loss 0.1423 (0.2548)	CeLoss 0.0212 (0.0412)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0038 (0.0020)	MaskLoss 0.0450 (0.0564)	MaskBCELoss 0.0315 (0.0074)	MaskDICELoss 0.0135 (0.0491)
Epoch: [2][327/500]	Time 72.284 (72.284)	Loss 0.4349 (0.3619)	CeLoss 0.0601 (0.0379)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0065 (0.0036)	MaskLoss 0.0960 (0.0894)	MaskBCELoss 0.0081 (0.0189)	MaskDICELoss 0.0879 (0.0705)
Epoch: [2][328/500]	Time 76.814 (76.814)	Loss 0.3961 (0.3214)	CeLoss 0.0315 (0.0305)	SegCLSLoss 0.0004 (0.0018)	KLLoss 0.0034 (0.0031)	MaskLoss 0.0924 (0.0821)	MaskBCELoss 0.0043 (0.0208)	MaskDICELoss 0.0882 (0.0613)
Epoch: [2][329/500]	Time 79.340 (79.340)	Loss 0.4284 (0.3780)	CeLoss 0.0613 (0.0498)	SegCLSLoss 0.0007 (0.0018)	KLLoss 0.0030 (0.0024)	MaskLoss 0.1019 (0.0886)	MaskBCELoss 0.0220 (0.0148)	MaskDICELoss 0.0799 (0.0738)
Epoch: [2][330/500]	Time 80.437 (80.437)	Loss 0.4199 (0.3719)	CeLoss 0.0242 (0.0475)	SegCLSLoss 0.0022 (0.0016)	KLLoss 0.0037 (0.0027)	MaskLoss 0.0992 (0.0885)	MaskBCELoss 0.0030 (0.0166)	MaskDICELoss 0.0962 (0.0719)
Epoch: [2][331/500]	Time 80.015 (80.015)	Loss 0.0892 (0.3033)	CeLoss 0.0598 (0.0461)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0022 (0.0025)	MaskLoss 0.0098 (0.0723)	MaskBCELoss 0.0062 (0.0175)	MaskDICELoss 0.0036 (0.0548)
Epoch: [2][332/500]	Time 77.242 (77.242)	Loss 0.4289 (0.3995)	CeLoss 0.0189 (0.0303)	SegCLSLoss 0.0021 (0.0022)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1043 (0.0989)	MaskBCELoss 0.0057 (0.0155)	MaskDICELoss 0.0985 (0.0835)
Epoch: [2][333/500]	Time 72.866 (72.866)	Loss 0.4247 (0.3693)	CeLoss 0.0199 (0.0399)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0037 (0.0024)	MaskLoss 0.1035 (0.0888)	MaskBCELoss 0.0068 (0.0144)	MaskDICELoss 0.0967 (0.0744)
Epoch: [2][334/500]	Time 83.886 (83.886)	Loss 0.5922 (0.3855)	CeLoss 0.0277 (0.0297)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0032 (0.0031)	MaskLoss 0.1809 (0.0968)	MaskBCELoss 0.0813 (0.0176)	MaskDICELoss 0.0996 (0.0792)
Epoch: [2][335/500]	Time 72.360 (72.360)	Loss 0.4982 (0.3615)	CeLoss 0.0752 (0.0457)	SegCLSLoss 0.0008 (0.0007)	KLLoss 0.0065 (0.0031)	MaskLoss 0.1264 (0.0943)	MaskBCELoss 0.0450 (0.0325)	MaskDICELoss 0.0815 (0.0618)
Epoch: [2][336/500]	Time 79.129 (79.129)	Loss 0.4201 (0.2944)	CeLoss 0.0225 (0.0423)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0020 (0.0024)	MaskLoss 0.1005 (0.0703)	MaskBCELoss 0.0036 (0.0161)	MaskDICELoss 0.0969 (0.0542)
Epoch: [2][337/500]	Time 75.501 (75.501)	Loss 0.3656 (0.4150)	CeLoss 0.0239 (0.0512)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0020 (0.0025)	MaskLoss 0.1141 (0.1070)	MaskBCELoss 0.0586 (0.0338)	MaskDICELoss 0.0556 (0.0733)
Epoch: [2][338/500]	Time 72.913 (72.913)	Loss 0.0718 (0.3890)	CeLoss 0.0239 (0.0388)	SegCLSLoss 0.0011 (0.0014)	KLLoss 0.0042 (0.0031)	MaskLoss 0.0144 (0.0940)	MaskBCELoss 0.0072 (0.0149)	MaskDICELoss 0.0072 (0.0791)
Epoch: [2][339/500]	Time 76.362 (76.362)	Loss 0.3164 (0.3356)	CeLoss 0.0243 (0.0387)	SegCLSLoss 0.0016 (0.0016)	KLLoss 0.0025 (0.0023)	MaskLoss 0.0840 (0.0828)	MaskBCELoss 0.0236 (0.0188)	MaskDICELoss 0.0604 (0.0640)
Epoch: [2][340/500]	Time 75.400 (75.400)	Loss 0.4481 (0.3660)	CeLoss 0.0405 (0.0506)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0062 (0.0034)	MaskLoss 0.1010 (0.0900)	MaskBCELoss 0.0016 (0.0243)	MaskDICELoss 0.0994 (0.0657)
Epoch: [2][341/500]	Time 83.051 (83.051)	Loss 0.4045 (0.4028)	CeLoss 0.0635 (0.0419)	SegCLSLoss 0.0003 (0.0019)	KLLoss 0.0034 (0.0029)	MaskLoss 0.0914 (0.1012)	MaskBCELoss 0.0141 (0.0239)	MaskDICELoss 0.0773 (0.0773)
Epoch: [2][342/500]	Time 83.778 (83.778)	Loss 0.5964 (0.4447)	CeLoss 0.1030 (0.0517)	SegCLSLoss 0.0007 (0.0008)	KLLoss 0.0034 (0.0030)	MaskLoss 0.1674 (0.1156)	MaskBCELoss 0.0896 (0.0363)	MaskDICELoss 0.0777 (0.0793)
Epoch: [2][343/500]	Time 72.708 (72.708)	Loss 0.4294 (0.4282)	CeLoss 0.0251 (0.0520)	SegCLSLoss 0.0025 (0.0014)	KLLoss 0.0029 (0.0037)	MaskLoss 0.1006 (0.1038)	MaskBCELoss 0.0012 (0.0216)	MaskDICELoss 0.0995 (0.0821)
Epoch: [2][344/500]	Time 80.079 (80.079)	Loss 0.3084 (0.3672)	CeLoss 0.0566 (0.0432)	SegCLSLoss 0.0024 (0.0016)	KLLoss 0.0021 (0.0024)	MaskLoss 0.0804 (0.0917)	MaskBCELoss 0.0364 (0.0230)	MaskDICELoss 0.0439 (0.0687)
Epoch: [2][345/500]	Time 77.625 (77.625)	Loss 0.4280 (0.4091)	CeLoss 0.0245 (0.0336)	SegCLSLoss 0.0030 (0.0013)	KLLoss 0.0018 (0.0028)	MaskLoss 0.1024 (0.1047)	MaskBCELoss 0.0046 (0.0233)	MaskDICELoss 0.0978 (0.0814)
Epoch: [2][346/500]	Time 76.335 (76.335)	Loss 0.4207 (0.3525)	CeLoss 0.0693 (0.0547)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0027 (0.0029)	MaskLoss 0.1061 (0.0940)	MaskBCELoss 0.0380 (0.0409)	MaskDICELoss 0.0681 (0.0532)
Epoch: [2][347/500]	Time 74.609 (74.609)	Loss 0.4373 (0.4293)	CeLoss 0.0693 (0.0474)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0036 (0.0026)	MaskLoss 0.1110 (0.1071)	MaskBCELoss 0.0398 (0.0248)	MaskDICELoss 0.0712 (0.0823)
Epoch: [2][348/500]	Time 70.822 (70.822)	Loss 0.5213 (0.2969)	CeLoss 0.1226 (0.0648)	SegCLSLoss 0.0007 (0.0018)	KLLoss 0.0029 (0.0028)	MaskLoss 0.1000 (0.0694)	MaskBCELoss 0.0023 (0.0246)	MaskDICELoss 0.0977 (0.0448)
Epoch: [2][349/500]	Time 74.556 (74.556)	Loss 0.3879 (0.4030)	CeLoss 0.0261 (0.0524)	SegCLSLoss 0.0010 (0.0006)	KLLoss 0.0023 (0.0030)	MaskLoss 0.0970 (0.0962)	MaskBCELoss 0.0146 (0.0187)	MaskDICELoss 0.0824 (0.0775)
Epoch: [2][350/500]	Time 74.274 (74.274)	Loss 0.4625 (0.2844)	CeLoss 0.0540 (0.0295)	SegCLSLoss 0.0032 (0.0015)	KLLoss 0.0020 (0.0022)	MaskLoss 0.1027 (0.0685)	MaskBCELoss 0.0028 (0.0110)	MaskDICELoss 0.0999 (0.0575)
Epoch: [2][351/500]	Time 79.595 (79.595)	Loss 0.4036 (0.4130)	CeLoss 0.0610 (0.0441)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0028 (0.0031)	MaskLoss 0.0949 (0.1038)	MaskBCELoss 0.0203 (0.0249)	MaskDICELoss 0.0746 (0.0789)
Epoch: [2][352/500]	Time 76.102 (76.102)	Loss 0.3849 (0.3332)	CeLoss 0.0869 (0.0411)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0039 (0.0033)	MaskLoss 0.0807 (0.0789)	MaskBCELoss 0.0147 (0.0138)	MaskDICELoss 0.0660 (0.0652)
Epoch: [2][353/500]	Time 72.201 (72.201)	Loss 0.6899 (0.3795)	CeLoss 0.0811 (0.0519)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0027 (0.0029)	MaskLoss 0.2185 (0.0928)	MaskBCELoss 0.1343 (0.0235)	MaskDICELoss 0.0842 (0.0693)
Epoch: [2][354/500]	Time 78.881 (78.881)	Loss 0.3855 (0.3849)	CeLoss 0.0140 (0.0493)	SegCLSLoss 0.0034 (0.0012)	KLLoss 0.0032 (0.0028)	MaskLoss 0.1095 (0.0938)	MaskBCELoss 0.0356 (0.0214)	MaskDICELoss 0.0738 (0.0723)
Epoch: [2][355/500]	Time 78.167 (78.167)	Loss 0.4546 (0.3853)	CeLoss 0.0520 (0.0343)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0026 (0.0027)	MaskLoss 0.1011 (0.0954)	MaskBCELoss 0.0026 (0.0171)	MaskDICELoss 0.0985 (0.0783)
Epoch: [2][356/500]	Time 76.358 (76.358)	Loss 0.4849 (0.3655)	CeLoss 0.0620 (0.0532)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0036 (0.0028)	MaskLoss 0.1122 (0.0867)	MaskBCELoss 0.0152 (0.0188)	MaskDICELoss 0.0970 (0.0678)
Epoch: [2][357/500]	Time 70.516 (70.516)	Loss 0.3710 (0.3741)	CeLoss 0.0280 (0.0379)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0021 (0.0021)	MaskLoss 0.0873 (0.0935)	MaskBCELoss 0.0045 (0.0202)	MaskDICELoss 0.0828 (0.0732)
Epoch: [2][358/500]	Time 80.100 (80.100)	Loss 0.4785 (0.3965)	CeLoss 0.0781 (0.0453)	SegCLSLoss 0.0009 (0.0009)	KLLoss 0.0030 (0.0027)	MaskLoss 0.1038 (0.0960)	MaskBCELoss 0.0092 (0.0179)	MaskDICELoss 0.0946 (0.0780)
Epoch: [2][359/500]	Time 76.722 (76.722)	Loss 0.3451 (0.4371)	CeLoss 0.0376 (0.0526)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0034 (0.0028)	MaskLoss 0.0792 (0.1016)	MaskBCELoss 0.0066 (0.0126)	MaskDICELoss 0.0726 (0.0890)
Epoch: [2][360/500]	Time 78.270 (78.270)	Loss 0.5039 (0.3524)	CeLoss 0.0488 (0.0463)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0055 (0.0029)	MaskLoss 0.1331 (0.0898)	MaskBCELoss 0.0416 (0.0282)	MaskDICELoss 0.0915 (0.0616)
Epoch: [2][361/500]	Time 76.766 (76.766)	Loss 0.0131 (0.2439)	CeLoss 0.0131 (0.0384)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0577)	MaskBCELoss 0.0000 (0.0141)	MaskDICELoss 0.0000 (0.0436)
Epoch: [2][362/500]	Time 76.260 (76.260)	Loss 0.4173 (0.3824)	CeLoss 0.0239 (0.0572)	SegCLSLoss 0.0037 (0.0014)	KLLoss 0.0029 (0.0028)	MaskLoss 0.0976 (0.0859)	MaskBCELoss 0.0009 (0.0109)	MaskDICELoss 0.0967 (0.0750)
Epoch: [2][363/500]	Time 79.334 (79.334)	Loss 0.1580 (0.3908)	CeLoss 0.0674 (0.0335)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0028 (0.0026)	MaskLoss 0.0299 (0.0983)	MaskBCELoss 0.0159 (0.0197)	MaskDICELoss 0.0140 (0.0786)
Epoch: [2][364/500]	Time 76.903 (76.903)	Loss 0.1291 (0.3899)	CeLoss 0.0630 (0.0408)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0030 (0.0022)	MaskLoss 0.0162 (0.0957)	MaskBCELoss 0.0009 (0.0183)	MaskDICELoss 0.0152 (0.0774)
Epoch: [2][365/500]	Time 84.345 (84.345)	Loss 0.4586 (0.3235)	CeLoss 0.0493 (0.0339)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0019 (0.0016)	MaskLoss 0.1036 (0.0834)	MaskBCELoss 0.0037 (0.0230)	MaskDICELoss 0.0999 (0.0604)
Epoch: [2][366/500]	Time 82.348 (82.348)	Loss 0.3210 (0.3692)	CeLoss 0.0140 (0.0296)	SegCLSLoss 0.0004 (0.0019)	KLLoss 0.0030 (0.0030)	MaskLoss 0.0859 (0.0963)	MaskBCELoss 0.0199 (0.0248)	MaskDICELoss 0.0660 (0.0715)
Epoch: [2][367/500]	Time 71.859 (71.859)	Loss 0.1447 (0.3100)	CeLoss 0.1094 (0.0436)	SegCLSLoss 0.0004 (0.0016)	KLLoss 0.0020 (0.0022)	MaskLoss 0.0091 (0.0720)	MaskBCELoss 0.0017 (0.0124)	MaskDICELoss 0.0074 (0.0597)
Epoch: [2][368/500]	Time 81.260 (81.260)	Loss 0.4724 (0.4630)	CeLoss 0.0718 (0.0519)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0029 (0.0031)	MaskLoss 0.1006 (0.1132)	MaskBCELoss 0.0025 (0.0226)	MaskDICELoss 0.0981 (0.0905)
Epoch: [2][369/500]	Time 77.504 (77.504)	Loss 0.4416 (0.4481)	CeLoss 0.0461 (0.0515)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0014 (0.0030)	MaskLoss 0.1250 (0.1102)	MaskBCELoss 0.0533 (0.0240)	MaskDICELoss 0.0717 (0.0862)
Epoch: [2][370/500]	Time 80.709 (80.709)	Loss 0.5346 (0.3816)	CeLoss 0.0299 (0.0452)	SegCLSLoss 0.0008 (0.0008)	KLLoss 0.0022 (0.0026)	MaskLoss 0.1535 (0.0970)	MaskBCELoss 0.0559 (0.0274)	MaskDICELoss 0.0976 (0.0696)
Epoch: [2][371/500]	Time 82.339 (82.339)	Loss 0.2355 (0.3514)	CeLoss 0.0236 (0.0607)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0031 (0.0021)	MaskLoss 0.0548 (0.0775)	MaskBCELoss 0.0055 (0.0111)	MaskDICELoss 0.0493 (0.0664)
Epoch: [2][372/500]	Time 89.206 (89.206)	Loss 0.4459 (0.3991)	CeLoss 0.0254 (0.0396)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0024 (0.0026)	MaskLoss 0.1132 (0.0978)	MaskBCELoss 0.0176 (0.0174)	MaskDICELoss 0.0955 (0.0804)
Epoch: [2][373/500]	Time 76.990 (76.990)	Loss 0.4489 (0.4136)	CeLoss 0.0464 (0.0431)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0015 (0.0028)	MaskLoss 0.1027 (0.0983)	MaskBCELoss 0.0050 (0.0130)	MaskDICELoss 0.0977 (0.0853)
Epoch: [2][374/500]	Time 74.458 (74.458)	Loss 0.4511 (0.3257)	CeLoss 0.0415 (0.0477)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0025 (0.0029)	MaskLoss 0.1370 (0.0778)	MaskBCELoss 0.0705 (0.0183)	MaskDICELoss 0.0665 (0.0595)
Epoch: [2][375/500]	Time 82.903 (82.903)	Loss 0.0694 (0.3549)	CeLoss 0.0270 (0.0519)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0019 (0.0024)	MaskLoss 0.0112 (0.0846)	MaskBCELoss 0.0023 (0.0192)	MaskDICELoss 0.0089 (0.0654)
Epoch: [2][376/500]	Time 81.742 (81.742)	Loss 0.4510 (0.3604)	CeLoss 0.0227 (0.0401)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0037 (0.0031)	MaskLoss 0.1176 (0.0883)	MaskBCELoss 0.0231 (0.0183)	MaskDICELoss 0.0945 (0.0700)
Epoch: [2][377/500]	Time 73.345 (73.345)	Loss 0.1755 (0.3903)	CeLoss 0.0220 (0.0508)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0029 (0.0030)	MaskLoss 0.0479 (0.0906)	MaskBCELoss 0.0208 (0.0132)	MaskDICELoss 0.0271 (0.0773)
Epoch: [2][378/500]	Time 76.547 (76.547)	Loss 0.4331 (0.3499)	CeLoss 0.0229 (0.0523)	SegCLSLoss 0.0025 (0.0012)	KLLoss 0.0027 (0.0025)	MaskLoss 0.1034 (0.0779)	MaskBCELoss 0.0037 (0.0085)	MaskDICELoss 0.0997 (0.0694)
Epoch: [2][379/500]	Time 74.446 (74.446)	Loss 0.2843 (0.3730)	CeLoss 0.0669 (0.0453)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0025 (0.0025)	MaskLoss 0.0722 (0.0894)	MaskBCELoss 0.0369 (0.0165)	MaskDICELoss 0.0353 (0.0729)
Epoch: [2][380/500]	Time 76.553 (76.553)	Loss 0.4313 (0.3673)	CeLoss 0.0674 (0.0478)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0022 (0.0021)	MaskLoss 0.0985 (0.0871)	MaskBCELoss 0.0165 (0.0159)	MaskDICELoss 0.0820 (0.0712)
Epoch: [2][381/500]	Time 73.855 (73.855)	Loss 0.1317 (0.3332)	CeLoss 0.0547 (0.0551)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0011 (0.0022)	MaskLoss 0.0205 (0.0745)	MaskBCELoss 0.0032 (0.0113)	MaskDICELoss 0.0174 (0.0632)
Epoch: [2][382/500]	Time 73.206 (73.206)	Loss 0.3004 (0.4076)	CeLoss 0.0238 (0.0422)	SegCLSLoss 0.0021 (0.0014)	KLLoss 0.0030 (0.0023)	MaskLoss 0.0873 (0.1067)	MaskBCELoss 0.0384 (0.0321)	MaskDICELoss 0.0489 (0.0746)
Epoch: [2][383/500]	Time 78.221 (78.221)	Loss 0.4265 (0.3606)	CeLoss 0.0232 (0.0419)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0022 (0.0031)	MaskLoss 0.1020 (0.0894)	MaskBCELoss 0.0037 (0.0211)	MaskDICELoss 0.0983 (0.0682)
Epoch: [2][384/500]	Time 73.385 (73.385)	Loss 0.1635 (0.4239)	CeLoss 0.0146 (0.0360)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0031 (0.0029)	MaskLoss 0.0557 (0.1199)	MaskBCELoss 0.0386 (0.0478)	MaskDICELoss 0.0171 (0.0721)
Epoch: [2][385/500]	Time 76.850 (76.850)	Loss 0.4372 (0.3503)	CeLoss 0.0260 (0.0430)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0025 (0.0025)	MaskLoss 0.1054 (0.0836)	MaskBCELoss 0.0068 (0.0150)	MaskDICELoss 0.0986 (0.0686)
Epoch: [2][386/500]	Time 85.187 (85.187)	Loss 0.3106 (0.3187)	CeLoss 0.0327 (0.0339)	SegCLSLoss 0.0003 (0.0022)	KLLoss 0.0040 (0.0027)	MaskLoss 0.0963 (0.0809)	MaskBCELoss 0.0558 (0.0212)	MaskDICELoss 0.0405 (0.0596)
Epoch: [2][387/500]	Time 78.618 (78.618)	Loss 0.3804 (0.3849)	CeLoss 0.0239 (0.0309)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0022 (0.0026)	MaskLoss 0.0960 (0.0980)	MaskBCELoss 0.0151 (0.0207)	MaskDICELoss 0.0808 (0.0773)
Epoch: [2][388/500]	Time 77.607 (77.607)	Loss 0.1822 (0.3136)	CeLoss 0.0121 (0.0372)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0028 (0.0022)	MaskLoss 0.0485 (0.0769)	MaskBCELoss 0.0135 (0.0171)	MaskDICELoss 0.0350 (0.0599)
Epoch: [2][389/500]	Time 76.780 (76.780)	Loss 0.2087 (0.3086)	CeLoss 0.0515 (0.0306)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0016 (0.0022)	MaskLoss 0.0402 (0.0794)	MaskBCELoss 0.0028 (0.0213)	MaskDICELoss 0.0374 (0.0581)
Epoch: [2][390/500]	Time 73.383 (73.383)	Loss 0.3483 (0.3247)	CeLoss 0.0221 (0.0364)	SegCLSLoss 0.0027 (0.0012)	KLLoss 0.0028 (0.0029)	MaskLoss 0.1067 (0.0784)	MaskBCELoss 0.0523 (0.0144)	MaskDICELoss 0.0544 (0.0640)
Epoch: [2][391/500]	Time 72.055 (72.055)	Loss 0.4336 (0.3720)	CeLoss 0.0217 (0.0495)	SegCLSLoss 0.0014 (0.0018)	KLLoss 0.0017 (0.0022)	MaskLoss 0.1073 (0.0889)	MaskBCELoss 0.0098 (0.0182)	MaskDICELoss 0.0974 (0.0708)
Epoch: [2][392/500]	Time 80.535 (80.535)	Loss 0.3923 (0.3714)	CeLoss 0.0176 (0.0335)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0020 (0.0024)	MaskLoss 0.1164 (0.0986)	MaskBCELoss 0.0465 (0.0298)	MaskDICELoss 0.0699 (0.0689)
Epoch: [2][393/500]	Time 77.532 (77.532)	Loss 0.4436 (0.3635)	CeLoss 0.0403 (0.0410)	SegCLSLoss 0.0028 (0.0011)	KLLoss 0.0018 (0.0023)	MaskLoss 0.1037 (0.0862)	MaskBCELoss 0.0074 (0.0125)	MaskDICELoss 0.0964 (0.0737)
Epoch: [2][394/500]	Time 80.724 (80.724)	Loss 0.1649 (0.3553)	CeLoss 0.1172 (0.0521)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0027 (0.0026)	MaskLoss 0.0144 (0.0814)	MaskBCELoss 0.0062 (0.0127)	MaskDICELoss 0.0083 (0.0687)
Epoch: [2][395/500]	Time 79.346 (79.346)	Loss 0.1199 (0.3141)	CeLoss 0.0388 (0.0409)	SegCLSLoss 0.0002 (0.0014)	KLLoss 0.0026 (0.0024)	MaskLoss 0.0220 (0.0772)	MaskBCELoss 0.0049 (0.0194)	MaskDICELoss 0.0171 (0.0578)
Epoch: [2][396/500]	Time 72.655 (72.655)	Loss 0.4433 (0.3382)	CeLoss 0.0299 (0.0385)	SegCLSLoss 0.0018 (0.0012)	KLLoss 0.0022 (0.0030)	MaskLoss 0.1052 (0.0849)	MaskBCELoss 0.0053 (0.0218)	MaskDICELoss 0.0999 (0.0631)
Epoch: [2][397/500]	Time 77.812 (77.812)	Loss 0.0178 (0.3646)	CeLoss 0.0178 (0.0395)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0911)	MaskBCELoss 0.0000 (0.0213)	MaskDICELoss 0.0000 (0.0698)
Epoch: [2][398/500]	Time 81.152 (81.152)	Loss 0.4635 (0.4315)	CeLoss 0.0625 (0.0453)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0033 (0.0027)	MaskLoss 0.0997 (0.1101)	MaskBCELoss 0.0008 (0.0289)	MaskDICELoss 0.0989 (0.0812)
Epoch: [2][399/500]	Time 73.452 (73.452)	Loss 0.4103 (0.2948)	CeLoss 0.0610 (0.0406)	SegCLSLoss 0.0020 (0.0013)	KLLoss 0.0026 (0.0026)	MaskLoss 0.0900 (0.0697)	MaskBCELoss 0.0073 (0.0139)	MaskDICELoss 0.0827 (0.0558)
[2025-03-11 21:56:25,132] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[0.00028271084337349396], mom=[(0.9, 0.95)]
[2025-03-11 21:56:25,143] [INFO] [timer.py:215:stop] epoch=0/micro_step=1400/global_step=140, RunningAvgSamplesPerSec=0.6837958850372575, CurrSamplesPerSec=0.5431541891842193, MemAllocated=59.55GB, MaxMemAllocated=74.71GB
Epoch: [2][400/500]	Time 76.994 (76.994)	Loss 0.5068 (0.2603)	CeLoss 0.0659 (0.0435)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0050 (0.0020)	MaskLoss 0.1195 (0.0631)	MaskBCELoss 0.0213 (0.0191)	MaskDICELoss 0.0982 (0.0440)
Epoch: [2][401/500]	Time 81.476 (81.476)	Loss 0.4801 (0.3961)	CeLoss 0.0591 (0.0522)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0047 (0.0029)	MaskLoss 0.1108 (0.0931)	MaskBCELoss 0.0135 (0.0161)	MaskDICELoss 0.0973 (0.0770)
Epoch: [2][402/500]	Time 72.159 (72.159)	Loss 0.4288 (0.3034)	CeLoss 0.0214 (0.0365)	SegCLSLoss 0.0033 (0.0011)	KLLoss 0.0017 (0.0021)	MaskLoss 0.1043 (0.0737)	MaskBCELoss 0.0065 (0.0153)	MaskDICELoss 0.0978 (0.0585)
Epoch: [2][403/500]	Time 82.908 (82.908)	Loss 0.2395 (0.2201)	CeLoss 0.0164 (0.0415)	SegCLSLoss 0.0018 (0.0011)	KLLoss 0.0022 (0.0019)	MaskLoss 0.0735 (0.0485)	MaskBCELoss 0.0371 (0.0090)	MaskDICELoss 0.0365 (0.0395)
Epoch: [2][404/500]	Time 79.640 (79.640)	Loss 0.0116 (0.2153)	CeLoss 0.0116 (0.0314)	SegCLSLoss 0.0000 (0.0005)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0480)	MaskBCELoss 0.0000 (0.0052)	MaskDICELoss 0.0000 (0.0428)
Epoch: [2][405/500]	Time 73.508 (73.508)	Loss 0.4497 (0.3631)	CeLoss 0.0240 (0.0398)	SegCLSLoss 0.0027 (0.0016)	KLLoss 0.0027 (0.0022)	MaskLoss 0.1108 (0.0899)	MaskBCELoss 0.0108 (0.0196)	MaskDICELoss 0.1000 (0.0703)
Epoch: [2][406/500]	Time 72.794 (72.794)	Loss 0.4129 (0.3733)	CeLoss 0.0212 (0.0412)	SegCLSLoss 0.0020 (0.0016)	KLLoss 0.0036 (0.0031)	MaskLoss 0.1167 (0.0940)	MaskBCELoss 0.0398 (0.0239)	MaskDICELoss 0.0769 (0.0701)
Epoch: [2][407/500]	Time 79.184 (79.184)	Loss 0.0096 (0.2778)	CeLoss 0.0096 (0.0412)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0018)	MaskLoss 0.0000 (0.0598)	MaskBCELoss 0.0000 (0.0024)	MaskDICELoss 0.0000 (0.0574)
Epoch: [2][408/500]	Time 77.815 (77.815)	Loss 0.0342 (0.2722)	CeLoss 0.0342 (0.0294)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0630)	MaskBCELoss 0.0000 (0.0059)	MaskDICELoss 0.0000 (0.0571)
Epoch: [2][409/500]	Time 81.938 (81.938)	Loss 0.0285 (0.2886)	CeLoss 0.0286 (0.0331)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0685)	MaskBCELoss 0.0000 (0.0108)	MaskDICELoss 0.0000 (0.0578)
Epoch: [2][410/500]	Time 73.580 (73.580)	Loss 0.3999 (0.2995)	CeLoss 0.0447 (0.0437)	SegCLSLoss 0.0005 (0.0005)	KLLoss 0.0031 (0.0018)	MaskLoss 0.0923 (0.0677)	MaskBCELoss 0.0087 (0.0086)	MaskDICELoss 0.0836 (0.0591)
Epoch: [2][411/500]	Time 79.866 (79.866)	Loss 0.4677 (0.1948)	CeLoss 0.0742 (0.0474)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0030 (0.0022)	MaskLoss 0.1175 (0.0418)	MaskBCELoss 0.0399 (0.0113)	MaskDICELoss 0.0775 (0.0305)
Epoch: [2][412/500]	Time 83.820 (83.820)	Loss 0.4216 (0.3890)	CeLoss 0.0217 (0.0297)	SegCLSLoss 0.0025 (0.0013)	KLLoss 0.0029 (0.0028)	MaskLoss 0.0996 (0.1000)	MaskBCELoss 0.0014 (0.0220)	MaskDICELoss 0.0982 (0.0780)
Epoch: [2][413/500]	Time 84.674 (84.674)	Loss 0.1119 (0.4205)	CeLoss 0.0342 (0.0462)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0027 (0.0024)	MaskLoss 0.0242 (0.1162)	MaskBCELoss 0.0110 (0.0466)	MaskDICELoss 0.0132 (0.0696)
Epoch: [2][414/500]	Time 83.375 (83.375)	Loss 0.3096 (0.2279)	CeLoss 0.0227 (0.0431)	SegCLSLoss 0.0016 (0.0006)	KLLoss 0.0018 (0.0016)	MaskLoss 0.0921 (0.0569)	MaskBCELoss 0.0422 (0.0222)	MaskDICELoss 0.0500 (0.0346)
Epoch: [2][415/500]	Time 74.604 (74.604)	Loss 0.4841 (0.2853)	CeLoss 0.0859 (0.0528)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0024 (0.0021)	MaskLoss 0.1114 (0.0646)	MaskBCELoss 0.0251 (0.0142)	MaskDICELoss 0.0863 (0.0503)
Epoch: [2][416/500]	Time 81.006 (81.006)	Loss 0.3858 (0.3282)	CeLoss 0.0649 (0.0437)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0025 (0.0023)	MaskLoss 0.0825 (0.0803)	MaskBCELoss 0.0059 (0.0198)	MaskDICELoss 0.0766 (0.0605)
Epoch: [2][417/500]	Time 76.522 (76.522)	Loss 0.2376 (0.2998)	CeLoss 0.0496 (0.0340)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0018 (0.0022)	MaskLoss 0.0594 (0.0767)	MaskBCELoss 0.0257 (0.0220)	MaskDICELoss 0.0336 (0.0548)
Epoch: [2][418/500]	Time 80.972 (80.972)	Loss 0.2813 (0.3747)	CeLoss 0.0237 (0.0502)	SegCLSLoss 0.0047 (0.0016)	KLLoss 0.0024 (0.0029)	MaskLoss 0.0809 (0.0952)	MaskBCELoss 0.0354 (0.0300)	MaskDICELoss 0.0455 (0.0652)
Epoch: [2][419/500]	Time 80.816 (80.816)	Loss 0.0406 (0.2988)	CeLoss 0.0405 (0.0356)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0018)	MaskLoss 0.0000 (0.0725)	MaskBCELoss 0.0000 (0.0145)	MaskDICELoss 0.0000 (0.0580)
Epoch: [2][420/500]	Time 73.814 (73.814)	Loss 0.0266 (0.3258)	CeLoss 0.0266 (0.0535)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0755)	MaskBCELoss 0.0000 (0.0161)	MaskDICELoss 0.0000 (0.0594)
Epoch: [2][421/500]	Time 70.017 (70.017)	Loss 0.3001 (0.2671)	CeLoss 0.0315 (0.0463)	SegCLSLoss 0.0013 (0.0008)	KLLoss 0.0031 (0.0020)	MaskLoss 0.0788 (0.0634)	MaskBCELoss 0.0251 (0.0176)	MaskDICELoss 0.0537 (0.0458)
Epoch: [2][422/500]	Time 72.165 (72.165)	Loss 0.1569 (0.3623)	CeLoss 0.0693 (0.0573)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0020 (0.0026)	MaskLoss 0.0324 (0.0930)	MaskBCELoss 0.0218 (0.0350)	MaskDICELoss 0.0105 (0.0580)
Epoch: [2][423/500]	Time 77.185 (77.185)	Loss 0.1039 (0.3725)	CeLoss 0.0762 (0.0540)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0032 (0.0028)	MaskLoss 0.0092 (0.0910)	MaskBCELoss 0.0060 (0.0245)	MaskDICELoss 0.0032 (0.0665)
Epoch: [2][424/500]	Time 77.902 (77.902)	Loss 0.4675 (0.3830)	CeLoss 0.0845 (0.0377)	SegCLSLoss 0.0024 (0.0013)	KLLoss 0.0021 (0.0022)	MaskLoss 0.1010 (0.1018)	MaskBCELoss 0.0120 (0.0323)	MaskDICELoss 0.0890 (0.0695)
Epoch: [2][425/500]	Time 73.834 (73.834)	Loss 0.5469 (0.5080)	CeLoss 0.0393 (0.0479)	SegCLSLoss 0.0008 (0.0009)	KLLoss 0.0027 (0.0028)	MaskLoss 0.1681 (0.1523)	MaskBCELoss 0.0839 (0.0763)	MaskDICELoss 0.0842 (0.0761)
Epoch: [2][426/500]	Time 77.516 (77.516)	Loss 0.2192 (0.3473)	CeLoss 0.0243 (0.0497)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0022 (0.0025)	MaskLoss 0.0675 (0.0865)	MaskBCELoss 0.0390 (0.0258)	MaskDICELoss 0.0286 (0.0607)
Epoch: [2][427/500]	Time 73.626 (73.626)	Loss 0.4620 (0.2980)	CeLoss 0.0405 (0.0369)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0041 (0.0033)	MaskLoss 0.1086 (0.0723)	MaskBCELoss 0.0086 (0.0160)	MaskDICELoss 0.1000 (0.0563)
Epoch: [2][428/500]	Time 78.558 (78.558)	Loss 0.0326 (0.3774)	CeLoss 0.0327 (0.0413)	SegCLSLoss 0.0000 (0.0017)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0985)	MaskBCELoss 0.0000 (0.0306)	MaskDICELoss 0.0000 (0.0679)
Epoch: [2][429/500]	Time 74.726 (74.726)	Loss 0.4924 (0.3993)	CeLoss 0.0199 (0.0323)	SegCLSLoss 0.0021 (0.0020)	KLLoss 0.0035 (0.0023)	MaskLoss 0.1373 (0.0983)	MaskBCELoss 0.0407 (0.0147)	MaskDICELoss 0.0966 (0.0836)
Epoch: [2][430/500]	Time 74.320 (74.320)	Loss 0.3398 (0.3849)	CeLoss 0.0635 (0.0489)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0034 (0.0029)	MaskLoss 0.0783 (0.0908)	MaskBCELoss 0.0208 (0.0153)	MaskDICELoss 0.0576 (0.0755)
Epoch: [2][431/500]	Time 75.908 (75.908)	Loss 0.5365 (0.2936)	CeLoss 0.0598 (0.0394)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0024 (0.0022)	MaskLoss 0.1781 (0.0739)	MaskBCELoss 0.1193 (0.0222)	MaskDICELoss 0.0589 (0.0518)
Epoch: [2][432/500]	Time 71.482 (71.482)	Loss 0.4308 (0.3832)	CeLoss 0.0206 (0.0365)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0038 (0.0030)	MaskLoss 0.1029 (0.0960)	MaskBCELoss 0.0030 (0.0205)	MaskDICELoss 0.0999 (0.0755)
Epoch: [2][433/500]	Time 79.309 (79.309)	Loss 0.4560 (0.3660)	CeLoss 0.0479 (0.0515)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0017 (0.0022)	MaskLoss 0.1028 (0.0878)	MaskBCELoss 0.0029 (0.0197)	MaskDICELoss 0.1000 (0.0681)
Epoch: [2][434/500]	Time 71.305 (71.305)	Loss 0.3715 (0.3455)	CeLoss 0.0713 (0.0554)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0026 (0.0021)	MaskLoss 0.0774 (0.0796)	MaskBCELoss 0.0061 (0.0153)	MaskDICELoss 0.0713 (0.0642)
Epoch: [2][435/500]	Time 76.991 (76.991)	Loss 0.3453 (0.3680)	CeLoss 0.0223 (0.0486)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0020 (0.0024)	MaskLoss 0.1093 (0.0916)	MaskBCELoss 0.0585 (0.0250)	MaskDICELoss 0.0508 (0.0666)
Epoch: [2][436/500]	Time 74.858 (74.858)	Loss 0.4491 (0.2880)	CeLoss 0.0618 (0.0475)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0016 (0.0024)	MaskLoss 0.1021 (0.0685)	MaskBCELoss 0.0116 (0.0182)	MaskDICELoss 0.0906 (0.0503)
Epoch: [2][437/500]	Time 71.564 (71.564)	Loss 0.4820 (0.3270)	CeLoss 0.0752 (0.0443)	SegCLSLoss 0.0019 (0.0010)	KLLoss 0.0029 (0.0025)	MaskLoss 0.1017 (0.0758)	MaskBCELoss 0.0017 (0.0117)	MaskDICELoss 0.1000 (0.0641)
Epoch: [2][438/500]	Time 72.854 (72.854)	Loss 0.0172 (0.2824)	CeLoss 0.0172 (0.0415)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0019)	MaskLoss 0.0000 (0.0652)	MaskBCELoss 0.0000 (0.0111)	MaskDICELoss 0.0000 (0.0541)
Epoch: [2][439/500]	Time 73.992 (73.992)	Loss 0.2431 (0.3031)	CeLoss 0.0566 (0.0350)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0014 (0.0026)	MaskLoss 0.0510 (0.0778)	MaskBCELoss 0.0095 (0.0232)	MaskDICELoss 0.0415 (0.0546)
Epoch: [2][440/500]	Time 69.898 (69.898)	Loss 0.5040 (0.3408)	CeLoss 0.0586 (0.0383)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0072 (0.0030)	MaskLoss 0.1255 (0.0852)	MaskBCELoss 0.0320 (0.0211)	MaskDICELoss 0.0935 (0.0641)
Epoch: [2][441/500]	Time 81.716 (81.716)	Loss 0.4051 (0.3634)	CeLoss 0.0189 (0.0380)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0027 (0.0028)	MaskLoss 0.0967 (0.0869)	MaskBCELoss 0.0022 (0.0128)	MaskDICELoss 0.0946 (0.0741)
Epoch: [2][442/500]	Time 74.082 (74.082)	Loss 0.0492 (0.2518)	CeLoss 0.0493 (0.0386)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0563)	MaskBCELoss 0.0000 (0.0074)	MaskDICELoss 0.0000 (0.0488)
Epoch: [2][443/500]	Time 74.344 (74.344)	Loss 0.3236 (0.3509)	CeLoss 0.0227 (0.0346)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0028 (0.0032)	MaskLoss 0.0857 (0.0886)	MaskBCELoss 0.0226 (0.0208)	MaskDICELoss 0.0631 (0.0678)
Epoch: [2][444/500]	Time 77.841 (77.841)	Loss 0.1699 (0.3479)	CeLoss 0.0214 (0.0523)	SegCLSLoss 0.0017 (0.0012)	KLLoss 0.0027 (0.0033)	MaskLoss 0.0441 (0.0806)	MaskBCELoss 0.0158 (0.0154)	MaskDICELoss 0.0283 (0.0652)
Epoch: [2][445/500]	Time 74.074 (74.074)	Loss 0.4687 (0.3928)	CeLoss 0.0635 (0.0458)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0020 (0.0027)	MaskLoss 0.1014 (0.0960)	MaskBCELoss 0.0014 (0.0201)	MaskDICELoss 0.1000 (0.0759)
Epoch: [2][446/500]	Time 75.226 (75.226)	Loss 0.4744 (0.4151)	CeLoss 0.0713 (0.0524)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0019 (0.0027)	MaskLoss 0.1272 (0.1033)	MaskBCELoss 0.0539 (0.0269)	MaskDICELoss 0.0733 (0.0764)
Epoch: [2][447/500]	Time 74.230 (74.230)	Loss 0.4089 (0.3361)	CeLoss 0.0403 (0.0426)	SegCLSLoss 0.0019 (0.0013)	KLLoss 0.0029 (0.0037)	MaskLoss 0.1072 (0.0883)	MaskBCELoss 0.0319 (0.0321)	MaskDICELoss 0.0752 (0.0562)
Epoch: [2][448/500]	Time 71.931 (71.931)	Loss 0.0715 (0.2642)	CeLoss 0.0713 (0.0503)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0594)	MaskBCELoss 0.0000 (0.0131)	MaskDICELoss 0.0000 (0.0463)
Epoch: [2][449/500]	Time 72.365 (72.365)	Loss 0.5658 (0.3874)	CeLoss 0.0718 (0.0459)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0023 (0.0023)	MaskLoss 0.1753 (0.0986)	MaskBCELoss 0.1051 (0.0278)	MaskDICELoss 0.0703 (0.0707)
Epoch: [2][450/500]	Time 74.971 (74.971)	Loss 0.3010 (0.3940)	CeLoss 0.0244 (0.0501)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0046 (0.0033)	MaskLoss 0.0760 (0.0964)	MaskBCELoss 0.0162 (0.0226)	MaskDICELoss 0.0598 (0.0738)
Epoch: [2][451/500]	Time 70.165 (70.165)	Loss 0.2570 (0.3599)	CeLoss 0.0273 (0.0560)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0039 (0.0029)	MaskLoss 0.0653 (0.0815)	MaskBCELoss 0.0179 (0.0127)	MaskDICELoss 0.0473 (0.0688)
Epoch: [2][452/500]	Time 73.640 (73.640)	Loss 0.3169 (0.3571)	CeLoss 0.0493 (0.0438)	SegCLSLoss 0.0047 (0.0012)	KLLoss 0.0042 (0.0031)	MaskLoss 0.0707 (0.0864)	MaskBCELoss 0.0111 (0.0180)	MaskDICELoss 0.0596 (0.0684)
Epoch: [2][453/500]	Time 74.977 (74.977)	Loss 0.3802 (0.3964)	CeLoss 0.0562 (0.0390)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0032 (0.0030)	MaskLoss 0.0962 (0.1006)	MaskBCELoss 0.0319 (0.0243)	MaskDICELoss 0.0642 (0.0763)
Epoch: [2][454/500]	Time 81.048 (81.048)	Loss 0.4188 (0.3395)	CeLoss 0.0234 (0.0376)	SegCLSLoss 0.0023 (0.0010)	KLLoss 0.0027 (0.0029)	MaskLoss 0.1005 (0.0856)	MaskBCELoss 0.0053 (0.0220)	MaskDICELoss 0.0952 (0.0636)
Epoch: [2][455/500]	Time 75.488 (75.488)	Loss 0.5920 (0.2044)	CeLoss 0.0231 (0.0320)	SegCLSLoss 0.0011 (0.0008)	KLLoss 0.0028 (0.0010)	MaskLoss 0.1841 (0.0501)	MaskBCELoss 0.0853 (0.0146)	MaskDICELoss 0.0987 (0.0355)
Epoch: [2][456/500]	Time 79.233 (79.233)	Loss 0.4698 (0.3540)	CeLoss 0.0247 (0.0460)	SegCLSLoss 0.0029 (0.0011)	KLLoss 0.0020 (0.0022)	MaskLoss 0.1208 (0.0840)	MaskBCELoss 0.0208 (0.0153)	MaskDICELoss 0.1000 (0.0687)
Epoch: [2][457/500]	Time 74.965 (74.965)	Loss 0.4478 (0.3686)	CeLoss 0.0261 (0.0435)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0014 (0.0032)	MaskLoss 0.1099 (0.0900)	MaskBCELoss 0.0099 (0.0193)	MaskDICELoss 0.1000 (0.0707)
Epoch: [2][458/500]	Time 71.304 (71.304)	Loss 0.1953 (0.2811)	CeLoss 0.0225 (0.0448)	SegCLSLoss 0.0017 (0.0018)	KLLoss 0.0020 (0.0028)	MaskLoss 0.0486 (0.0700)	MaskBCELoss 0.0122 (0.0238)	MaskDICELoss 0.0364 (0.0462)
Epoch: [2][459/500]	Time 76.773 (76.773)	Loss 0.4643 (0.4519)	CeLoss 0.0601 (0.0496)	SegCLSLoss 0.0021 (0.0012)	KLLoss 0.0073 (0.0039)	MaskLoss 0.1140 (0.1210)	MaskBCELoss 0.0301 (0.0430)	MaskDICELoss 0.0838 (0.0780)
Epoch: [2][460/500]	Time 78.569 (78.569)	Loss 0.4628 (0.3049)	CeLoss 0.0618 (0.0493)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0027 (0.0023)	MaskLoss 0.1032 (0.0676)	MaskBCELoss 0.0073 (0.0087)	MaskDICELoss 0.0958 (0.0589)
Epoch: [2][461/500]	Time 72.564 (72.564)	Loss 0.4473 (0.4178)	CeLoss 0.0195 (0.0502)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0023 (0.0035)	MaskLoss 0.1125 (0.1084)	MaskBCELoss 0.0126 (0.0350)	MaskDICELoss 0.0999 (0.0734)
Epoch: [2][462/500]	Time 71.799 (71.799)	Loss 0.4036 (0.3928)	CeLoss 0.0208 (0.0453)	SegCLSLoss 0.0023 (0.0016)	KLLoss 0.0031 (0.0025)	MaskLoss 0.0958 (0.0969)	MaskBCELoss 0.0023 (0.0217)	MaskDICELoss 0.0935 (0.0752)
Epoch: [2][463/500]	Time 70.886 (70.886)	Loss 0.4039 (0.3608)	CeLoss 0.0210 (0.0411)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0040 (0.0031)	MaskLoss 0.1046 (0.0844)	MaskBCELoss 0.0198 (0.0107)	MaskDICELoss 0.0847 (0.0736)
Epoch: [2][464/500]	Time 75.306 (75.306)	Loss 0.0459 (0.2449)	CeLoss 0.0459 (0.0387)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0545)	MaskBCELoss 0.0000 (0.0075)	MaskDICELoss 0.0000 (0.0470)
Epoch: [2][465/500]	Time 76.694 (76.694)	Loss 0.1341 (0.3045)	CeLoss 0.0703 (0.0514)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0052 (0.0035)	MaskLoss 0.0209 (0.0708)	MaskBCELoss 0.0127 (0.0171)	MaskDICELoss 0.0082 (0.0538)
Epoch: [2][466/500]	Time 74.612 (74.612)	Loss 0.4117 (0.3947)	CeLoss 0.0347 (0.0533)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0040 (0.0030)	MaskLoss 0.1069 (0.0988)	MaskBCELoss 0.0273 (0.0287)	MaskDICELoss 0.0796 (0.0701)
Epoch: [2][467/500]	Time 82.478 (82.478)	Loss 0.4992 (0.3372)	CeLoss 0.0226 (0.0377)	SegCLSLoss 0.0055 (0.0012)	KLLoss 0.0044 (0.0031)	MaskLoss 0.1533 (0.0839)	MaskBCELoss 0.0719 (0.0199)	MaskDICELoss 0.0814 (0.0640)
Epoch: [2][468/500]	Time 71.762 (71.762)	Loss 0.6219 (0.3270)	CeLoss 0.0806 (0.0512)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0031 (0.0032)	MaskLoss 0.1700 (0.0769)	MaskBCELoss 0.0711 (0.0178)	MaskDICELoss 0.0989 (0.0591)
Epoch: [2][469/500]	Time 76.546 (76.546)	Loss 0.5322 (0.3945)	CeLoss 0.1123 (0.0449)	SegCLSLoss 0.0009 (0.0016)	KLLoss 0.0042 (0.0030)	MaskLoss 0.1083 (0.0895)	MaskBCELoss 0.0090 (0.0061)	MaskDICELoss 0.0992 (0.0834)
Epoch: [2][470/500]	Time 77.645 (77.645)	Loss 0.4808 (0.3992)	CeLoss 0.0605 (0.0322)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0022 (0.0032)	MaskLoss 0.1112 (0.1027)	MaskBCELoss 0.0137 (0.0239)	MaskDICELoss 0.0976 (0.0788)
Epoch: [2][471/500]	Time 78.699 (78.699)	Loss 0.4351 (0.4291)	CeLoss 0.0195 (0.0324)	SegCLSLoss 0.0028 (0.0015)	KLLoss 0.0035 (0.0040)	MaskLoss 0.1055 (0.1058)	MaskBCELoss 0.0057 (0.0156)	MaskDICELoss 0.0998 (0.0902)
Epoch: [2][472/500]	Time 71.436 (71.436)	Loss 0.3924 (0.3228)	CeLoss 0.0640 (0.0442)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0050 (0.0025)	MaskLoss 0.0881 (0.0747)	MaskBCELoss 0.0146 (0.0116)	MaskDICELoss 0.0735 (0.0631)
Epoch: [2][473/500]	Time 83.611 (83.611)	Loss 0.2228 (0.3767)	CeLoss 0.0145 (0.0306)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0028 (0.0035)	MaskLoss 0.0528 (0.0900)	MaskBCELoss 0.0030 (0.0090)	MaskDICELoss 0.0498 (0.0810)
Epoch: [2][474/500]	Time 79.611 (79.611)	Loss 0.1435 (0.3281)	CeLoss 0.0306 (0.0488)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0040 (0.0032)	MaskLoss 0.0295 (0.0777)	MaskBCELoss 0.0049 (0.0176)	MaskDICELoss 0.0246 (0.0600)
Epoch: [2][475/500]	Time 75.194 (75.194)	Loss 0.2640 (0.3194)	CeLoss 0.0698 (0.0447)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0041 (0.0032)	MaskLoss 0.0489 (0.0755)	MaskBCELoss 0.0029 (0.0156)	MaskDICELoss 0.0460 (0.0600)
Epoch: [2][476/500]	Time 68.689 (68.689)	Loss 0.1198 (0.2820)	CeLoss 0.0216 (0.0477)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0058 (0.0029)	MaskLoss 0.0332 (0.0650)	MaskBCELoss 0.0204 (0.0147)	MaskDICELoss 0.0128 (0.0504)
Epoch: [2][477/500]	Time 74.492 (74.492)	Loss 0.3928 (0.4414)	CeLoss 0.0254 (0.0451)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0038 (0.0032)	MaskLoss 0.0936 (0.1121)	MaskBCELoss 0.0056 (0.0279)	MaskDICELoss 0.0880 (0.0842)
Epoch: [2][478/500]	Time 74.365 (74.365)	Loss 0.3933 (0.3979)	CeLoss 0.0938 (0.0408)	SegCLSLoss 0.0014 (0.0021)	KLLoss 0.0024 (0.0033)	MaskLoss 0.0753 (0.0970)	MaskBCELoss 0.0023 (0.0176)	MaskDICELoss 0.0730 (0.0794)
Epoch: [2][479/500]	Time 75.672 (75.672)	Loss 0.4695 (0.3343)	CeLoss 0.0498 (0.0499)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0034 (0.0029)	MaskLoss 0.1119 (0.0795)	MaskBCELoss 0.0158 (0.0185)	MaskDICELoss 0.0961 (0.0610)
Epoch: [2][480/500]	Time 76.423 (76.423)	Loss 0.2263 (0.3662)	CeLoss 0.0830 (0.0551)	SegCLSLoss 0.0026 (0.0015)	KLLoss 0.0022 (0.0028)	MaskLoss 0.0366 (0.0869)	MaskBCELoss 0.0032 (0.0201)	MaskDICELoss 0.0334 (0.0669)
Epoch: [2][481/500]	Time 80.600 (80.600)	Loss 0.4050 (0.4174)	CeLoss 0.0261 (0.0365)	SegCLSLoss 0.0008 (0.0015)	KLLoss 0.0035 (0.0032)	MaskLoss 0.1030 (0.1101)	MaskBCELoss 0.0186 (0.0316)	MaskDICELoss 0.0844 (0.0785)
Epoch: [2][482/500]	Time 70.768 (70.768)	Loss 0.0629 (0.2998)	CeLoss 0.0208 (0.0370)	SegCLSLoss 0.0008 (0.0015)	KLLoss 0.0041 (0.0025)	MaskLoss 0.0115 (0.0697)	MaskBCELoss 0.0041 (0.0096)	MaskDICELoss 0.0073 (0.0601)
Epoch: [2][483/500]	Time 74.452 (74.452)	Loss 0.4322 (0.3629)	CeLoss 0.0222 (0.0361)	SegCLSLoss 0.0027 (0.0020)	KLLoss 0.0048 (0.0028)	MaskLoss 0.1042 (0.0954)	MaskBCELoss 0.0065 (0.0294)	MaskDICELoss 0.0977 (0.0660)
Epoch: [2][484/500]	Time 74.264 (74.264)	Loss 0.0212 (0.3328)	CeLoss 0.0212 (0.0561)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0742)	MaskBCELoss 0.0000 (0.0115)	MaskDICELoss 0.0000 (0.0627)
Epoch: [2][485/500]	Time 77.832 (77.832)	Loss 0.2982 (0.3514)	CeLoss 0.0291 (0.0459)	SegCLSLoss 0.0010 (0.0008)	KLLoss 0.0022 (0.0028)	MaskLoss 0.0691 (0.0829)	MaskBCELoss 0.0050 (0.0146)	MaskDICELoss 0.0641 (0.0683)
Epoch: [2][486/500]	Time 72.760 (72.760)	Loss 0.0241 (0.3163)	CeLoss 0.0242 (0.0425)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0848)	MaskBCELoss 0.0000 (0.0347)	MaskDICELoss 0.0000 (0.0502)
Epoch: [2][487/500]	Time 74.676 (74.676)	Loss 0.0161 (0.3516)	CeLoss 0.0161 (0.0377)	SegCLSLoss 0.0000 (0.0017)	KLLoss 0.0000 (0.0025)	MaskLoss 0.0000 (0.0869)	MaskBCELoss 0.0000 (0.0185)	MaskDICELoss 0.0000 (0.0684)
Epoch: [2][488/500]	Time 70.676 (70.676)	Loss 0.5050 (0.4149)	CeLoss 0.0204 (0.0437)	SegCLSLoss 0.0015 (0.0016)	KLLoss 0.0030 (0.0025)	MaskLoss 0.1420 (0.1081)	MaskBCELoss 0.0435 (0.0324)	MaskDICELoss 0.0985 (0.0758)
Epoch: [2][489/500]	Time 74.332 (74.332)	Loss 0.4230 (0.3058)	CeLoss 0.0520 (0.0377)	SegCLSLoss 0.0016 (0.0010)	KLLoss 0.0026 (0.0022)	MaskLoss 0.1051 (0.0756)	MaskBCELoss 0.0264 (0.0184)	MaskDICELoss 0.0787 (0.0571)
Epoch: [2][490/500]	Time 71.440 (71.440)	Loss 0.4692 (0.3168)	CeLoss 0.0598 (0.0386)	SegCLSLoss 0.0031 (0.0012)	KLLoss 0.0030 (0.0031)	MaskLoss 0.1037 (0.0825)	MaskBCELoss 0.0050 (0.0278)	MaskDICELoss 0.0987 (0.0547)
Epoch: [2][491/500]	Time 70.022 (70.022)	Loss 0.0953 (0.3540)	CeLoss 0.0267 (0.0353)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0019 (0.0023)	MaskLoss 0.0189 (0.0850)	MaskBCELoss 0.0049 (0.0122)	MaskDICELoss 0.0140 (0.0728)
Epoch: [2][492/500]	Time 75.179 (75.179)	Loss 0.2877 (0.3290)	CeLoss 0.0258 (0.0359)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0019 (0.0023)	MaskLoss 0.0864 (0.0840)	MaskBCELoss 0.0429 (0.0228)	MaskDICELoss 0.0435 (0.0612)
Epoch: [2][493/500]	Time 74.710 (74.710)	Loss 0.4834 (0.3947)	CeLoss 0.0752 (0.0459)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0020 (0.0029)	MaskLoss 0.1028 (0.1037)	MaskBCELoss 0.0028 (0.0347)	MaskDICELoss 0.1000 (0.0690)
Epoch: [2][494/500]	Time 71.082 (71.082)	Loss 0.4881 (0.3412)	CeLoss 0.0571 (0.0537)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0030 (0.0029)	MaskLoss 0.1178 (0.0844)	MaskBCELoss 0.0221 (0.0268)	MaskDICELoss 0.0957 (0.0576)
Epoch: [2][495/500]	Time 73.319 (73.319)	Loss 0.0781 (0.2672)	CeLoss 0.0781 (0.0449)	SegCLSLoss 0.0000 (0.0006)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0649)	MaskBCELoss 0.0000 (0.0198)	MaskDICELoss 0.0000 (0.0451)
Epoch: [2][496/500]	Time 82.283 (82.283)	Loss 0.4147 (0.3274)	CeLoss 0.0162 (0.0376)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0029 (0.0021)	MaskLoss 0.1193 (0.0804)	MaskBCELoss 0.0409 (0.0173)	MaskDICELoss 0.0783 (0.0632)
Epoch: [2][497/500]	Time 75.302 (75.302)	Loss 0.4707 (0.3214)	CeLoss 0.0654 (0.0404)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0069 (0.0032)	MaskLoss 0.1099 (0.0763)	MaskBCELoss 0.0207 (0.0140)	MaskDICELoss 0.0891 (0.0623)
Epoch: [2][498/500]	Time 71.242 (71.242)	Loss 0.4675 (0.4104)	CeLoss 0.0527 (0.0388)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0030 (0.0031)	MaskLoss 0.1115 (0.1049)	MaskBCELoss 0.0173 (0.0258)	MaskDICELoss 0.0942 (0.0790)
Epoch: [2][499/500]	Time 79.507 (79.507)	Loss 0.4851 (0.3559)	CeLoss 0.0688 (0.0478)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0021 (0.0025)	MaskLoss 0.1070 (0.0788)	MaskBCELoss 0.0071 (0.0051)	MaskDICELoss 0.1000 (0.0737)
[2025-03-12 00:02:35,801] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[0.0002813855421686747], mom=[(0.9, 0.95)]
[2025-03-12 00:02:35,812] [INFO] [timer.py:215:stop] epoch=0/micro_step=1500/global_step=150, RunningAvgSamplesPerSec=0.6708254094147357, CurrSamplesPerSec=0.5405029099458585, MemAllocated=59.3GB, MaxMemAllocated=74.71GB
Epoch: [2][500/500]	Time 78.315 (78.315)	Loss 0.5325 (0.3415)	CeLoss 0.0225 (0.0452)	SegCLSLoss 0.0022 (0.0011)	KLLoss 0.0021 (0.0027)	MaskLoss 0.1535 (0.0827)	MaskBCELoss 0.0535 (0.0189)	MaskDICELoss 0.1000 (0.0638)


































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [02:41<00:00,  1.19it/s]

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [02:41<00:00,  1.24it/s]
[2025-03-12 00:05:19,702] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step150 is about to be saved!
[2025-03-12 00:05:53,634] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step150/mp_rank_00_model_states.pt
[2025-03-12 00:05:53,634] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step150/mp_rank_00_model_states.pt...
[2025-03-12 00:09:42,629] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step150/mp_rank_00_model_states.pt.
[2025-03-12 00:09:44,590] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-12 00:09:55,959] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-12 00:09:56,002] [INFO] [engine.py:3244:_save_zero_checkpoint] zero checkpoint saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-12 00:09:56,003] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step150 is ready now!
Epoch: [3][  1/500]	Time 72.748 (72.748)	Loss 0.2586 (0.3811)	CeLoss 0.0815 (0.0414)	SegCLSLoss 0.0004 (0.0018)	KLLoss 0.0109 (0.0038)	MaskLoss 0.0526 (0.0947)	MaskBCELoss 0.0222 (0.0218)	MaskDICELoss 0.0304 (0.0729)
Epoch: [3][  2/500]	Time 72.474 (72.474)	Loss 0.5213 (0.3713)	CeLoss 0.0747 (0.0631)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0018 (0.0024)	MaskLoss 0.1246 (0.0900)	MaskBCELoss 0.0271 (0.0273)	MaskDICELoss 0.0975 (0.0627)
Epoch: [3][  3/500]	Time 73.105 (73.105)	Loss 0.5113 (0.4084)	CeLoss 0.0786 (0.0533)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0054 (0.0035)	MaskLoss 0.1234 (0.1021)	MaskBCELoss 0.0332 (0.0285)	MaskDICELoss 0.0902 (0.0736)
Epoch: [3][  4/500]	Time 75.261 (75.261)	Loss 0.5523 (0.4170)	CeLoss 0.0571 (0.0342)	SegCLSLoss 0.0010 (0.0015)	KLLoss 0.0014 (0.0034)	MaskLoss 0.1487 (0.1095)	MaskBCELoss 0.0507 (0.0296)	MaskDICELoss 0.0980 (0.0799)
Epoch: [3][  5/500]	Time 79.428 (79.428)	Loss 0.5323 (0.3672)	CeLoss 0.0698 (0.0430)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0046 (0.0039)	MaskLoss 0.1288 (0.0913)	MaskBCELoss 0.0288 (0.0228)	MaskDICELoss 0.0999 (0.0685)
Epoch: [3][  6/500]	Time 73.104 (73.104)	Loss 0.5556 (0.3936)	CeLoss 0.0889 (0.0370)	SegCLSLoss 0.0019 (0.0012)	KLLoss 0.0034 (0.0030)	MaskLoss 0.1331 (0.1019)	MaskBCELoss 0.0349 (0.0273)	MaskDICELoss 0.0982 (0.0746)
Epoch: [3][  7/500]	Time 80.117 (80.117)	Loss 0.2768 (0.2886)	CeLoss 0.0679 (0.0418)	SegCLSLoss 0.0022 (0.0010)	KLLoss 0.0021 (0.0021)	MaskLoss 0.0657 (0.0674)	MaskBCELoss 0.0286 (0.0127)	MaskDICELoss 0.0371 (0.0547)
Epoch: [3][  8/500]	Time 72.083 (72.083)	Loss 0.6221 (0.3218)	CeLoss 0.0811 (0.0384)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0030 (0.0033)	MaskLoss 0.1770 (0.0804)	MaskBCELoss 0.0849 (0.0211)	MaskDICELoss 0.0921 (0.0593)
Epoch: [3][  9/500]	Time 77.580 (77.580)	Loss 0.5326 (0.3509)	CeLoss 0.0820 (0.0543)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0027 (0.0036)	MaskLoss 0.1281 (0.0831)	MaskBCELoss 0.0324 (0.0199)	MaskDICELoss 0.0957 (0.0632)
Epoch: [3][ 10/500]	Time 78.199 (78.199)	Loss 0.3777 (0.3987)	CeLoss 0.0649 (0.0539)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0030 (0.0027)	MaskLoss 0.0807 (0.0912)	MaskBCELoss 0.0065 (0.0116)	MaskDICELoss 0.0742 (0.0796)
Epoch: [3][ 11/500]	Time 75.218 (75.218)	Loss 0.3938 (0.3953)	CeLoss 0.0214 (0.0270)	SegCLSLoss 0.0022 (0.0018)	KLLoss 0.0044 (0.0031)	MaskLoss 0.1023 (0.1032)	MaskBCELoss 0.0211 (0.0242)	MaskDICELoss 0.0811 (0.0790)
Epoch: [3][ 12/500]	Time 74.437 (74.437)	Loss 0.4040 (0.4006)	CeLoss 0.0222 (0.0462)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0029 (0.0031)	MaskLoss 0.1162 (0.0993)	MaskBCELoss 0.0433 (0.0232)	MaskDICELoss 0.0729 (0.0761)
Epoch: [3][ 13/500]	Time 78.559 (78.559)	Loss 0.0336 (0.3535)	CeLoss 0.0337 (0.0263)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0020)	MaskLoss 0.0000 (0.0911)	MaskBCELoss 0.0000 (0.0198)	MaskDICELoss 0.0000 (0.0713)
Epoch: [3][ 14/500]	Time 73.619 (73.619)	Loss 0.3225 (0.3731)	CeLoss 0.0237 (0.0481)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0067 (0.0033)	MaskLoss 0.1001 (0.0927)	MaskBCELoss 0.0543 (0.0249)	MaskDICELoss 0.0458 (0.0679)
Epoch: [3][ 15/500]	Time 76.036 (76.036)	Loss 0.4492 (0.4218)	CeLoss 0.0574 (0.0464)	SegCLSLoss 0.0027 (0.0021)	KLLoss 0.0029 (0.0031)	MaskLoss 0.1134 (0.1071)	MaskBCELoss 0.0331 (0.0285)	MaskDICELoss 0.0803 (0.0786)
Epoch: [3][ 16/500]	Time 74.278 (74.278)	Loss 0.4350 (0.3317)	CeLoss 0.0232 (0.0331)	SegCLSLoss 0.0020 (0.0012)	KLLoss 0.0019 (0.0027)	MaskLoss 0.1048 (0.0857)	MaskBCELoss 0.0050 (0.0239)	MaskDICELoss 0.0998 (0.0619)
Epoch: [3][ 17/500]	Time 76.032 (76.032)	Loss 0.3610 (0.4336)	CeLoss 0.0635 (0.0472)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0036 (0.0028)	MaskLoss 0.0800 (0.1067)	MaskBCELoss 0.0134 (0.0220)	MaskDICELoss 0.0666 (0.0847)
Epoch: [3][ 18/500]	Time 71.511 (71.511)	Loss 0.4018 (0.3662)	CeLoss 0.0194 (0.0406)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0029 (0.0025)	MaskLoss 0.1139 (0.0887)	MaskBCELoss 0.0385 (0.0161)	MaskDICELoss 0.0755 (0.0726)
Epoch: [3][ 19/500]	Time 80.225 (80.225)	Loss 0.3821 (0.4032)	CeLoss 0.0442 (0.0390)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0049 (0.0032)	MaskLoss 0.0902 (0.1035)	MaskBCELoss 0.0141 (0.0267)	MaskDICELoss 0.0761 (0.0768)
Epoch: [3][ 20/500]	Time 71.029 (71.029)	Loss 0.3542 (0.3866)	CeLoss 0.0500 (0.0595)	SegCLSLoss 0.0017 (0.0017)	KLLoss 0.0019 (0.0033)	MaskLoss 0.0815 (0.0917)	MaskBCELoss 0.0123 (0.0220)	MaskDICELoss 0.0692 (0.0698)
Epoch: [3][ 21/500]	Time 82.818 (82.818)	Loss 0.0125 (0.2728)	CeLoss 0.0125 (0.0344)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0021)	MaskLoss 0.0000 (0.0636)	MaskBCELoss 0.0000 (0.0093)	MaskDICELoss 0.0000 (0.0543)
Epoch: [3][ 22/500]	Time 75.050 (75.050)	Loss 0.4105 (0.3857)	CeLoss 0.0337 (0.0359)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0038 (0.0028)	MaskLoss 0.0990 (0.0962)	MaskBCELoss 0.0116 (0.0192)	MaskDICELoss 0.0874 (0.0770)
Epoch: [3][ 23/500]	Time 85.156 (85.156)	Loss 0.4084 (0.3500)	CeLoss 0.0153 (0.0288)	SegCLSLoss 0.0020 (0.0015)	KLLoss 0.0023 (0.0039)	MaskLoss 0.1015 (0.0881)	MaskBCELoss 0.0081 (0.0180)	MaskDICELoss 0.0934 (0.0701)
Epoch: [3][ 24/500]	Time 77.965 (77.965)	Loss 0.4220 (0.3574)	CeLoss 0.0227 (0.0479)	SegCLSLoss 0.0012 (0.0009)	KLLoss 0.0031 (0.0027)	MaskLoss 0.1094 (0.0883)	MaskBCELoss 0.0209 (0.0235)	MaskDICELoss 0.0884 (0.0648)
Epoch: [3][ 25/500]	Time 78.041 (78.041)	Loss 0.0146 (0.3221)	CeLoss 0.0145 (0.0342)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0025)	MaskLoss 0.0000 (0.0824)	MaskBCELoss 0.0000 (0.0225)	MaskDICELoss 0.0000 (0.0599)
Epoch: [3][ 26/500]	Time 83.438 (83.438)	Loss 0.0843 (0.2894)	CeLoss 0.0186 (0.0299)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0019 (0.0022)	MaskLoss 0.0182 (0.0749)	MaskBCELoss 0.0045 (0.0213)	MaskDICELoss 0.0136 (0.0536)
Epoch: [3][ 27/500]	Time 78.714 (78.714)	Loss 0.5169 (0.2228)	CeLoss 0.0757 (0.0333)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0036 (0.0025)	MaskLoss 0.1212 (0.0536)	MaskBCELoss 0.0237 (0.0139)	MaskDICELoss 0.0974 (0.0397)
Epoch: [3][ 28/500]	Time 82.172 (82.172)	Loss 0.2924 (0.3881)	CeLoss 0.0208 (0.0469)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0023 (0.0032)	MaskLoss 0.0720 (0.0961)	MaskBCELoss 0.0097 (0.0236)	MaskDICELoss 0.0622 (0.0725)
Epoch: [3][ 29/500]	Time 76.873 (76.873)	Loss 0.4782 (0.3973)	CeLoss 0.0427 (0.0514)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0028 (0.0031)	MaskLoss 0.1208 (0.0968)	MaskBCELoss 0.0254 (0.0224)	MaskDICELoss 0.0954 (0.0743)
Epoch: [3][ 30/500]	Time 77.366 (77.366)	Loss 0.0110 (0.2423)	CeLoss 0.0110 (0.0280)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0024)	MaskLoss 0.0000 (0.0586)	MaskBCELoss 0.0000 (0.0116)	MaskDICELoss 0.0000 (0.0470)
Epoch: [3][ 31/500]	Time 74.756 (74.756)	Loss 0.0144 (0.3627)	CeLoss 0.0143 (0.0484)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0029)	MaskLoss 0.0000 (0.0969)	MaskBCELoss 0.0000 (0.0384)	MaskDICELoss 0.0000 (0.0585)
Epoch: [3][ 32/500]	Time 77.784 (77.784)	Loss 0.4282 (0.4222)	CeLoss 0.0227 (0.0389)	SegCLSLoss 0.0042 (0.0015)	KLLoss 0.0031 (0.0030)	MaskLoss 0.1122 (0.1042)	MaskBCELoss 0.0241 (0.0187)	MaskDICELoss 0.0880 (0.0855)
Epoch: [3][ 33/500]	Time 73.611 (73.611)	Loss 0.0270 (0.3250)	CeLoss 0.0270 (0.0450)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0790)	MaskBCELoss 0.0000 (0.0197)	MaskDICELoss 0.0000 (0.0593)
Epoch: [3][ 34/500]	Time 79.135 (79.135)	Loss 0.2827 (0.3617)	CeLoss 0.0239 (0.0311)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0021 (0.0022)	MaskLoss 0.0740 (0.0885)	MaskBCELoss 0.0202 (0.0131)	MaskDICELoss 0.0538 (0.0754)
Epoch: [3][ 35/500]	Time 74.647 (74.647)	Loss 0.3600 (0.3664)	CeLoss 0.0226 (0.0639)	SegCLSLoss 0.0027 (0.0011)	KLLoss 0.0053 (0.0032)	MaskLoss 0.0918 (0.0892)	MaskBCELoss 0.0182 (0.0291)	MaskDICELoss 0.0736 (0.0601)
Epoch: [3][ 36/500]	Time 74.079 (74.079)	Loss 0.2904 (0.3392)	CeLoss 0.0674 (0.0450)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0018 (0.0026)	MaskLoss 0.0622 (0.0811)	MaskBCELoss 0.0139 (0.0166)	MaskDICELoss 0.0483 (0.0644)
Epoch: [3][ 37/500]	Time 77.448 (77.448)	Loss 0.4062 (0.3931)	CeLoss 0.0815 (0.0442)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0033 (0.0029)	MaskLoss 0.0811 (0.1010)	MaskBCELoss 0.0019 (0.0295)	MaskDICELoss 0.0792 (0.0716)
Epoch: [3][ 38/500]	Time 74.758 (74.758)	Loss 0.4306 (0.3340)	CeLoss 0.0187 (0.0373)	SegCLSLoss 0.0014 (0.0018)	KLLoss 0.0027 (0.0024)	MaskLoss 0.1046 (0.0852)	MaskBCELoss 0.0049 (0.0238)	MaskDICELoss 0.0997 (0.0614)
Epoch: [3][ 39/500]	Time 81.061 (81.061)	Loss 0.3833 (0.3956)	CeLoss 0.0659 (0.0455)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0012 (0.0022)	MaskLoss 0.0892 (0.1043)	MaskBCELoss 0.0205 (0.0349)	MaskDICELoss 0.0687 (0.0694)
Epoch: [3][ 40/500]	Time 73.555 (73.555)	Loss 0.4547 (0.3726)	CeLoss 0.0535 (0.0358)	SegCLSLoss 0.0018 (0.0012)	KLLoss 0.0033 (0.0027)	MaskLoss 0.1027 (0.0908)	MaskBCELoss 0.0068 (0.0149)	MaskDICELoss 0.0959 (0.0759)
Epoch: [3][ 41/500]	Time 74.775 (74.775)	Loss 0.4432 (0.3611)	CeLoss 0.0242 (0.0493)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0018 (0.0023)	MaskLoss 0.1084 (0.0872)	MaskBCELoss 0.0084 (0.0197)	MaskDICELoss 0.1000 (0.0674)
Epoch: [3][ 42/500]	Time 72.935 (72.935)	Loss 0.4334 (0.3352)	CeLoss 0.0228 (0.0293)	SegCLSLoss 0.0030 (0.0016)	KLLoss 0.0024 (0.0031)	MaskLoss 0.1034 (0.0833)	MaskBCELoss 0.0034 (0.0156)	MaskDICELoss 0.1000 (0.0677)
Epoch: [3][ 43/500]	Time 70.899 (70.899)	Loss 0.4159 (0.2765)	CeLoss 0.0222 (0.0230)	SegCLSLoss 0.0060 (0.0031)	KLLoss 0.0019 (0.0027)	MaskLoss 0.0999 (0.0693)	MaskBCELoss 0.0056 (0.0140)	MaskDICELoss 0.0944 (0.0553)
Epoch: [3][ 44/500]	Time 79.400 (79.400)	Loss 0.4300 (0.3143)	CeLoss 0.0476 (0.0385)	SegCLSLoss 0.0020 (0.0014)	KLLoss 0.0041 (0.0032)	MaskLoss 0.0956 (0.0812)	MaskBCELoss 0.0027 (0.0265)	MaskDICELoss 0.0930 (0.0547)
Epoch: [3][ 45/500]	Time 74.058 (74.058)	Loss 0.3004 (0.3992)	CeLoss 0.0204 (0.0458)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0035 (0.0032)	MaskLoss 0.0709 (0.1034)	MaskBCELoss 0.0037 (0.0320)	MaskDICELoss 0.0672 (0.0714)
Epoch: [3][ 46/500]	Time 76.033 (76.033)	Loss 0.3605 (0.3230)	CeLoss 0.0271 (0.0268)	SegCLSLoss 0.0005 (0.0017)	KLLoss 0.0028 (0.0029)	MaskLoss 0.0881 (0.0806)	MaskBCELoss 0.0110 (0.0150)	MaskDICELoss 0.0771 (0.0656)
Epoch: [3][ 47/500]	Time 67.249 (67.249)	Loss 0.4313 (0.2868)	CeLoss 0.0226 (0.0419)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0028 (0.0025)	MaskLoss 0.1027 (0.0656)	MaskBCELoss 0.0028 (0.0101)	MaskDICELoss 0.0999 (0.0554)
Epoch: [3][ 48/500]	Time 78.113 (78.113)	Loss 0.4307 (0.4390)	CeLoss 0.0248 (0.0463)	SegCLSLoss 0.0028 (0.0017)	KLLoss 0.0031 (0.0033)	MaskLoss 0.1020 (0.1040)	MaskBCELoss 0.0033 (0.0139)	MaskDICELoss 0.0987 (0.0902)
Epoch: [3][ 49/500]	Time 68.373 (68.373)	Loss 0.1952 (0.3300)	CeLoss 0.0791 (0.0460)	SegCLSLoss 0.0003 (0.0020)	KLLoss 0.0040 (0.0029)	MaskLoss 0.0375 (0.0772)	MaskBCELoss 0.0188 (0.0145)	MaskDICELoss 0.0187 (0.0628)
Epoch: [3][ 50/500]	Time 70.219 (70.219)	Loss 0.2750 (0.3479)	CeLoss 0.0559 (0.0401)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0033 (0.0029)	MaskLoss 0.0559 (0.0860)	MaskBCELoss 0.0038 (0.0198)	MaskDICELoss 0.0521 (0.0662)
Epoch: [3][ 51/500]	Time 70.596 (70.596)	Loss 0.4690 (0.3504)	CeLoss 0.0562 (0.0374)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0033 (0.0028)	MaskLoss 0.1066 (0.0841)	MaskBCELoss 0.0088 (0.0133)	MaskDICELoss 0.0978 (0.0708)
Epoch: [3][ 52/500]	Time 76.604 (76.604)	Loss 0.1497 (0.3421)	CeLoss 0.0203 (0.0402)	SegCLSLoss 0.0042 (0.0014)	KLLoss 0.0025 (0.0028)	MaskLoss 0.0398 (0.0828)	MaskBCELoss 0.0173 (0.0165)	MaskDICELoss 0.0226 (0.0664)
Epoch: [3][ 53/500]	Time 78.237 (78.237)	Loss 0.1674 (0.3038)	CeLoss 0.0238 (0.0457)	SegCLSLoss 0.0013 (0.0008)	KLLoss 0.0039 (0.0029)	MaskLoss 0.0455 (0.0711)	MaskBCELoss 0.0216 (0.0148)	MaskDICELoss 0.0240 (0.0563)
Epoch: [3][ 54/500]	Time 74.097 (74.097)	Loss 0.4762 (0.3871)	CeLoss 0.0723 (0.0462)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0023 (0.0027)	MaskLoss 0.1019 (0.0912)	MaskBCELoss 0.0033 (0.0136)	MaskDICELoss 0.0987 (0.0776)
Epoch: [3][ 55/500]	Time 74.295 (74.295)	Loss 0.4922 (0.3195)	CeLoss 0.0762 (0.0357)	SegCLSLoss 0.0021 (0.0014)	KLLoss 0.0042 (0.0028)	MaskLoss 0.1055 (0.0771)	MaskBCELoss 0.0056 (0.0141)	MaskDICELoss 0.0998 (0.0630)
Epoch: [3][ 56/500]	Time 74.473 (74.473)	Loss 0.4560 (0.3697)	CeLoss 0.0825 (0.0498)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0028 (0.0028)	MaskLoss 0.0944 (0.0904)	MaskBCELoss 0.0034 (0.0225)	MaskDICELoss 0.0910 (0.0679)
Epoch: [3][ 57/500]	Time 77.907 (77.907)	Loss 0.1565 (0.3025)	CeLoss 0.0247 (0.0381)	SegCLSLoss 0.0010 (0.0015)	KLLoss 0.0017 (0.0028)	MaskLoss 0.0395 (0.0722)	MaskBCELoss 0.0143 (0.0140)	MaskDICELoss 0.0253 (0.0582)
Epoch: [3][ 58/500]	Time 74.564 (74.564)	Loss 0.0687 (0.3968)	CeLoss 0.0245 (0.0348)	SegCLSLoss 0.0008 (0.0019)	KLLoss 0.0029 (0.0034)	MaskLoss 0.0159 (0.0955)	MaskBCELoss 0.0112 (0.0123)	MaskDICELoss 0.0046 (0.0833)
Epoch: [3][ 59/500]	Time 71.069 (71.069)	Loss 0.4653 (0.3518)	CeLoss 0.0613 (0.0391)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0029 (0.0027)	MaskLoss 0.1033 (0.0854)	MaskBCELoss 0.0060 (0.0160)	MaskDICELoss 0.0973 (0.0694)
Epoch: [3][ 60/500]	Time 69.598 (69.598)	Loss 0.4533 (0.3522)	CeLoss 0.0306 (0.0350)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0026 (0.0025)	MaskLoss 0.1130 (0.0852)	MaskBCELoss 0.0162 (0.0133)	MaskDICELoss 0.0968 (0.0719)
Epoch: [3][ 61/500]	Time 72.810 (72.810)	Loss 0.3613 (0.3462)	CeLoss 0.0214 (0.0393)	SegCLSLoss 0.0016 (0.0016)	KLLoss 0.0029 (0.0031)	MaskLoss 0.0993 (0.0876)	MaskBCELoss 0.0305 (0.0238)	MaskDICELoss 0.0688 (0.0638)
Epoch: [3][ 62/500]	Time 78.930 (78.930)	Loss 0.5021 (0.2901)	CeLoss 0.0947 (0.0451)	SegCLSLoss 0.0005 (0.0006)	KLLoss 0.0031 (0.0026)	MaskLoss 0.1037 (0.0644)	MaskBCELoss 0.0056 (0.0079)	MaskDICELoss 0.0981 (0.0565)
Epoch: [3][ 63/500]	Time 70.074 (70.074)	Loss 0.3634 (0.3699)	CeLoss 0.0464 (0.0498)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0031 (0.0033)	MaskLoss 0.0910 (0.0863)	MaskBCELoss 0.0253 (0.0146)	MaskDICELoss 0.0657 (0.0717)
Epoch: [3][ 64/500]	Time 74.689 (74.689)	Loss 0.3646 (0.3216)	CeLoss 0.0228 (0.0368)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0046 (0.0034)	MaskLoss 0.0931 (0.0764)	MaskBCELoss 0.0179 (0.0124)	MaskDICELoss 0.0752 (0.0640)
Epoch: [3][ 65/500]	Time 73.693 (73.693)	Loss 0.4187 (0.2882)	CeLoss 0.0654 (0.0394)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0031 (0.0029)	MaskLoss 0.0878 (0.0661)	MaskBCELoss 0.0007 (0.0094)	MaskDICELoss 0.0871 (0.0567)
Epoch: [3][ 66/500]	Time 75.511 (75.511)	Loss 0.3612 (0.3056)	CeLoss 0.0447 (0.0442)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0039 (0.0031)	MaskLoss 0.0783 (0.0694)	MaskBCELoss 0.0006 (0.0099)	MaskDICELoss 0.0777 (0.0595)
Epoch: [3][ 67/500]	Time 73.835 (73.835)	Loss 0.2114 (0.3085)	CeLoss 0.0669 (0.0400)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0023 (0.0026)	MaskLoss 0.0368 (0.0748)	MaskBCELoss 0.0024 (0.0169)	MaskDICELoss 0.0344 (0.0578)
Epoch: [3][ 68/500]	Time 73.893 (73.893)	Loss 0.2063 (0.3197)	CeLoss 0.0222 (0.0436)	SegCLSLoss 0.0009 (0.0022)	KLLoss 0.0052 (0.0030)	MaskLoss 0.0530 (0.0796)	MaskBCELoss 0.0168 (0.0232)	MaskDICELoss 0.0362 (0.0564)
Epoch: [3][ 69/500]	Time 68.713 (68.713)	Loss 0.4316 (0.3306)	CeLoss 0.0231 (0.0518)	SegCLSLoss 0.0027 (0.0013)	KLLoss 0.0035 (0.0025)	MaskLoss 0.1054 (0.0813)	MaskBCELoss 0.0090 (0.0247)	MaskDICELoss 0.0964 (0.0566)
Epoch: [3][ 70/500]	Time 68.089 (68.089)	Loss 0.4300 (0.3916)	CeLoss 0.0247 (0.0462)	SegCLSLoss 0.0023 (0.0013)	KLLoss 0.0039 (0.0031)	MaskLoss 0.1013 (0.0962)	MaskBCELoss 0.0024 (0.0216)	MaskDICELoss 0.0989 (0.0746)
Epoch: [3][ 71/500]	Time 70.653 (70.653)	Loss 0.1584 (0.3272)	CeLoss 0.0967 (0.0539)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0022 (0.0023)	MaskLoss 0.0226 (0.0773)	MaskBCELoss 0.0154 (0.0191)	MaskDICELoss 0.0072 (0.0581)
Epoch: [3][ 72/500]	Time 80.958 (80.958)	Loss 0.0349 (0.3090)	CeLoss 0.0215 (0.0412)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0025 (0.0029)	MaskLoss 0.0033 (0.0738)	MaskBCELoss 0.0013 (0.0154)	MaskDICELoss 0.0020 (0.0584)
Epoch: [3][ 73/500]	Time 77.102 (77.102)	Loss 0.4530 (0.3099)	CeLoss 0.0212 (0.0371)	SegCLSLoss 0.0022 (0.0019)	KLLoss 0.0020 (0.0026)	MaskLoss 0.1441 (0.0759)	MaskBCELoss 0.0739 (0.0172)	MaskDICELoss 0.0702 (0.0587)
Epoch: [3][ 74/500]	Time 71.213 (71.213)	Loss 0.4322 (0.2574)	CeLoss 0.0242 (0.0450)	SegCLSLoss 0.0026 (0.0013)	KLLoss 0.0025 (0.0027)	MaskLoss 0.1022 (0.0561)	MaskBCELoss 0.0022 (0.0078)	MaskDICELoss 0.1000 (0.0484)
Epoch: [3][ 75/500]	Time 67.811 (67.811)	Loss 0.3919 (0.2963)	CeLoss 0.0242 (0.0471)	SegCLSLoss 0.0034 (0.0015)	KLLoss 0.0042 (0.0030)	MaskLoss 0.0946 (0.0720)	MaskBCELoss 0.0085 (0.0213)	MaskDICELoss 0.0862 (0.0507)
Epoch: [3][ 76/500]	Time 75.220 (75.220)	Loss 0.1760 (0.3534)	CeLoss 0.0432 (0.0418)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0015 (0.0024)	MaskLoss 0.0453 (0.0851)	MaskBCELoss 0.0251 (0.0159)	MaskDICELoss 0.0202 (0.0693)
Epoch: [3][ 77/500]	Time 71.149 (71.149)	Loss 0.1173 (0.2580)	CeLoss 0.0223 (0.0341)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0014 (0.0020)	MaskLoss 0.0297 (0.0593)	MaskBCELoss 0.0128 (0.0079)	MaskDICELoss 0.0169 (0.0514)
Epoch: [3][ 78/500]	Time 74.582 (74.582)	Loss 0.4900 (0.3242)	CeLoss 0.0718 (0.0432)	SegCLSLoss 0.0046 (0.0010)	KLLoss 0.0039 (0.0027)	MaskLoss 0.1207 (0.0801)	MaskBCELoss 0.0354 (0.0213)	MaskDICELoss 0.0853 (0.0588)
Epoch: [3][ 79/500]	Time 72.091 (72.091)	Loss 0.4613 (0.3741)	CeLoss 0.0488 (0.0467)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0039 (0.0032)	MaskLoss 0.1154 (0.0962)	MaskBCELoss 0.0269 (0.0306)	MaskDICELoss 0.0885 (0.0656)
Epoch: [3][ 80/500]	Time 74.856 (74.856)	Loss 0.3974 (0.3106)	CeLoss 0.0151 (0.0244)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0029 (0.0030)	MaskLoss 0.1014 (0.0765)	MaskBCELoss 0.0135 (0.0119)	MaskDICELoss 0.0879 (0.0647)
Epoch: [3][ 81/500]	Time 71.976 (71.976)	Loss 0.4844 (0.3689)	CeLoss 0.0830 (0.0432)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0037 (0.0030)	MaskLoss 0.1004 (0.0894)	MaskBCELoss 0.0023 (0.0179)	MaskDICELoss 0.0981 (0.0715)
Epoch: [3][ 82/500]	Time 69.049 (69.049)	Loss 0.2665 (0.2744)	CeLoss 0.0361 (0.0471)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0044 (0.0038)	MaskLoss 0.0712 (0.0630)	MaskBCELoss 0.0295 (0.0145)	MaskDICELoss 0.0417 (0.0485)
Epoch: [3][ 83/500]	Time 70.522 (70.522)	Loss 0.3668 (0.3660)	CeLoss 0.0703 (0.0416)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0017 (0.0029)	MaskLoss 0.0759 (0.0965)	MaskBCELoss 0.0045 (0.0326)	MaskDICELoss 0.0714 (0.0639)
Epoch: [3][ 84/500]	Time 74.203 (74.203)	Loss 0.1085 (0.2827)	CeLoss 0.0801 (0.0490)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0031 (0.0028)	MaskLoss 0.0090 (0.0621)	MaskBCELoss 0.0053 (0.0089)	MaskDICELoss 0.0037 (0.0532)
Epoch: [3][ 85/500]	Time 74.181 (74.181)	Loss 0.4325 (0.3658)	CeLoss 0.0258 (0.0536)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0022 (0.0030)	MaskLoss 0.1020 (0.0917)	MaskBCELoss 0.0021 (0.0290)	MaskDICELoss 0.0999 (0.0627)
Epoch: [3][ 86/500]	Time 75.141 (75.141)	Loss 0.4940 (0.3556)	CeLoss 0.0332 (0.0581)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0031 (0.0029)	MaskLoss 0.1287 (0.0818)	MaskBCELoss 0.0287 (0.0166)	MaskDICELoss 0.1000 (0.0652)
Epoch: [3][ 87/500]	Time 67.498 (67.498)	Loss 0.4842 (0.3520)	CeLoss 0.0811 (0.0529)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0024 (0.0030)	MaskLoss 0.1038 (0.0812)	MaskBCELoss 0.0077 (0.0147)	MaskDICELoss 0.0961 (0.0665)
Epoch: [3][ 88/500]	Time 76.347 (76.347)	Loss 0.5117 (0.3862)	CeLoss 0.0703 (0.0291)	SegCLSLoss 0.0011 (0.0019)	KLLoss 0.0035 (0.0037)	MaskLoss 0.1194 (0.0961)	MaskBCELoss 0.0200 (0.0159)	MaskDICELoss 0.0994 (0.0802)
Epoch: [3][ 89/500]	Time 72.472 (72.472)	Loss 0.0373 (0.3661)	CeLoss 0.0374 (0.0515)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0849)	MaskBCELoss 0.0000 (0.0141)	MaskDICELoss 0.0000 (0.0708)
Epoch: [3][ 90/500]	Time 65.187 (65.187)	Loss 0.4238 (0.3217)	CeLoss 0.0239 (0.0447)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0019 (0.0030)	MaskLoss 0.1004 (0.0776)	MaskBCELoss 0.0023 (0.0185)	MaskDICELoss 0.0981 (0.0591)
Epoch: [3][ 91/500]	Time 72.375 (72.375)	Loss 0.2683 (0.3975)	CeLoss 0.0232 (0.0363)	SegCLSLoss 0.0060 (0.0021)	KLLoss 0.0044 (0.0030)	MaskLoss 0.0816 (0.1017)	MaskBCELoss 0.0442 (0.0249)	MaskDICELoss 0.0373 (0.0769)
Epoch: [3][ 92/500]	Time 75.762 (75.762)	Loss 0.2700 (0.4371)	CeLoss 0.0947 (0.0473)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0023 (0.0029)	MaskLoss 0.0571 (0.1065)	MaskBCELoss 0.0279 (0.0200)	MaskDICELoss 0.0293 (0.0865)
Epoch: [3][ 93/500]	Time 75.553 (75.553)	Loss 0.4335 (0.3593)	CeLoss 0.0240 (0.0306)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0034 (0.0029)	MaskLoss 0.1114 (0.0876)	MaskBCELoss 0.0204 (0.0127)	MaskDICELoss 0.0911 (0.0749)
Epoch: [3][ 94/500]	Time 71.903 (71.903)	Loss 0.4787 (0.3584)	CeLoss 0.0522 (0.0488)	SegCLSLoss 0.0017 (0.0008)	KLLoss 0.0036 (0.0034)	MaskLoss 0.1197 (0.0856)	MaskBCELoss 0.0284 (0.0183)	MaskDICELoss 0.0913 (0.0673)
Epoch: [3][ 95/500]	Time 68.895 (68.895)	Loss 0.0563 (0.3201)	CeLoss 0.0562 (0.0457)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0027)	MaskLoss 0.0000 (0.0726)	MaskBCELoss 0.0000 (0.0097)	MaskDICELoss 0.0000 (0.0629)
Epoch: [3][ 96/500]	Time 66.945 (66.945)	Loss 0.3896 (0.3164)	CeLoss 0.0183 (0.0414)	SegCLSLoss 0.0031 (0.0023)	KLLoss 0.0051 (0.0033)	MaskLoss 0.1041 (0.0765)	MaskBCELoss 0.0260 (0.0177)	MaskDICELoss 0.0782 (0.0587)
Epoch: [3][ 97/500]	Time 73.042 (73.042)	Loss 0.2266 (0.3326)	CeLoss 0.0732 (0.0440)	SegCLSLoss 0.0008 (0.0017)	KLLoss 0.0014 (0.0030)	MaskLoss 0.0531 (0.0804)	MaskBCELoss 0.0305 (0.0183)	MaskDICELoss 0.0227 (0.0620)
Epoch: [3][ 98/500]	Time 70.309 (70.309)	Loss 0.4297 (0.3587)	CeLoss 0.0201 (0.0238)	SegCLSLoss 0.0026 (0.0026)	KLLoss 0.0027 (0.0031)	MaskLoss 0.1031 (0.0883)	MaskBCELoss 0.0034 (0.0113)	MaskDICELoss 0.0997 (0.0770)
Epoch: [3][ 99/500]	Time 72.185 (72.185)	Loss 0.4465 (0.2641)	CeLoss 0.0403 (0.0414)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0015 (0.0019)	MaskLoss 0.1025 (0.0618)	MaskBCELoss 0.0026 (0.0134)	MaskDICELoss 0.0999 (0.0484)
[2025-03-12 02:13:50,464] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[0.0002800722891566265], mom=[(0.9, 0.95)]
[2025-03-12 02:13:50,476] [INFO] [timer.py:215:stop] epoch=0/micro_step=1600/global_step=160, RunningAvgSamplesPerSec=0.6594948848809937, CurrSamplesPerSec=0.5497762182033946, MemAllocated=60.69GB, MaxMemAllocated=74.71GB
Epoch: [3][100/500]	Time 68.078 (68.078)	Loss 0.4300 (0.4079)	CeLoss 0.0317 (0.0536)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0024 (0.0029)	MaskLoss 0.1069 (0.0979)	MaskBCELoss 0.0161 (0.0202)	MaskDICELoss 0.0909 (0.0777)
Epoch: [3][101/500]	Time 67.831 (67.831)	Loss 0.2393 (0.4662)	CeLoss 0.0417 (0.0521)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0022 (0.0033)	MaskLoss 0.0520 (0.1212)	MaskBCELoss 0.0065 (0.0373)	MaskDICELoss 0.0455 (0.0839)
Epoch: [3][102/500]	Time 72.069 (72.069)	Loss 0.4439 (0.3618)	CeLoss 0.0752 (0.0407)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0043 (0.0034)	MaskLoss 0.1101 (0.0843)	MaskBCELoss 0.0384 (0.0099)	MaskDICELoss 0.0718 (0.0743)
Epoch: [3][103/500]	Time 70.933 (70.933)	Loss 0.3820 (0.3461)	CeLoss 0.0248 (0.0496)	SegCLSLoss 0.0023 (0.0010)	KLLoss 0.0035 (0.0032)	MaskLoss 0.1073 (0.0849)	MaskBCELoss 0.0383 (0.0234)	MaskDICELoss 0.0690 (0.0615)
Epoch: [3][104/500]	Time 72.086 (72.086)	Loss 0.4071 (0.3343)	CeLoss 0.0214 (0.0353)	SegCLSLoss 0.0036 (0.0027)	KLLoss 0.0040 (0.0033)	MaskLoss 0.1146 (0.0826)	MaskBCELoss 0.0393 (0.0180)	MaskDICELoss 0.0753 (0.0646)
Epoch: [3][105/500]	Time 66.406 (66.406)	Loss 0.4251 (0.3540)	CeLoss 0.0693 (0.0450)	SegCLSLoss 0.0007 (0.0022)	KLLoss 0.0020 (0.0025)	MaskLoss 0.0907 (0.0829)	MaskBCELoss 0.0045 (0.0132)	MaskDICELoss 0.0861 (0.0697)
Epoch: [3][106/500]	Time 76.177 (76.177)	Loss 0.4508 (0.3652)	CeLoss 0.0391 (0.0379)	SegCLSLoss 0.0016 (0.0015)	KLLoss 0.0045 (0.0029)	MaskLoss 0.1175 (0.0876)	MaskBCELoss 0.0319 (0.0135)	MaskDICELoss 0.0857 (0.0742)
Epoch: [3][107/500]	Time 74.149 (74.149)	Loss 0.4815 (0.3227)	CeLoss 0.0398 (0.0364)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0016 (0.0033)	MaskLoss 0.1200 (0.0766)	MaskBCELoss 0.0203 (0.0121)	MaskDICELoss 0.0997 (0.0645)
Epoch: [3][108/500]	Time 81.560 (81.560)	Loss 0.0650 (0.2190)	CeLoss 0.0222 (0.0338)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0035 (0.0031)	MaskLoss 0.0145 (0.0533)	MaskBCELoss 0.0095 (0.0158)	MaskDICELoss 0.0049 (0.0375)
Epoch: [3][109/500]	Time 74.528 (74.528)	Loss 0.1449 (0.3097)	CeLoss 0.0227 (0.0359)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0019 (0.0026)	MaskLoss 0.0308 (0.0733)	MaskBCELoss 0.0018 (0.0114)	MaskDICELoss 0.0290 (0.0619)
Epoch: [3][110/500]	Time 77.091 (77.091)	Loss 0.1579 (0.3506)	CeLoss 0.0203 (0.0338)	SegCLSLoss 0.0030 (0.0012)	KLLoss 0.0021 (0.0032)	MaskLoss 0.0503 (0.0847)	MaskBCELoss 0.0336 (0.0130)	MaskDICELoss 0.0167 (0.0717)
Epoch: [3][111/500]	Time 73.910 (73.910)	Loss 0.0180 (0.3771)	CeLoss 0.0179 (0.0316)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0029)	MaskLoss 0.0000 (0.1013)	MaskBCELoss 0.0000 (0.0316)	MaskDICELoss 0.0000 (0.0696)
Epoch: [3][112/500]	Time 67.247 (67.247)	Loss 0.4337 (0.3785)	CeLoss 0.0232 (0.0425)	SegCLSLoss 0.0018 (0.0013)	KLLoss 0.0021 (0.0033)	MaskLoss 0.1038 (0.0977)	MaskBCELoss 0.0039 (0.0293)	MaskDICELoss 0.1000 (0.0684)
Epoch: [3][113/500]	Time 72.057 (72.057)	Loss 0.4320 (0.3792)	CeLoss 0.0249 (0.0466)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0038 (0.0031)	MaskLoss 0.1019 (0.0923)	MaskBCELoss 0.0024 (0.0203)	MaskDICELoss 0.0995 (0.0721)
Epoch: [3][114/500]	Time 74.648 (74.648)	Loss 0.3108 (0.3585)	CeLoss 0.0613 (0.0467)	SegCLSLoss 0.0027 (0.0011)	KLLoss 0.0035 (0.0029)	MaskLoss 0.0770 (0.0844)	MaskBCELoss 0.0315 (0.0146)	MaskDICELoss 0.0454 (0.0698)
Epoch: [3][115/500]	Time 73.502 (73.502)	Loss 0.3673 (0.3508)	CeLoss 0.0217 (0.0471)	SegCLSLoss 0.0023 (0.0014)	KLLoss 0.0027 (0.0034)	MaskLoss 0.0898 (0.0817)	MaskBCELoss 0.0087 (0.0136)	MaskDICELoss 0.0811 (0.0681)
Epoch: [3][116/500]	Time 71.460 (71.460)	Loss 0.4298 (0.3356)	CeLoss 0.0223 (0.0365)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0039 (0.0035)	MaskLoss 0.1022 (0.0785)	MaskBCELoss 0.0031 (0.0096)	MaskDICELoss 0.0991 (0.0689)
Epoch: [3][117/500]	Time 78.318 (78.318)	Loss 0.4233 (0.3757)	CeLoss 0.0130 (0.0354)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0042 (0.0030)	MaskLoss 0.1032 (0.0971)	MaskBCELoss 0.0034 (0.0258)	MaskDICELoss 0.0998 (0.0713)
Epoch: [3][118/500]	Time 70.916 (70.916)	Loss 0.2119 (0.3003)	CeLoss 0.0469 (0.0373)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0035 (0.0025)	MaskLoss 0.0428 (0.0702)	MaskBCELoss 0.0053 (0.0104)	MaskDICELoss 0.0375 (0.0598)
Epoch: [3][119/500]	Time 71.810 (71.810)	Loss 0.0123 (0.3596)	CeLoss 0.0123 (0.0419)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0871)	MaskBCELoss 0.0000 (0.0174)	MaskDICELoss 0.0000 (0.0698)
Epoch: [3][120/500]	Time 70.670 (70.670)	Loss 0.1053 (0.2974)	CeLoss 0.0222 (0.0405)	SegCLSLoss 0.0020 (0.0013)	KLLoss 0.0016 (0.0028)	MaskLoss 0.0299 (0.0724)	MaskBCELoss 0.0196 (0.0180)	MaskDICELoss 0.0103 (0.0544)
Epoch: [3][121/500]	Time 78.360 (78.360)	Loss 0.4648 (0.4515)	CeLoss 0.0693 (0.0422)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0020 (0.0031)	MaskLoss 0.0986 (0.1161)	MaskBCELoss 0.0008 (0.0294)	MaskDICELoss 0.0978 (0.0867)
Epoch: [3][122/500]	Time 67.514 (67.514)	Loss 0.4838 (0.3196)	CeLoss 0.0410 (0.0440)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0011 (0.0029)	MaskLoss 0.1206 (0.0726)	MaskBCELoss 0.0207 (0.0093)	MaskDICELoss 0.1000 (0.0633)
Epoch: [3][123/500]	Time 69.882 (69.882)	Loss 0.2507 (0.2862)	CeLoss 0.0684 (0.0397)	SegCLSLoss 0.0014 (0.0009)	KLLoss 0.0034 (0.0027)	MaskLoss 0.0652 (0.0698)	MaskBCELoss 0.0413 (0.0178)	MaskDICELoss 0.0238 (0.0519)
Epoch: [3][124/500]	Time 78.879 (78.879)	Loss 0.4920 (0.3977)	CeLoss 0.0454 (0.0576)	SegCLSLoss 0.0017 (0.0010)	KLLoss 0.0019 (0.0030)	MaskLoss 0.1250 (0.0917)	MaskBCELoss 0.0280 (0.0150)	MaskDICELoss 0.0970 (0.0766)
Epoch: [3][125/500]	Time 72.340 (72.340)	Loss 0.5133 (0.3963)	CeLoss 0.0869 (0.0415)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0022 (0.0033)	MaskLoss 0.1174 (0.0928)	MaskBCELoss 0.0231 (0.0102)	MaskDICELoss 0.0943 (0.0826)
Epoch: [3][126/500]	Time 78.318 (78.318)	Loss 0.5527 (0.3735)	CeLoss 0.0598 (0.0465)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0031 (0.0027)	MaskLoss 0.1725 (0.0941)	MaskBCELoss 0.1003 (0.0262)	MaskDICELoss 0.0722 (0.0678)
Epoch: [3][127/500]	Time 76.036 (76.036)	Loss 0.4229 (0.3168)	CeLoss 0.0444 (0.0320)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0073 (0.0030)	MaskLoss 0.1307 (0.0787)	MaskBCELoss 0.0759 (0.0168)	MaskDICELoss 0.0548 (0.0619)
Epoch: [3][128/500]	Time 70.699 (70.699)	Loss 0.4152 (0.3194)	CeLoss 0.0238 (0.0400)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0020 (0.0020)	MaskLoss 0.0989 (0.0812)	MaskBCELoss 0.0035 (0.0240)	MaskDICELoss 0.0954 (0.0572)
Epoch: [3][129/500]	Time 72.115 (72.115)	Loss 0.4740 (0.3255)	CeLoss 0.0239 (0.0435)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0016 (0.0033)	MaskLoss 0.1385 (0.0771)	MaskBCELoss 0.0531 (0.0152)	MaskDICELoss 0.0854 (0.0619)
Epoch: [3][130/500]	Time 68.163 (68.163)	Loss 0.1535 (0.2640)	CeLoss 0.0247 (0.0420)	SegCLSLoss 0.0020 (0.0014)	KLLoss 0.0024 (0.0029)	MaskLoss 0.0445 (0.0587)	MaskBCELoss 0.0263 (0.0083)	MaskDICELoss 0.0182 (0.0504)
Epoch: [3][131/500]	Time 68.806 (68.806)	Loss 0.1486 (0.3544)	CeLoss 0.0571 (0.0485)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0040 (0.0025)	MaskLoss 0.0260 (0.0806)	MaskBCELoss 0.0083 (0.0097)	MaskDICELoss 0.0176 (0.0709)
Epoch: [3][132/500]	Time 71.998 (71.998)	Loss 0.4344 (0.3568)	CeLoss 0.0237 (0.0407)	SegCLSLoss 0.0023 (0.0017)	KLLoss 0.0030 (0.0031)	MaskLoss 0.1051 (0.0908)	MaskBCELoss 0.0070 (0.0256)	MaskDICELoss 0.0981 (0.0652)
Epoch: [3][133/500]	Time 72.707 (72.707)	Loss 0.1806 (0.3740)	CeLoss 0.0493 (0.0418)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0036 (0.0031)	MaskLoss 0.0330 (0.0887)	MaskBCELoss 0.0023 (0.0131)	MaskDICELoss 0.0307 (0.0755)
Epoch: [3][134/500]	Time 73.657 (73.657)	Loss 0.3767 (0.3306)	CeLoss 0.0261 (0.0459)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0026 (0.0037)	MaskLoss 0.0879 (0.0763)	MaskBCELoss 0.0021 (0.0125)	MaskDICELoss 0.0858 (0.0639)
Epoch: [3][135/500]	Time 77.392 (77.392)	Loss 0.4591 (0.4211)	CeLoss 0.0540 (0.0332)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0031 (0.0036)	MaskLoss 0.1129 (0.1157)	MaskBCELoss 0.0251 (0.0396)	MaskDICELoss 0.0879 (0.0761)
Epoch: [3][136/500]	Time 75.854 (75.854)	Loss 0.4603 (0.2839)	CeLoss 0.0552 (0.0400)	SegCLSLoss 0.0018 (0.0013)	KLLoss 0.0048 (0.0033)	MaskLoss 0.1138 (0.0668)	MaskBCELoss 0.0277 (0.0136)	MaskDICELoss 0.0861 (0.0532)
Epoch: [3][137/500]	Time 71.337 (71.337)	Loss 0.1813 (0.3622)	CeLoss 0.0187 (0.0356)	SegCLSLoss 0.0022 (0.0013)	KLLoss 0.0022 (0.0039)	MaskLoss 0.0459 (0.0851)	MaskBCELoss 0.0122 (0.0093)	MaskDICELoss 0.0338 (0.0759)
Epoch: [3][138/500]	Time 73.149 (73.149)	Loss 0.4855 (0.4296)	CeLoss 0.0610 (0.0411)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0042 (0.0033)	MaskLoss 0.1102 (0.1047)	MaskBCELoss 0.0103 (0.0172)	MaskDICELoss 0.0999 (0.0876)
Epoch: [3][139/500]	Time 69.468 (69.468)	Loss 0.4544 (0.4323)	CeLoss 0.0386 (0.0416)	SegCLSLoss 0.0028 (0.0023)	KLLoss 0.0027 (0.0035)	MaskLoss 0.1192 (0.1117)	MaskBCELoss 0.0325 (0.0303)	MaskDICELoss 0.0867 (0.0814)
Epoch: [3][140/500]	Time 67.904 (67.904)	Loss 0.3711 (0.3983)	CeLoss 0.0386 (0.0566)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0069 (0.0034)	MaskLoss 0.0902 (0.0931)	MaskBCELoss 0.0176 (0.0172)	MaskDICELoss 0.0726 (0.0759)
Epoch: [3][141/500]	Time 72.988 (72.988)	Loss 0.4312 (0.3586)	CeLoss 0.0574 (0.0380)	SegCLSLoss 0.0011 (0.0014)	KLLoss 0.0026 (0.0035)	MaskLoss 0.0993 (0.0897)	MaskBCELoss 0.0132 (0.0213)	MaskDICELoss 0.0860 (0.0685)
Epoch: [3][142/500]	Time 70.699 (70.699)	Loss 0.1585 (0.3804)	CeLoss 0.0217 (0.0344)	SegCLSLoss 0.0016 (0.0015)	KLLoss 0.0034 (0.0035)	MaskLoss 0.0471 (0.0988)	MaskBCELoss 0.0279 (0.0267)	MaskDICELoss 0.0192 (0.0721)
Epoch: [3][143/500]	Time 64.904 (64.904)	Loss 0.3383 (0.3289)	CeLoss 0.0398 (0.0591)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0041 (0.0032)	MaskLoss 0.0840 (0.0716)	MaskBCELoss 0.0210 (0.0103)	MaskDICELoss 0.0630 (0.0613)
Epoch: [3][144/500]	Time 67.285 (67.285)	Loss 0.4228 (0.3897)	CeLoss 0.0242 (0.0612)	SegCLSLoss 0.0012 (0.0023)	KLLoss 0.0041 (0.0039)	MaskLoss 0.0999 (0.0911)	MaskBCELoss 0.0029 (0.0204)	MaskDICELoss 0.0970 (0.0706)
Epoch: [3][145/500]	Time 74.498 (74.498)	Loss 0.3760 (0.3178)	CeLoss 0.0206 (0.0406)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0016 (0.0035)	MaskLoss 0.0927 (0.0780)	MaskBCELoss 0.0089 (0.0195)	MaskDICELoss 0.0838 (0.0586)
Epoch: [3][146/500]	Time 76.670 (76.670)	Loss 0.4983 (0.3562)	CeLoss 0.0933 (0.0488)	SegCLSLoss 0.0012 (0.0007)	KLLoss 0.0039 (0.0033)	MaskLoss 0.1009 (0.0924)	MaskBCELoss 0.0015 (0.0330)	MaskDICELoss 0.0994 (0.0595)
Epoch: [3][147/500]	Time 80.463 (80.463)	Loss 0.1577 (0.4635)	CeLoss 0.0613 (0.0393)	SegCLSLoss 0.0003 (0.0017)	KLLoss 0.0025 (0.0036)	MaskLoss 0.0281 (0.1364)	MaskBCELoss 0.0093 (0.0630)	MaskDICELoss 0.0189 (0.0735)
Epoch: [3][148/500]	Time 72.335 (72.335)	Loss 0.4277 (0.4844)	CeLoss 0.0220 (0.0507)	SegCLSLoss 0.0028 (0.0017)	KLLoss 0.0026 (0.0032)	MaskLoss 0.1021 (0.1380)	MaskBCELoss 0.0033 (0.0612)	MaskDICELoss 0.0988 (0.0768)
Epoch: [3][149/500]	Time 78.796 (78.796)	Loss 0.3770 (0.2646)	CeLoss 0.0806 (0.0330)	SegCLSLoss 0.0015 (0.0009)	KLLoss 0.0032 (0.0026)	MaskLoss 0.0852 (0.0633)	MaskBCELoss 0.0240 (0.0122)	MaskDICELoss 0.0611 (0.0511)
Epoch: [3][150/500]	Time 75.852 (75.852)	Loss 0.4318 (0.4812)	CeLoss 0.0221 (0.0408)	SegCLSLoss 0.0024 (0.0015)	KLLoss 0.0038 (0.0041)	MaskLoss 0.1025 (0.1438)	MaskBCELoss 0.0025 (0.0698)	MaskDICELoss 0.1000 (0.0740)
Epoch: [3][151/500]	Time 73.460 (73.460)	Loss 0.4837 (0.3639)	CeLoss 0.0664 (0.0535)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0036 (0.0040)	MaskLoss 0.1068 (0.0865)	MaskBCELoss 0.0069 (0.0202)	MaskDICELoss 0.0999 (0.0663)
Epoch: [3][152/500]	Time 65.113 (65.113)	Loss 0.4615 (0.3186)	CeLoss 0.0339 (0.0488)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0036 (0.0030)	MaskLoss 0.1116 (0.0715)	MaskBCELoss 0.0116 (0.0098)	MaskDICELoss 0.1000 (0.0616)
Epoch: [3][153/500]	Time 74.871 (74.871)	Loss 0.0443 (0.2427)	CeLoss 0.0444 (0.0313)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0593)	MaskBCELoss 0.0000 (0.0146)	MaskDICELoss 0.0000 (0.0447)
Epoch: [3][154/500]	Time 68.237 (68.237)	Loss 0.3997 (0.3412)	CeLoss 0.0206 (0.0474)	SegCLSLoss 0.0032 (0.0014)	KLLoss 0.0053 (0.0037)	MaskLoss 0.1073 (0.0824)	MaskBCELoss 0.0286 (0.0201)	MaskDICELoss 0.0788 (0.0623)
Epoch: [3][155/500]	Time 68.104 (68.104)	Loss 0.1671 (0.2798)	CeLoss 0.0215 (0.0300)	SegCLSLoss 0.0014 (0.0016)	KLLoss 0.0049 (0.0038)	MaskLoss 0.0504 (0.0700)	MaskBCELoss 0.0309 (0.0173)	MaskDICELoss 0.0195 (0.0527)
Epoch: [3][156/500]	Time 79.537 (79.537)	Loss 0.4300 (0.4112)	CeLoss 0.0244 (0.0481)	SegCLSLoss 0.0027 (0.0012)	KLLoss 0.0024 (0.0032)	MaskLoss 0.1017 (0.1061)	MaskBCELoss 0.0024 (0.0325)	MaskDICELoss 0.0993 (0.0736)
Epoch: [3][157/500]	Time 71.442 (71.442)	Loss 0.4208 (0.2097)	CeLoss 0.0352 (0.0507)	SegCLSLoss 0.0014 (0.0015)	KLLoss 0.0030 (0.0039)	MaskLoss 0.1148 (0.0507)	MaskBCELoss 0.0387 (0.0242)	MaskDICELoss 0.0761 (0.0265)
Epoch: [3][158/500]	Time 71.478 (71.478)	Loss 0.5332 (0.3852)	CeLoss 0.0591 (0.0499)	SegCLSLoss 0.0026 (0.0014)	KLLoss 0.0074 (0.0045)	MaskLoss 0.1556 (0.0991)	MaskBCELoss 0.0784 (0.0331)	MaskDICELoss 0.0772 (0.0660)
Epoch: [3][159/500]	Time 75.792 (75.792)	Loss 0.4802 (0.3098)	CeLoss 0.0767 (0.0319)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0030 (0.0041)	MaskLoss 0.1002 (0.0747)	MaskBCELoss 0.0005 (0.0129)	MaskDICELoss 0.0997 (0.0619)
Epoch: [3][160/500]	Time 77.548 (77.548)	Loss 0.4467 (0.3383)	CeLoss 0.0535 (0.0495)	SegCLSLoss 0.0021 (0.0009)	KLLoss 0.0021 (0.0028)	MaskLoss 0.1011 (0.0781)	MaskBCELoss 0.0071 (0.0135)	MaskDICELoss 0.0939 (0.0647)
Epoch: [3][161/500]	Time 72.787 (72.787)	Loss 0.4726 (0.3132)	CeLoss 0.0579 (0.0388)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0049 (0.0030)	MaskLoss 0.1060 (0.0777)	MaskBCELoss 0.0071 (0.0199)	MaskDICELoss 0.0989 (0.0578)
Epoch: [3][162/500]	Time 68.217 (68.217)	Loss 0.1354 (0.3725)	CeLoss 0.0198 (0.0406)	SegCLSLoss 0.0010 (0.0017)	KLLoss 0.0036 (0.0033)	MaskLoss 0.0384 (0.0966)	MaskBCELoss 0.0209 (0.0292)	MaskDICELoss 0.0174 (0.0674)
Epoch: [3][163/500]	Time 75.909 (75.909)	Loss 0.0979 (0.3130)	CeLoss 0.0381 (0.0374)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0029 (0.0035)	MaskLoss 0.0164 (0.0737)	MaskBCELoss 0.0044 (0.0117)	MaskDICELoss 0.0119 (0.0620)
Epoch: [3][164/500]	Time 71.515 (71.515)	Loss 0.4506 (0.2896)	CeLoss 0.0444 (0.0380)	SegCLSLoss 0.0003 (0.0015)	KLLoss 0.0028 (0.0033)	MaskLoss 0.1181 (0.0762)	MaskBCELoss 0.0347 (0.0286)	MaskDICELoss 0.0835 (0.0476)
Epoch: [3][165/500]	Time 74.408 (74.408)	Loss 0.4161 (0.3639)	CeLoss 0.0212 (0.0492)	SegCLSLoss 0.0021 (0.0010)	KLLoss 0.0032 (0.0031)	MaskLoss 0.1012 (0.0875)	MaskBCELoss 0.0072 (0.0194)	MaskDICELoss 0.0940 (0.0681)
Epoch: [3][166/500]	Time 71.987 (71.987)	Loss 0.4590 (0.3644)	CeLoss 0.0496 (0.0432)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0041 (0.0036)	MaskLoss 0.1382 (0.0943)	MaskBCELoss 0.0739 (0.0301)	MaskDICELoss 0.0643 (0.0642)
Epoch: [3][167/500]	Time 68.449 (68.449)	Loss 0.3232 (0.3021)	CeLoss 0.0270 (0.0283)	SegCLSLoss 0.0009 (0.0018)	KLLoss 0.0022 (0.0028)	MaskLoss 0.0766 (0.0826)	MaskBCELoss 0.0063 (0.0302)	MaskDICELoss 0.0703 (0.0524)
Epoch: [3][168/500]	Time 69.432 (69.432)	Loss 0.3908 (0.2746)	CeLoss 0.0447 (0.0314)	SegCLSLoss 0.0003 (0.0022)	KLLoss 0.0040 (0.0034)	MaskLoss 0.1076 (0.0688)	MaskBCELoss 0.0442 (0.0183)	MaskDICELoss 0.0634 (0.0505)
Epoch: [3][169/500]	Time 67.915 (67.915)	Loss 0.2636 (0.3662)	CeLoss 0.0240 (0.0400)	SegCLSLoss 0.0023 (0.0018)	KLLoss 0.0055 (0.0036)	MaskLoss 0.0586 (0.0931)	MaskBCELoss 0.0007 (0.0253)	MaskDICELoss 0.0579 (0.0677)
Epoch: [3][170/500]	Time 77.774 (77.774)	Loss 0.5462 (0.4078)	CeLoss 0.0104 (0.0458)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0042 (0.0036)	MaskLoss 0.1661 (0.1080)	MaskBCELoss 0.0664 (0.0370)	MaskDICELoss 0.0996 (0.0710)
Epoch: [3][171/500]	Time 67.480 (67.480)	Loss 0.2428 (0.3956)	CeLoss 0.0435 (0.0410)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0026 (0.0039)	MaskLoss 0.0711 (0.1057)	MaskBCELoss 0.0440 (0.0364)	MaskDICELoss 0.0271 (0.0693)
Epoch: [3][172/500]	Time 68.627 (68.627)	Loss 0.2153 (0.3268)	CeLoss 0.0223 (0.0418)	SegCLSLoss 0.0071 (0.0017)	KLLoss 0.0038 (0.0039)	MaskLoss 0.0496 (0.0755)	MaskBCELoss 0.0064 (0.0108)	MaskDICELoss 0.0432 (0.0647)
Epoch: [3][173/500]	Time 74.644 (74.644)	Loss 0.3601 (0.2713)	CeLoss 0.0171 (0.0432)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0072 (0.0036)	MaskLoss 0.0978 (0.0632)	MaskBCELoss 0.0279 (0.0143)	MaskDICELoss 0.0700 (0.0489)
Epoch: [3][174/500]	Time 74.352 (74.352)	Loss 0.0202 (0.3423)	CeLoss 0.0203 (0.0502)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0793)	MaskBCELoss 0.0000 (0.0144)	MaskDICELoss 0.0000 (0.0649)
Epoch: [3][175/500]	Time 67.277 (67.277)	Loss 0.4323 (0.3900)	CeLoss 0.0222 (0.0496)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0064 (0.0038)	MaskLoss 0.1117 (0.0906)	MaskBCELoss 0.0219 (0.0132)	MaskDICELoss 0.0898 (0.0774)
Epoch: [3][176/500]	Time 71.650 (71.650)	Loss 0.3086 (0.3760)	CeLoss 0.0236 (0.0358)	SegCLSLoss 0.0052 (0.0022)	KLLoss 0.0030 (0.0035)	MaskLoss 0.0942 (0.0955)	MaskBCELoss 0.0487 (0.0231)	MaskDICELoss 0.0455 (0.0723)
Epoch: [3][177/500]	Time 79.040 (79.040)	Loss 0.0508 (0.2886)	CeLoss 0.0508 (0.0404)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0648)	MaskBCELoss 0.0000 (0.0073)	MaskDICELoss 0.0000 (0.0576)
Epoch: [3][178/500]	Time 74.547 (74.547)	Loss 0.4882 (0.3413)	CeLoss 0.0212 (0.0461)	SegCLSLoss 0.0017 (0.0010)	KLLoss 0.0029 (0.0047)	MaskLoss 0.1434 (0.0869)	MaskBCELoss 0.0553 (0.0288)	MaskDICELoss 0.0882 (0.0581)
Epoch: [3][179/500]	Time 74.192 (74.192)	Loss 0.4869 (0.2728)	CeLoss 0.0232 (0.0390)	SegCLSLoss 0.0020 (0.0008)	KLLoss 0.0029 (0.0019)	MaskLoss 0.1407 (0.0668)	MaskBCELoss 0.0514 (0.0178)	MaskDICELoss 0.0893 (0.0490)
Epoch: [3][180/500]	Time 72.255 (72.255)	Loss 0.4197 (0.3018)	CeLoss 0.0238 (0.0425)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0032 (0.0031)	MaskLoss 0.0989 (0.0704)	MaskBCELoss 0.0018 (0.0129)	MaskDICELoss 0.0971 (0.0575)
Epoch: [3][181/500]	Time 70.780 (70.780)	Loss 0.4690 (0.4051)	CeLoss 0.0500 (0.0432)	SegCLSLoss 0.0003 (0.0016)	KLLoss 0.0045 (0.0042)	MaskLoss 0.1080 (0.0951)	MaskBCELoss 0.0088 (0.0116)	MaskDICELoss 0.0992 (0.0835)
Epoch: [3][182/500]	Time 70.760 (70.760)	Loss 0.0135 (0.2586)	CeLoss 0.0135 (0.0341)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0660)	MaskBCELoss 0.0000 (0.0216)	MaskDICELoss 0.0000 (0.0444)
Epoch: [3][183/500]	Time 72.258 (72.258)	Loss 0.4845 (0.3605)	CeLoss 0.0618 (0.0502)	SegCLSLoss 0.0021 (0.0011)	KLLoss 0.0021 (0.0035)	MaskLoss 0.1108 (0.0849)	MaskBCELoss 0.0118 (0.0168)	MaskDICELoss 0.0990 (0.0681)
Epoch: [3][184/500]	Time 70.871 (70.871)	Loss 0.1687 (0.4221)	CeLoss 0.0693 (0.0358)	SegCLSLoss 0.0007 (0.0017)	KLLoss 0.0025 (0.0032)	MaskLoss 0.0288 (0.1147)	MaskBCELoss 0.0097 (0.0383)	MaskDICELoss 0.0192 (0.0764)
Epoch: [3][185/500]	Time 70.603 (70.603)	Loss 0.5052 (0.3183)	CeLoss 0.0801 (0.0480)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0045 (0.0036)	MaskLoss 0.1101 (0.0726)	MaskBCELoss 0.0102 (0.0122)	MaskDICELoss 0.0999 (0.0604)
Epoch: [3][186/500]	Time 77.938 (77.938)	Loss 0.4117 (0.3848)	CeLoss 0.0127 (0.0329)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0023 (0.0033)	MaskLoss 0.1026 (0.0967)	MaskBCELoss 0.0070 (0.0193)	MaskDICELoss 0.0956 (0.0773)
Epoch: [3][187/500]	Time 65.672 (65.672)	Loss 0.2319 (0.4074)	CeLoss 0.0233 (0.0451)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0027 (0.0040)	MaskLoss 0.0625 (0.0982)	MaskBCELoss 0.0224 (0.0175)	MaskDICELoss 0.0401 (0.0807)
Epoch: [3][188/500]	Time 71.480 (71.480)	Loss 0.4553 (0.3480)	CeLoss 0.0684 (0.0365)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0020 (0.0029)	MaskLoss 0.0974 (0.0882)	MaskBCELoss 0.0025 (0.0223)	MaskDICELoss 0.0949 (0.0659)
Epoch: [3][189/500]	Time 76.484 (76.484)	Loss 0.4211 (0.3766)	CeLoss 0.0214 (0.0465)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0031 (0.0040)	MaskLoss 0.1206 (0.0906)	MaskBCELoss 0.0432 (0.0185)	MaskDICELoss 0.0774 (0.0721)
Epoch: [3][190/500]	Time 69.338 (69.338)	Loss 0.3825 (0.3280)	CeLoss 0.0649 (0.0540)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0038 (0.0037)	MaskLoss 0.0797 (0.0807)	MaskBCELoss 0.0026 (0.0265)	MaskDICELoss 0.0771 (0.0542)
Epoch: [3][191/500]	Time 75.086 (75.086)	Loss 0.5009 (0.3478)	CeLoss 0.0928 (0.0442)	SegCLSLoss 0.0049 (0.0017)	KLLoss 0.0051 (0.0042)	MaskLoss 0.1122 (0.0873)	MaskBCELoss 0.0239 (0.0254)	MaskDICELoss 0.0883 (0.0619)
Epoch: [3][192/500]	Time 74.784 (74.784)	Loss 0.4791 (0.3644)	CeLoss 0.0515 (0.0391)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0035 (0.0040)	MaskLoss 0.1118 (0.0928)	MaskBCELoss 0.0118 (0.0252)	MaskDICELoss 0.1000 (0.0676)
Epoch: [3][193/500]	Time 77.467 (77.467)	Loss 0.2888 (0.3137)	CeLoss 0.0256 (0.0320)	SegCLSLoss 0.0009 (0.0007)	KLLoss 0.0111 (0.0052)	MaskLoss 0.0790 (0.0764)	MaskBCELoss 0.0322 (0.0147)	MaskDICELoss 0.0468 (0.0617)
Epoch: [3][194/500]	Time 71.020 (71.020)	Loss 0.4546 (0.3487)	CeLoss 0.0571 (0.0385)	SegCLSLoss 0.0019 (0.0019)	KLLoss 0.0028 (0.0033)	MaskLoss 0.1012 (0.0825)	MaskBCELoss 0.0054 (0.0121)	MaskDICELoss 0.0958 (0.0705)
Epoch: [3][195/500]	Time 78.554 (78.554)	Loss 0.3984 (0.3184)	CeLoss 0.0552 (0.0423)	SegCLSLoss 0.0017 (0.0009)	KLLoss 0.0040 (0.0033)	MaskLoss 0.0939 (0.0789)	MaskBCELoss 0.0185 (0.0216)	MaskDICELoss 0.0754 (0.0573)
Epoch: [3][196/500]	Time 78.824 (78.824)	Loss 0.4355 (0.3432)	CeLoss 0.0214 (0.0428)	SegCLSLoss 0.0034 (0.0013)	KLLoss 0.0031 (0.0036)	MaskLoss 0.1063 (0.0809)	MaskBCELoss 0.0079 (0.0137)	MaskDICELoss 0.0984 (0.0672)
Epoch: [3][197/500]	Time 70.990 (70.990)	Loss 0.5544 (0.3963)	CeLoss 0.0425 (0.0506)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0052 (0.0038)	MaskLoss 0.1580 (0.0960)	MaskBCELoss 0.0630 (0.0214)	MaskDICELoss 0.0950 (0.0746)
Epoch: [3][198/500]	Time 74.136 (74.136)	Loss 0.4868 (0.2678)	CeLoss 0.0386 (0.0485)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0060 (0.0032)	MaskLoss 0.1222 (0.0635)	MaskBCELoss 0.0232 (0.0192)	MaskDICELoss 0.0990 (0.0444)
Epoch: [3][199/500]	Time 67.753 (67.753)	Loss 0.2095 (0.3320)	CeLoss 0.0232 (0.0381)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0056 (0.0042)	MaskLoss 0.0597 (0.0815)	MaskBCELoss 0.0294 (0.0185)	MaskDICELoss 0.0303 (0.0630)
[2025-03-12 04:15:04,840] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[0.0002787469879518072], mom=[(0.9, 0.95)]
[2025-03-12 04:15:04,850] [INFO] [timer.py:215:stop] epoch=0/micro_step=1700/global_step=170, RunningAvgSamplesPerSec=0.6512900327363411, CurrSamplesPerSec=0.5669033891202068, MemAllocated=60.45GB, MaxMemAllocated=74.71GB
Epoch: [3][200/500]	Time 75.102 (75.102)	Loss 0.4492 (0.3813)	CeLoss 0.0500 (0.0430)	SegCLSLoss 0.0006 (0.0009)	KLLoss 0.0033 (0.0032)	MaskLoss 0.0992 (0.0990)	MaskBCELoss 0.0006 (0.0307)	MaskDICELoss 0.0986 (0.0683)
Epoch: [3][201/500]	Time 70.811 (70.811)	Loss 0.3133 (0.3873)	CeLoss 0.0898 (0.0595)	SegCLSLoss 0.0002 (0.0018)	KLLoss 0.0035 (0.0027)	MaskLoss 0.0814 (0.0984)	MaskBCELoss 0.0528 (0.0347)	MaskDICELoss 0.0286 (0.0637)
Epoch: [3][202/500]	Time 80.545 (80.545)	Loss 0.1790 (0.3556)	CeLoss 0.0251 (0.0346)	SegCLSLoss 0.0021 (0.0015)	KLLoss 0.0030 (0.0030)	MaskLoss 0.0452 (0.0883)	MaskBCELoss 0.0155 (0.0181)	MaskDICELoss 0.0297 (0.0703)
Epoch: [3][203/500]	Time 68.712 (68.712)	Loss 0.1344 (0.3938)	CeLoss 0.0198 (0.0267)	SegCLSLoss 0.0015 (0.0016)	KLLoss 0.0038 (0.0036)	MaskLoss 0.0324 (0.0976)	MaskBCELoss 0.0098 (0.0138)	MaskDICELoss 0.0227 (0.0838)
Epoch: [3][204/500]	Time 73.889 (73.889)	Loss 0.4642 (0.3063)	CeLoss 0.0515 (0.0501)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0039 (0.0033)	MaskLoss 0.1042 (0.0714)	MaskBCELoss 0.0043 (0.0167)	MaskDICELoss 0.0999 (0.0547)
Epoch: [3][205/500]	Time 69.996 (69.996)	Loss 0.4206 (0.3849)	CeLoss 0.0142 (0.0386)	SegCLSLoss 0.0004 (0.0015)	KLLoss 0.0048 (0.0035)	MaskLoss 0.1008 (0.0954)	MaskBCELoss 0.0008 (0.0199)	MaskDICELoss 0.1000 (0.0756)
Epoch: [3][206/500]	Time 73.855 (73.855)	Loss 0.4356 (0.3429)	CeLoss 0.0439 (0.0495)	SegCLSLoss 0.0028 (0.0012)	KLLoss 0.0045 (0.0037)	MaskLoss 0.1051 (0.0802)	MaskBCELoss 0.0174 (0.0158)	MaskDICELoss 0.0878 (0.0644)
Epoch: [3][207/500]	Time 79.051 (79.051)	Loss 0.4534 (0.4177)	CeLoss 0.0613 (0.0456)	SegCLSLoss 0.0011 (0.0014)	KLLoss 0.0034 (0.0036)	MaskLoss 0.1158 (0.1021)	MaskBCELoss 0.0376 (0.0203)	MaskDICELoss 0.0783 (0.0818)
Epoch: [3][208/500]	Time 72.698 (72.698)	Loss 0.5615 (0.4573)	CeLoss 0.0732 (0.0460)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0039 (0.0037)	MaskLoss 0.1454 (0.1118)	MaskBCELoss 0.0491 (0.0202)	MaskDICELoss 0.0963 (0.0916)
Epoch: [3][209/500]	Time 68.215 (68.215)	Loss 0.4645 (0.2935)	CeLoss 0.0747 (0.0359)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0036 (0.0031)	MaskLoss 0.1013 (0.0729)	MaskBCELoss 0.0097 (0.0189)	MaskDICELoss 0.0917 (0.0540)
Epoch: [3][210/500]	Time 66.817 (66.817)	Loss 0.4929 (0.3554)	CeLoss 0.0508 (0.0477)	SegCLSLoss 0.0029 (0.0013)	KLLoss 0.0032 (0.0036)	MaskLoss 0.1203 (0.0811)	MaskBCELoss 0.0219 (0.0106)	MaskDICELoss 0.0984 (0.0706)
Epoch: [3][211/500]	Time 67.797 (67.797)	Loss 0.4314 (0.4095)	CeLoss 0.0239 (0.0536)	SegCLSLoss 0.0025 (0.0013)	KLLoss 0.0018 (0.0036)	MaskLoss 0.1067 (0.0947)	MaskBCELoss 0.0112 (0.0137)	MaskDICELoss 0.0955 (0.0811)
Epoch: [3][212/500]	Time 71.795 (71.795)	Loss 0.4619 (0.4311)	CeLoss 0.0654 (0.0553)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0023 (0.0036)	MaskLoss 0.0994 (0.0978)	MaskBCELoss 0.0021 (0.0098)	MaskDICELoss 0.0973 (0.0880)
Epoch: [3][213/500]	Time 73.122 (73.122)	Loss 0.5748 (0.3547)	CeLoss 0.1030 (0.0416)	SegCLSLoss 0.0041 (0.0012)	KLLoss 0.0037 (0.0029)	MaskLoss 0.1358 (0.0868)	MaskBCELoss 0.0388 (0.0189)	MaskDICELoss 0.0969 (0.0679)
Epoch: [3][214/500]	Time 71.840 (71.840)	Loss 0.1282 (0.3672)	CeLoss 0.0732 (0.0520)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0035 (0.0031)	MaskLoss 0.0171 (0.0826)	MaskBCELoss 0.0084 (0.0095)	MaskDICELoss 0.0087 (0.0731)
Epoch: [3][215/500]	Time 80.916 (80.916)	Loss 0.3917 (0.3882)	CeLoss 0.0234 (0.0320)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0052 (0.0031)	MaskLoss 0.1203 (0.1110)	MaskBCELoss 0.0595 (0.0457)	MaskDICELoss 0.0609 (0.0653)
Epoch: [3][216/500]	Time 73.301 (73.301)	Loss 0.3058 (0.3367)	CeLoss 0.1030 (0.0447)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0034 (0.0031)	MaskLoss 0.0534 (0.0809)	MaskBCELoss 0.0070 (0.0176)	MaskDICELoss 0.0464 (0.0632)
Epoch: [3][217/500]	Time 72.680 (72.680)	Loss 0.3386 (0.3424)	CeLoss 0.0535 (0.0484)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0042 (0.0037)	MaskLoss 0.1066 (0.0921)	MaskBCELoss 0.0729 (0.0395)	MaskDICELoss 0.0338 (0.0527)
Epoch: [3][218/500]	Time 74.192 (74.192)	Loss 0.4173 (0.3602)	CeLoss 0.0256 (0.0361)	SegCLSLoss 0.0022 (0.0017)	KLLoss 0.0038 (0.0032)	MaskLoss 0.1123 (0.0909)	MaskBCELoss 0.0311 (0.0218)	MaskDICELoss 0.0812 (0.0691)
Epoch: [3][219/500]	Time 71.539 (71.539)	Loss 0.3935 (0.3307)	CeLoss 0.0371 (0.0394)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0035 (0.0039)	MaskLoss 0.0894 (0.0924)	MaskBCELoss 0.0027 (0.0414)	MaskDICELoss 0.0867 (0.0510)
Epoch: [3][220/500]	Time 72.449 (72.449)	Loss 0.4189 (0.3961)	CeLoss 0.0223 (0.0551)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0030 (0.0040)	MaskLoss 0.1191 (0.0935)	MaskBCELoss 0.0420 (0.0187)	MaskDICELoss 0.0771 (0.0748)
Epoch: [3][221/500]	Time 82.623 (82.623)	Loss 0.3060 (0.3048)	CeLoss 0.0571 (0.0340)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0025 (0.0040)	MaskLoss 0.0735 (0.0753)	MaskBCELoss 0.0242 (0.0174)	MaskDICELoss 0.0494 (0.0579)
Epoch: [3][222/500]	Time 69.641 (69.641)	Loss 0.3399 (0.3797)	CeLoss 0.0435 (0.0414)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0028 (0.0044)	MaskLoss 0.0757 (0.0908)	MaskBCELoss 0.0048 (0.0150)	MaskDICELoss 0.0710 (0.0758)
Epoch: [3][223/500]	Time 72.520 (72.520)	Loss 0.4066 (0.2889)	CeLoss 0.0610 (0.0545)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0025 (0.0036)	MaskLoss 0.0875 (0.0654)	MaskBCELoss 0.0038 (0.0156)	MaskDICELoss 0.0838 (0.0497)
Epoch: [3][224/500]	Time 81.234 (81.234)	Loss 0.0144 (0.2912)	CeLoss 0.0143 (0.0311)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.0754)	MaskBCELoss 0.0000 (0.0228)	MaskDICELoss 0.0000 (0.0526)
Epoch: [3][225/500]	Time 71.271 (71.271)	Loss 0.0314 (0.3132)	CeLoss 0.0315 (0.0398)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0735)	MaskBCELoss 0.0000 (0.0122)	MaskDICELoss 0.0000 (0.0613)
Epoch: [3][226/500]	Time 68.316 (68.316)	Loss 0.4555 (0.3773)	CeLoss 0.0220 (0.0421)	SegCLSLoss 0.0028 (0.0011)	KLLoss 0.0024 (0.0036)	MaskLoss 0.1232 (0.0908)	MaskBCELoss 0.0316 (0.0161)	MaskDICELoss 0.0917 (0.0747)
Epoch: [3][227/500]	Time 72.110 (72.110)	Loss 0.1195 (0.3138)	CeLoss 0.0767 (0.0410)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0025 (0.0032)	MaskLoss 0.0124 (0.0749)	MaskBCELoss 0.0048 (0.0153)	MaskDICELoss 0.0076 (0.0596)
Epoch: [3][228/500]	Time 74.995 (74.995)	Loss 0.4577 (0.3567)	CeLoss 0.0208 (0.0367)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0031 (0.0033)	MaskLoss 0.1220 (0.0912)	MaskBCELoss 0.0274 (0.0243)	MaskDICELoss 0.0946 (0.0669)
Epoch: [3][229/500]	Time 65.209 (65.209)	Loss 0.2473 (0.2836)	CeLoss 0.0242 (0.0466)	SegCLSLoss 0.0017 (0.0009)	KLLoss 0.0041 (0.0037)	MaskLoss 0.0676 (0.0687)	MaskBCELoss 0.0260 (0.0210)	MaskDICELoss 0.0416 (0.0478)
Epoch: [3][230/500]	Time 79.578 (79.578)	Loss 0.1373 (0.3262)	CeLoss 0.0247 (0.0429)	SegCLSLoss 0.0026 (0.0012)	KLLoss 0.0036 (0.0030)	MaskLoss 0.0315 (0.0767)	MaskBCELoss 0.0091 (0.0137)	MaskDICELoss 0.0224 (0.0631)
Epoch: [3][231/500]	Time 71.052 (71.052)	Loss 0.4718 (0.3529)	CeLoss 0.0811 (0.0348)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0025 (0.0037)	MaskLoss 0.0990 (0.0854)	MaskBCELoss 0.0041 (0.0140)	MaskDICELoss 0.0949 (0.0715)
Epoch: [3][232/500]	Time 71.091 (71.091)	Loss 0.1709 (0.3914)	CeLoss 0.0598 (0.0540)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0037 (0.0037)	MaskLoss 0.0326 (0.0953)	MaskBCELoss 0.0115 (0.0239)	MaskDICELoss 0.0212 (0.0713)
Epoch: [3][233/500]	Time 68.421 (68.421)	Loss 0.4320 (0.3798)	CeLoss 0.0161 (0.0464)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0054 (0.0033)	MaskLoss 0.1051 (0.0914)	MaskBCELoss 0.0051 (0.0181)	MaskDICELoss 0.1000 (0.0734)
Epoch: [3][234/500]	Time 71.380 (71.380)	Loss 0.2607 (0.3442)	CeLoss 0.0217 (0.0384)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0017 (0.0030)	MaskLoss 0.0634 (0.0820)	MaskBCELoss 0.0087 (0.0129)	MaskDICELoss 0.0547 (0.0691)
Epoch: [3][235/500]	Time 79.065 (79.065)	Loss 0.3459 (0.3504)	CeLoss 0.0232 (0.0343)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0037 (0.0045)	MaskLoss 0.0830 (0.0869)	MaskBCELoss 0.0068 (0.0183)	MaskDICELoss 0.0762 (0.0686)
Epoch: [3][236/500]	Time 71.439 (71.439)	Loss 0.4464 (0.3150)	CeLoss 0.0222 (0.0350)	SegCLSLoss 0.0042 (0.0014)	KLLoss 0.0036 (0.0027)	MaskLoss 0.1093 (0.0735)	MaskBCELoss 0.0093 (0.0088)	MaskDICELoss 0.1000 (0.0648)
Epoch: [3][237/500]	Time 74.122 (74.122)	Loss 0.1640 (0.3278)	CeLoss 0.0260 (0.0384)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0041 (0.0044)	MaskLoss 0.0429 (0.0863)	MaskBCELoss 0.0193 (0.0305)	MaskDICELoss 0.0236 (0.0558)
Epoch: [3][238/500]	Time 76.115 (76.115)	Loss 0.3290 (0.2893)	CeLoss 0.0674 (0.0354)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0026 (0.0035)	MaskLoss 0.0886 (0.0761)	MaskBCELoss 0.0481 (0.0273)	MaskDICELoss 0.0405 (0.0488)
Epoch: [3][239/500]	Time 69.303 (69.303)	Loss 0.4300 (0.3883)	CeLoss 0.0461 (0.0473)	SegCLSLoss 0.0018 (0.0018)	KLLoss 0.0081 (0.0044)	MaskLoss 0.1065 (0.0940)	MaskBCELoss 0.0256 (0.0200)	MaskDICELoss 0.0810 (0.0740)
Epoch: [3][240/500]	Time 70.340 (70.340)	Loss 0.1785 (0.3321)	CeLoss 0.0150 (0.0450)	SegCLSLoss 0.0003 (0.0018)	KLLoss 0.0045 (0.0043)	MaskLoss 0.0402 (0.0868)	MaskBCELoss 0.0010 (0.0327)	MaskDICELoss 0.0392 (0.0541)
Epoch: [3][241/500]	Time 75.014 (75.014)	Loss 0.4903 (0.3078)	CeLoss 0.0737 (0.0453)	SegCLSLoss 0.0011 (0.0014)	KLLoss 0.0038 (0.0035)	MaskLoss 0.1062 (0.0716)	MaskBCELoss 0.0063 (0.0141)	MaskDICELoss 0.0999 (0.0575)
Epoch: [3][242/500]	Time 72.468 (72.468)	Loss 0.3945 (0.3733)	CeLoss 0.0593 (0.0363)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0027 (0.0032)	MaskLoss 0.0994 (0.0925)	MaskBCELoss 0.0327 (0.0184)	MaskDICELoss 0.0666 (0.0741)
Epoch: [3][243/500]	Time 71.196 (71.196)	Loss 0.4284 (0.3738)	CeLoss 0.0221 (0.0339)	SegCLSLoss 0.0033 (0.0018)	KLLoss 0.0039 (0.0034)	MaskLoss 0.1009 (0.0930)	MaskBCELoss 0.0015 (0.0182)	MaskDICELoss 0.0994 (0.0748)
Epoch: [3][244/500]	Time 71.473 (71.473)	Loss 0.0907 (0.2788)	CeLoss 0.0214 (0.0487)	SegCLSLoss 0.0007 (0.0008)	KLLoss 0.0023 (0.0044)	MaskLoss 0.0213 (0.0604)	MaskBCELoss 0.0092 (0.0082)	MaskDICELoss 0.0120 (0.0522)
Epoch: [3][245/500]	Time 73.470 (73.470)	Loss 0.1963 (0.3646)	CeLoss 0.0167 (0.0466)	SegCLSLoss 0.0004 (0.0016)	KLLoss 0.0038 (0.0043)	MaskLoss 0.0562 (0.0876)	MaskBCELoss 0.0245 (0.0187)	MaskDICELoss 0.0317 (0.0688)
Epoch: [3][246/500]	Time 67.705 (67.705)	Loss 0.5161 (0.3802)	CeLoss 0.0967 (0.0491)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0025 (0.0036)	MaskLoss 0.1085 (0.0899)	MaskBCELoss 0.0085 (0.0163)	MaskDICELoss 0.1000 (0.0736)
Epoch: [3][247/500]	Time 74.292 (74.292)	Loss 0.2957 (0.3506)	CeLoss 0.0232 (0.0554)	SegCLSLoss 0.0016 (0.0012)	KLLoss 0.0028 (0.0029)	MaskLoss 0.0751 (0.0790)	MaskBCELoss 0.0157 (0.0121)	MaskDICELoss 0.0594 (0.0669)
Epoch: [3][248/500]	Time 75.083 (75.083)	Loss 0.4206 (0.3480)	CeLoss 0.0220 (0.0326)	SegCLSLoss 0.0023 (0.0017)	KLLoss 0.0034 (0.0040)	MaskLoss 0.1017 (0.0861)	MaskBCELoss 0.0064 (0.0169)	MaskDICELoss 0.0953 (0.0692)
Epoch: [3][249/500]	Time 68.762 (68.762)	Loss 0.3662 (0.3236)	CeLoss 0.0562 (0.0594)	SegCLSLoss 0.0002 (0.0007)	KLLoss 0.0042 (0.0031)	MaskLoss 0.1035 (0.0764)	MaskBCELoss 0.0541 (0.0226)	MaskDICELoss 0.0493 (0.0538)
Epoch: [3][250/500]	Time 71.521 (71.521)	Loss 0.2653 (0.3445)	CeLoss 0.0466 (0.0539)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0054 (0.0041)	MaskLoss 0.0684 (0.0792)	MaskBCELoss 0.0306 (0.0154)	MaskDICELoss 0.0379 (0.0638)
Epoch: [3][251/500]	Time 77.571 (77.571)	Loss 0.4743 (0.4213)	CeLoss 0.0713 (0.0429)	SegCLSLoss 0.0008 (0.0017)	KLLoss 0.0041 (0.0035)	MaskLoss 0.1018 (0.1111)	MaskBCELoss 0.0041 (0.0352)	MaskDICELoss 0.0977 (0.0759)
Epoch: [3][252/500]	Time 69.785 (69.785)	Loss 0.3953 (0.4026)	CeLoss 0.0571 (0.0544)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0041 (0.0037)	MaskLoss 0.0892 (0.0952)	MaskBCELoss 0.0116 (0.0183)	MaskDICELoss 0.0776 (0.0768)
Epoch: [3][253/500]	Time 72.089 (72.089)	Loss 0.2754 (0.3338)	CeLoss 0.0359 (0.0415)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0032 (0.0030)	MaskLoss 0.0652 (0.0766)	MaskBCELoss 0.0124 (0.0087)	MaskDICELoss 0.0528 (0.0678)
Epoch: [3][254/500]	Time 67.923 (67.923)	Loss 0.4507 (0.4353)	CeLoss 0.0474 (0.0444)	SegCLSLoss 0.0015 (0.0017)	KLLoss 0.0033 (0.0037)	MaskLoss 0.1012 (0.1128)	MaskBCELoss 0.0028 (0.0324)	MaskDICELoss 0.0984 (0.0804)
Epoch: [3][255/500]	Time 67.632 (67.632)	Loss 0.4317 (0.3531)	CeLoss 0.0208 (0.0330)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0026 (0.0038)	MaskLoss 0.1039 (0.0866)	MaskBCELoss 0.0039 (0.0154)	MaskDICELoss 0.1000 (0.0712)
Epoch: [3][256/500]	Time 79.255 (79.255)	Loss 0.4684 (0.3594)	CeLoss 0.0598 (0.0466)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0029 (0.0032)	MaskLoss 0.1044 (0.0862)	MaskBCELoss 0.0061 (0.0178)	MaskDICELoss 0.0983 (0.0684)
Epoch: [3][257/500]	Time 78.229 (78.229)	Loss 0.4751 (0.3976)	CeLoss 0.0698 (0.0468)	SegCLSLoss 0.0012 (0.0015)	KLLoss 0.0035 (0.0036)	MaskLoss 0.1012 (0.0950)	MaskBCELoss 0.0019 (0.0168)	MaskDICELoss 0.0993 (0.0782)
Epoch: [3][258/500]	Time 71.568 (71.568)	Loss 0.4339 (0.3023)	CeLoss 0.0227 (0.0485)	SegCLSLoss 0.0042 (0.0017)	KLLoss 0.0047 (0.0027)	MaskLoss 0.1055 (0.0707)	MaskBCELoss 0.0087 (0.0162)	MaskDICELoss 0.0967 (0.0545)
Epoch: [3][259/500]	Time 72.648 (72.648)	Loss 0.0338 (0.3418)	CeLoss 0.0337 (0.0404)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0861)	MaskBCELoss 0.0000 (0.0233)	MaskDICELoss 0.0000 (0.0628)
Epoch: [3][260/500]	Time 73.742 (73.742)	Loss 0.2665 (0.2868)	CeLoss 0.0188 (0.0539)	SegCLSLoss 0.0077 (0.0017)	KLLoss 0.0032 (0.0025)	MaskLoss 0.0798 (0.0635)	MaskBCELoss 0.0393 (0.0122)	MaskDICELoss 0.0405 (0.0513)
Epoch: [3][261/500]	Time 78.533 (78.533)	Loss 0.3859 (0.3961)	CeLoss 0.0840 (0.0445)	SegCLSLoss 0.0017 (0.0008)	KLLoss 0.0023 (0.0038)	MaskLoss 0.0754 (0.1020)	MaskBCELoss 0.0015 (0.0304)	MaskDICELoss 0.0740 (0.0717)
Epoch: [3][262/500]	Time 70.853 (70.853)	Loss 0.3868 (0.3752)	CeLoss 0.0649 (0.0438)	SegCLSLoss 0.0023 (0.0017)	KLLoss 0.0036 (0.0039)	MaskLoss 0.0961 (0.0929)	MaskBCELoss 0.0336 (0.0226)	MaskDICELoss 0.0625 (0.0704)
Epoch: [3][263/500]	Time 73.586 (73.586)	Loss 0.3273 (0.2617)	CeLoss 0.0130 (0.0407)	SegCLSLoss 0.0013 (0.0008)	KLLoss 0.0028 (0.0041)	MaskLoss 0.0791 (0.0590)	MaskBCELoss 0.0027 (0.0096)	MaskDICELoss 0.0764 (0.0493)
Epoch: [3][264/500]	Time 74.467 (74.467)	Loss 0.3634 (0.3631)	CeLoss 0.0771 (0.0435)	SegCLSLoss 0.0015 (0.0016)	KLLoss 0.0034 (0.0036)	MaskLoss 0.0794 (0.0868)	MaskBCELoss 0.0179 (0.0161)	MaskDICELoss 0.0615 (0.0707)
Epoch: [3][265/500]	Time 75.439 (75.439)	Loss 0.2689 (0.3560)	CeLoss 0.0527 (0.0506)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0031 (0.0035)	MaskLoss 0.0720 (0.0888)	MaskBCELoss 0.0377 (0.0271)	MaskDICELoss 0.0343 (0.0618)
Epoch: [3][266/500]	Time 81.493 (81.493)	Loss 0.3737 (0.3839)	CeLoss 0.0273 (0.0307)	SegCLSLoss 0.0049 (0.0015)	KLLoss 0.0034 (0.0046)	MaskLoss 0.0860 (0.0964)	MaskBCELoss 0.0017 (0.0189)	MaskDICELoss 0.0843 (0.0775)
Epoch: [3][267/500]	Time 82.541 (82.541)	Loss 0.4775 (0.3435)	CeLoss 0.0718 (0.0479)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0029 (0.0033)	MaskLoss 0.1023 (0.0787)	MaskBCELoss 0.0033 (0.0115)	MaskDICELoss 0.0990 (0.0672)
Epoch: [3][268/500]	Time 71.381 (71.381)	Loss 0.5071 (0.3720)	CeLoss 0.0908 (0.0642)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0025 (0.0033)	MaskLoss 0.1070 (0.0812)	MaskBCELoss 0.0072 (0.0104)	MaskDICELoss 0.0998 (0.0707)
Epoch: [3][269/500]	Time 76.234 (76.234)	Loss 0.4578 (0.2930)	CeLoss 0.0405 (0.0359)	SegCLSLoss 0.0011 (0.0010)	KLLoss 0.0027 (0.0032)	MaskLoss 0.1070 (0.0711)	MaskBCELoss 0.0070 (0.0156)	MaskDICELoss 0.1000 (0.0555)
Epoch: [3][270/500]	Time 71.110 (71.110)	Loss 0.4344 (0.4339)	CeLoss 0.0635 (0.0417)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0040 (0.0036)	MaskLoss 0.0958 (0.1022)	MaskBCELoss 0.0083 (0.0104)	MaskDICELoss 0.0875 (0.0918)
Epoch: [3][271/500]	Time 67.665 (67.665)	Loss 0.4613 (0.2842)	CeLoss 0.0520 (0.0472)	SegCLSLoss 0.0014 (0.0011)	KLLoss 0.0030 (0.0032)	MaskLoss 0.1027 (0.0654)	MaskBCELoss 0.0027 (0.0142)	MaskDICELoss 0.1000 (0.0512)
Epoch: [3][272/500]	Time 67.435 (67.435)	Loss 0.5929 (0.4295)	CeLoss 0.1182 (0.0591)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0058 (0.0034)	MaskLoss 0.1399 (0.0988)	MaskBCELoss 0.0450 (0.0143)	MaskDICELoss 0.0949 (0.0845)
Epoch: [3][273/500]	Time 74.862 (74.862)	Loss 0.3065 (0.2886)	CeLoss 0.0210 (0.0265)	SegCLSLoss 0.0021 (0.0015)	KLLoss 0.0035 (0.0039)	MaskLoss 0.0935 (0.0716)	MaskBCELoss 0.0466 (0.0145)	MaskDICELoss 0.0469 (0.0571)
Epoch: [3][274/500]	Time 80.105 (80.105)	Loss 0.0116 (0.2560)	CeLoss 0.0116 (0.0386)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0583)	MaskBCELoss 0.0000 (0.0097)	MaskDICELoss 0.0000 (0.0486)
Epoch: [3][275/500]	Time 74.925 (74.925)	Loss 0.3667 (0.3653)	CeLoss 0.0236 (0.0399)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0041 (0.0047)	MaskLoss 0.1084 (0.0911)	MaskBCELoss 0.0474 (0.0222)	MaskDICELoss 0.0610 (0.0689)
Epoch: [3][276/500]	Time 71.754 (71.754)	Loss 0.4774 (0.2925)	CeLoss 0.0732 (0.0441)	SegCLSLoss 0.0020 (0.0013)	KLLoss 0.0056 (0.0042)	MaskLoss 0.1011 (0.0670)	MaskBCELoss 0.0032 (0.0121)	MaskDICELoss 0.0978 (0.0549)
Epoch: [3][277/500]	Time 72.452 (72.452)	Loss 0.2853 (0.3673)	CeLoss 0.0220 (0.0470)	SegCLSLoss 0.0008 (0.0008)	KLLoss 0.0030 (0.0038)	MaskLoss 0.0658 (0.0837)	MaskBCELoss 0.0016 (0.0094)	MaskDICELoss 0.0642 (0.0744)
Epoch: [3][278/500]	Time 74.732 (74.732)	Loss 0.0387 (0.3118)	CeLoss 0.0386 (0.0446)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0779)	MaskBCELoss 0.0000 (0.0243)	MaskDICELoss 0.0000 (0.0536)
Epoch: [3][279/500]	Time 71.095 (71.095)	Loss 0.0619 (0.3096)	CeLoss 0.0222 (0.0517)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0038 (0.0035)	MaskLoss 0.0130 (0.0678)	MaskBCELoss 0.0083 (0.0087)	MaskDICELoss 0.0047 (0.0591)
Epoch: [3][280/500]	Time 67.590 (67.590)	Loss 0.4742 (0.3314)	CeLoss 0.0425 (0.0392)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0040 (0.0035)	MaskLoss 0.1141 (0.0799)	MaskBCELoss 0.0145 (0.0159)	MaskDICELoss 0.0996 (0.0640)
Epoch: [3][281/500]	Time 70.486 (70.486)	Loss 0.3512 (0.2694)	CeLoss 0.0172 (0.0392)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0035 (0.0042)	MaskLoss 0.1090 (0.0666)	MaskBCELoss 0.0529 (0.0205)	MaskDICELoss 0.0561 (0.0461)
Epoch: [3][282/500]	Time 80.400 (80.400)	Loss 0.4276 (0.3811)	CeLoss 0.0376 (0.0522)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0040 (0.0042)	MaskLoss 0.1128 (0.0872)	MaskBCELoss 0.0328 (0.0123)	MaskDICELoss 0.0801 (0.0749)
Epoch: [3][283/500]	Time 77.607 (77.607)	Loss 0.3117 (0.3081)	CeLoss 0.0260 (0.0372)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0079 (0.0041)	MaskLoss 0.0844 (0.0739)	MaskBCELoss 0.0303 (0.0146)	MaskDICELoss 0.0541 (0.0593)
Epoch: [3][284/500]	Time 80.510 (80.510)	Loss 0.2375 (0.3395)	CeLoss 0.0232 (0.0364)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0042 (0.0028)	MaskLoss 0.0694 (0.0810)	MaskBCELoss 0.0339 (0.0122)	MaskDICELoss 0.0355 (0.0689)
Epoch: [3][285/500]	Time 76.401 (76.401)	Loss 0.5052 (0.3911)	CeLoss 0.0474 (0.0423)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0036 (0.0035)	MaskLoss 0.1280 (0.0985)	MaskBCELoss 0.0293 (0.0247)	MaskDICELoss 0.0987 (0.0738)
Epoch: [3][286/500]	Time 68.500 (68.500)	Loss 0.0340 (0.3347)	CeLoss 0.0339 (0.0345)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0810)	MaskBCELoss 0.0000 (0.0139)	MaskDICELoss 0.0000 (0.0671)
Epoch: [3][287/500]	Time 70.183 (70.183)	Loss 0.2522 (0.3229)	CeLoss 0.0212 (0.0306)	SegCLSLoss 0.0050 (0.0017)	KLLoss 0.0051 (0.0038)	MaskLoss 0.0733 (0.0925)	MaskBCELoss 0.0349 (0.0411)	MaskDICELoss 0.0384 (0.0514)
Epoch: [3][288/500]	Time 86.641 (86.641)	Loss 0.4068 (0.3570)	CeLoss 0.0254 (0.0382)	SegCLSLoss 0.0013 (0.0008)	KLLoss 0.0031 (0.0040)	MaskLoss 0.0955 (0.0905)	MaskBCELoss 0.0022 (0.0238)	MaskDICELoss 0.0933 (0.0667)
Epoch: [3][289/500]	Time 68.661 (68.661)	Loss 0.4285 (0.2926)	CeLoss 0.0195 (0.0376)	SegCLSLoss 0.0021 (0.0015)	KLLoss 0.0043 (0.0042)	MaskLoss 0.1018 (0.0709)	MaskBCELoss 0.0018 (0.0167)	MaskDICELoss 0.1000 (0.0541)
Epoch: [3][290/500]	Time 73.012 (73.012)	Loss 0.0369 (0.3779)	CeLoss 0.0369 (0.0472)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.0884)	MaskBCELoss 0.0000 (0.0134)	MaskDICELoss 0.0000 (0.0750)
Epoch: [3][291/500]	Time 68.347 (68.347)	Loss 0.4263 (0.3918)	CeLoss 0.0137 (0.0435)	SegCLSLoss 0.0017 (0.0017)	KLLoss 0.0047 (0.0043)	MaskLoss 0.1053 (0.0949)	MaskBCELoss 0.0070 (0.0182)	MaskDICELoss 0.0982 (0.0767)
Epoch: [3][292/500]	Time 73.026 (73.026)	Loss 0.0172 (0.2343)	CeLoss 0.0172 (0.0402)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0523)	MaskBCELoss 0.0000 (0.0090)	MaskDICELoss 0.0000 (0.0433)
Epoch: [3][293/500]	Time 75.719 (75.719)	Loss 0.0137 (0.2964)	CeLoss 0.0137 (0.0481)	SegCLSLoss 0.0000 (0.0005)	KLLoss 0.0000 (0.0023)	MaskLoss 0.0000 (0.0697)	MaskBCELoss 0.0000 (0.0165)	MaskDICELoss 0.0000 (0.0531)
Epoch: [3][294/500]	Time 72.978 (72.978)	Loss 0.4243 (0.4078)	CeLoss 0.0221 (0.0435)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0037 (0.0046)	MaskLoss 0.1021 (0.1033)	MaskBCELoss 0.0052 (0.0270)	MaskDICELoss 0.0969 (0.0763)
Epoch: [3][295/500]	Time 69.831 (69.831)	Loss 0.4705 (0.3145)	CeLoss 0.0391 (0.0531)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0027 (0.0031)	MaskLoss 0.1273 (0.0721)	MaskBCELoss 0.0404 (0.0153)	MaskDICELoss 0.0869 (0.0568)
Epoch: [3][296/500]	Time 72.134 (72.134)	Loss 0.4230 (0.3170)	CeLoss 0.0208 (0.0359)	SegCLSLoss 0.0031 (0.0023)	KLLoss 0.0028 (0.0034)	MaskLoss 0.1004 (0.0780)	MaskBCELoss 0.0019 (0.0178)	MaskDICELoss 0.0985 (0.0602)
Epoch: [3][297/500]	Time 76.633 (76.633)	Loss 0.4428 (0.3166)	CeLoss 0.0225 (0.0361)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0039 (0.0037)	MaskLoss 0.1093 (0.0782)	MaskBCELoss 0.0106 (0.0184)	MaskDICELoss 0.0987 (0.0598)
Epoch: [3][298/500]	Time 75.059 (75.059)	Loss 0.4650 (0.3444)	CeLoss 0.0193 (0.0376)	SegCLSLoss 0.0002 (0.0010)	KLLoss 0.0071 (0.0037)	MaskLoss 0.1199 (0.0808)	MaskBCELoss 0.0206 (0.0102)	MaskDICELoss 0.0993 (0.0705)
Epoch: [3][299/500]	Time 68.255 (68.255)	Loss 0.2944 (0.3650)	CeLoss 0.0566 (0.0433)	SegCLSLoss 0.0017 (0.0010)	KLLoss 0.0033 (0.0038)	MaskLoss 0.0592 (0.0892)	MaskBCELoss 0.0016 (0.0197)	MaskDICELoss 0.0575 (0.0694)
[2025-03-12 06:17:08,598] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[0.0002774216867469879], mom=[(0.9, 0.95)]
[2025-03-12 06:17:08,609] [INFO] [timer.py:215:stop] epoch=0/micro_step=1800/global_step=180, RunningAvgSamplesPerSec=0.6435202983845196, CurrSamplesPerSec=0.5458452915547896, MemAllocated=59.76GB, MaxMemAllocated=74.71GB
Epoch: [3][300/500]	Time 75.658 (75.658)	Loss 0.4729 (0.3475)	CeLoss 0.0625 (0.0285)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0037 (0.0042)	MaskLoss 0.1034 (0.0893)	MaskBCELoss 0.0036 (0.0215)	MaskDICELoss 0.0998 (0.0678)
Epoch: [3][301/500]	Time 75.093 (75.093)	Loss 0.4263 (0.3658)	CeLoss 0.0264 (0.0453)	SegCLSLoss 0.0022 (0.0011)	KLLoss 0.0032 (0.0047)	MaskLoss 0.1034 (0.0835)	MaskBCELoss 0.0090 (0.0093)	MaskDICELoss 0.0944 (0.0742)
Epoch: [3][302/500]	Time 72.891 (72.891)	Loss 0.3350 (0.4389)	CeLoss 0.0894 (0.0483)	SegCLSLoss 0.0028 (0.0013)	KLLoss 0.0046 (0.0043)	MaskLoss 0.0669 (0.1097)	MaskBCELoss 0.0141 (0.0266)	MaskDICELoss 0.0527 (0.0831)
Epoch: [3][303/500]	Time 78.103 (78.103)	Loss 0.4513 (0.3609)	CeLoss 0.0566 (0.0411)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0041 (0.0038)	MaskLoss 0.0994 (0.0871)	MaskBCELoss 0.0037 (0.0165)	MaskDICELoss 0.0957 (0.0706)
Epoch: [3][304/500]	Time 72.641 (72.641)	Loss 0.4427 (0.2763)	CeLoss 0.0408 (0.0543)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0040 (0.0035)	MaskLoss 0.0998 (0.0586)	MaskBCELoss 0.0007 (0.0081)	MaskDICELoss 0.0991 (0.0505)
Epoch: [3][305/500]	Time 72.686 (72.686)	Loss 0.1772 (0.4168)	CeLoss 0.0286 (0.0307)	SegCLSLoss 0.0010 (0.0018)	KLLoss 0.0049 (0.0043)	MaskLoss 0.0478 (0.1129)	MaskBCELoss 0.0240 (0.0354)	MaskDICELoss 0.0238 (0.0775)
Epoch: [3][306/500]	Time 65.846 (65.846)	Loss 0.5059 (0.3739)	CeLoss 0.0781 (0.0449)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0038 (0.0039)	MaskLoss 0.1123 (0.0916)	MaskBCELoss 0.0129 (0.0210)	MaskDICELoss 0.0994 (0.0706)
Epoch: [3][307/500]	Time 74.892 (74.892)	Loss 0.4928 (0.3304)	CeLoss 0.0118 (0.0356)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0052 (0.0032)	MaskLoss 0.1378 (0.0878)	MaskBCELoss 0.0379 (0.0300)	MaskDICELoss 0.0999 (0.0578)
Epoch: [3][308/500]	Time 74.943 (74.943)	Loss 0.0837 (0.3304)	CeLoss 0.0232 (0.0456)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0033 (0.0038)	MaskLoss 0.0196 (0.0801)	MaskBCELoss 0.0107 (0.0200)	MaskDICELoss 0.0089 (0.0601)
Epoch: [3][309/500]	Time 66.813 (66.813)	Loss 0.2781 (0.2981)	CeLoss 0.0486 (0.0471)	SegCLSLoss 0.0031 (0.0014)	KLLoss 0.0040 (0.0046)	MaskLoss 0.0617 (0.0703)	MaskBCELoss 0.0112 (0.0178)	MaskDICELoss 0.0505 (0.0525)
Epoch: [3][310/500]	Time 74.537 (74.537)	Loss 0.4770 (0.3805)	CeLoss 0.0703 (0.0367)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0019 (0.0038)	MaskLoss 0.1023 (0.0921)	MaskBCELoss 0.0025 (0.0146)	MaskDICELoss 0.0998 (0.0775)
Epoch: [3][311/500]	Time 70.305 (70.305)	Loss 0.4452 (0.3857)	CeLoss 0.0674 (0.0452)	SegCLSLoss 0.0005 (0.0017)	KLLoss 0.0039 (0.0046)	MaskLoss 0.1096 (0.0926)	MaskBCELoss 0.0326 (0.0177)	MaskDICELoss 0.0770 (0.0749)
Epoch: [3][312/500]	Time 73.964 (73.964)	Loss 0.4657 (0.2562)	CeLoss 0.0737 (0.0436)	SegCLSLoss 0.0043 (0.0011)	KLLoss 0.0041 (0.0037)	MaskLoss 0.1031 (0.0608)	MaskBCELoss 0.0131 (0.0173)	MaskDICELoss 0.0899 (0.0435)
Epoch: [3][313/500]	Time 71.773 (71.773)	Loss 0.3046 (0.3973)	CeLoss 0.0264 (0.0370)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0023 (0.0028)	MaskLoss 0.0701 (0.1009)	MaskBCELoss 0.0026 (0.0234)	MaskDICELoss 0.0675 (0.0775)
Epoch: [3][314/500]	Time 70.797 (70.797)	Loss 0.0124 (0.3302)	CeLoss 0.0123 (0.0526)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0042)	MaskLoss 0.0000 (0.0718)	MaskBCELoss 0.0000 (0.0072)	MaskDICELoss 0.0000 (0.0646)
Epoch: [3][315/500]	Time 73.537 (73.537)	Loss 0.2725 (0.3000)	CeLoss 0.0654 (0.0445)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0029 (0.0032)	MaskLoss 0.0773 (0.0724)	MaskBCELoss 0.0526 (0.0189)	MaskDICELoss 0.0246 (0.0535)
Epoch: [3][316/500]	Time 71.414 (71.414)	Loss 0.3557 (0.3354)	CeLoss 0.0225 (0.0385)	SegCLSLoss 0.0016 (0.0018)	KLLoss 0.0074 (0.0046)	MaskLoss 0.0855 (0.0859)	MaskBCELoss 0.0084 (0.0262)	MaskDICELoss 0.0770 (0.0597)
Epoch: [3][317/500]	Time 67.572 (67.572)	Loss 0.0940 (0.3269)	CeLoss 0.0226 (0.0391)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0048 (0.0041)	MaskLoss 0.0241 (0.0775)	MaskBCELoss 0.0150 (0.0133)	MaskDICELoss 0.0091 (0.0641)
Epoch: [3][318/500]	Time 74.757 (74.757)	Loss 0.2221 (0.3743)	CeLoss 0.0508 (0.0475)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0063 (0.0031)	MaskLoss 0.0531 (0.0894)	MaskBCELoss 0.0239 (0.0173)	MaskDICELoss 0.0292 (0.0721)
Epoch: [3][319/500]	Time 73.702 (73.702)	Loss 0.1523 (0.2981)	CeLoss 0.0889 (0.0409)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0048 (0.0038)	MaskLoss 0.0208 (0.0712)	MaskBCELoss 0.0122 (0.0160)	MaskDICELoss 0.0085 (0.0552)
Epoch: [3][320/500]	Time 78.495 (78.495)	Loss 0.0138 (0.3654)	CeLoss 0.0138 (0.0356)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0040)	MaskLoss 0.0000 (0.0996)	MaskBCELoss 0.0000 (0.0367)	MaskDICELoss 0.0000 (0.0629)
Epoch: [3][321/500]	Time 72.361 (72.361)	Loss 0.4073 (0.4722)	CeLoss 0.0562 (0.0561)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0034 (0.0046)	MaskLoss 0.0900 (0.1259)	MaskBCELoss 0.0064 (0.0464)	MaskDICELoss 0.0836 (0.0796)
Epoch: [3][322/500]	Time 74.570 (74.570)	Loss 0.5522 (0.3365)	CeLoss 0.0177 (0.0260)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0058 (0.0046)	MaskLoss 0.1645 (0.0982)	MaskBCELoss 0.0646 (0.0438)	MaskDICELoss 0.0998 (0.0544)
Epoch: [3][323/500]	Time 71.028 (71.028)	Loss 0.3753 (0.3392)	CeLoss 0.0649 (0.0461)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0031 (0.0047)	MaskLoss 0.0774 (0.0841)	MaskBCELoss 0.0015 (0.0244)	MaskDICELoss 0.0759 (0.0597)
Epoch: [3][324/500]	Time 71.525 (71.525)	Loss 0.4896 (0.3981)	CeLoss 0.0845 (0.0453)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0045 (0.0048)	MaskLoss 0.1001 (0.0974)	MaskBCELoss 0.0001 (0.0211)	MaskDICELoss 0.1000 (0.0763)
Epoch: [3][325/500]	Time 68.767 (68.767)	Loss 0.1158 (0.2928)	CeLoss 0.0708 (0.0740)	SegCLSLoss 0.0007 (0.0007)	KLLoss 0.0046 (0.0037)	MaskLoss 0.0160 (0.0602)	MaskBCELoss 0.0120 (0.0131)	MaskDICELoss 0.0040 (0.0471)
Epoch: [3][326/500]	Time 75.381 (75.381)	Loss 0.3634 (0.2861)	CeLoss 0.0225 (0.0323)	SegCLSLoss 0.0027 (0.0016)	KLLoss 0.0033 (0.0033)	MaskLoss 0.0928 (0.0676)	MaskBCELoss 0.0174 (0.0103)	MaskDICELoss 0.0753 (0.0573)
Epoch: [3][327/500]	Time 66.991 (66.991)	Loss 0.2757 (0.3044)	CeLoss 0.0554 (0.0378)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0036 (0.0041)	MaskLoss 0.0593 (0.0744)	MaskBCELoss 0.0103 (0.0179)	MaskDICELoss 0.0489 (0.0565)
Epoch: [3][328/500]	Time 74.610 (74.610)	Loss 0.3355 (0.3050)	CeLoss 0.0222 (0.0356)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0042 (0.0038)	MaskLoss 0.0969 (0.0719)	MaskBCELoss 0.0395 (0.0113)	MaskDICELoss 0.0574 (0.0606)
Epoch: [3][329/500]	Time 68.100 (68.100)	Loss 0.3351 (0.3850)	CeLoss 0.0398 (0.0474)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0022 (0.0035)	MaskLoss 0.0804 (0.0908)	MaskBCELoss 0.0144 (0.0149)	MaskDICELoss 0.0660 (0.0760)
Epoch: [3][330/500]	Time 72.325 (72.325)	Loss 0.4293 (0.3385)	CeLoss 0.0227 (0.0317)	SegCLSLoss 0.0023 (0.0022)	KLLoss 0.0035 (0.0040)	MaskLoss 0.1013 (0.0900)	MaskBCELoss 0.0015 (0.0292)	MaskDICELoss 0.0997 (0.0608)
Epoch: [3][331/500]	Time 70.832 (70.832)	Loss 0.5470 (0.4446)	CeLoss 0.0591 (0.0424)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0052 (0.0041)	MaskLoss 0.1414 (0.1102)	MaskBCELoss 0.0414 (0.0218)	MaskDICELoss 0.0999 (0.0884)
Epoch: [3][332/500]	Time 71.676 (71.676)	Loss 0.1418 (0.3343)	CeLoss 0.1079 (0.0384)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0051 (0.0042)	MaskLoss 0.0102 (0.0852)	MaskBCELoss 0.0061 (0.0249)	MaskDICELoss 0.0041 (0.0603)
Epoch: [3][333/500]	Time 74.132 (74.132)	Loss 0.4868 (0.3109)	CeLoss 0.0356 (0.0389)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0049 (0.0047)	MaskLoss 0.1244 (0.0744)	MaskBCELoss 0.0257 (0.0154)	MaskDICELoss 0.0987 (0.0590)
Epoch: [3][334/500]	Time 69.097 (69.097)	Loss 0.4635 (0.3357)	CeLoss 0.0574 (0.0355)	SegCLSLoss 0.0008 (0.0008)	KLLoss 0.0024 (0.0032)	MaskLoss 0.1025 (0.0853)	MaskBCELoss 0.0034 (0.0223)	MaskDICELoss 0.0991 (0.0630)
Epoch: [3][335/500]	Time 72.081 (72.081)	Loss 0.0166 (0.2839)	CeLoss 0.0166 (0.0449)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0036)	MaskLoss 0.0000 (0.0662)	MaskBCELoss 0.0000 (0.0151)	MaskDICELoss 0.0000 (0.0512)
Epoch: [3][336/500]	Time 71.385 (71.385)	Loss 0.3003 (0.3410)	CeLoss 0.0217 (0.0425)	SegCLSLoss 0.0017 (0.0009)	KLLoss 0.0049 (0.0030)	MaskLoss 0.0706 (0.0825)	MaskBCELoss 0.0047 (0.0175)	MaskDICELoss 0.0659 (0.0650)
Epoch: [3][337/500]	Time 71.474 (71.474)	Loss 0.4151 (0.3799)	CeLoss 0.0189 (0.0394)	SegCLSLoss 0.0037 (0.0017)	KLLoss 0.0032 (0.0034)	MaskLoss 0.0993 (0.0913)	MaskBCELoss 0.0031 (0.0145)	MaskDICELoss 0.0962 (0.0768)
Epoch: [3][338/500]	Time 71.256 (71.256)	Loss 0.4411 (0.4011)	CeLoss 0.0330 (0.0352)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0034 (0.0032)	MaskLoss 0.1021 (0.1032)	MaskBCELoss 0.0021 (0.0255)	MaskDICELoss 0.1000 (0.0778)
Epoch: [3][339/500]	Time 71.374 (71.374)	Loss 0.4026 (0.3172)	CeLoss 0.0243 (0.0505)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0055 (0.0042)	MaskLoss 0.0984 (0.0777)	MaskBCELoss 0.0109 (0.0245)	MaskDICELoss 0.0875 (0.0532)
Epoch: [3][340/500]	Time 71.913 (71.913)	Loss 0.4621 (0.2499)	CeLoss 0.0713 (0.0375)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0043 (0.0041)	MaskLoss 0.1115 (0.0577)	MaskBCELoss 0.0298 (0.0114)	MaskDICELoss 0.0817 (0.0463)
Epoch: [3][341/500]	Time 71.723 (71.723)	Loss 0.4342 (0.3111)	CeLoss 0.0247 (0.0514)	SegCLSLoss 0.0014 (0.0011)	KLLoss 0.0021 (0.0034)	MaskLoss 0.1033 (0.0790)	MaskBCELoss 0.0033 (0.0300)	MaskDICELoss 0.1000 (0.0489)
Epoch: [3][342/500]	Time 71.983 (71.983)	Loss 0.4150 (0.2993)	CeLoss 0.0135 (0.0308)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0024 (0.0031)	MaskLoss 0.1003 (0.0777)	MaskBCELoss 0.0015 (0.0230)	MaskDICELoss 0.0988 (0.0547)
Epoch: [3][343/500]	Time 72.462 (72.462)	Loss 0.7922 (0.3747)	CeLoss 0.0757 (0.0580)	SegCLSLoss 0.0037 (0.0015)	KLLoss 0.0035 (0.0046)	MaskLoss 0.2931 (0.0973)	MaskBCELoss 0.2306 (0.0389)	MaskDICELoss 0.0624 (0.0584)
Epoch: [3][344/500]	Time 77.687 (77.687)	Loss 0.0309 (0.3299)	CeLoss 0.0309 (0.0405)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0792)	MaskBCELoss 0.0000 (0.0155)	MaskDICELoss 0.0000 (0.0637)
Epoch: [3][345/500]	Time 64.947 (64.947)	Loss 0.2198 (0.2884)	CeLoss 0.0386 (0.0499)	SegCLSLoss 0.0025 (0.0013)	KLLoss 0.0035 (0.0039)	MaskLoss 0.0485 (0.0689)	MaskBCELoss 0.0089 (0.0209)	MaskDICELoss 0.0397 (0.0480)
Epoch: [3][346/500]	Time 73.398 (73.398)	Loss 0.4799 (0.3169)	CeLoss 0.0713 (0.0504)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0041 (0.0039)	MaskLoss 0.1041 (0.0746)	MaskBCELoss 0.0057 (0.0180)	MaskDICELoss 0.0984 (0.0565)
Epoch: [3][347/500]	Time 75.360 (75.360)	Loss 0.3371 (0.3399)	CeLoss 0.0238 (0.0488)	SegCLSLoss 0.0025 (0.0014)	KLLoss 0.0041 (0.0044)	MaskLoss 0.0774 (0.0839)	MaskBCELoss 0.0009 (0.0249)	MaskDICELoss 0.0766 (0.0591)
Epoch: [3][348/500]	Time 68.191 (68.191)	Loss 0.4516 (0.3731)	CeLoss 0.0212 (0.0433)	SegCLSLoss 0.0020 (0.0015)	KLLoss 0.0034 (0.0039)	MaskLoss 0.1136 (0.0872)	MaskBCELoss 0.0142 (0.0120)	MaskDICELoss 0.0994 (0.0753)
Epoch: [3][349/500]	Time 68.486 (68.486)	Loss 0.1839 (0.3642)	CeLoss 0.0515 (0.0383)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0033 (0.0040)	MaskLoss 0.0402 (0.0908)	MaskBCELoss 0.0162 (0.0208)	MaskDICELoss 0.0240 (0.0699)
Epoch: [3][350/500]	Time 68.325 (68.325)	Loss 0.2870 (0.3929)	CeLoss 0.0806 (0.0625)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0046 (0.0045)	MaskLoss 0.0647 (0.0964)	MaskBCELoss 0.0286 (0.0302)	MaskDICELoss 0.0361 (0.0662)
Epoch: [3][351/500]	Time 78.318 (78.318)	Loss 0.4431 (0.2799)	CeLoss 0.0242 (0.0464)	SegCLSLoss 0.0025 (0.0014)	KLLoss 0.0039 (0.0038)	MaskLoss 0.1071 (0.0635)	MaskBCELoss 0.0073 (0.0125)	MaskDICELoss 0.0998 (0.0510)
Epoch: [3][352/500]	Time 71.440 (71.440)	Loss 0.3788 (0.3544)	CeLoss 0.0254 (0.0370)	SegCLSLoss 0.0020 (0.0018)	KLLoss 0.0044 (0.0043)	MaskLoss 0.0879 (0.0853)	MaskBCELoss 0.0019 (0.0145)	MaskDICELoss 0.0860 (0.0708)
Epoch: [3][353/500]	Time 79.481 (79.481)	Loss 0.4925 (0.4341)	CeLoss 0.0786 (0.0458)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0046 (0.0043)	MaskLoss 0.1051 (0.1131)	MaskBCELoss 0.0057 (0.0345)	MaskDICELoss 0.0994 (0.0786)
Epoch: [3][354/500]	Time 72.187 (72.187)	Loss 0.1360 (0.3714)	CeLoss 0.0203 (0.0478)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0037 (0.0038)	MaskLoss 0.0309 (0.0884)	MaskBCELoss 0.0060 (0.0172)	MaskDICELoss 0.0249 (0.0712)
Epoch: [3][355/500]	Time 67.093 (67.093)	Loss 0.3245 (0.2799)	CeLoss 0.0540 (0.0441)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0042 (0.0039)	MaskLoss 0.0735 (0.0628)	MaskBCELoss 0.0140 (0.0099)	MaskDICELoss 0.0595 (0.0529)
Epoch: [3][356/500]	Time 79.887 (79.887)	Loss 0.1066 (0.3459)	CeLoss 0.0256 (0.0406)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0056 (0.0039)	MaskLoss 0.0241 (0.0805)	MaskBCELoss 0.0107 (0.0107)	MaskDICELoss 0.0135 (0.0698)
Epoch: [3][357/500]	Time 74.464 (74.464)	Loss 0.3336 (0.3162)	CeLoss 0.0183 (0.0408)	SegCLSLoss 0.0028 (0.0012)	KLLoss 0.0043 (0.0042)	MaskLoss 0.0851 (0.0736)	MaskBCELoss 0.0154 (0.0120)	MaskDICELoss 0.0697 (0.0617)
Epoch: [3][358/500]	Time 70.167 (70.167)	Loss 0.0410 (0.3203)	CeLoss 0.0410 (0.0478)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0055)	MaskLoss 0.0000 (0.0745)	MaskBCELoss 0.0000 (0.0157)	MaskDICELoss 0.0000 (0.0588)
Epoch: [3][359/500]	Time 76.120 (76.120)	Loss 0.4022 (0.4044)	CeLoss 0.0148 (0.0417)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0027 (0.0037)	MaskLoss 0.1021 (0.0998)	MaskBCELoss 0.0120 (0.0203)	MaskDICELoss 0.0901 (0.0795)
Epoch: [3][360/500]	Time 74.191 (74.191)	Loss 0.5174 (0.3561)	CeLoss 0.0894 (0.0513)	SegCLSLoss 0.0006 (0.0016)	KLLoss 0.0042 (0.0043)	MaskLoss 0.1129 (0.0825)	MaskBCELoss 0.0142 (0.0152)	MaskDICELoss 0.0987 (0.0673)
Epoch: [3][361/500]	Time 67.904 (67.904)	Loss 0.3097 (0.3532)	CeLoss 0.0430 (0.0329)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0025 (0.0036)	MaskLoss 0.0773 (0.0927)	MaskBCELoss 0.0227 (0.0275)	MaskDICELoss 0.0546 (0.0652)
Epoch: [3][362/500]	Time 69.718 (69.718)	Loss 0.5028 (0.3490)	CeLoss 0.0913 (0.0467)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0053 (0.0043)	MaskLoss 0.1028 (0.0817)	MaskBCELoss 0.0028 (0.0147)	MaskDICELoss 0.1000 (0.0670)
Epoch: [3][363/500]	Time 80.552 (80.552)	Loss 0.4814 (0.4239)	CeLoss 0.0586 (0.0498)	SegCLSLoss 0.0016 (0.0010)	KLLoss 0.0046 (0.0043)	MaskLoss 0.1087 (0.1070)	MaskBCELoss 0.0087 (0.0294)	MaskDICELoss 0.1000 (0.0776)
Epoch: [3][364/500]	Time 75.442 (75.442)	Loss 0.0111 (0.2682)	CeLoss 0.0111 (0.0369)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0646)	MaskBCELoss 0.0000 (0.0157)	MaskDICELoss 0.0000 (0.0489)
Epoch: [3][365/500]	Time 74.652 (74.652)	Loss 0.4593 (0.2745)	CeLoss 0.0513 (0.0323)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0037 (0.0029)	MaskLoss 0.1024 (0.0653)	MaskBCELoss 0.0028 (0.0113)	MaskDICELoss 0.0997 (0.0540)
Epoch: [3][366/500]	Time 74.831 (74.831)	Loss 0.2457 (0.3480)	CeLoss 0.1006 (0.0513)	SegCLSLoss 0.0017 (0.0009)	KLLoss 0.0032 (0.0039)	MaskLoss 0.0426 (0.0800)	MaskBCELoss 0.0146 (0.0139)	MaskDICELoss 0.0280 (0.0661)
Epoch: [3][367/500]	Time 69.087 (69.087)	Loss 0.3517 (0.4119)	CeLoss 0.0221 (0.0527)	SegCLSLoss 0.0023 (0.0011)	KLLoss 0.0047 (0.0053)	MaskLoss 0.0823 (0.0999)	MaskBCELoss 0.0027 (0.0231)	MaskDICELoss 0.0796 (0.0768)
Epoch: [3][368/500]	Time 69.704 (69.704)	Loss 0.2137 (0.3800)	CeLoss 0.0364 (0.0306)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0029 (0.0040)	MaskLoss 0.0548 (0.1068)	MaskBCELoss 0.0224 (0.0411)	MaskDICELoss 0.0323 (0.0656)
Epoch: [3][369/500]	Time 67.959 (67.959)	Loss 0.5068 (0.3504)	CeLoss 0.0972 (0.0472)	SegCLSLoss 0.0004 (0.0015)	KLLoss 0.0034 (0.0037)	MaskLoss 0.1294 (0.0833)	MaskBCELoss 0.0558 (0.0173)	MaskDICELoss 0.0736 (0.0660)
Epoch: [3][370/500]	Time 72.069 (72.069)	Loss 0.3465 (0.3503)	CeLoss 0.0243 (0.0376)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0040 (0.0038)	MaskLoss 0.0861 (0.0831)	MaskBCELoss 0.0134 (0.0120)	MaskDICELoss 0.0727 (0.0711)
Epoch: [3][371/500]	Time 70.817 (70.817)	Loss 0.1578 (0.3707)	CeLoss 0.0236 (0.0388)	SegCLSLoss 0.0010 (0.0018)	KLLoss 0.0036 (0.0033)	MaskLoss 0.0342 (0.0898)	MaskBCELoss 0.0033 (0.0158)	MaskDICELoss 0.0309 (0.0740)
Epoch: [3][372/500]	Time 79.489 (79.489)	Loss 0.4867 (0.3553)	CeLoss 0.0820 (0.0462)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0028 (0.0034)	MaskLoss 0.1008 (0.0816)	MaskBCELoss 0.0008 (0.0105)	MaskDICELoss 0.1000 (0.0711)
Epoch: [3][373/500]	Time 71.159 (71.159)	Loss 0.4229 (0.3078)	CeLoss 0.0164 (0.0301)	SegCLSLoss 0.0007 (0.0017)	KLLoss 0.0047 (0.0042)	MaskLoss 0.1019 (0.0802)	MaskBCELoss 0.0029 (0.0241)	MaskDICELoss 0.0989 (0.0561)
Epoch: [3][374/500]	Time 78.115 (78.115)	Loss 0.4771 (0.3312)	CeLoss 0.0732 (0.0431)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0032 (0.0046)	MaskLoss 0.1035 (0.0795)	MaskBCELoss 0.0070 (0.0175)	MaskDICELoss 0.0966 (0.0620)
Epoch: [3][375/500]	Time 69.238 (69.238)	Loss 0.3026 (0.3696)	CeLoss 0.0203 (0.0334)	SegCLSLoss 0.0033 (0.0015)	KLLoss 0.0040 (0.0036)	MaskLoss 0.0907 (0.1034)	MaskBCELoss 0.0430 (0.0410)	MaskDICELoss 0.0477 (0.0625)
Epoch: [3][376/500]	Time 74.971 (74.971)	Loss 0.4949 (0.4048)	CeLoss 0.0747 (0.0423)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0033 (0.0040)	MaskLoss 0.1146 (0.1030)	MaskBCELoss 0.0207 (0.0270)	MaskDICELoss 0.0938 (0.0760)
Epoch: [3][377/500]	Time 67.785 (67.785)	Loss 0.3105 (0.3122)	CeLoss 0.0217 (0.0267)	SegCLSLoss 0.0020 (0.0026)	KLLoss 0.0050 (0.0050)	MaskLoss 0.0761 (0.0776)	MaskBCELoss 0.0108 (0.0156)	MaskDICELoss 0.0653 (0.0620)
Epoch: [3][378/500]	Time 69.446 (69.446)	Loss 0.3342 (0.3299)	CeLoss 0.0239 (0.0541)	SegCLSLoss 0.0015 (0.0014)	KLLoss 0.0052 (0.0044)	MaskLoss 0.0865 (0.0740)	MaskBCELoss 0.0208 (0.0126)	MaskDICELoss 0.0657 (0.0614)
Epoch: [3][379/500]	Time 71.986 (71.986)	Loss 0.1890 (0.3565)	CeLoss 0.0554 (0.0399)	SegCLSLoss 0.0004 (0.0016)	KLLoss 0.0045 (0.0039)	MaskLoss 0.0487 (0.0869)	MaskBCELoss 0.0329 (0.0180)	MaskDICELoss 0.0158 (0.0689)
Epoch: [3][380/500]	Time 76.677 (76.677)	Loss 0.3766 (0.3121)	CeLoss 0.0811 (0.0425)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0028 (0.0038)	MaskLoss 0.0877 (0.0788)	MaskBCELoss 0.0293 (0.0252)	MaskDICELoss 0.0584 (0.0537)
Epoch: [3][381/500]	Time 69.541 (69.541)	Loss 0.5144 (0.4089)	CeLoss 0.1133 (0.0566)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0039 (0.0037)	MaskLoss 0.1008 (0.0967)	MaskBCELoss 0.0034 (0.0195)	MaskDICELoss 0.0974 (0.0772)
Epoch: [3][382/500]	Time 74.303 (74.303)	Loss 0.0412 (0.2958)	CeLoss 0.0198 (0.0385)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0046 (0.0044)	MaskLoss 0.0053 (0.0686)	MaskBCELoss 0.0026 (0.0111)	MaskDICELoss 0.0028 (0.0576)
Epoch: [3][383/500]	Time 72.762 (72.762)	Loss 0.0159 (0.2921)	CeLoss 0.0159 (0.0399)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0689)	MaskBCELoss 0.0000 (0.0139)	MaskDICELoss 0.0000 (0.0550)
Epoch: [3][384/500]	Time 69.190 (69.190)	Loss 0.4717 (0.3536)	CeLoss 0.0425 (0.0536)	SegCLSLoss 0.0003 (0.0017)	KLLoss 0.0047 (0.0034)	MaskLoss 0.1122 (0.0818)	MaskBCELoss 0.0122 (0.0157)	MaskDICELoss 0.1000 (0.0661)
Epoch: [3][385/500]	Time 74.139 (74.139)	Loss 0.4529 (0.3338)	CeLoss 0.0942 (0.0541)	SegCLSLoss 0.0004 (0.0017)	KLLoss 0.0038 (0.0046)	MaskLoss 0.1143 (0.0741)	MaskBCELoss 0.0513 (0.0111)	MaskDICELoss 0.0630 (0.0630)
Epoch: [3][386/500]	Time 70.317 (70.317)	Loss 0.4413 (0.2590)	CeLoss 0.0256 (0.0289)	SegCLSLoss 0.0025 (0.0015)	KLLoss 0.0041 (0.0042)	MaskLoss 0.1081 (0.0603)	MaskBCELoss 0.0109 (0.0079)	MaskDICELoss 0.0972 (0.0524)
Epoch: [3][387/500]	Time 73.233 (73.233)	Loss 0.4333 (0.3545)	CeLoss 0.0225 (0.0357)	SegCLSLoss 0.0029 (0.0012)	KLLoss 0.0040 (0.0037)	MaskLoss 0.1028 (0.0935)	MaskBCELoss 0.0029 (0.0297)	MaskDICELoss 0.0999 (0.0638)
Epoch: [3][388/500]	Time 70.689 (70.689)	Loss 0.4012 (0.3127)	CeLoss 0.0189 (0.0427)	SegCLSLoss 0.0024 (0.0019)	KLLoss 0.0050 (0.0044)	MaskLoss 0.1051 (0.0767)	MaskBCELoss 0.0221 (0.0211)	MaskDICELoss 0.0830 (0.0556)
Epoch: [3][389/500]	Time 71.614 (71.614)	Loss 0.4120 (0.3819)	CeLoss 0.0211 (0.0460)	SegCLSLoss 0.0040 (0.0011)	KLLoss 0.0036 (0.0045)	MaskLoss 0.1067 (0.0960)	MaskBCELoss 0.0207 (0.0266)	MaskDICELoss 0.0860 (0.0695)
Epoch: [3][390/500]	Time 79.950 (79.950)	Loss 0.2481 (0.3862)	CeLoss 0.0762 (0.0400)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0028 (0.0038)	MaskLoss 0.0558 (0.0936)	MaskBCELoss 0.0273 (0.0162)	MaskDICELoss 0.0286 (0.0774)
Epoch: [3][391/500]	Time 70.821 (70.821)	Loss 0.4736 (0.4246)	CeLoss 0.0140 (0.0521)	SegCLSLoss 0.0036 (0.0015)	KLLoss 0.0080 (0.0050)	MaskLoss 0.1346 (0.1001)	MaskBCELoss 0.0442 (0.0168)	MaskDICELoss 0.0903 (0.0833)
Epoch: [3][392/500]	Time 66.369 (66.369)	Loss 0.2789 (0.4181)	CeLoss 0.0232 (0.0421)	SegCLSLoss 0.0037 (0.0016)	KLLoss 0.0034 (0.0046)	MaskLoss 0.0736 (0.1036)	MaskBCELoss 0.0219 (0.0218)	MaskDICELoss 0.0516 (0.0818)
Epoch: [3][393/500]	Time 75.070 (75.070)	Loss 0.4516 (0.2898)	CeLoss 0.0425 (0.0365)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0027 (0.0031)	MaskLoss 0.1031 (0.0666)	MaskBCELoss 0.0032 (0.0084)	MaskDICELoss 0.1000 (0.0582)
Epoch: [3][394/500]	Time 67.140 (67.140)	Loss 0.1322 (0.3128)	CeLoss 0.0598 (0.0532)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0039 (0.0042)	MaskLoss 0.0250 (0.0789)	MaskBCELoss 0.0158 (0.0303)	MaskDICELoss 0.0092 (0.0486)
Epoch: [3][395/500]	Time 68.930 (68.930)	Loss 0.4404 (0.2966)	CeLoss 0.0239 (0.0414)	SegCLSLoss 0.0039 (0.0014)	KLLoss 0.0046 (0.0035)	MaskLoss 0.1384 (0.0729)	MaskBCELoss 0.0719 (0.0202)	MaskDICELoss 0.0666 (0.0526)
Epoch: [3][396/500]	Time 74.972 (74.972)	Loss 0.0391 (0.2571)	CeLoss 0.0391 (0.0332)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0029)	MaskLoss 0.0000 (0.0640)	MaskBCELoss 0.0000 (0.0178)	MaskDICELoss 0.0000 (0.0462)
Epoch: [3][397/500]	Time 77.915 (77.915)	Loss 0.2772 (0.3983)	CeLoss 0.0153 (0.0405)	SegCLSLoss 0.0002 (0.0011)	KLLoss 0.0045 (0.0047)	MaskLoss 0.0689 (0.1025)	MaskBCELoss 0.0091 (0.0287)	MaskDICELoss 0.0598 (0.0738)
Epoch: [3][398/500]	Time 71.306 (71.306)	Loss 0.4943 (0.3887)	CeLoss 0.0830 (0.0391)	SegCLSLoss 0.0006 (0.0018)	KLLoss 0.0046 (0.0041)	MaskLoss 0.1032 (0.0972)	MaskBCELoss 0.0034 (0.0221)	MaskDICELoss 0.0998 (0.0751)
Epoch: [3][399/500]	Time 68.103 (68.103)	Loss 0.4872 (0.3874)	CeLoss 0.0586 (0.0386)	SegCLSLoss 0.0008 (0.0019)	KLLoss 0.0060 (0.0045)	MaskLoss 0.1183 (0.0949)	MaskBCELoss 0.0255 (0.0182)	MaskDICELoss 0.0928 (0.0767)
[2025-03-12 08:17:45,382] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[0.00027609638554216865], mom=[(0.9, 0.95)]
[2025-03-12 08:17:45,390] [INFO] [timer.py:215:stop] epoch=0/micro_step=1900/global_step=190, RunningAvgSamplesPerSec=0.6373680815693076, CurrSamplesPerSec=0.5375761689275395, MemAllocated=61.01GB, MaxMemAllocated=74.71GB
Epoch: [3][400/500]	Time 77.261 (77.261)	Loss 0.4651 (0.3601)	CeLoss 0.0601 (0.0436)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0019 (0.0032)	MaskLoss 0.1013 (0.0842)	MaskBCELoss 0.0013 (0.0120)	MaskDICELoss 0.1000 (0.0721)
Epoch: [3][401/500]	Time 70.837 (70.837)	Loss 0.5125 (0.3693)	CeLoss 0.0698 (0.0524)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0055 (0.0038)	MaskLoss 0.1401 (0.1013)	MaskBCELoss 0.0618 (0.0462)	MaskDICELoss 0.0783 (0.0550)
Epoch: [3][402/500]	Time 78.196 (78.196)	Loss 0.0169 (0.2783)	CeLoss 0.0168 (0.0329)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0043)	MaskLoss 0.0000 (0.0694)	MaskBCELoss 0.0000 (0.0185)	MaskDICELoss 0.0000 (0.0508)
Epoch: [3][403/500]	Time 77.824 (77.824)	Loss 0.4011 (0.3002)	CeLoss 0.0747 (0.0537)	SegCLSLoss 0.0012 (0.0008)	KLLoss 0.0035 (0.0036)	MaskLoss 0.0926 (0.0696)	MaskBCELoss 0.0242 (0.0178)	MaskDICELoss 0.0684 (0.0517)
Epoch: [3][404/500]	Time 67.867 (67.867)	Loss 0.3175 (0.2693)	CeLoss 0.0579 (0.0389)	SegCLSLoss 0.0019 (0.0019)	KLLoss 0.0055 (0.0040)	MaskLoss 0.0691 (0.0669)	MaskBCELoss 0.0115 (0.0210)	MaskDICELoss 0.0576 (0.0459)
Epoch: [3][405/500]	Time 71.092 (71.092)	Loss 0.5622 (0.4065)	CeLoss 0.0439 (0.0614)	SegCLSLoss 0.0017 (0.0016)	KLLoss 0.0033 (0.0049)	MaskLoss 0.1617 (0.1001)	MaskBCELoss 0.0663 (0.0304)	MaskDICELoss 0.0954 (0.0697)
Epoch: [3][406/500]	Time 78.078 (78.078)	Loss 0.0963 (0.3544)	CeLoss 0.0820 (0.0487)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0039 (0.0047)	MaskLoss 0.0030 (0.0888)	MaskBCELoss 0.0010 (0.0273)	MaskDICELoss 0.0020 (0.0614)
Epoch: [3][407/500]	Time 72.783 (72.783)	Loss 0.3804 (0.4425)	CeLoss 0.0115 (0.0520)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0050 (0.0037)	MaskLoss 0.0914 (0.1078)	MaskBCELoss 0.0013 (0.0225)	MaskDICELoss 0.0901 (0.0853)
Epoch: [3][408/500]	Time 67.744 (67.744)	Loss 0.1751 (0.2415)	CeLoss 0.0194 (0.0300)	SegCLSLoss 0.0033 (0.0014)	KLLoss 0.0045 (0.0039)	MaskLoss 0.0514 (0.0591)	MaskBCELoss 0.0280 (0.0147)	MaskDICELoss 0.0234 (0.0444)
Epoch: [3][409/500]	Time 75.954 (75.954)	Loss 0.4647 (0.3359)	CeLoss 0.0559 (0.0278)	SegCLSLoss 0.0008 (0.0018)	KLLoss 0.0036 (0.0039)	MaskLoss 0.1026 (0.0837)	MaskBCELoss 0.0026 (0.0159)	MaskDICELoss 0.0999 (0.0679)
Epoch: [3][410/500]	Time 72.580 (72.580)	Loss 0.4795 (0.3097)	CeLoss 0.0210 (0.0365)	SegCLSLoss 0.0030 (0.0011)	KLLoss 0.0032 (0.0036)	MaskLoss 0.1299 (0.0724)	MaskBCELoss 0.0330 (0.0103)	MaskDICELoss 0.0969 (0.0621)
Epoch: [3][411/500]	Time 74.336 (74.336)	Loss 0.0523 (0.2874)	CeLoss 0.0522 (0.0389)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0043)	MaskLoss 0.0000 (0.0695)	MaskBCELoss 0.0000 (0.0173)	MaskDICELoss 0.0000 (0.0522)
Epoch: [3][412/500]	Time 67.304 (67.304)	Loss 0.2815 (0.3363)	CeLoss 0.0474 (0.0508)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0036 (0.0055)	MaskLoss 0.0798 (0.0847)	MaskBCELoss 0.0448 (0.0296)	MaskDICELoss 0.0350 (0.0550)
Epoch: [3][413/500]	Time 69.738 (69.738)	Loss 0.0144 (0.3255)	CeLoss 0.0143 (0.0432)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0038)	MaskLoss 0.0000 (0.0798)	MaskBCELoss 0.0000 (0.0206)	MaskDICELoss 0.0000 (0.0592)
Epoch: [3][414/500]	Time 68.485 (68.485)	Loss 0.4056 (0.4020)	CeLoss 0.0752 (0.0405)	SegCLSLoss 0.0006 (0.0018)	KLLoss 0.0017 (0.0032)	MaskLoss 0.0837 (0.0951)	MaskBCELoss 0.0033 (0.0115)	MaskDICELoss 0.0804 (0.0836)
Epoch: [3][415/500]	Time 70.881 (70.881)	Loss 0.3262 (0.3442)	CeLoss 0.0229 (0.0395)	SegCLSLoss 0.0026 (0.0012)	KLLoss 0.0049 (0.0034)	MaskLoss 0.0820 (0.0835)	MaskBCELoss 0.0155 (0.0166)	MaskDICELoss 0.0665 (0.0669)
Epoch: [3][416/500]	Time 69.055 (69.055)	Loss 0.4577 (0.3549)	CeLoss 0.0430 (0.0526)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0035 (0.0041)	MaskLoss 0.1065 (0.0887)	MaskBCELoss 0.0078 (0.0288)	MaskDICELoss 0.0988 (0.0600)
Epoch: [3][417/500]	Time 68.002 (68.002)	Loss 0.0606 (0.3600)	CeLoss 0.0254 (0.0372)	SegCLSLoss 0.0014 (0.0015)	KLLoss 0.0043 (0.0039)	MaskLoss 0.0102 (0.0861)	MaskBCELoss 0.0054 (0.0131)	MaskDICELoss 0.0048 (0.0730)
Epoch: [3][418/500]	Time 67.188 (67.188)	Loss 0.0449 (0.3492)	CeLoss 0.0256 (0.0451)	SegCLSLoss 0.0009 (0.0018)	KLLoss 0.0040 (0.0034)	MaskLoss 0.0053 (0.0835)	MaskBCELoss 0.0032 (0.0171)	MaskDICELoss 0.0021 (0.0664)
Epoch: [3][419/500]	Time 75.565 (75.565)	Loss 0.3890 (0.3581)	CeLoss 0.0198 (0.0343)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0026 (0.0043)	MaskLoss 0.0987 (0.0921)	MaskBCELoss 0.0142 (0.0247)	MaskDICELoss 0.0845 (0.0674)
Epoch: [3][420/500]	Time 71.867 (71.867)	Loss 0.1421 (0.2935)	CeLoss 0.0811 (0.0405)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0047 (0.0041)	MaskLoss 0.0147 (0.0758)	MaskBCELoss 0.0015 (0.0275)	MaskDICELoss 0.0132 (0.0482)
Epoch: [3][421/500]	Time 75.407 (75.407)	Loss 0.3135 (0.3290)	CeLoss 0.0242 (0.0464)	SegCLSLoss 0.0042 (0.0015)	KLLoss 0.0037 (0.0042)	MaskLoss 0.0879 (0.0764)	MaskBCELoss 0.0340 (0.0140)	MaskDICELoss 0.0539 (0.0624)
Epoch: [3][422/500]	Time 76.479 (76.479)	Loss 0.3177 (0.3249)	CeLoss 0.0635 (0.0379)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0053 (0.0049)	MaskLoss 0.0712 (0.0863)	MaskBCELoss 0.0184 (0.0318)	MaskDICELoss 0.0529 (0.0545)
Epoch: [3][423/500]	Time 71.643 (71.643)	Loss 0.4651 (0.3569)	CeLoss 0.0889 (0.0569)	SegCLSLoss 0.0006 (0.0014)	KLLoss 0.0034 (0.0037)	MaskLoss 0.1095 (0.0833)	MaskBCELoss 0.0329 (0.0188)	MaskDICELoss 0.0766 (0.0645)
Epoch: [3][424/500]	Time 82.150 (82.150)	Loss 0.4358 (0.3519)	CeLoss 0.0332 (0.0388)	SegCLSLoss 0.0010 (0.0018)	KLLoss 0.0048 (0.0051)	MaskLoss 0.1073 (0.0857)	MaskBCELoss 0.0159 (0.0179)	MaskDICELoss 0.0914 (0.0678)
Epoch: [3][425/500]	Time 73.985 (73.985)	Loss 0.0398 (0.3747)	CeLoss 0.0398 (0.0348)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0043)	MaskLoss 0.0000 (0.0962)	MaskBCELoss 0.0000 (0.0248)	MaskDICELoss 0.0000 (0.0713)
Epoch: [3][426/500]	Time 77.595 (77.595)	Loss 0.4332 (0.3295)	CeLoss 0.0178 (0.0402)	SegCLSLoss 0.0034 (0.0011)	KLLoss 0.0039 (0.0041)	MaskLoss 0.1058 (0.0819)	MaskBCELoss 0.0066 (0.0215)	MaskDICELoss 0.0991 (0.0604)
Epoch: [3][427/500]	Time 72.657 (72.657)	Loss 0.4379 (0.2570)	CeLoss 0.0225 (0.0452)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0034 (0.0033)	MaskLoss 0.1059 (0.0610)	MaskBCELoss 0.0061 (0.0179)	MaskDICELoss 0.0998 (0.0431)
Epoch: [3][428/500]	Time 76.496 (76.496)	Loss 0.4899 (0.4183)	CeLoss 0.0640 (0.0447)	SegCLSLoss 0.0015 (0.0014)	KLLoss 0.0042 (0.0044)	MaskLoss 0.1130 (0.1024)	MaskBCELoss 0.0155 (0.0206)	MaskDICELoss 0.0974 (0.0818)
Epoch: [3][429/500]	Time 72.439 (72.439)	Loss 0.4176 (0.4170)	CeLoss 0.0225 (0.0528)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0058 (0.0039)	MaskLoss 0.0975 (0.0978)	MaskBCELoss 0.0007 (0.0158)	MaskDICELoss 0.0968 (0.0820)
Epoch: [3][430/500]	Time 73.358 (73.358)	Loss 0.1306 (0.2730)	CeLoss 0.0250 (0.0416)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0046 (0.0040)	MaskLoss 0.0309 (0.0654)	MaskBCELoss 0.0116 (0.0173)	MaskDICELoss 0.0193 (0.0480)
Epoch: [3][431/500]	Time 72.599 (72.599)	Loss 0.7887 (0.3686)	CeLoss 0.0216 (0.0362)	SegCLSLoss 0.0017 (0.0017)	KLLoss 0.0028 (0.0047)	MaskLoss 0.2907 (0.0966)	MaskBCELoss 0.1998 (0.0298)	MaskDICELoss 0.0910 (0.0668)
Epoch: [3][432/500]	Time 74.531 (74.531)	Loss 0.4311 (0.2761)	CeLoss 0.0320 (0.0365)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0028 (0.0045)	MaskLoss 0.1013 (0.0631)	MaskBCELoss 0.0046 (0.0089)	MaskDICELoss 0.0966 (0.0542)
Epoch: [3][433/500]	Time 76.277 (76.277)	Loss 0.3286 (0.3456)	CeLoss 0.0854 (0.0450)	SegCLSLoss 0.0012 (0.0010)	KLLoss 0.0032 (0.0054)	MaskLoss 0.0816 (0.0881)	MaskBCELoss 0.0435 (0.0289)	MaskDICELoss 0.0381 (0.0592)
Epoch: [3][434/500]	Time 76.679 (76.679)	Loss 0.0248 (0.3420)	CeLoss 0.0248 (0.0371)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0039)	MaskLoss 0.0000 (0.0869)	MaskBCELoss 0.0000 (0.0237)	MaskDICELoss 0.0000 (0.0633)
Epoch: [3][435/500]	Time 75.624 (75.624)	Loss 0.3603 (0.3585)	CeLoss 0.0547 (0.0422)	SegCLSLoss 0.0008 (0.0008)	KLLoss 0.0031 (0.0040)	MaskLoss 0.0805 (0.0903)	MaskBCELoss 0.0099 (0.0246)	MaskDICELoss 0.0706 (0.0657)
Epoch: [3][436/500]	Time 76.787 (76.787)	Loss 0.4608 (0.2959)	CeLoss 0.0287 (0.0344)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0046 (0.0041)	MaskLoss 0.1293 (0.0728)	MaskBCELoss 0.0452 (0.0172)	MaskDICELoss 0.0841 (0.0556)
Epoch: [3][437/500]	Time 70.249 (70.249)	Loss 0.1275 (0.3858)	CeLoss 0.0771 (0.0701)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0041 (0.0043)	MaskLoss 0.0141 (0.0862)	MaskBCELoss 0.0051 (0.0171)	MaskDICELoss 0.0090 (0.0692)
Epoch: [3][438/500]	Time 70.775 (70.775)	Loss 0.4348 (0.3668)	CeLoss 0.0276 (0.0380)	SegCLSLoss 0.0027 (0.0015)	KLLoss 0.0041 (0.0046)	MaskLoss 0.1009 (0.0884)	MaskBCELoss 0.0009 (0.0150)	MaskDICELoss 0.1000 (0.0734)
Epoch: [3][439/500]	Time 75.751 (75.751)	Loss 0.4105 (0.3580)	CeLoss 0.0245 (0.0333)	SegCLSLoss 0.0010 (0.0018)	KLLoss 0.0038 (0.0045)	MaskLoss 0.1163 (0.0886)	MaskBCELoss 0.0418 (0.0176)	MaskDICELoss 0.0745 (0.0710)
Epoch: [3][440/500]	Time 70.427 (70.427)	Loss 0.3449 (0.3592)	CeLoss 0.0459 (0.0470)	SegCLSLoss 0.0004 (0.0015)	KLLoss 0.0040 (0.0041)	MaskLoss 0.0795 (0.0852)	MaskBCELoss 0.0115 (0.0168)	MaskDICELoss 0.0680 (0.0684)
Epoch: [3][441/500]	Time 80.224 (80.224)	Loss 0.4629 (0.3571)	CeLoss 0.0601 (0.0326)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0044 (0.0038)	MaskLoss 0.1002 (0.0830)	MaskBCELoss 0.0014 (0.0060)	MaskDICELoss 0.0988 (0.0770)
Epoch: [3][442/500]	Time 76.083 (76.083)	Loss 0.4084 (0.3284)	CeLoss 0.0601 (0.0396)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0051 (0.0047)	MaskLoss 0.0873 (0.0797)	MaskBCELoss 0.0033 (0.0176)	MaskDICELoss 0.0840 (0.0621)
Epoch: [3][443/500]	Time 73.321 (73.321)	Loss 0.1264 (0.3499)	CeLoss 0.0625 (0.0389)	SegCLSLoss 0.0006 (0.0020)	KLLoss 0.0023 (0.0042)	MaskLoss 0.0186 (0.0830)	MaskBCELoss 0.0066 (0.0132)	MaskDICELoss 0.0120 (0.0698)
Epoch: [3][444/500]	Time 74.214 (74.214)	Loss 0.1415 (0.3926)	CeLoss 0.0669 (0.0498)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0045 (0.0049)	MaskLoss 0.0203 (0.0916)	MaskBCELoss 0.0056 (0.0147)	MaskDICELoss 0.0147 (0.0770)
Epoch: [3][445/500]	Time 76.394 (76.394)	Loss 0.4023 (0.2923)	CeLoss 0.0204 (0.0501)	SegCLSLoss 0.0028 (0.0010)	KLLoss 0.0033 (0.0037)	MaskLoss 0.0957 (0.0689)	MaskBCELoss 0.0028 (0.0189)	MaskDICELoss 0.0929 (0.0500)
Epoch: [3][446/500]	Time 69.833 (69.833)	Loss 0.4593 (0.2770)	CeLoss 0.0483 (0.0374)	SegCLSLoss 0.0012 (0.0008)	KLLoss 0.0042 (0.0038)	MaskLoss 0.1040 (0.0685)	MaskBCELoss 0.0049 (0.0194)	MaskDICELoss 0.0991 (0.0491)
Epoch: [3][447/500]	Time 84.648 (84.648)	Loss 0.1812 (0.3905)	CeLoss 0.0188 (0.0473)	SegCLSLoss 0.0002 (0.0008)	KLLoss 0.0058 (0.0048)	MaskLoss 0.0485 (0.0931)	MaskBCELoss 0.0187 (0.0172)	MaskDICELoss 0.0298 (0.0759)
Epoch: [3][448/500]	Time 73.156 (73.156)	Loss 0.1409 (0.3282)	CeLoss 0.0115 (0.0388)	SegCLSLoss 0.0011 (0.0014)	KLLoss 0.0039 (0.0042)	MaskLoss 0.0342 (0.0807)	MaskBCELoss 0.0059 (0.0193)	MaskDICELoss 0.0283 (0.0614)
Epoch: [3][449/500]	Time 70.268 (70.268)	Loss 0.3942 (0.3402)	CeLoss 0.0522 (0.0473)	SegCLSLoss 0.0030 (0.0013)	KLLoss 0.0036 (0.0039)	MaskLoss 0.1015 (0.0850)	MaskBCELoss 0.0347 (0.0258)	MaskDICELoss 0.0668 (0.0592)
Epoch: [3][450/500]	Time 74.951 (74.951)	Loss 0.4446 (0.3374)	CeLoss 0.0405 (0.0457)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0046 (0.0047)	MaskLoss 0.1013 (0.0792)	MaskBCELoss 0.0030 (0.0153)	MaskDICELoss 0.0983 (0.0639)
Epoch: [3][451/500]	Time 68.692 (68.692)	Loss 0.3705 (0.2903)	CeLoss 0.0693 (0.0528)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0057 (0.0042)	MaskLoss 0.0823 (0.0638)	MaskBCELoss 0.0168 (0.0112)	MaskDICELoss 0.0655 (0.0526)
Epoch: [3][452/500]	Time 70.388 (70.388)	Loss 0.3429 (0.4885)	CeLoss 0.0635 (0.0548)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0042 (0.0048)	MaskLoss 0.0753 (0.1212)	MaskBCELoss 0.0133 (0.0282)	MaskDICELoss 0.0620 (0.0930)
Epoch: [3][453/500]	Time 75.423 (75.423)	Loss 0.1793 (0.3208)	CeLoss 0.0209 (0.0435)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0041 (0.0051)	MaskLoss 0.0428 (0.0818)	MaskBCELoss 0.0086 (0.0278)	MaskDICELoss 0.0341 (0.0540)
Epoch: [3][454/500]	Time 72.416 (72.416)	Loss 0.3762 (0.3068)	CeLoss 0.1025 (0.0591)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0059 (0.0041)	MaskLoss 0.0677 (0.0675)	MaskBCELoss 0.0017 (0.0134)	MaskDICELoss 0.0661 (0.0540)
Epoch: [3][455/500]	Time 77.356 (77.356)	Loss 0.3989 (0.3585)	CeLoss 0.0227 (0.0376)	SegCLSLoss 0.0016 (0.0015)	KLLoss 0.0033 (0.0045)	MaskLoss 0.1114 (0.0854)	MaskBCELoss 0.0368 (0.0130)	MaskDICELoss 0.0746 (0.0724)
Epoch: [3][456/500]	Time 72.749 (72.749)	Loss 0.1907 (0.3126)	CeLoss 0.0806 (0.0429)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0034 (0.0040)	MaskLoss 0.0353 (0.0716)	MaskBCELoss 0.0174 (0.0107)	MaskDICELoss 0.0179 (0.0609)
Epoch: [3][457/500]	Time 74.686 (74.686)	Loss 0.1055 (0.2745)	CeLoss 0.1055 (0.0456)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0633)	MaskBCELoss 0.0000 (0.0144)	MaskDICELoss 0.0000 (0.0489)
Epoch: [3][458/500]	Time 71.437 (71.437)	Loss 0.5695 (0.3365)	CeLoss 0.0532 (0.0389)	SegCLSLoss 0.0037 (0.0020)	KLLoss 0.0035 (0.0043)	MaskLoss 0.1605 (0.0825)	MaskBCELoss 0.0656 (0.0190)	MaskDICELoss 0.0949 (0.0636)
Epoch: [3][459/500]	Time 71.550 (71.550)	Loss 0.4725 (0.3626)	CeLoss 0.0540 (0.0416)	SegCLSLoss 0.0005 (0.0017)	KLLoss 0.0047 (0.0040)	MaskLoss 0.1095 (0.0875)	MaskBCELoss 0.0122 (0.0170)	MaskDICELoss 0.0973 (0.0706)
Epoch: [3][460/500]	Time 81.341 (81.341)	Loss 0.5298 (0.3202)	CeLoss 0.1187 (0.0507)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0094 (0.0046)	MaskLoss 0.1315 (0.0758)	MaskBCELoss 0.0626 (0.0193)	MaskDICELoss 0.0689 (0.0564)
Epoch: [3][461/500]	Time 73.865 (73.865)	Loss 0.1151 (0.3574)	CeLoss 0.0203 (0.0446)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0065 (0.0045)	MaskLoss 0.0255 (0.0833)	MaskBCELoss 0.0071 (0.0128)	MaskDICELoss 0.0184 (0.0705)
Epoch: [3][462/500]	Time 73.961 (73.961)	Loss 0.4687 (0.4048)	CeLoss 0.0718 (0.0412)	SegCLSLoss 0.0011 (0.0014)	KLLoss 0.0040 (0.0040)	MaskLoss 0.1003 (0.0957)	MaskBCELoss 0.0043 (0.0120)	MaskDICELoss 0.0960 (0.0838)
Epoch: [3][463/500]	Time 71.483 (71.483)	Loss 0.4512 (0.3862)	CeLoss 0.0261 (0.0397)	SegCLSLoss 0.0020 (0.0009)	KLLoss 0.0031 (0.0039)	MaskLoss 0.1105 (0.0975)	MaskBCELoss 0.0105 (0.0238)	MaskDICELoss 0.1000 (0.0736)
Epoch: [3][464/500]	Time 71.458 (71.458)	Loss 0.3428 (0.3054)	CeLoss 0.0193 (0.0404)	SegCLSLoss 0.0030 (0.0012)	KLLoss 0.0039 (0.0036)	MaskLoss 0.0798 (0.0696)	MaskBCELoss 0.0005 (0.0088)	MaskDICELoss 0.0793 (0.0608)
Epoch: [3][465/500]	Time 84.100 (84.100)	Loss 0.0145 (0.3891)	CeLoss 0.0145 (0.0207)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0041)	MaskLoss 0.0000 (0.1016)	MaskBCELoss 0.0000 (0.0214)	MaskDICELoss 0.0000 (0.0802)
Epoch: [3][466/500]	Time 80.027 (80.027)	Loss 0.0214 (0.3181)	CeLoss 0.0214 (0.0402)	SegCLSLoss 0.0000 (0.0018)	KLLoss 0.0000 (0.0043)	MaskLoss 0.0000 (0.0761)	MaskBCELoss 0.0000 (0.0157)	MaskDICELoss 0.0000 (0.0604)
Epoch: [3][467/500]	Time 72.190 (72.190)	Loss 0.5384 (0.3477)	CeLoss 0.0977 (0.0530)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0033 (0.0038)	MaskLoss 0.1186 (0.0785)	MaskBCELoss 0.0188 (0.0117)	MaskDICELoss 0.0998 (0.0668)
Epoch: [3][468/500]	Time 73.469 (73.469)	Loss 0.4012 (0.4505)	CeLoss 0.0216 (0.0489)	SegCLSLoss 0.0052 (0.0015)	KLLoss 0.0045 (0.0050)	MaskLoss 0.1097 (0.1238)	MaskBCELoss 0.0332 (0.0496)	MaskDICELoss 0.0765 (0.0742)
Epoch: [3][469/500]	Time 83.896 (83.896)	Loss 0.4442 (0.3443)	CeLoss 0.0396 (0.0393)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0033 (0.0039)	MaskLoss 0.1004 (0.0878)	MaskBCELoss 0.0004 (0.0254)	MaskDICELoss 0.1000 (0.0624)
Epoch: [3][470/500]	Time 71.288 (71.288)	Loss 0.4464 (0.3643)	CeLoss 0.0219 (0.0303)	SegCLSLoss 0.0024 (0.0022)	KLLoss 0.0052 (0.0044)	MaskLoss 0.1091 (0.0937)	MaskBCELoss 0.0092 (0.0231)	MaskDICELoss 0.1000 (0.0706)
Epoch: [3][471/500]	Time 79.790 (79.790)	Loss 0.4582 (0.2539)	CeLoss 0.0273 (0.0431)	SegCLSLoss 0.0008 (0.0005)	KLLoss 0.0033 (0.0024)	MaskLoss 0.1136 (0.0561)	MaskBCELoss 0.0136 (0.0081)	MaskDICELoss 0.1000 (0.0480)
Epoch: [3][472/500]	Time 72.856 (72.856)	Loss 0.1310 (0.2897)	CeLoss 0.0757 (0.0362)	SegCLSLoss 0.0003 (0.0015)	KLLoss 0.0032 (0.0036)	MaskLoss 0.0141 (0.0725)	MaskBCELoss 0.0021 (0.0204)	MaskDICELoss 0.0120 (0.0521)
Epoch: [3][473/500]	Time 81.563 (81.563)	Loss 0.3001 (0.3548)	CeLoss 0.0184 (0.0355)	SegCLSLoss 0.0007 (0.0017)	KLLoss 0.0032 (0.0042)	MaskLoss 0.0796 (0.0940)	MaskBCELoss 0.0201 (0.0308)	MaskDICELoss 0.0595 (0.0632)
Epoch: [3][474/500]	Time 75.986 (75.986)	Loss 0.2967 (0.3293)	CeLoss 0.0488 (0.0491)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0029 (0.0044)	MaskLoss 0.0643 (0.0754)	MaskBCELoss 0.0062 (0.0131)	MaskDICELoss 0.0581 (0.0622)
Epoch: [3][475/500]	Time 75.398 (75.398)	Loss 0.5233 (0.4137)	CeLoss 0.0613 (0.0524)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0047 (0.0039)	MaskLoss 0.1388 (0.1093)	MaskBCELoss 0.0492 (0.0403)	MaskDICELoss 0.0896 (0.0690)
Epoch: [3][476/500]	Time 83.252 (83.252)	Loss 0.2976 (0.3583)	CeLoss 0.0183 (0.0280)	SegCLSLoss 0.0024 (0.0017)	KLLoss 0.0042 (0.0044)	MaskLoss 0.0835 (0.0927)	MaskBCELoss 0.0301 (0.0229)	MaskDICELoss 0.0534 (0.0698)
Epoch: [3][477/500]	Time 79.664 (79.664)	Loss 0.0475 (0.3402)	CeLoss 0.0474 (0.0465)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0840)	MaskBCELoss 0.0000 (0.0230)	MaskDICELoss 0.0000 (0.0611)
Epoch: [3][478/500]	Time 82.007 (82.007)	Loss 0.4224 (0.3643)	CeLoss 0.0247 (0.0264)	SegCLSLoss 0.0020 (0.0013)	KLLoss 0.0040 (0.0046)	MaskLoss 0.0986 (0.0930)	MaskBCELoss 0.0009 (0.0197)	MaskDICELoss 0.0977 (0.0733)
Epoch: [3][479/500]	Time 82.534 (82.534)	Loss 0.0120 (0.3011)	CeLoss 0.0120 (0.0367)	SegCLSLoss 0.0000 (0.0018)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0758)	MaskBCELoss 0.0000 (0.0219)	MaskDICELoss 0.0000 (0.0540)
Epoch: [3][480/500]	Time 83.135 (83.135)	Loss 0.3806 (0.3325)	CeLoss 0.0217 (0.0301)	SegCLSLoss 0.0008 (0.0007)	KLLoss 0.0039 (0.0027)	MaskLoss 0.0898 (0.0781)	MaskBCELoss 0.0023 (0.0066)	MaskDICELoss 0.0875 (0.0715)
Epoch: [3][481/500]	Time 75.270 (75.270)	Loss 0.3849 (0.2875)	CeLoss 0.0211 (0.0440)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0019 (0.0038)	MaskLoss 0.1213 (0.0743)	MaskBCELoss 0.0621 (0.0292)	MaskDICELoss 0.0592 (0.0452)
Epoch: [3][482/500]	Time 75.647 (75.647)	Loss 0.4985 (0.3877)	CeLoss 0.0835 (0.0445)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0071 (0.0047)	MaskLoss 0.1037 (0.0914)	MaskBCELoss 0.0037 (0.0137)	MaskDICELoss 0.1000 (0.0776)
Epoch: [3][483/500]	Time 83.057 (83.057)	Loss 0.2165 (0.3135)	CeLoss 0.0214 (0.0421)	SegCLSLoss 0.0021 (0.0015)	KLLoss 0.0043 (0.0038)	MaskLoss 0.0580 (0.0731)	MaskBCELoss 0.0212 (0.0128)	MaskDICELoss 0.0369 (0.0603)
Epoch: [3][484/500]	Time 78.120 (78.120)	Loss 0.4516 (0.3143)	CeLoss 0.0403 (0.0545)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0038 (0.0035)	MaskLoss 0.1036 (0.0717)	MaskBCELoss 0.0036 (0.0156)	MaskDICELoss 0.1000 (0.0561)
Epoch: [3][485/500]	Time 72.434 (72.434)	Loss 0.3320 (0.3690)	CeLoss 0.0258 (0.0440)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0048 (0.0034)	MaskLoss 0.0942 (0.0863)	MaskBCELoss 0.0380 (0.0121)	MaskDICELoss 0.0562 (0.0742)
Epoch: [3][486/500]	Time 79.496 (79.496)	Loss 0.4306 (0.4114)	CeLoss 0.0352 (0.0456)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0042 (0.0040)	MaskLoss 0.1027 (0.1017)	MaskBCELoss 0.0100 (0.0227)	MaskDICELoss 0.0926 (0.0789)
Epoch: [3][487/500]	Time 71.603 (71.603)	Loss 0.4148 (0.3871)	CeLoss 0.0635 (0.0482)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0043 (0.0046)	MaskLoss 0.1149 (0.0929)	MaskBCELoss 0.0567 (0.0188)	MaskDICELoss 0.0583 (0.0741)
Epoch: [3][488/500]	Time 78.881 (78.881)	Loss 0.3984 (0.3785)	CeLoss 0.0581 (0.0442)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0060 (0.0043)	MaskLoss 0.0909 (0.0866)	MaskBCELoss 0.0148 (0.0084)	MaskDICELoss 0.0761 (0.0781)
Epoch: [3][489/500]	Time 73.847 (73.847)	Loss 0.5154 (0.3139)	CeLoss 0.0918 (0.0509)	SegCLSLoss 0.0020 (0.0012)	KLLoss 0.0060 (0.0034)	MaskLoss 0.1233 (0.0747)	MaskBCELoss 0.0384 (0.0200)	MaskDICELoss 0.0849 (0.0548)
Epoch: [3][490/500]	Time 79.843 (79.843)	Loss 0.4853 (0.3885)	CeLoss 0.0708 (0.0537)	SegCLSLoss 0.0017 (0.0009)	KLLoss 0.0053 (0.0040)	MaskLoss 0.1412 (0.0941)	MaskBCELoss 0.0782 (0.0231)	MaskDICELoss 0.0630 (0.0710)
Epoch: [3][491/500]	Time 74.874 (74.874)	Loss 0.4489 (0.3876)	CeLoss 0.0289 (0.0418)	SegCLSLoss 0.0009 (0.0015)	KLLoss 0.0040 (0.0041)	MaskLoss 0.1093 (0.0937)	MaskBCELoss 0.0108 (0.0170)	MaskDICELoss 0.0985 (0.0767)
Epoch: [3][492/500]	Time 75.381 (75.381)	Loss 0.4779 (0.3422)	CeLoss 0.0625 (0.0508)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0052 (0.0029)	MaskLoss 0.1069 (0.0768)	MaskBCELoss 0.0089 (0.0096)	MaskDICELoss 0.0981 (0.0672)
Epoch: [3][493/500]	Time 72.160 (72.160)	Loss 0.2768 (0.2817)	CeLoss 0.0232 (0.0389)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0035 (0.0033)	MaskLoss 0.0880 (0.0715)	MaskBCELoss 0.0513 (0.0234)	MaskDICELoss 0.0367 (0.0480)
Epoch: [3][494/500]	Time 79.899 (79.899)	Loss 0.4087 (0.2795)	CeLoss 0.0581 (0.0364)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0035 (0.0039)	MaskLoss 0.1217 (0.0739)	MaskBCELoss 0.0702 (0.0285)	MaskDICELoss 0.0516 (0.0454)
Epoch: [3][495/500]	Time 79.054 (79.054)	Loss 0.4741 (0.3732)	CeLoss 0.0610 (0.0377)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0027 (0.0038)	MaskLoss 0.1058 (0.0898)	MaskBCELoss 0.0066 (0.0140)	MaskDICELoss 0.0992 (0.0757)
Epoch: [3][496/500]	Time 88.383 (88.383)	Loss 0.1332 (0.2843)	CeLoss 0.0291 (0.0383)	SegCLSLoss 0.0015 (0.0010)	KLLoss 0.0054 (0.0041)	MaskLoss 0.0314 (0.0684)	MaskBCELoss 0.0140 (0.0161)	MaskDICELoss 0.0175 (0.0523)
Epoch: [3][497/500]	Time 76.404 (76.404)	Loss 0.2840 (0.4230)	CeLoss 0.0654 (0.0541)	SegCLSLoss 0.0010 (0.0007)	KLLoss 0.0021 (0.0041)	MaskLoss 0.0830 (0.1133)	MaskBCELoss 0.0578 (0.0445)	MaskDICELoss 0.0252 (0.0688)
Epoch: [3][498/500]	Time 74.986 (74.986)	Loss 0.4273 (0.3033)	CeLoss 0.0297 (0.0342)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0030 (0.0034)	MaskLoss 0.1091 (0.0722)	MaskBCELoss 0.0209 (0.0117)	MaskDICELoss 0.0882 (0.0605)
Epoch: [3][499/500]	Time 75.035 (75.035)	Loss 0.4091 (0.3955)	CeLoss 0.0242 (0.0563)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0043 (0.0041)	MaskLoss 0.0957 (0.0906)	MaskBCELoss 0.0015 (0.0139)	MaskDICELoss 0.0942 (0.0766)
  0%|                                                                                                                                                              | 0/200 [00:00<?, ?it/s]
[2025-03-12 10:22:54,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0002747710843373494], mom=[(0.9, 0.95)]
[2025-03-12 10:22:54,720] [INFO] [timer.py:215:stop] epoch=0/micro_step=2000/global_step=200, RunningAvgSamplesPerSec=0.6313279315759679, CurrSamplesPerSec=0.5297613586057667, MemAllocated=60.05GB, MaxMemAllocated=74.71GB







































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [02:44<00:00,  1.21it/s]
giou: 0.2623, ciou: 0.2248
[2025-03-12 10:25:41,989] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is about to be saved!
[2025-03-12 10:26:16,373] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step200/mp_rank_00_model_states.pt
[2025-03-12 10:26:16,374] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step200/mp_rank_00_model_states.pt...
[2025-03-12 10:29:39,569] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step200/mp_rank_00_model_states.pt.
[2025-03-12 10:29:41,781] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-12 10:29:57,213] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-12 10:29:57,216] [INFO] [engine.py:3244:_save_zero_checkpoint] zero checkpoint saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-12 10:29:57,216] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step200 is ready now!
Epoch: [4][  1/500]	Time 73.780 (73.780)	Loss 0.4897 (0.4308)	CeLoss 0.0850 (0.0522)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0052 (0.0041)	MaskLoss 0.1061 (0.1100)	MaskBCELoss 0.0124 (0.0330)	MaskDICELoss 0.0937 (0.0770)
Epoch: [4][  2/500]	Time 76.756 (76.756)	Loss 0.1734 (0.2966)	CeLoss 0.0703 (0.0400)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0054 (0.0037)	MaskLoss 0.0295 (0.0734)	MaskBCELoss 0.0101 (0.0206)	MaskDICELoss 0.0194 (0.0528)
Epoch: [4][  3/500]	Time 71.820 (71.820)	Loss 0.4733 (0.3827)	CeLoss 0.0232 (0.0465)	SegCLSLoss 0.0031 (0.0015)	KLLoss 0.0028 (0.0042)	MaskLoss 0.1316 (0.0914)	MaskBCELoss 0.0405 (0.0172)	MaskDICELoss 0.0912 (0.0742)
Epoch: [4][  4/500]	Time 80.090 (80.090)	Loss 0.5239 (0.3748)	CeLoss 0.0410 (0.0326)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0068 (0.0039)	MaskLoss 0.1384 (0.0932)	MaskBCELoss 0.0389 (0.0176)	MaskDICELoss 0.0995 (0.0757)
Epoch: [4][  5/500]	Time 84.054 (84.054)	Loss 0.4330 (0.3920)	CeLoss 0.0228 (0.0439)	SegCLSLoss 0.0023 (0.0013)	KLLoss 0.0036 (0.0035)	MaskLoss 0.1027 (0.0971)	MaskBCELoss 0.0028 (0.0223)	MaskDICELoss 0.0999 (0.0748)
Epoch: [4][  6/500]	Time 74.135 (74.135)	Loss 0.0193 (0.3110)	CeLoss 0.0193 (0.0409)	SegCLSLoss 0.0000 (0.0016)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0742)	MaskBCELoss 0.0000 (0.0155)	MaskDICELoss 0.0000 (0.0587)
Epoch: [4][  7/500]	Time 76.440 (76.440)	Loss 0.4245 (0.3305)	CeLoss 0.0674 (0.0470)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0032 (0.0037)	MaskLoss 0.0928 (0.0759)	MaskBCELoss 0.0086 (0.0122)	MaskDICELoss 0.0841 (0.0636)
Epoch: [4][  8/500]	Time 80.538 (80.538)	Loss 0.3835 (0.3359)	CeLoss 0.0115 (0.0286)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0025 (0.0037)	MaskLoss 0.0971 (0.0822)	MaskBCELoss 0.0096 (0.0131)	MaskDICELoss 0.0875 (0.0691)
Epoch: [4][  9/500]	Time 79.818 (79.818)	Loss 0.1069 (0.3446)	CeLoss 0.0228 (0.0427)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0022 (0.0038)	MaskLoss 0.0239 (0.0851)	MaskBCELoss 0.0072 (0.0215)	MaskDICELoss 0.0167 (0.0637)
Epoch: [4][ 10/500]	Time 77.599 (77.599)	Loss 0.4589 (0.4313)	CeLoss 0.0234 (0.0593)	SegCLSLoss 0.0045 (0.0010)	KLLoss 0.0042 (0.0038)	MaskLoss 0.1263 (0.1022)	MaskBCELoss 0.0381 (0.0205)	MaskDICELoss 0.0882 (0.0817)
Epoch: [4][ 11/500]	Time 72.645 (72.645)	Loss 0.0314 (0.3212)	CeLoss 0.0315 (0.0380)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0741)	MaskBCELoss 0.0000 (0.0081)	MaskDICELoss 0.0000 (0.0660)
Epoch: [4][ 12/500]	Time 74.879 (74.879)	Loss 0.0424 (0.3462)	CeLoss 0.0425 (0.0473)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.0837)	MaskBCELoss 0.0000 (0.0200)	MaskDICELoss 0.0000 (0.0637)
Epoch: [4][ 13/500]	Time 73.724 (73.724)	Loss 0.4214 (0.3266)	CeLoss 0.0237 (0.0369)	SegCLSLoss 0.0037 (0.0019)	KLLoss 0.0033 (0.0034)	MaskLoss 0.1050 (0.0791)	MaskBCELoss 0.0135 (0.0156)	MaskDICELoss 0.0914 (0.0635)
Epoch: [4][ 14/500]	Time 72.455 (72.455)	Loss 0.2740 (0.3496)	CeLoss 0.0398 (0.0371)	SegCLSLoss 0.0028 (0.0016)	KLLoss 0.0034 (0.0035)	MaskLoss 0.0715 (0.0908)	MaskBCELoss 0.0283 (0.0276)	MaskDICELoss 0.0432 (0.0632)
Epoch: [4][ 15/500]	Time 71.494 (71.494)	Loss 0.4962 (0.3624)	CeLoss 0.0153 (0.0402)	SegCLSLoss 0.0014 (0.0015)	KLLoss 0.0054 (0.0035)	MaskLoss 0.1421 (0.0937)	MaskBCELoss 0.0467 (0.0283)	MaskDICELoss 0.0954 (0.0653)
Epoch: [4][ 16/500]	Time 75.237 (75.237)	Loss 0.3212 (0.3836)	CeLoss 0.0444 (0.0474)	SegCLSLoss 0.0025 (0.0009)	KLLoss 0.0053 (0.0036)	MaskLoss 0.0777 (0.0972)	MaskBCELoss 0.0204 (0.0283)	MaskDICELoss 0.0573 (0.0689)
Epoch: [4][ 17/500]	Time 72.938 (72.938)	Loss 0.2039 (0.2948)	CeLoss 0.0212 (0.0408)	SegCLSLoss 0.0027 (0.0019)	KLLoss 0.0032 (0.0043)	MaskLoss 0.0548 (0.0698)	MaskBCELoss 0.0206 (0.0151)	MaskDICELoss 0.0343 (0.0546)
Epoch: [4][ 18/500]	Time 77.153 (77.153)	Loss 0.4625 (0.3620)	CeLoss 0.0415 (0.0415)	SegCLSLoss 0.0023 (0.0012)	KLLoss 0.0032 (0.0044)	MaskLoss 0.1086 (0.0900)	MaskBCELoss 0.0089 (0.0223)	MaskDICELoss 0.0997 (0.0677)
Epoch: [4][ 19/500]	Time 75.800 (75.800)	Loss 0.0193 (0.3195)	CeLoss 0.0193 (0.0451)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0809)	MaskBCELoss 0.0000 (0.0265)	MaskDICELoss 0.0000 (0.0544)
Epoch: [4][ 20/500]	Time 78.719 (78.719)	Loss 0.0875 (0.2648)	CeLoss 0.0240 (0.0384)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0061 (0.0035)	MaskLoss 0.0170 (0.0677)	MaskBCELoss 0.0056 (0.0241)	MaskDICELoss 0.0114 (0.0436)
Epoch: [4][ 21/500]	Time 73.890 (73.890)	Loss 0.4679 (0.4269)	CeLoss 0.0459 (0.0370)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0037 (0.0042)	MaskLoss 0.1094 (0.1153)	MaskBCELoss 0.0097 (0.0380)	MaskDICELoss 0.0997 (0.0773)
Epoch: [4][ 22/500]	Time 76.995 (76.995)	Loss 0.3107 (0.3858)	CeLoss 0.0280 (0.0375)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0023 (0.0034)	MaskLoss 0.0948 (0.1011)	MaskBCELoss 0.0497 (0.0301)	MaskDICELoss 0.0451 (0.0710)
Epoch: [4][ 23/500]	Time 89.899 (89.899)	Loss 0.3310 (0.3191)	CeLoss 0.0233 (0.0390)	SegCLSLoss 0.0024 (0.0008)	KLLoss 0.0040 (0.0045)	MaskLoss 0.0760 (0.0755)	MaskBCELoss 0.0008 (0.0134)	MaskDICELoss 0.0752 (0.0621)
Epoch: [4][ 24/500]	Time 69.928 (69.928)	Loss 0.4703 (0.3327)	CeLoss 0.0216 (0.0500)	SegCLSLoss 0.0038 (0.0016)	KLLoss 0.0057 (0.0028)	MaskLoss 0.1364 (0.0841)	MaskBCELoss 0.0522 (0.0287)	MaskDICELoss 0.0842 (0.0554)
Epoch: [4][ 25/500]	Time 75.937 (75.937)	Loss 0.1214 (0.2185)	CeLoss 0.0261 (0.0388)	SegCLSLoss 0.0010 (0.0006)	KLLoss 0.0031 (0.0027)	MaskLoss 0.0356 (0.0504)	MaskBCELoss 0.0254 (0.0125)	MaskDICELoss 0.0102 (0.0379)
Epoch: [4][ 26/500]	Time 70.499 (70.499)	Loss 0.3516 (0.3113)	CeLoss 0.0381 (0.0635)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0036 (0.0034)	MaskLoss 0.0933 (0.0702)	MaskBCELoss 0.0319 (0.0184)	MaskDICELoss 0.0615 (0.0518)
Epoch: [4][ 27/500]	Time 73.197 (73.197)	Loss 0.4156 (0.3268)	CeLoss 0.0205 (0.0356)	SegCLSLoss 0.0029 (0.0025)	KLLoss 0.0027 (0.0036)	MaskLoss 0.1189 (0.0839)	MaskBCELoss 0.0423 (0.0245)	MaskDICELoss 0.0766 (0.0593)
Epoch: [4][ 28/500]	Time 73.440 (73.440)	Loss 0.3068 (0.4195)	CeLoss 0.1030 (0.0532)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0050 (0.0033)	MaskLoss 0.0565 (0.1035)	MaskBCELoss 0.0135 (0.0258)	MaskDICELoss 0.0430 (0.0777)
Epoch: [4][ 29/500]	Time 77.680 (77.680)	Loss 0.3840 (0.3128)	CeLoss 0.0869 (0.0526)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0037 (0.0040)	MaskLoss 0.0789 (0.0734)	MaskBCELoss 0.0113 (0.0188)	MaskDICELoss 0.0676 (0.0546)
Epoch: [4][ 30/500]	Time 78.653 (78.653)	Loss 0.3151 (0.3346)	CeLoss 0.0261 (0.0549)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0023 (0.0033)	MaskLoss 0.0789 (0.0799)	MaskBCELoss 0.0147 (0.0218)	MaskDICELoss 0.0642 (0.0581)
Epoch: [4][ 31/500]	Time 83.061 (83.061)	Loss 0.4340 (0.3080)	CeLoss 0.0464 (0.0484)	SegCLSLoss 0.0014 (0.0021)	KLLoss 0.0034 (0.0038)	MaskLoss 0.0984 (0.0721)	MaskBCELoss 0.0050 (0.0168)	MaskDICELoss 0.0934 (0.0553)
Epoch: [4][ 32/500]	Time 72.833 (72.833)	Loss 0.5076 (0.4123)	CeLoss 0.0713 (0.0406)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0029 (0.0039)	MaskLoss 0.1245 (0.0990)	MaskBCELoss 0.0323 (0.0145)	MaskDICELoss 0.0922 (0.0845)
Epoch: [4][ 33/500]	Time 80.287 (80.287)	Loss 0.6182 (0.4057)	CeLoss 0.0581 (0.0411)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0146 (0.0046)	MaskLoss 0.1809 (0.1020)	MaskBCELoss 0.0895 (0.0243)	MaskDICELoss 0.0914 (0.0777)
Epoch: [4][ 34/500]	Time 82.902 (82.902)	Loss 0.1221 (0.3388)	CeLoss 0.0820 (0.0559)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0018 (0.0035)	MaskLoss 0.0121 (0.0789)	MaskBCELoss 0.0052 (0.0183)	MaskDICELoss 0.0069 (0.0606)
Epoch: [4][ 35/500]	Time 82.750 (82.750)	Loss 0.2861 (0.3867)	CeLoss 0.0684 (0.0431)	SegCLSLoss 0.0025 (0.0015)	KLLoss 0.0029 (0.0034)	MaskLoss 0.0670 (0.0954)	MaskBCELoss 0.0270 (0.0209)	MaskDICELoss 0.0400 (0.0744)
Epoch: [4][ 36/500]	Time 74.674 (74.674)	Loss 0.1937 (0.3491)	CeLoss 0.1006 (0.0405)	SegCLSLoss 0.0002 (0.0011)	KLLoss 0.0030 (0.0039)	MaskLoss 0.0301 (0.0848)	MaskBCELoss 0.0152 (0.0176)	MaskDICELoss 0.0148 (0.0672)
Epoch: [4][ 37/500]	Time 79.771 (79.771)	Loss 0.4988 (0.3365)	CeLoss 0.0835 (0.0369)	SegCLSLoss 0.0003 (0.0017)	KLLoss 0.0058 (0.0035)	MaskLoss 0.1057 (0.0800)	MaskBCELoss 0.0067 (0.0125)	MaskDICELoss 0.0990 (0.0676)
Epoch: [4][ 38/500]	Time 77.017 (77.017)	Loss 0.4587 (0.3135)	CeLoss 0.0444 (0.0427)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0059 (0.0036)	MaskLoss 0.1041 (0.0752)	MaskBCELoss 0.0043 (0.0169)	MaskDICELoss 0.0998 (0.0582)
Epoch: [4][ 39/500]	Time 68.808 (68.808)	Loss 0.4630 (0.3600)	CeLoss 0.0535 (0.0523)	SegCLSLoss 0.0005 (0.0015)	KLLoss 0.0030 (0.0030)	MaskLoss 0.1030 (0.0817)	MaskBCELoss 0.0030 (0.0115)	MaskDICELoss 0.1000 (0.0702)
Epoch: [4][ 40/500]	Time 46.986 (46.986)	Loss 0.2628 (0.3887)	CeLoss 0.0260 (0.0554)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0043 (0.0029)	MaskLoss 0.0715 (0.0891)	MaskBCELoss 0.0270 (0.0132)	MaskDICELoss 0.0445 (0.0759)
Epoch: [4][ 41/500]	Time 48.924 (48.924)	Loss 0.3188 (0.3291)	CeLoss 0.0527 (0.0456)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0029 (0.0035)	MaskLoss 0.0764 (0.0778)	MaskBCELoss 0.0212 (0.0158)	MaskDICELoss 0.0551 (0.0620)
Epoch: [4][ 42/500]	Time 50.167 (50.167)	Loss 0.1234 (0.3126)	CeLoss 0.0566 (0.0291)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0042 (0.0033)	MaskLoss 0.0196 (0.0773)	MaskBCELoss 0.0081 (0.0148)	MaskDICELoss 0.0116 (0.0625)
Epoch: [4][ 43/500]	Time 50.863 (50.863)	Loss 0.1116 (0.3465)	CeLoss 0.0447 (0.0425)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0031 (0.0035)	MaskLoss 0.0167 (0.0825)	MaskBCELoss 0.0018 (0.0149)	MaskDICELoss 0.0150 (0.0675)
Epoch: [4][ 44/500]	Time 43.487 (43.487)	Loss 0.4866 (0.2856)	CeLoss 0.0938 (0.0579)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0031 (0.0037)	MaskLoss 0.1016 (0.0670)	MaskBCELoss 0.0085 (0.0220)	MaskDICELoss 0.0931 (0.0449)
Epoch: [4][ 45/500]	Time 44.305 (44.305)	Loss 0.1367 (0.3688)	CeLoss 0.0698 (0.0614)	SegCLSLoss 0.0015 (0.0010)	KLLoss 0.0055 (0.0042)	MaskLoss 0.0195 (0.0854)	MaskBCELoss 0.0088 (0.0195)	MaskDICELoss 0.0107 (0.0660)
Epoch: [4][ 46/500]	Time 48.589 (48.589)	Loss 0.3286 (0.3656)	CeLoss 0.0540 (0.0368)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0030 (0.0030)	MaskLoss 0.0743 (0.0891)	MaskBCELoss 0.0130 (0.0157)	MaskDICELoss 0.0613 (0.0734)
Epoch: [4][ 47/500]	Time 48.652 (48.652)	Loss 0.3097 (0.3806)	CeLoss 0.0198 (0.0426)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0020 (0.0033)	MaskLoss 0.0953 (0.1004)	MaskBCELoss 0.0469 (0.0339)	MaskDICELoss 0.0484 (0.0665)
Epoch: [4][ 48/500]	Time 49.494 (49.494)	Loss 0.4953 (0.3418)	CeLoss 0.0889 (0.0429)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0036 (0.0035)	MaskLoss 0.1060 (0.0795)	MaskBCELoss 0.0108 (0.0115)	MaskDICELoss 0.0952 (0.0680)
Epoch: [4][ 49/500]	Time 46.057 (46.057)	Loss 0.3432 (0.3580)	CeLoss 0.0532 (0.0434)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0029 (0.0033)	MaskLoss 0.0746 (0.0869)	MaskBCELoss 0.0057 (0.0185)	MaskDICELoss 0.0689 (0.0684)
Epoch: [4][ 50/500]	Time 45.982 (45.982)	Loss 0.4780 (0.4022)	CeLoss 0.0552 (0.0447)	SegCLSLoss 0.0005 (0.0018)	KLLoss 0.0033 (0.0037)	MaskLoss 0.1105 (0.1014)	MaskBCELoss 0.0113 (0.0264)	MaskDICELoss 0.0992 (0.0750)
Epoch: [4][ 51/500]	Time 48.610 (48.610)	Loss 0.4377 (0.3701)	CeLoss 0.0215 (0.0339)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0036 (0.0029)	MaskLoss 0.1064 (0.0936)	MaskBCELoss 0.0069 (0.0209)	MaskDICELoss 0.0996 (0.0727)
Epoch: [4][ 52/500]	Time 46.256 (46.256)	Loss 0.3540 (0.2959)	CeLoss 0.0150 (0.0356)	SegCLSLoss 0.0060 (0.0022)	KLLoss 0.0053 (0.0035)	MaskLoss 0.0912 (0.0731)	MaskBCELoss 0.0170 (0.0182)	MaskDICELoss 0.0742 (0.0549)
Epoch: [4][ 53/500]	Time 51.650 (51.650)	Loss 0.3876 (0.3509)	CeLoss 0.0425 (0.0329)	SegCLSLoss 0.0026 (0.0009)	KLLoss 0.0043 (0.0039)	MaskLoss 0.0942 (0.0903)	MaskBCELoss 0.0187 (0.0238)	MaskDICELoss 0.0756 (0.0665)
Epoch: [4][ 54/500]	Time 47.792 (47.792)	Loss 0.1706 (0.2854)	CeLoss 0.0874 (0.0437)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0039 (0.0038)	MaskLoss 0.0240 (0.0706)	MaskBCELoss 0.0086 (0.0225)	MaskDICELoss 0.0154 (0.0481)
Epoch: [4][ 55/500]	Time 50.091 (50.091)	Loss 0.4945 (0.3205)	CeLoss 0.0352 (0.0349)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0074 (0.0042)	MaskLoss 0.1595 (0.0795)	MaskBCELoss 0.0931 (0.0184)	MaskDICELoss 0.0664 (0.0611)
Epoch: [4][ 56/500]	Time 47.615 (47.615)	Loss 0.4653 (0.2909)	CeLoss 0.0513 (0.0410)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0027 (0.0030)	MaskLoss 0.1129 (0.0673)	MaskBCELoss 0.0203 (0.0115)	MaskDICELoss 0.0926 (0.0559)
Epoch: [4][ 57/500]	Time 49.005 (49.005)	Loss 0.6652 (0.3538)	CeLoss 0.0212 (0.0427)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0037 (0.0035)	MaskLoss 0.2241 (0.0910)	MaskBCELoss 0.1283 (0.0285)	MaskDICELoss 0.0958 (0.0625)
Epoch: [4][ 58/500]	Time 55.420 (55.420)	Loss 0.5032 (0.3058)	CeLoss 0.0942 (0.0341)	SegCLSLoss 0.0009 (0.0009)	KLLoss 0.0049 (0.0028)	MaskLoss 0.1020 (0.0698)	MaskBCELoss 0.0020 (0.0053)	MaskDICELoss 0.1000 (0.0645)
Epoch: [4][ 59/500]	Time 45.061 (45.061)	Loss 0.1929 (0.3873)	CeLoss 0.0432 (0.0444)	SegCLSLoss 0.0004 (0.0020)	KLLoss 0.0036 (0.0037)	MaskLoss 0.0372 (0.0894)	MaskBCELoss 0.0013 (0.0096)	MaskDICELoss 0.0358 (0.0797)
Epoch: [4][ 60/500]	Time 51.702 (51.702)	Loss 0.2913 (0.3816)	CeLoss 0.0674 (0.0451)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0051 (0.0032)	MaskLoss 0.0616 (0.1069)	MaskBCELoss 0.0139 (0.0473)	MaskDICELoss 0.0477 (0.0596)
Epoch: [4][ 61/500]	Time 44.716 (44.716)	Loss 0.5929 (0.3631)	CeLoss 0.0386 (0.0386)	SegCLSLoss 0.0011 (0.0020)	KLLoss 0.0030 (0.0040)	MaskLoss 0.1976 (0.0955)	MaskBCELoss 0.1197 (0.0313)	MaskDICELoss 0.0779 (0.0642)
Epoch: [4][ 62/500]	Time 48.364 (48.364)	Loss 0.1037 (0.3184)	CeLoss 0.0267 (0.0413)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0024 (0.0027)	MaskLoss 0.0245 (0.0768)	MaskBCELoss 0.0120 (0.0165)	MaskDICELoss 0.0125 (0.0602)
Epoch: [4][ 63/500]	Time 46.542 (46.542)	Loss 0.3896 (0.2972)	CeLoss 0.0239 (0.0369)	SegCLSLoss 0.0023 (0.0019)	KLLoss 0.0061 (0.0042)	MaskLoss 0.0916 (0.0695)	MaskBCELoss 0.0039 (0.0113)	MaskDICELoss 0.0877 (0.0581)
Epoch: [4][ 64/500]	Time 45.098 (45.098)	Loss 0.3880 (0.3596)	CeLoss 0.0693 (0.0432)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0026 (0.0035)	MaskLoss 0.0844 (0.0836)	MaskBCELoss 0.0110 (0.0112)	MaskDICELoss 0.0735 (0.0724)
Epoch: [4][ 65/500]	Time 49.685 (49.685)	Loss 0.4538 (0.3511)	CeLoss 0.0532 (0.0355)	SegCLSLoss 0.0027 (0.0013)	KLLoss 0.0029 (0.0037)	MaskLoss 0.1016 (0.0916)	MaskBCELoss 0.0050 (0.0276)	MaskDICELoss 0.0966 (0.0640)
Epoch: [4][ 66/500]	Time 45.965 (45.965)	Loss 0.4702 (0.3162)	CeLoss 0.0850 (0.0440)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0025 (0.0030)	MaskLoss 0.1188 (0.0832)	MaskBCELoss 0.0463 (0.0322)	MaskDICELoss 0.0725 (0.0511)
Epoch: [4][ 67/500]	Time 43.785 (43.785)	Loss 0.3399 (0.2862)	CeLoss 0.0234 (0.0359)	SegCLSLoss 0.0013 (0.0019)	KLLoss 0.0021 (0.0025)	MaskLoss 0.0802 (0.0687)	MaskBCELoss 0.0036 (0.0140)	MaskDICELoss 0.0766 (0.0547)
Epoch: [4][ 68/500]	Time 46.314 (46.314)	Loss 0.4524 (0.3631)	CeLoss 0.0781 (0.0387)	SegCLSLoss 0.0003 (0.0019)	KLLoss 0.0048 (0.0040)	MaskLoss 0.1015 (0.0901)	MaskBCELoss 0.0183 (0.0205)	MaskDICELoss 0.0833 (0.0696)
Epoch: [4][ 69/500]	Time 48.433 (48.433)	Loss 0.2424 (0.3519)	CeLoss 0.0243 (0.0401)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0062 (0.0040)	MaskLoss 0.0600 (0.0874)	MaskBCELoss 0.0141 (0.0212)	MaskDICELoss 0.0458 (0.0662)
Epoch: [4][ 70/500]	Time 50.171 (50.171)	Loss 0.0437 (0.3474)	CeLoss 0.0437 (0.0399)	SegCLSLoss 0.0000 (0.0017)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0874)	MaskBCELoss 0.0000 (0.0228)	MaskDICELoss 0.0000 (0.0646)
Epoch: [4][ 71/500]	Time 43.257 (43.257)	Loss 0.5294 (0.2747)	CeLoss 0.0532 (0.0455)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0038 (0.0031)	MaskLoss 0.1372 (0.0606)	MaskBCELoss 0.0383 (0.0084)	MaskDICELoss 0.0989 (0.0521)
Epoch: [4][ 72/500]	Time 49.344 (49.344)	Loss 0.2928 (0.3317)	CeLoss 0.0258 (0.0380)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0072 (0.0038)	MaskLoss 0.0771 (0.0825)	MaskBCELoss 0.0246 (0.0202)	MaskDICELoss 0.0525 (0.0623)
Epoch: [4][ 73/500]	Time 47.421 (47.421)	Loss 0.3301 (0.3238)	CeLoss 0.0215 (0.0409)	SegCLSLoss 0.0023 (0.0015)	KLLoss 0.0048 (0.0035)	MaskLoss 0.0787 (0.0843)	MaskBCELoss 0.0059 (0.0293)	MaskDICELoss 0.0727 (0.0550)
Epoch: [4][ 74/500]	Time 45.403 (45.403)	Loss 0.0629 (0.3336)	CeLoss 0.0630 (0.0523)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0806)	MaskBCELoss 0.0000 (0.0227)	MaskDICELoss 0.0000 (0.0580)
Epoch: [4][ 75/500]	Time 49.075 (49.075)	Loss 0.0156 (0.3544)	CeLoss 0.0156 (0.0402)	SegCLSLoss 0.0000 (0.0018)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0904)	MaskBCELoss 0.0000 (0.0258)	MaskDICELoss 0.0000 (0.0646)
Epoch: [4][ 76/500]	Time 44.202 (44.202)	Loss 0.4390 (0.2978)	CeLoss 0.0459 (0.0338)	SegCLSLoss 0.0028 (0.0022)	KLLoss 0.0038 (0.0044)	MaskLoss 0.0996 (0.0765)	MaskBCELoss 0.0054 (0.0239)	MaskDICELoss 0.0943 (0.0527)
Epoch: [4][ 77/500]	Time 51.216 (51.216)	Loss 0.3568 (0.4078)	CeLoss 0.0593 (0.0462)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0026 (0.0036)	MaskLoss 0.0769 (0.0993)	MaskBCELoss 0.0067 (0.0198)	MaskDICELoss 0.0702 (0.0794)
Epoch: [4][ 78/500]	Time 47.708 (47.708)	Loss 0.4458 (0.3421)	CeLoss 0.0242 (0.0452)	SegCLSLoss 0.0011 (0.0007)	KLLoss 0.0032 (0.0033)	MaskLoss 0.1104 (0.0795)	MaskBCELoss 0.0118 (0.0124)	MaskDICELoss 0.0985 (0.0671)
Epoch: [4][ 79/500]	Time 46.859 (46.859)	Loss 0.0239 (0.3191)	CeLoss 0.0239 (0.0543)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0771)	MaskBCELoss 0.0000 (0.0238)	MaskDICELoss 0.0000 (0.0533)
Epoch: [4][ 80/500]	Time 49.194 (49.194)	Loss 0.3744 (0.3123)	CeLoss 0.0286 (0.0350)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0037 (0.0035)	MaskLoss 0.1053 (0.0748)	MaskBCELoss 0.0398 (0.0129)	MaskDICELoss 0.0655 (0.0619)
Epoch: [4][ 81/500]	Time 52.075 (52.075)	Loss 0.1379 (0.2952)	CeLoss 0.0742 (0.0432)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0043 (0.0035)	MaskLoss 0.0201 (0.0673)	MaskBCELoss 0.0105 (0.0105)	MaskDICELoss 0.0096 (0.0568)
Epoch: [4][ 82/500]	Time 46.550 (46.550)	Loss 0.5154 (0.2941)	CeLoss 0.1069 (0.0457)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0032 (0.0031)	MaskLoss 0.1048 (0.0685)	MaskBCELoss 0.0070 (0.0146)	MaskDICELoss 0.0978 (0.0539)
Epoch: [4][ 83/500]	Time 51.576 (51.576)	Loss 0.4233 (0.3988)	CeLoss 0.0143 (0.0222)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0032 (0.0041)	MaskLoss 0.1029 (0.1038)	MaskBCELoss 0.0031 (0.0216)	MaskDICELoss 0.0998 (0.0821)
Epoch: [4][ 84/500]	Time 48.453 (48.453)	Loss 0.1141 (0.2776)	CeLoss 0.0513 (0.0406)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0025 (0.0031)	MaskLoss 0.0213 (0.0678)	MaskBCELoss 0.0126 (0.0188)	MaskDICELoss 0.0088 (0.0490)
Epoch: [4][ 85/500]	Time 48.844 (48.844)	Loss 0.4332 (0.2773)	CeLoss 0.0261 (0.0368)	SegCLSLoss 0.0019 (0.0023)	KLLoss 0.0020 (0.0030)	MaskLoss 0.1021 (0.0647)	MaskBCELoss 0.0021 (0.0111)	MaskDICELoss 0.1000 (0.0535)
Epoch: [4][ 86/500]	Time 51.236 (51.236)	Loss 0.2340 (0.2524)	CeLoss 0.0092 (0.0287)	SegCLSLoss 0.0003 (0.0016)	KLLoss 0.0037 (0.0026)	MaskLoss 0.0715 (0.0644)	MaskBCELoss 0.0326 (0.0187)	MaskDICELoss 0.0390 (0.0457)
Epoch: [4][ 87/500]	Time 44.590 (44.590)	Loss 0.4491 (0.3058)	CeLoss 0.0391 (0.0424)	SegCLSLoss 0.0003 (0.0015)	KLLoss 0.0048 (0.0037)	MaskLoss 0.1283 (0.0805)	MaskBCELoss 0.0539 (0.0315)	MaskDICELoss 0.0743 (0.0490)
Epoch: [4][ 88/500]	Time 43.437 (43.437)	Loss 0.5060 (0.2896)	CeLoss 0.0222 (0.0377)	SegCLSLoss 0.0009 (0.0012)	KLLoss 0.0042 (0.0036)	MaskLoss 0.1512 (0.0715)	MaskBCELoss 0.0628 (0.0191)	MaskDICELoss 0.0884 (0.0524)
Epoch: [4][ 89/500]	Time 49.394 (49.394)	Loss 0.4555 (0.2504)	CeLoss 0.0703 (0.0317)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0032 (0.0027)	MaskLoss 0.0979 (0.0616)	MaskBCELoss 0.0049 (0.0155)	MaskDICELoss 0.0930 (0.0461)
Epoch: [4][ 90/500]	Time 46.054 (46.054)	Loss 0.0683 (0.2311)	CeLoss 0.0254 (0.0251)	SegCLSLoss 0.0017 (0.0012)	KLLoss 0.0034 (0.0028)	MaskLoss 0.0104 (0.0586)	MaskBCELoss 0.0016 (0.0160)	MaskDICELoss 0.0089 (0.0427)
Epoch: [4][ 91/500]	Time 48.581 (48.581)	Loss 0.0176 (0.3209)	CeLoss 0.0176 (0.0407)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0734)	MaskBCELoss 0.0000 (0.0086)	MaskDICELoss 0.0000 (0.0648)
Epoch: [4][ 92/500]	Time 51.557 (51.557)	Loss 0.3384 (0.3421)	CeLoss 0.0986 (0.0481)	SegCLSLoss 0.0003 (0.0006)	KLLoss 0.0045 (0.0039)	MaskLoss 0.0667 (0.0830)	MaskBCELoss 0.0158 (0.0210)	MaskDICELoss 0.0509 (0.0619)
Epoch: [4][ 93/500]	Time 46.407 (46.407)	Loss 0.5068 (0.3968)	CeLoss 0.0598 (0.0473)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1234 (0.0969)	MaskBCELoss 0.0251 (0.0210)	MaskDICELoss 0.0983 (0.0759)
Epoch: [4][ 94/500]	Time 46.575 (46.575)	Loss 0.5337 (0.3928)	CeLoss 0.0464 (0.0592)	SegCLSLoss 0.0032 (0.0018)	KLLoss 0.0039 (0.0031)	MaskLoss 0.1449 (0.0902)	MaskBCELoss 0.0487 (0.0156)	MaskDICELoss 0.0962 (0.0746)
Epoch: [4][ 95/500]	Time 41.248 (41.248)	Loss 0.2355 (0.2699)	CeLoss 0.0610 (0.0459)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0040 (0.0032)	MaskLoss 0.0472 (0.0599)	MaskBCELoss 0.0093 (0.0097)	MaskDICELoss 0.0379 (0.0502)
Epoch: [4][ 96/500]	Time 47.589 (47.589)	Loss 0.4568 (0.3587)	CeLoss 0.1104 (0.0506)	SegCLSLoss 0.0021 (0.0021)	KLLoss 0.0029 (0.0037)	MaskLoss 0.0868 (0.0804)	MaskBCELoss 0.0021 (0.0091)	MaskDICELoss 0.0846 (0.0713)
Epoch: [4][ 97/500]	Time 46.844 (46.844)	Loss 0.3571 (0.2644)	CeLoss 0.0245 (0.0381)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0034 (0.0034)	MaskLoss 0.0834 (0.0589)	MaskBCELoss 0.0027 (0.0066)	MaskDICELoss 0.0807 (0.0522)
Epoch: [4][ 98/500]	Time 48.736 (48.736)	Loss 0.4125 (0.2803)	CeLoss 0.0669 (0.0353)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0029 (0.0029)	MaskLoss 0.0984 (0.0736)	MaskBCELoss 0.0255 (0.0263)	MaskDICELoss 0.0729 (0.0472)
Epoch: [4][ 99/500]	Time 46.163 (46.163)	Loss 0.4896 (0.3484)	CeLoss 0.0806 (0.0313)	SegCLSLoss 0.0024 (0.0015)	KLLoss 0.0026 (0.0028)	MaskLoss 0.1028 (0.0845)	MaskBCELoss 0.0031 (0.0122)	MaskDICELoss 0.0998 (0.0723)
[2025-03-12 12:08:13,935] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[0.0002734578313253012], mom=[(0.9, 0.95)]
[2025-03-12 12:08:13,947] [INFO] [timer.py:215:stop] epoch=0/micro_step=2100/global_step=210, RunningAvgSamplesPerSec=0.6337285433483388, CurrSamplesPerSec=0.999676659977712, MemAllocated=59.64GB, MaxMemAllocated=74.71GB
Epoch: [4][100/500]	Time 49.048 (49.048)	Loss 0.2368 (0.2882)	CeLoss 0.0254 (0.0391)	SegCLSLoss 0.0037 (0.0013)	KLLoss 0.0030 (0.0032)	MaskLoss 0.0524 (0.0671)	MaskBCELoss 0.0013 (0.0115)	MaskDICELoss 0.0510 (0.0555)
Epoch: [4][101/500]	Time 46.474 (46.474)	Loss 0.3854 (0.2798)	CeLoss 0.0133 (0.0364)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0040 (0.0036)	MaskLoss 0.0946 (0.0674)	MaskBCELoss 0.0053 (0.0151)	MaskDICELoss 0.0893 (0.0522)
Epoch: [4][102/500]	Time 47.057 (47.057)	Loss 0.4149 (0.2886)	CeLoss 0.0312 (0.0377)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0045 (0.0039)	MaskLoss 0.0982 (0.0690)	MaskBCELoss 0.0072 (0.0150)	MaskDICELoss 0.0910 (0.0541)
Epoch: [4][103/500]	Time 50.854 (50.854)	Loss 0.5075 (0.2806)	CeLoss 0.0776 (0.0440)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0042 (0.0033)	MaskLoss 0.1131 (0.0662)	MaskBCELoss 0.0139 (0.0161)	MaskDICELoss 0.0992 (0.0501)
Epoch: [4][104/500]	Time 47.595 (47.595)	Loss 0.1923 (0.2314)	CeLoss 0.0264 (0.0314)	SegCLSLoss 0.0023 (0.0012)	KLLoss 0.0034 (0.0033)	MaskLoss 0.0538 (0.0546)	MaskBCELoss 0.0269 (0.0111)	MaskDICELoss 0.0269 (0.0435)
Epoch: [4][105/500]	Time 54.183 (54.183)	Loss 0.4345 (0.3136)	CeLoss 0.0552 (0.0316)	SegCLSLoss 0.0015 (0.0019)	KLLoss 0.0062 (0.0038)	MaskLoss 0.0968 (0.0798)	MaskBCELoss 0.0073 (0.0209)	MaskDICELoss 0.0894 (0.0589)
Epoch: [4][106/500]	Time 42.553 (42.553)	Loss 0.4216 (0.3426)	CeLoss 0.0674 (0.0426)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0049 (0.0040)	MaskLoss 0.0881 (0.0780)	MaskBCELoss 0.0018 (0.0083)	MaskDICELoss 0.0863 (0.0697)
Epoch: [4][107/500]	Time 48.219 (48.219)	Loss 0.4964 (0.4122)	CeLoss 0.0228 (0.0382)	SegCLSLoss 0.0034 (0.0016)	KLLoss 0.0037 (0.0043)	MaskLoss 0.1394 (0.1091)	MaskBCELoss 0.0448 (0.0338)	MaskDICELoss 0.0946 (0.0753)
Epoch: [4][108/500]	Time 44.412 (44.412)	Loss 0.4878 (0.4227)	CeLoss 0.0277 (0.0525)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0040 (0.0040)	MaskLoss 0.1346 (0.1045)	MaskBCELoss 0.0414 (0.0262)	MaskDICELoss 0.0931 (0.0783)
Epoch: [4][109/500]	Time 48.970 (48.970)	Loss 0.4464 (0.3580)	CeLoss 0.0366 (0.0358)	SegCLSLoss 0.0016 (0.0017)	KLLoss 0.0020 (0.0031)	MaskLoss 0.1037 (0.0893)	MaskBCELoss 0.0038 (0.0194)	MaskDICELoss 0.0999 (0.0699)
Epoch: [4][110/500]	Time 51.287 (51.287)	Loss 0.4934 (0.4226)	CeLoss 0.0776 (0.0449)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0086 (0.0049)	MaskLoss 0.1040 (0.1108)	MaskBCELoss 0.0045 (0.0355)	MaskDICELoss 0.0995 (0.0753)
Epoch: [4][111/500]	Time 50.767 (50.767)	Loss 0.4319 (0.3719)	CeLoss 0.0237 (0.0325)	SegCLSLoss 0.0012 (0.0010)	KLLoss 0.0052 (0.0032)	MaskLoss 0.1038 (0.0912)	MaskBCELoss 0.0063 (0.0145)	MaskDICELoss 0.0974 (0.0766)
Epoch: [4][112/500]	Time 47.290 (47.290)	Loss 0.2072 (0.2336)	CeLoss 0.0664 (0.0520)	SegCLSLoss 0.0017 (0.0014)	KLLoss 0.0052 (0.0043)	MaskLoss 0.0489 (0.0515)	MaskBCELoss 0.0304 (0.0148)	MaskDICELoss 0.0185 (0.0368)
Epoch: [4][113/500]	Time 44.461 (44.461)	Loss 0.4563 (0.3659)	CeLoss 0.0601 (0.0445)	SegCLSLoss 0.0009 (0.0020)	KLLoss 0.0029 (0.0035)	MaskLoss 0.1018 (0.0892)	MaskBCELoss 0.0071 (0.0199)	MaskDICELoss 0.0947 (0.0693)
Epoch: [4][114/500]	Time 47.626 (47.626)	Loss 0.4777 (0.3154)	CeLoss 0.0688 (0.0462)	SegCLSLoss 0.0015 (0.0009)	KLLoss 0.0046 (0.0035)	MaskLoss 0.1019 (0.0786)	MaskBCELoss 0.0019 (0.0245)	MaskDICELoss 0.0999 (0.0541)
Epoch: [4][115/500]	Time 48.261 (48.261)	Loss 0.3765 (0.3207)	CeLoss 0.0381 (0.0329)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0034 (0.0038)	MaskLoss 0.0916 (0.0832)	MaskBCELoss 0.0158 (0.0246)	MaskDICELoss 0.0758 (0.0587)
Epoch: [4][116/500]	Time 44.625 (44.625)	Loss 0.0473 (0.2896)	CeLoss 0.0474 (0.0441)	SegCLSLoss 0.0000 (0.0021)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0707)	MaskBCELoss 0.0000 (0.0206)	MaskDICELoss 0.0000 (0.0501)
Epoch: [4][117/500]	Time 46.961 (46.961)	Loss 0.4356 (0.3341)	CeLoss 0.0143 (0.0386)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0035 (0.0028)	MaskLoss 0.1096 (0.0864)	MaskBCELoss 0.0105 (0.0265)	MaskDICELoss 0.0992 (0.0599)
Epoch: [4][118/500]	Time 45.543 (45.543)	Loss 0.4190 (0.3244)	CeLoss 0.0232 (0.0372)	SegCLSLoss 0.0019 (0.0016)	KLLoss 0.0031 (0.0034)	MaskLoss 0.0983 (0.0814)	MaskBCELoss 0.0007 (0.0212)	MaskDICELoss 0.0976 (0.0602)
Epoch: [4][119/500]	Time 48.113 (48.113)	Loss 0.3504 (0.3220)	CeLoss 0.0781 (0.0429)	SegCLSLoss 0.0006 (0.0020)	KLLoss 0.0036 (0.0039)	MaskLoss 0.0738 (0.0767)	MaskBCELoss 0.0134 (0.0162)	MaskDICELoss 0.0604 (0.0605)
Epoch: [4][120/500]	Time 48.664 (48.664)	Loss 0.4541 (0.3103)	CeLoss 0.0625 (0.0585)	SegCLSLoss 0.0013 (0.0007)	KLLoss 0.0036 (0.0039)	MaskLoss 0.0988 (0.0680)	MaskBCELoss 0.0039 (0.0123)	MaskDICELoss 0.0949 (0.0557)
Epoch: [4][121/500]	Time 45.789 (45.789)	Loss 0.1943 (0.3225)	CeLoss 0.0461 (0.0414)	SegCLSLoss 0.0005 (0.0031)	KLLoss 0.0036 (0.0039)	MaskLoss 0.0580 (0.0801)	MaskBCELoss 0.0438 (0.0224)	MaskDICELoss 0.0142 (0.0577)
Epoch: [4][122/500]	Time 42.276 (42.276)	Loss 0.2133 (0.3555)	CeLoss 0.0177 (0.0406)	SegCLSLoss 0.0036 (0.0020)	KLLoss 0.0025 (0.0032)	MaskLoss 0.0593 (0.0918)	MaskBCELoss 0.0229 (0.0283)	MaskDICELoss 0.0364 (0.0635)
Epoch: [4][123/500]	Time 51.641 (51.641)	Loss 0.2008 (0.1771)	CeLoss 0.0811 (0.0366)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0025 (0.0027)	MaskLoss 0.0300 (0.0368)	MaskBCELoss 0.0016 (0.0049)	MaskDICELoss 0.0284 (0.0319)
Epoch: [4][124/500]	Time 46.353 (46.353)	Loss 0.0964 (0.3413)	CeLoss 0.0593 (0.0406)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0022 (0.0045)	MaskLoss 0.0112 (0.0798)	MaskBCELoss 0.0052 (0.0119)	MaskDICELoss 0.0061 (0.0679)
Epoch: [4][125/500]	Time 44.845 (44.845)	Loss 0.4656 (0.4170)	CeLoss 0.0586 (0.0453)	SegCLSLoss 0.0025 (0.0018)	KLLoss 0.0044 (0.0041)	MaskLoss 0.1011 (0.1054)	MaskBCELoss 0.0015 (0.0274)	MaskDICELoss 0.0996 (0.0780)
Epoch: [4][126/500]	Time 52.584 (52.584)	Loss 0.0117 (0.3359)	CeLoss 0.0117 (0.0395)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0802)	MaskBCELoss 0.0000 (0.0140)	MaskDICELoss 0.0000 (0.0662)
Epoch: [4][127/500]	Time 49.436 (49.436)	Loss 0.4450 (0.3335)	CeLoss 0.0261 (0.0435)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0054 (0.0036)	MaskLoss 0.1195 (0.0779)	MaskBCELoss 0.0325 (0.0129)	MaskDICELoss 0.0870 (0.0649)
Epoch: [4][128/500]	Time 40.937 (40.937)	Loss 0.3267 (0.3365)	CeLoss 0.0237 (0.0448)	SegCLSLoss 0.0050 (0.0016)	KLLoss 0.0052 (0.0036)	MaskLoss 0.0798 (0.0808)	MaskBCELoss 0.0119 (0.0179)	MaskDICELoss 0.0679 (0.0629)
Epoch: [4][129/500]	Time 46.121 (46.121)	Loss 0.5662 (0.3622)	CeLoss 0.0229 (0.0342)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0021 (0.0035)	MaskLoss 0.2111 (0.0935)	MaskBCELoss 0.1518 (0.0250)	MaskDICELoss 0.0593 (0.0684)
Epoch: [4][130/500]	Time 45.718 (45.718)	Loss 0.3954 (0.2848)	CeLoss 0.0188 (0.0396)	SegCLSLoss 0.0053 (0.0018)	KLLoss 0.0034 (0.0031)	MaskLoss 0.1074 (0.0656)	MaskBCELoss 0.0295 (0.0105)	MaskDICELoss 0.0779 (0.0551)
Epoch: [4][131/500]	Time 51.997 (51.997)	Loss 0.3477 (0.4048)	CeLoss 0.0542 (0.0439)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0034 (0.0046)	MaskLoss 0.0987 (0.0988)	MaskBCELoss 0.0526 (0.0198)	MaskDICELoss 0.0461 (0.0790)
Epoch: [4][132/500]	Time 43.454 (43.454)	Loss 0.4752 (0.3260)	CeLoss 0.0742 (0.0362)	SegCLSLoss 0.0010 (0.0023)	KLLoss 0.0040 (0.0041)	MaskLoss 0.1030 (0.0788)	MaskBCELoss 0.0076 (0.0154)	MaskDICELoss 0.0954 (0.0634)
Epoch: [4][133/500]	Time 51.363 (51.363)	Loss 0.3359 (0.3857)	CeLoss 0.0175 (0.0352)	SegCLSLoss 0.0017 (0.0013)	KLLoss 0.0045 (0.0044)	MaskLoss 0.0881 (0.0993)	MaskBCELoss 0.0197 (0.0258)	MaskDICELoss 0.0684 (0.0735)
Epoch: [4][134/500]	Time 49.964 (49.964)	Loss 0.3145 (0.2479)	CeLoss 0.0474 (0.0359)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0049 (0.0032)	MaskLoss 0.0793 (0.0627)	MaskBCELoss 0.0277 (0.0212)	MaskDICELoss 0.0516 (0.0415)
Epoch: [4][135/500]	Time 50.519 (50.519)	Loss 0.1679 (0.2643)	CeLoss 0.0476 (0.0367)	SegCLSLoss 0.0002 (0.0009)	KLLoss 0.0023 (0.0027)	MaskLoss 0.0383 (0.0606)	MaskBCELoss 0.0176 (0.0090)	MaskDICELoss 0.0207 (0.0516)
Epoch: [4][136/500]	Time 48.469 (48.469)	Loss 0.0847 (0.3935)	CeLoss 0.0227 (0.0490)	SegCLSLoss 0.0009 (0.0020)	KLLoss 0.0037 (0.0041)	MaskLoss 0.0206 (0.0991)	MaskBCELoss 0.0123 (0.0285)	MaskDICELoss 0.0083 (0.0706)
Epoch: [4][137/500]	Time 45.110 (45.110)	Loss 0.4410 (0.3226)	CeLoss 0.0347 (0.0492)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0026 (0.0037)	MaskLoss 0.1018 (0.0754)	MaskBCELoss 0.0021 (0.0162)	MaskDICELoss 0.0997 (0.0592)
Epoch: [4][138/500]	Time 54.679 (54.679)	Loss 0.0876 (0.3526)	CeLoss 0.0415 (0.0418)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0025 (0.0032)	MaskLoss 0.0114 (0.0869)	MaskBCELoss 0.0010 (0.0202)	MaskDICELoss 0.0104 (0.0667)
Epoch: [4][139/500]	Time 45.092 (45.092)	Loss 0.3146 (0.3646)	CeLoss 0.0581 (0.0459)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0043 (0.0041)	MaskLoss 0.0853 (0.0917)	MaskBCELoss 0.0447 (0.0263)	MaskDICELoss 0.0406 (0.0654)
Epoch: [4][140/500]	Time 47.775 (47.775)	Loss 0.2843 (0.2632)	CeLoss 0.0210 (0.0377)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0050 (0.0042)	MaskLoss 0.0729 (0.0625)	MaskBCELoss 0.0169 (0.0147)	MaskDICELoss 0.0560 (0.0479)
Epoch: [4][141/500]	Time 46.747 (46.747)	Loss 0.2473 (0.3411)	CeLoss 0.0250 (0.0344)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0031 (0.0033)	MaskLoss 0.0646 (0.0823)	MaskBCELoss 0.0199 (0.0134)	MaskDICELoss 0.0447 (0.0690)
Epoch: [4][142/500]	Time 48.257 (48.257)	Loss 0.4575 (0.4525)	CeLoss 0.0430 (0.0400)	SegCLSLoss 0.0006 (0.0009)	KLLoss 0.0029 (0.0045)	MaskLoss 0.1057 (0.1179)	MaskBCELoss 0.0058 (0.0321)	MaskDICELoss 0.0999 (0.0859)
Epoch: [4][143/500]	Time 53.621 (53.621)	Loss 0.4414 (0.3177)	CeLoss 0.0767 (0.0434)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0023 (0.0039)	MaskLoss 0.0934 (0.0754)	MaskBCELoss 0.0058 (0.0159)	MaskDICELoss 0.0877 (0.0595)
Epoch: [4][144/500]	Time 44.964 (44.964)	Loss 0.4197 (0.3523)	CeLoss 0.0237 (0.0459)	SegCLSLoss 0.0050 (0.0013)	KLLoss 0.0034 (0.0045)	MaskLoss 0.0983 (0.0822)	MaskBCELoss 0.0014 (0.0137)	MaskDICELoss 0.0969 (0.0685)
Epoch: [4][145/500]	Time 50.424 (50.424)	Loss 0.4736 (0.3652)	CeLoss 0.0693 (0.0480)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0027 (0.0036)	MaskLoss 0.1040 (0.0924)	MaskBCELoss 0.0078 (0.0284)	MaskDICELoss 0.0962 (0.0641)
Epoch: [4][146/500]	Time 43.823 (43.823)	Loss 0.0355 (0.2860)	CeLoss 0.0194 (0.0484)	SegCLSLoss 0.0008 (0.0022)	KLLoss 0.0033 (0.0033)	MaskLoss 0.0046 (0.0646)	MaskBCELoss 0.0030 (0.0126)	MaskDICELoss 0.0016 (0.0520)
Epoch: [4][147/500]	Time 46.956 (46.956)	Loss 0.1563 (0.3783)	CeLoss 0.0454 (0.0432)	SegCLSLoss 0.0003 (0.0020)	KLLoss 0.0042 (0.0046)	MaskLoss 0.0389 (0.0979)	MaskBCELoss 0.0245 (0.0311)	MaskDICELoss 0.0144 (0.0668)
Epoch: [4][148/500]	Time 43.480 (43.480)	Loss 0.4661 (0.4100)	CeLoss 0.0732 (0.0513)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0025 (0.0038)	MaskLoss 0.0980 (0.0966)	MaskBCELoss 0.0013 (0.0161)	MaskDICELoss 0.0967 (0.0805)
Epoch: [4][149/500]	Time 53.071 (53.071)	Loss 0.4608 (0.3127)	CeLoss 0.0250 (0.0322)	SegCLSLoss 0.0007 (0.0006)	KLLoss 0.0047 (0.0039)	MaskLoss 0.1272 (0.0777)	MaskBCELoss 0.0390 (0.0172)	MaskDICELoss 0.0882 (0.0605)
Epoch: [4][150/500]	Time 45.523 (45.523)	Loss 0.4344 (0.3184)	CeLoss 0.0208 (0.0473)	SegCLSLoss 0.0027 (0.0012)	KLLoss 0.0039 (0.0035)	MaskLoss 0.1042 (0.0735)	MaskBCELoss 0.0042 (0.0135)	MaskDICELoss 0.1000 (0.0600)
Epoch: [4][151/500]	Time 46.360 (46.360)	Loss 0.4842 (0.4176)	CeLoss 0.0742 (0.0505)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0045 (0.0046)	MaskLoss 0.1023 (0.1045)	MaskBCELoss 0.0023 (0.0281)	MaskDICELoss 0.1000 (0.0764)
Epoch: [4][152/500]	Time 48.327 (48.327)	Loss 0.4174 (0.2903)	CeLoss 0.0178 (0.0406)	SegCLSLoss 0.0019 (0.0010)	KLLoss 0.0048 (0.0035)	MaskLoss 0.1081 (0.0718)	MaskBCELoss 0.0194 (0.0207)	MaskDICELoss 0.0887 (0.0511)
Epoch: [4][153/500]	Time 44.402 (44.402)	Loss 0.2203 (0.3455)	CeLoss 0.0212 (0.0321)	SegCLSLoss 0.0014 (0.0017)	KLLoss 0.0044 (0.0043)	MaskLoss 0.0576 (0.0880)	MaskBCELoss 0.0182 (0.0217)	MaskDICELoss 0.0394 (0.0662)
Epoch: [4][154/500]	Time 45.232 (45.232)	Loss 0.2651 (0.3441)	CeLoss 0.0280 (0.0306)	SegCLSLoss 0.0007 (0.0013)	KLLoss 0.0049 (0.0041)	MaskLoss 0.0870 (0.0885)	MaskBCELoss 0.0580 (0.0226)	MaskDICELoss 0.0290 (0.0659)
Epoch: [4][155/500]	Time 45.064 (45.064)	Loss 0.0175 (0.3820)	CeLoss 0.0175 (0.0508)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0040)	MaskLoss 0.0000 (0.0907)	MaskBCELoss 0.0000 (0.0183)	MaskDICELoss 0.0000 (0.0724)
Epoch: [4][156/500]	Time 48.057 (48.057)	Loss 0.3324 (0.3217)	CeLoss 0.0825 (0.0483)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0038 (0.0037)	MaskLoss 0.0733 (0.0774)	MaskBCELoss 0.0238 (0.0202)	MaskDICELoss 0.0495 (0.0572)
Epoch: [4][157/500]	Time 49.664 (49.664)	Loss 0.3672 (0.3063)	CeLoss 0.0206 (0.0499)	SegCLSLoss 0.0028 (0.0009)	KLLoss 0.0031 (0.0040)	MaskLoss 0.0862 (0.0715)	MaskBCELoss 0.0014 (0.0170)	MaskDICELoss 0.0849 (0.0545)
Epoch: [4][158/500]	Time 43.071 (43.071)	Loss 0.0496 (0.3309)	CeLoss 0.0347 (0.0370)	SegCLSLoss 0.0003 (0.0018)	KLLoss 0.0026 (0.0040)	MaskLoss 0.0037 (0.0768)	MaskBCELoss 0.0014 (0.0092)	MaskDICELoss 0.0023 (0.0676)
Epoch: [4][159/500]	Time 54.095 (54.095)	Loss 0.2157 (0.3128)	CeLoss 0.0610 (0.0472)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0038 (0.0045)	MaskLoss 0.0536 (0.0748)	MaskBCELoss 0.0317 (0.0193)	MaskDICELoss 0.0219 (0.0555)
Epoch: [4][160/500]	Time 49.363 (49.363)	Loss 0.3096 (0.3157)	CeLoss 0.0540 (0.0350)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0045 (0.0032)	MaskLoss 0.0670 (0.0778)	MaskBCELoss 0.0087 (0.0171)	MaskDICELoss 0.0583 (0.0607)
Epoch: [4][161/500]	Time 49.626 (49.626)	Loss 0.4795 (0.3118)	CeLoss 0.0466 (0.0360)	SegCLSLoss 0.0005 (0.0017)	KLLoss 0.0034 (0.0036)	MaskLoss 0.1148 (0.0745)	MaskBCELoss 0.0151 (0.0134)	MaskDICELoss 0.0997 (0.0611)
Epoch: [4][162/500]	Time 45.242 (45.242)	Loss 0.4456 (0.3686)	CeLoss 0.0242 (0.0378)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0027 (0.0047)	MaskLoss 0.1185 (0.0886)	MaskBCELoss 0.0281 (0.0144)	MaskDICELoss 0.0905 (0.0742)
Epoch: [4][163/500]	Time 45.821 (45.821)	Loss 0.4231 (0.3067)	CeLoss 0.0181 (0.0353)	SegCLSLoss 0.0036 (0.0014)	KLLoss 0.0023 (0.0033)	MaskLoss 0.1005 (0.0716)	MaskBCELoss 0.0005 (0.0096)	MaskDICELoss 0.1000 (0.0621)
Epoch: [4][164/500]	Time 47.713 (47.713)	Loss 0.4083 (0.3549)	CeLoss 0.0210 (0.0426)	SegCLSLoss 0.0029 (0.0010)	KLLoss 0.0032 (0.0036)	MaskLoss 0.0984 (0.0869)	MaskBCELoss 0.0056 (0.0197)	MaskDICELoss 0.0928 (0.0672)
Epoch: [4][165/500]	Time 47.151 (47.151)	Loss 0.6096 (0.2960)	CeLoss 0.0459 (0.0356)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0058 (0.0033)	MaskLoss 0.1817 (0.0764)	MaskBCELoss 0.0847 (0.0247)	MaskDICELoss 0.0970 (0.0517)
Epoch: [4][166/500]	Time 45.553 (45.553)	Loss 0.5258 (0.3434)	CeLoss 0.0850 (0.0452)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0031 (0.0038)	MaskLoss 0.1192 (0.0795)	MaskBCELoss 0.0197 (0.0122)	MaskDICELoss 0.0995 (0.0674)
Epoch: [4][167/500]	Time 46.090 (46.090)	Loss 0.4288 (0.4098)	CeLoss 0.0234 (0.0264)	SegCLSLoss 0.0028 (0.0020)	KLLoss 0.0045 (0.0047)	MaskLoss 0.1022 (0.1081)	MaskBCELoss 0.0047 (0.0273)	MaskDICELoss 0.0976 (0.0808)
Epoch: [4][168/500]	Time 45.276 (45.276)	Loss 0.3449 (0.4135)	CeLoss 0.0693 (0.0539)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0045 (0.0038)	MaskLoss 0.0839 (0.1046)	MaskBCELoss 0.0328 (0.0317)	MaskDICELoss 0.0511 (0.0729)
Epoch: [4][169/500]	Time 49.877 (49.877)	Loss 0.3698 (0.3537)	CeLoss 0.0111 (0.0333)	SegCLSLoss 0.0003 (0.0013)	KLLoss 0.0033 (0.0040)	MaskLoss 0.1016 (0.0880)	MaskBCELoss 0.0255 (0.0180)	MaskDICELoss 0.0760 (0.0699)
Epoch: [4][170/500]	Time 49.930 (49.930)	Loss 0.4920 (0.3705)	CeLoss 0.0620 (0.0411)	SegCLSLoss 0.0009 (0.0009)	KLLoss 0.0027 (0.0036)	MaskLoss 0.1209 (0.0960)	MaskBCELoss 0.0284 (0.0293)	MaskDICELoss 0.0925 (0.0667)
Epoch: [4][171/500]	Time 49.112 (49.112)	Loss 0.4200 (0.3100)	CeLoss 0.0203 (0.0328)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0030 (0.0034)	MaskLoss 0.1016 (0.0763)	MaskBCELoss 0.0049 (0.0160)	MaskDICELoss 0.0967 (0.0603)
Epoch: [4][172/500]	Time 47.539 (47.539)	Loss 0.4343 (0.2703)	CeLoss 0.0231 (0.0446)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0041 (0.0023)	MaskLoss 0.1035 (0.0572)	MaskBCELoss 0.0036 (0.0029)	MaskDICELoss 0.0998 (0.0543)
Epoch: [4][173/500]	Time 50.263 (50.263)	Loss 0.3302 (0.3924)	CeLoss 0.0205 (0.0354)	SegCLSLoss 0.0027 (0.0013)	KLLoss 0.0043 (0.0044)	MaskLoss 0.0878 (0.0967)	MaskBCELoss 0.0236 (0.0175)	MaskDICELoss 0.0642 (0.0792)
Epoch: [4][174/500]	Time 50.222 (50.222)	Loss 0.4494 (0.3881)	CeLoss 0.0325 (0.0438)	SegCLSLoss 0.0008 (0.0009)	KLLoss 0.0076 (0.0046)	MaskLoss 0.1083 (0.0974)	MaskBCELoss 0.0121 (0.0252)	MaskDICELoss 0.0962 (0.0722)
Epoch: [4][175/500]	Time 45.039 (45.039)	Loss 0.4346 (0.3377)	CeLoss 0.0547 (0.0464)	SegCLSLoss 0.0047 (0.0019)	KLLoss 0.0057 (0.0049)	MaskLoss 0.1043 (0.0799)	MaskBCELoss 0.0225 (0.0171)	MaskDICELoss 0.0818 (0.0628)
Epoch: [4][176/500]	Time 45.789 (45.789)	Loss 0.4671 (0.3708)	CeLoss 0.0287 (0.0398)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0045 (0.0050)	MaskLoss 0.1172 (0.0933)	MaskBCELoss 0.0177 (0.0238)	MaskDICELoss 0.0995 (0.0695)
Epoch: [4][177/500]	Time 52.704 (52.704)	Loss 0.4484 (0.3697)	CeLoss 0.0310 (0.0480)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0045 (0.0040)	MaskLoss 0.1070 (0.0830)	MaskBCELoss 0.0077 (0.0073)	MaskDICELoss 0.0993 (0.0756)
Epoch: [4][178/500]	Time 50.775 (50.775)	Loss 0.4135 (0.3111)	CeLoss 0.1025 (0.0406)	SegCLSLoss 0.0038 (0.0014)	KLLoss 0.0031 (0.0037)	MaskLoss 0.0819 (0.0725)	MaskBCELoss 0.0106 (0.0119)	MaskDICELoss 0.0713 (0.0605)
Epoch: [4][179/500]	Time 50.761 (50.761)	Loss 0.3098 (0.3051)	CeLoss 0.0610 (0.0522)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0044 (0.0042)	MaskLoss 0.0728 (0.0759)	MaskBCELoss 0.0233 (0.0275)	MaskDICELoss 0.0495 (0.0483)
Epoch: [4][180/500]	Time 49.903 (49.903)	Loss 0.2137 (0.3507)	CeLoss 0.0227 (0.0370)	SegCLSLoss 0.0031 (0.0013)	KLLoss 0.0021 (0.0042)	MaskLoss 0.0516 (0.0897)	MaskBCELoss 0.0095 (0.0248)	MaskDICELoss 0.0421 (0.0648)
Epoch: [4][181/500]	Time 47.289 (47.289)	Loss 0.2924 (0.3965)	CeLoss 0.0223 (0.0356)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0067 (0.0036)	MaskLoss 0.0674 (0.1002)	MaskBCELoss 0.0032 (0.0221)	MaskDICELoss 0.0642 (0.0781)
Epoch: [4][182/500]	Time 48.544 (48.544)	Loss 0.3057 (0.4011)	CeLoss 0.0228 (0.0427)	SegCLSLoss 0.0039 (0.0014)	KLLoss 0.0044 (0.0046)	MaskLoss 0.0747 (0.0995)	MaskBCELoss 0.0112 (0.0223)	MaskDICELoss 0.0635 (0.0771)
Epoch: [4][183/500]	Time 48.048 (48.048)	Loss 0.4299 (0.3641)	CeLoss 0.0225 (0.0498)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0048 (0.0040)	MaskLoss 0.1013 (0.0870)	MaskBCELoss 0.0016 (0.0191)	MaskDICELoss 0.0998 (0.0679)
Epoch: [4][184/500]	Time 48.692 (48.692)	Loss 0.4390 (0.3279)	CeLoss 0.0258 (0.0423)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0040 (0.0036)	MaskLoss 0.1044 (0.0782)	MaskBCELoss 0.0044 (0.0156)	MaskDICELoss 0.1000 (0.0625)
Epoch: [4][185/500]	Time 52.295 (52.295)	Loss 0.3122 (0.3632)	CeLoss 0.1030 (0.0370)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0033 (0.0038)	MaskLoss 0.0600 (0.0988)	MaskBCELoss 0.0171 (0.0366)	MaskDICELoss 0.0430 (0.0622)
Epoch: [4][186/500]	Time 48.630 (48.630)	Loss 0.4741 (0.2926)	CeLoss 0.0508 (0.0375)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0041 (0.0027)	MaskLoss 0.1094 (0.0763)	MaskBCELoss 0.0097 (0.0266)	MaskDICELoss 0.0997 (0.0497)
Epoch: [4][187/500]	Time 42.728 (42.728)	Loss 0.4933 (0.3826)	CeLoss 0.0254 (0.0418)	SegCLSLoss 0.0009 (0.0017)	KLLoss 0.0044 (0.0039)	MaskLoss 0.1317 (0.0910)	MaskBCELoss 0.0317 (0.0139)	MaskDICELoss 0.0999 (0.0771)
Epoch: [4][188/500]	Time 52.774 (52.774)	Loss 0.3861 (0.3169)	CeLoss 0.0515 (0.0347)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0027 (0.0031)	MaskLoss 0.0943 (0.0793)	MaskBCELoss 0.0229 (0.0193)	MaskDICELoss 0.0714 (0.0600)
Epoch: [4][189/500]	Time 48.919 (48.919)	Loss 0.0422 (0.3140)	CeLoss 0.0422 (0.0432)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0039)	MaskLoss 0.0000 (0.0715)	MaskBCELoss 0.0000 (0.0099)	MaskDICELoss 0.0000 (0.0616)
Epoch: [4][190/500]	Time 48.664 (48.664)	Loss 0.4915 (0.3268)	CeLoss 0.0845 (0.0374)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0050 (0.0039)	MaskLoss 0.1009 (0.0767)	MaskBCELoss 0.0009 (0.0110)	MaskDICELoss 0.1000 (0.0657)
Epoch: [4][191/500]	Time 48.571 (48.571)	Loss 0.3551 (0.2854)	CeLoss 0.0215 (0.0385)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0049 (0.0038)	MaskLoss 0.0927 (0.0674)	MaskBCELoss 0.0213 (0.0135)	MaskDICELoss 0.0714 (0.0539)
Epoch: [4][192/500]	Time 52.191 (52.191)	Loss 0.4325 (0.3415)	CeLoss 0.0123 (0.0372)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0032 (0.0028)	MaskLoss 0.1172 (0.0855)	MaskBCELoss 0.0261 (0.0204)	MaskDICELoss 0.0911 (0.0651)
Epoch: [4][193/500]	Time 45.467 (45.467)	Loss 0.4127 (0.2596)	CeLoss 0.0260 (0.0392)	SegCLSLoss 0.0027 (0.0010)	KLLoss 0.0029 (0.0029)	MaskLoss 0.0970 (0.0582)	MaskBCELoss 0.0027 (0.0079)	MaskDICELoss 0.0942 (0.0503)
Epoch: [4][194/500]	Time 50.113 (50.113)	Loss 0.3988 (0.3871)	CeLoss 0.0703 (0.0345)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0030 (0.0035)	MaskLoss 0.0853 (0.0958)	MaskBCELoss 0.0080 (0.0174)	MaskDICELoss 0.0772 (0.0784)
Epoch: [4][195/500]	Time 48.345 (48.345)	Loss 0.3752 (0.3028)	CeLoss 0.0254 (0.0286)	SegCLSLoss 0.0022 (0.0013)	KLLoss 0.0051 (0.0034)	MaskLoss 0.0947 (0.0745)	MaskBCELoss 0.0177 (0.0139)	MaskDICELoss 0.0771 (0.0606)
Epoch: [4][196/500]	Time 47.167 (47.167)	Loss 0.0511 (0.2902)	CeLoss 0.0369 (0.0425)	SegCLSLoss 0.0002 (0.0019)	KLLoss 0.0026 (0.0033)	MaskLoss 0.0030 (0.0630)	MaskBCELoss 0.0002 (0.0043)	MaskDICELoss 0.0028 (0.0588)
Epoch: [4][197/500]	Time 65.258 (65.258)	Loss 0.0727 (0.3141)	CeLoss 0.0219 (0.0465)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0028 (0.0033)	MaskLoss 0.0139 (0.0751)	MaskBCELoss 0.0041 (0.0183)	MaskDICELoss 0.0098 (0.0567)
Epoch: [4][198/500]	Time 75.106 (75.106)	Loss 0.2773 (0.3767)	CeLoss 0.0143 (0.0375)	SegCLSLoss 0.0012 (0.0014)	KLLoss 0.0033 (0.0037)	MaskLoss 0.0728 (0.0917)	MaskBCELoss 0.0160 (0.0159)	MaskDICELoss 0.0568 (0.0757)
Epoch: [4][199/500]	Time 82.142 (82.142)	Loss 0.4511 (0.2940)	CeLoss 0.0593 (0.0407)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0031 (0.0041)	MaskLoss 0.0977 (0.0747)	MaskBCELoss 0.0013 (0.0250)	MaskDICELoss 0.0964 (0.0497)
[2025-03-12 13:29:49,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[0.0002721325301204819], mom=[(0.9, 0.95)]
[2025-03-12 13:29:49,820] [INFO] [timer.py:215:stop] epoch=0/micro_step=2200/global_step=220, RunningAvgSamplesPerSec=0.6406225269676187, CurrSamplesPerSec=0.6715145736358824, MemAllocated=59.42GB, MaxMemAllocated=74.71GB
Epoch: [4][200/500]	Time 72.004 (72.004)	Loss 0.3179 (0.3270)	CeLoss 0.0181 (0.0394)	SegCLSLoss 0.0081 (0.0027)	KLLoss 0.0053 (0.0034)	MaskLoss 0.0873 (0.0833)	MaskBCELoss 0.0294 (0.0251)	MaskDICELoss 0.0580 (0.0582)
Epoch: [4][201/500]	Time 78.858 (78.858)	Loss 0.1839 (0.2919)	CeLoss 0.0542 (0.0363)	SegCLSLoss 0.0021 (0.0016)	KLLoss 0.0068 (0.0040)	MaskLoss 0.0314 (0.0696)	MaskBCELoss 0.0020 (0.0138)	MaskDICELoss 0.0294 (0.0558)
Epoch: [4][202/500]	Time 74.934 (74.934)	Loss 0.3788 (0.3326)	CeLoss 0.0231 (0.0377)	SegCLSLoss 0.0016 (0.0018)	KLLoss 0.0039 (0.0034)	MaskLoss 0.1096 (0.0821)	MaskBCELoss 0.0436 (0.0188)	MaskDICELoss 0.0660 (0.0632)
Epoch: [4][203/500]	Time 79.626 (79.626)	Loss 0.0151 (0.3271)	CeLoss 0.0151 (0.0369)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0844)	MaskBCELoss 0.0000 (0.0254)	MaskDICELoss 0.0000 (0.0590)
Epoch: [4][204/500]	Time 71.944 (71.944)	Loss 0.2964 (0.4085)	CeLoss 0.0219 (0.0431)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0042 (0.0033)	MaskLoss 0.0714 (0.0983)	MaskBCELoss 0.0078 (0.0159)	MaskDICELoss 0.0636 (0.0824)
Epoch: [4][205/500]	Time 79.312 (79.312)	Loss 0.4308 (0.3054)	CeLoss 0.0237 (0.0374)	SegCLSLoss 0.0011 (0.0019)	KLLoss 0.0021 (0.0032)	MaskLoss 0.1023 (0.0766)	MaskBCELoss 0.0024 (0.0212)	MaskDICELoss 0.0999 (0.0554)
Epoch: [4][206/500]	Time 67.599 (67.599)	Loss 0.0540 (0.2790)	CeLoss 0.0248 (0.0347)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0029 (0.0027)	MaskLoss 0.0088 (0.0652)	MaskBCELoss 0.0047 (0.0098)	MaskDICELoss 0.0041 (0.0554)
Epoch: [4][207/500]	Time 46.997 (46.997)	Loss 0.4182 (0.3847)	CeLoss 0.0410 (0.0592)	SegCLSLoss 0.0028 (0.0008)	KLLoss 0.0055 (0.0046)	MaskLoss 0.1262 (0.0913)	MaskBCELoss 0.0673 (0.0223)	MaskDICELoss 0.0589 (0.0690)
Epoch: [4][208/500]	Time 51.176 (51.176)	Loss 0.4949 (0.3914)	CeLoss 0.0801 (0.0605)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0033 (0.0026)	MaskLoss 0.1066 (0.0902)	MaskBCELoss 0.0076 (0.0163)	MaskDICELoss 0.0990 (0.0739)
Epoch: [4][209/500]	Time 41.730 (41.730)	Loss 0.3434 (0.3332)	CeLoss 0.0287 (0.0459)	SegCLSLoss 0.0004 (0.0015)	KLLoss 0.0029 (0.0042)	MaskLoss 0.1090 (0.0834)	MaskBCELoss 0.0623 (0.0257)	MaskDICELoss 0.0468 (0.0577)
Epoch: [4][210/500]	Time 45.479 (45.479)	Loss 1.0111 (0.3667)	CeLoss 0.0242 (0.0345)	SegCLSLoss 0.0017 (0.0013)	KLLoss 0.0035 (0.0033)	MaskLoss 0.4348 (0.1115)	MaskBCELoss 0.3783 (0.0590)	MaskDICELoss 0.0565 (0.0526)
Epoch: [4][211/500]	Time 46.736 (46.736)	Loss 0.2154 (0.3784)	CeLoss 0.0488 (0.0376)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0040 (0.0048)	MaskLoss 0.0427 (0.1038)	MaskBCELoss 0.0042 (0.0398)	MaskDICELoss 0.0385 (0.0640)
Epoch: [4][212/500]	Time 44.618 (44.618)	Loss 0.3414 (0.2653)	CeLoss 0.0742 (0.0443)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0052 (0.0033)	MaskLoss 0.0668 (0.0637)	MaskBCELoss 0.0027 (0.0188)	MaskDICELoss 0.0641 (0.0448)
Epoch: [4][213/500]	Time 50.034 (50.034)	Loss 0.4108 (0.3744)	CeLoss 0.0217 (0.0356)	SegCLSLoss 0.0012 (0.0009)	KLLoss 0.0030 (0.0035)	MaskLoss 0.0988 (0.0918)	MaskBCELoss 0.0050 (0.0162)	MaskDICELoss 0.0939 (0.0756)
Epoch: [4][214/500]	Time 50.658 (50.658)	Loss 0.2420 (0.3017)	CeLoss 0.0420 (0.0327)	SegCLSLoss 0.0008 (0.0009)	KLLoss 0.0039 (0.0033)	MaskLoss 0.0558 (0.0783)	MaskBCELoss 0.0138 (0.0240)	MaskDICELoss 0.0420 (0.0543)
Epoch: [4][215/500]	Time 48.111 (48.111)	Loss 0.4378 (0.3314)	CeLoss 0.0193 (0.0380)	SegCLSLoss 0.0034 (0.0017)	KLLoss 0.0033 (0.0031)	MaskLoss 0.1076 (0.0819)	MaskBCELoss 0.0085 (0.0191)	MaskDICELoss 0.0991 (0.0628)
Epoch: [4][216/500]	Time 48.441 (48.441)	Loss 0.5004 (0.3529)	CeLoss 0.0630 (0.0357)	SegCLSLoss 0.0004 (0.0016)	KLLoss 0.0045 (0.0035)	MaskLoss 0.1460 (0.0907)	MaskBCELoss 0.0755 (0.0249)	MaskDICELoss 0.0705 (0.0658)
Epoch: [4][217/500]	Time 50.797 (50.797)	Loss 0.4083 (0.4626)	CeLoss 0.0391 (0.0458)	SegCLSLoss 0.0007 (0.0009)	KLLoss 0.0041 (0.0042)	MaskLoss 0.1165 (0.1196)	MaskBCELoss 0.0507 (0.0331)	MaskDICELoss 0.0658 (0.0865)
Epoch: [4][218/500]	Time 49.842 (49.842)	Loss 0.2354 (0.3213)	CeLoss 0.0732 (0.0351)	SegCLSLoss 0.0008 (0.0017)	KLLoss 0.0029 (0.0030)	MaskLoss 0.0493 (0.0774)	MaskBCELoss 0.0192 (0.0136)	MaskDICELoss 0.0301 (0.0638)
Epoch: [4][219/500]	Time 46.934 (46.934)	Loss 0.5524 (0.4061)	CeLoss 0.0183 (0.0475)	SegCLSLoss 0.0064 (0.0014)	KLLoss 0.0039 (0.0032)	MaskLoss 0.1674 (0.1041)	MaskBCELoss 0.0714 (0.0309)	MaskDICELoss 0.0961 (0.0732)
Epoch: [4][220/500]	Time 48.860 (48.860)	Loss 0.5057 (0.4152)	CeLoss 0.0830 (0.0436)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0027 (0.0029)	MaskLoss 0.1097 (0.1030)	MaskBCELoss 0.0097 (0.0218)	MaskDICELoss 0.1000 (0.0811)
Epoch: [4][221/500]	Time 46.327 (46.327)	Loss 0.4331 (0.3001)	CeLoss 0.0378 (0.0443)	SegCLSLoss 0.0007 (0.0007)	KLLoss 0.0035 (0.0029)	MaskLoss 0.1077 (0.0704)	MaskBCELoss 0.0197 (0.0145)	MaskDICELoss 0.0880 (0.0559)
Epoch: [4][222/500]	Time 45.234 (45.234)	Loss 0.3708 (0.3384)	CeLoss 0.0131 (0.0409)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0022 (0.0028)	MaskLoss 0.0917 (0.0829)	MaskBCELoss 0.0062 (0.0188)	MaskDICELoss 0.0856 (0.0641)
Epoch: [4][223/500]	Time 51.213 (51.213)	Loss 0.5139 (0.3198)	CeLoss 0.0840 (0.0443)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0038 (0.0022)	MaskLoss 0.1128 (0.0722)	MaskBCELoss 0.0128 (0.0080)	MaskDICELoss 0.1000 (0.0642)
Epoch: [4][224/500]	Time 45.503 (45.503)	Loss 0.1548 (0.3383)	CeLoss 0.0092 (0.0394)	SegCLSLoss 0.0003 (0.0018)	KLLoss 0.0027 (0.0030)	MaskLoss 0.0396 (0.0827)	MaskBCELoss 0.0079 (0.0180)	MaskDICELoss 0.0317 (0.0648)
Epoch: [4][225/500]	Time 45.117 (45.117)	Loss 0.4631 (0.4199)	CeLoss 0.0320 (0.0400)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0023 (0.0035)	MaskLoss 0.1157 (0.1096)	MaskBCELoss 0.0173 (0.0314)	MaskDICELoss 0.0984 (0.0782)
Epoch: [4][226/500]	Time 50.387 (50.387)	Loss 0.4317 (0.2866)	CeLoss 0.0811 (0.0344)	SegCLSLoss 0.0002 (0.0010)	KLLoss 0.0068 (0.0035)	MaskLoss 0.0907 (0.0672)	MaskBCELoss 0.0092 (0.0104)	MaskDICELoss 0.0814 (0.0569)
Epoch: [4][227/500]	Time 50.615 (50.615)	Loss 0.3874 (0.3610)	CeLoss 0.0645 (0.0505)	SegCLSLoss 0.0033 (0.0013)	KLLoss 0.0029 (0.0033)	MaskLoss 0.1001 (0.0858)	MaskBCELoss 0.0409 (0.0184)	MaskDICELoss 0.0592 (0.0675)
Epoch: [4][228/500]	Time 49.488 (49.488)	Loss 0.4802 (0.3454)	CeLoss 0.0254 (0.0313)	SegCLSLoss 0.0011 (0.0012)	KLLoss 0.0063 (0.0044)	MaskLoss 0.1246 (0.0847)	MaskBCELoss 0.0252 (0.0148)	MaskDICELoss 0.0994 (0.0699)
Epoch: [4][229/500]	Time 48.916 (48.916)	Loss 0.3973 (0.2879)	CeLoss 0.0208 (0.0392)	SegCLSLoss 0.0017 (0.0015)	KLLoss 0.0049 (0.0036)	MaskLoss 0.0949 (0.0735)	MaskBCELoss 0.0043 (0.0248)	MaskDICELoss 0.0905 (0.0487)
Epoch: [4][230/500]	Time 54.222 (54.222)	Loss 0.4454 (0.2265)	CeLoss 0.0251 (0.0318)	SegCLSLoss 0.0011 (0.0005)	KLLoss 0.0023 (0.0026)	MaskLoss 0.1088 (0.0541)	MaskBCELoss 0.0090 (0.0123)	MaskDICELoss 0.0998 (0.0418)
Epoch: [4][231/500]	Time 46.130 (46.130)	Loss 0.1017 (0.3321)	CeLoss 0.0264 (0.0375)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0024 (0.0034)	MaskLoss 0.0205 (0.0833)	MaskBCELoss 0.0049 (0.0213)	MaskDICELoss 0.0156 (0.0620)
Epoch: [4][232/500]	Time 47.520 (47.520)	Loss 0.4125 (0.2862)	CeLoss 0.0649 (0.0440)	SegCLSLoss 0.0041 (0.0012)	KLLoss 0.0037 (0.0026)	MaskLoss 0.0978 (0.0648)	MaskBCELoss 0.0245 (0.0101)	MaskDICELoss 0.0733 (0.0547)
Epoch: [4][233/500]	Time 51.737 (51.737)	Loss 0.0128 (0.3308)	CeLoss 0.0128 (0.0333)	SegCLSLoss 0.0000 (0.0009)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0826)	MaskBCELoss 0.0000 (0.0183)	MaskDICELoss 0.0000 (0.0644)
Epoch: [4][234/500]	Time 49.379 (49.379)	Loss 0.1422 (0.3336)	CeLoss 0.0306 (0.0382)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0024 (0.0028)	MaskLoss 0.0312 (0.0814)	MaskBCELoss 0.0080 (0.0166)	MaskDICELoss 0.0233 (0.0647)
Epoch: [4][235/500]	Time 49.739 (49.739)	Loss 0.4637 (0.3797)	CeLoss 0.0591 (0.0439)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0047 (0.0035)	MaskLoss 0.1157 (0.0991)	MaskBCELoss 0.0314 (0.0322)	MaskDICELoss 0.0843 (0.0668)
Epoch: [4][236/500]	Time 44.389 (44.389)	Loss 0.4518 (0.3808)	CeLoss 0.0713 (0.0744)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0019 (0.0033)	MaskLoss 0.0947 (0.0826)	MaskBCELoss 0.0006 (0.0139)	MaskDICELoss 0.0941 (0.0687)
Epoch: [4][237/500]	Time 49.926 (49.926)	Loss 0.3584 (0.3839)	CeLoss 0.0334 (0.0302)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0046 (0.0045)	MaskLoss 0.0869 (0.0935)	MaskBCELoss 0.0142 (0.0128)	MaskDICELoss 0.0727 (0.0807)
Epoch: [4][238/500]	Time 44.540 (44.540)	Loss 0.3031 (0.3920)	CeLoss 0.0249 (0.0602)	SegCLSLoss 0.0041 (0.0012)	KLLoss 0.0034 (0.0035)	MaskLoss 0.0793 (0.0941)	MaskBCELoss 0.0223 (0.0244)	MaskDICELoss 0.0571 (0.0697)
Epoch: [4][239/500]	Time 48.096 (48.096)	Loss 0.2362 (0.3543)	CeLoss 0.0260 (0.0404)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0031 (0.0041)	MaskLoss 0.0662 (0.0952)	MaskBCELoss 0.0290 (0.0357)	MaskDICELoss 0.0372 (0.0594)
Epoch: [4][240/500]	Time 44.916 (44.916)	Loss 0.2433 (0.3097)	CeLoss 0.0199 (0.0436)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0033 (0.0033)	MaskLoss 0.0647 (0.0712)	MaskBCELoss 0.0198 (0.0113)	MaskDICELoss 0.0450 (0.0599)
Epoch: [4][241/500]	Time 45.184 (45.184)	Loss 0.0754 (0.3189)	CeLoss 0.0752 (0.0455)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0752)	MaskBCELoss 0.0000 (0.0156)	MaskDICELoss 0.0000 (0.0596)
Epoch: [4][242/500]	Time 47.015 (47.015)	Loss 0.3749 (0.2823)	CeLoss 0.0254 (0.0424)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0035 (0.0026)	MaskLoss 0.0908 (0.0707)	MaskBCELoss 0.0087 (0.0229)	MaskDICELoss 0.0821 (0.0477)
Epoch: [4][243/500]	Time 45.761 (45.761)	Loss 0.1869 (0.3970)	CeLoss 0.0240 (0.0597)	SegCLSLoss 0.0015 (0.0012)	KLLoss 0.0040 (0.0031)	MaskLoss 0.0463 (0.0907)	MaskBCELoss 0.0136 (0.0147)	MaskDICELoss 0.0327 (0.0760)
Epoch: [4][244/500]	Time 52.108 (52.108)	Loss 0.3845 (0.2015)	CeLoss 0.0209 (0.0315)	SegCLSLoss 0.0063 (0.0017)	KLLoss 0.0043 (0.0032)	MaskLoss 0.1141 (0.0486)	MaskBCELoss 0.0501 (0.0142)	MaskDICELoss 0.0640 (0.0344)
Epoch: [4][245/500]	Time 52.195 (52.195)	Loss 0.4423 (0.3160)	CeLoss 0.0752 (0.0376)	SegCLSLoss 0.0023 (0.0013)	KLLoss 0.0027 (0.0032)	MaskLoss 0.0926 (0.0756)	MaskBCELoss 0.0037 (0.0140)	MaskDICELoss 0.0889 (0.0616)
Epoch: [4][246/500]	Time 52.743 (52.743)	Loss 0.1516 (0.2566)	CeLoss 0.0791 (0.0398)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0023 (0.0027)	MaskLoss 0.0198 (0.0624)	MaskBCELoss 0.0050 (0.0180)	MaskDICELoss 0.0148 (0.0444)
Epoch: [4][247/500]	Time 44.183 (44.183)	Loss 0.5003 (0.3143)	CeLoss 0.0903 (0.0393)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0033 (0.0032)	MaskLoss 0.1040 (0.0732)	MaskBCELoss 0.0047 (0.0107)	MaskDICELoss 0.0993 (0.0625)
Epoch: [4][248/500]	Time 46.923 (46.923)	Loss 0.2960 (0.2954)	CeLoss 0.0254 (0.0360)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0041 (0.0034)	MaskLoss 0.0740 (0.0763)	MaskBCELoss 0.0150 (0.0248)	MaskDICELoss 0.0590 (0.0515)
Epoch: [4][249/500]	Time 48.884 (48.884)	Loss 0.2180 (0.3115)	CeLoss 0.0771 (0.0447)	SegCLSLoss 0.0003 (0.0005)	KLLoss 0.0032 (0.0030)	MaskLoss 0.0535 (0.0712)	MaskBCELoss 0.0381 (0.0107)	MaskDICELoss 0.0154 (0.0605)
Epoch: [4][250/500]	Time 46.154 (46.154)	Loss 0.4447 (0.2463)	CeLoss 0.0869 (0.0419)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0026 (0.0027)	MaskLoss 0.0906 (0.0539)	MaskBCELoss 0.0042 (0.0072)	MaskDICELoss 0.0864 (0.0467)
Epoch: [4][251/500]	Time 50.356 (50.356)	Loss 0.5160 (0.3823)	CeLoss 0.0698 (0.0521)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0053 (0.0037)	MaskLoss 0.1249 (0.0875)	MaskBCELoss 0.0295 (0.0120)	MaskDICELoss 0.0954 (0.0755)
Epoch: [4][252/500]	Time 45.731 (45.731)	Loss 0.0291 (0.3268)	CeLoss 0.0291 (0.0377)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0822)	MaskBCELoss 0.0000 (0.0219)	MaskDICELoss 0.0000 (0.0603)
Epoch: [4][253/500]	Time 46.123 (46.123)	Loss 0.1043 (0.3435)	CeLoss 0.0776 (0.0424)	SegCLSLoss 0.0007 (0.0007)	KLLoss 0.0025 (0.0036)	MaskLoss 0.0067 (0.0872)	MaskBCELoss 0.0014 (0.0258)	MaskDICELoss 0.0052 (0.0614)
Epoch: [4][254/500]	Time 49.710 (49.710)	Loss 0.4283 (0.3986)	CeLoss 0.0208 (0.0421)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0040 (0.0036)	MaskLoss 0.1015 (0.0992)	MaskBCELoss 0.0016 (0.0223)	MaskDICELoss 0.0999 (0.0769)
Epoch: [4][255/500]	Time 48.598 (48.598)	Loss 0.4571 (0.3373)	CeLoss 0.0552 (0.0346)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0042 (0.0032)	MaskLoss 0.1000 (0.0836)	MaskBCELoss 0.0014 (0.0179)	MaskDICELoss 0.0986 (0.0658)
Epoch: [4][256/500]	Time 49.489 (49.489)	Loss 0.0626 (0.3505)	CeLoss 0.0243 (0.0335)	SegCLSLoss 0.0013 (0.0012)	KLLoss 0.0037 (0.0044)	MaskLoss 0.0104 (0.0909)	MaskBCELoss 0.0038 (0.0257)	MaskDICELoss 0.0066 (0.0651)
Epoch: [4][257/500]	Time 49.577 (49.577)	Loss 0.4400 (0.3365)	CeLoss 0.0203 (0.0288)	SegCLSLoss 0.0017 (0.0014)	KLLoss 0.0029 (0.0032)	MaskLoss 0.1299 (0.0805)	MaskBCELoss 0.0518 (0.0091)	MaskDICELoss 0.0781 (0.0714)
Epoch: [4][258/500]	Time 49.278 (49.278)	Loss 0.0141 (0.2927)	CeLoss 0.0140 (0.0287)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0701)	MaskBCELoss 0.0000 (0.0100)	MaskDICELoss 0.0000 (0.0601)
Epoch: [4][259/500]	Time 49.137 (49.137)	Loss 0.3363 (0.3751)	CeLoss 0.0214 (0.0369)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0027 (0.0035)	MaskLoss 0.0782 (0.0904)	MaskBCELoss 0.0007 (0.0139)	MaskDICELoss 0.0775 (0.0766)
Epoch: [4][260/500]	Time 49.216 (49.216)	Loss 0.1707 (0.3502)	CeLoss 0.0618 (0.0539)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0031 (0.0031)	MaskLoss 0.0340 (0.0800)	MaskBCELoss 0.0152 (0.0136)	MaskDICELoss 0.0188 (0.0664)
Epoch: [4][261/500]	Time 45.812 (45.812)	Loss 0.3659 (0.3543)	CeLoss 0.0364 (0.0505)	SegCLSLoss 0.0014 (0.0011)	KLLoss 0.0042 (0.0036)	MaskLoss 0.0965 (0.0809)	MaskBCELoss 0.0306 (0.0119)	MaskDICELoss 0.0659 (0.0689)
Epoch: [4][262/500]	Time 49.710 (49.710)	Loss 0.4497 (0.3828)	CeLoss 0.0444 (0.0392)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0022 (0.0035)	MaskLoss 0.1013 (0.0968)	MaskBCELoss 0.0013 (0.0240)	MaskDICELoss 0.1000 (0.0728)
Epoch: [4][263/500]	Time 48.508 (48.508)	Loss 0.4244 (0.3503)	CeLoss 0.0217 (0.0361)	SegCLSLoss 0.0014 (0.0009)	KLLoss 0.0027 (0.0032)	MaskLoss 0.1029 (0.0863)	MaskBCELoss 0.0062 (0.0174)	MaskDICELoss 0.0967 (0.0689)
Epoch: [4][264/500]	Time 48.507 (48.507)	Loss 0.2566 (0.3583)	CeLoss 0.0239 (0.0361)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0033 (0.0027)	MaskLoss 0.0577 (0.0886)	MaskBCELoss 0.0010 (0.0178)	MaskDICELoss 0.0567 (0.0708)
Epoch: [4][265/500]	Time 46.528 (46.528)	Loss 0.1146 (0.3739)	CeLoss 0.0211 (0.0553)	SegCLSLoss 0.0031 (0.0018)	KLLoss 0.0037 (0.0035)	MaskLoss 0.0311 (0.0875)	MaskBCELoss 0.0180 (0.0179)	MaskDICELoss 0.0130 (0.0696)
Epoch: [4][266/500]	Time 44.920 (44.920)	Loss 0.5135 (0.3705)	CeLoss 0.0359 (0.0364)	SegCLSLoss 0.0011 (0.0013)	KLLoss 0.0052 (0.0034)	MaskLoss 0.1524 (0.0959)	MaskBCELoss 0.0689 (0.0266)	MaskDICELoss 0.0835 (0.0692)
Epoch: [4][267/500]	Time 49.410 (49.410)	Loss 0.5102 (0.3234)	CeLoss 0.0320 (0.0289)	SegCLSLoss 0.0003 (0.0017)	KLLoss 0.0054 (0.0031)	MaskLoss 0.1513 (0.0782)	MaskBCELoss 0.0663 (0.0112)	MaskDICELoss 0.0850 (0.0670)
Epoch: [4][268/500]	Time 50.429 (50.429)	Loss 0.4327 (0.4043)	CeLoss 0.0222 (0.0332)	SegCLSLoss 0.0020 (0.0018)	KLLoss 0.0025 (0.0038)	MaskLoss 0.1035 (0.1027)	MaskBCELoss 0.0036 (0.0221)	MaskDICELoss 0.1000 (0.0806)
Epoch: [4][269/500]	Time 52.661 (52.661)	Loss 0.4407 (0.3761)	CeLoss 0.0208 (0.0324)	SegCLSLoss 0.0012 (0.0009)	KLLoss 0.0031 (0.0028)	MaskLoss 0.1083 (0.0905)	MaskBCELoss 0.0084 (0.0107)	MaskDICELoss 0.0999 (0.0798)
Epoch: [4][270/500]	Time 44.242 (44.242)	Loss 0.2597 (0.3589)	CeLoss 0.0437 (0.0404)	SegCLSLoss 0.0005 (0.0023)	KLLoss 0.0028 (0.0040)	MaskLoss 0.0742 (0.0872)	MaskBCELoss 0.0419 (0.0177)	MaskDICELoss 0.0323 (0.0695)
Epoch: [4][271/500]	Time 46.743 (46.743)	Loss 0.4829 (0.2788)	CeLoss 0.0781 (0.0464)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0022 (0.0029)	MaskLoss 0.1010 (0.0651)	MaskBCELoss 0.0010 (0.0157)	MaskDICELoss 0.1000 (0.0494)
Epoch: [4][272/500]	Time 50.325 (50.325)	Loss 0.0170 (0.2715)	CeLoss 0.0170 (0.0479)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0571)	MaskBCELoss 0.0000 (0.0040)	MaskDICELoss 0.0000 (0.0531)
Epoch: [4][273/500]	Time 44.735 (44.735)	Loss 0.4272 (0.3408)	CeLoss 0.0216 (0.0446)	SegCLSLoss 0.0039 (0.0015)	KLLoss 0.0027 (0.0029)	MaskLoss 0.1005 (0.0808)	MaskBCELoss 0.0005 (0.0154)	MaskDICELoss 0.1000 (0.0654)
Epoch: [4][274/500]	Time 45.393 (45.393)	Loss 0.3538 (0.3484)	CeLoss 0.0771 (0.0577)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0037 (0.0038)	MaskLoss 0.0741 (0.0774)	MaskBCELoss 0.0116 (0.0116)	MaskDICELoss 0.0625 (0.0659)
Epoch: [4][275/500]	Time 46.322 (46.322)	Loss 0.3213 (0.3998)	CeLoss 0.0215 (0.0359)	SegCLSLoss 0.0021 (0.0011)	KLLoss 0.0026 (0.0035)	MaskLoss 0.0948 (0.1051)	MaskBCELoss 0.0416 (0.0302)	MaskDICELoss 0.0532 (0.0748)
Epoch: [4][276/500]	Time 48.361 (48.361)	Loss 0.2585 (0.3040)	CeLoss 0.0103 (0.0361)	SegCLSLoss 0.0007 (0.0020)	KLLoss 0.0017 (0.0036)	MaskLoss 0.0633 (0.0740)	MaskBCELoss 0.0036 (0.0164)	MaskDICELoss 0.0598 (0.0576)
Epoch: [4][277/500]	Time 48.351 (48.351)	Loss 0.2084 (0.3312)	CeLoss 0.0405 (0.0434)	SegCLSLoss 0.0003 (0.0010)	KLLoss 0.0040 (0.0036)	MaskLoss 0.0504 (0.0779)	MaskBCELoss 0.0190 (0.0140)	MaskDICELoss 0.0315 (0.0639)
Epoch: [4][278/500]	Time 49.647 (49.647)	Loss 0.1927 (0.3419)	CeLoss 0.0203 (0.0350)	SegCLSLoss 0.0017 (0.0011)	KLLoss 0.0049 (0.0029)	MaskLoss 0.0487 (0.0868)	MaskBCELoss 0.0141 (0.0219)	MaskDICELoss 0.0346 (0.0649)
Epoch: [4][279/500]	Time 44.553 (44.553)	Loss 0.3910 (0.3629)	CeLoss 0.0366 (0.0541)	SegCLSLoss 0.0030 (0.0020)	KLLoss 0.0026 (0.0043)	MaskLoss 0.0896 (0.0848)	MaskBCELoss 0.0040 (0.0178)	MaskDICELoss 0.0856 (0.0670)
Epoch: [4][280/500]	Time 51.473 (51.473)	Loss 0.4619 (0.2894)	CeLoss 0.0289 (0.0352)	SegCLSLoss 0.0004 (0.0006)	KLLoss 0.0033 (0.0028)	MaskLoss 0.1151 (0.0650)	MaskBCELoss 0.0156 (0.0043)	MaskDICELoss 0.0996 (0.0606)
Epoch: [4][281/500]	Time 49.397 (49.397)	Loss 0.4395 (0.2525)	CeLoss 0.0369 (0.0424)	SegCLSLoss 0.0020 (0.0010)	KLLoss 0.0039 (0.0031)	MaskLoss 0.1011 (0.0539)	MaskBCELoss 0.0034 (0.0045)	MaskDICELoss 0.0977 (0.0494)
Epoch: [4][282/500]	Time 48.775 (48.775)	Loss 0.2165 (0.2890)	CeLoss 0.0742 (0.0435)	SegCLSLoss 0.0018 (0.0008)	KLLoss 0.0028 (0.0027)	MaskLoss 0.0360 (0.0647)	MaskBCELoss 0.0025 (0.0082)	MaskDICELoss 0.0334 (0.0565)
Epoch: [4][283/500]	Time 51.553 (51.553)	Loss 0.1276 (0.3449)	CeLoss 0.0104 (0.0340)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0042 (0.0032)	MaskLoss 0.0291 (0.0871)	MaskBCELoss 0.0019 (0.0207)	MaskDICELoss 0.0272 (0.0664)
Epoch: [4][284/500]	Time 49.449 (49.449)	Loss 0.0749 (0.3627)	CeLoss 0.0299 (0.0407)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0020 (0.0030)	MaskLoss 0.0136 (0.0971)	MaskBCELoss 0.0058 (0.0350)	MaskDICELoss 0.0078 (0.0621)
Epoch: [4][285/500]	Time 48.881 (48.881)	Loss 0.3383 (0.3560)	CeLoss 0.0232 (0.0449)	SegCLSLoss 0.0025 (0.0010)	KLLoss 0.0032 (0.0025)	MaskLoss 0.0806 (0.0902)	MaskBCELoss 0.0059 (0.0264)	MaskDICELoss 0.0747 (0.0638)
Epoch: [4][286/500]	Time 44.827 (44.827)	Loss 0.4498 (0.3551)	CeLoss 0.0425 (0.0479)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0045 (0.0035)	MaskLoss 0.1028 (0.0808)	MaskBCELoss 0.0042 (0.0101)	MaskDICELoss 0.0986 (0.0707)
Epoch: [4][287/500]	Time 48.118 (48.118)	Loss 0.1650 (0.3026)	CeLoss 0.0737 (0.0514)	SegCLSLoss 0.0013 (0.0008)	KLLoss 0.0059 (0.0032)	MaskLoss 0.0297 (0.0748)	MaskBCELoss 0.0172 (0.0258)	MaskDICELoss 0.0126 (0.0490)
Epoch: [4][288/500]	Time 46.756 (46.756)	Loss 0.1612 (0.2959)	CeLoss 0.0508 (0.0461)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0036 (0.0030)	MaskLoss 0.0323 (0.0681)	MaskBCELoss 0.0113 (0.0131)	MaskDICELoss 0.0210 (0.0549)
Epoch: [4][289/500]	Time 52.649 (52.649)	Loss 0.1201 (0.2742)	CeLoss 0.0129 (0.0346)	SegCLSLoss 0.0006 (0.0009)	KLLoss 0.0023 (0.0025)	MaskLoss 0.0348 (0.0706)	MaskBCELoss 0.0172 (0.0228)	MaskDICELoss 0.0176 (0.0478)
Epoch: [4][290/500]	Time 47.188 (47.188)	Loss 0.4883 (0.3327)	CeLoss 0.0244 (0.0385)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0033 (0.0030)	MaskLoss 0.1323 (0.0787)	MaskBCELoss 0.0346 (0.0120)	MaskDICELoss 0.0978 (0.0667)
Epoch: [4][291/500]	Time 48.141 (48.141)	Loss 0.4407 (0.3150)	CeLoss 0.0220 (0.0437)	SegCLSLoss 0.0032 (0.0014)	KLLoss 0.0046 (0.0029)	MaskLoss 0.1081 (0.0743)	MaskBCELoss 0.0100 (0.0147)	MaskDICELoss 0.0981 (0.0596)
Epoch: [4][292/500]	Time 45.699 (45.699)	Loss 0.4467 (0.4039)	CeLoss 0.0261 (0.0539)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0033 (0.0033)	MaskLoss 0.1099 (0.0905)	MaskBCELoss 0.0115 (0.0079)	MaskDICELoss 0.0984 (0.0826)
Epoch: [4][293/500]	Time 44.201 (44.201)	Loss 0.4871 (0.3913)	CeLoss 0.0811 (0.0567)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0028 (0.0040)	MaskLoss 0.1016 (0.0873)	MaskBCELoss 0.0016 (0.0097)	MaskDICELoss 0.1000 (0.0776)
Epoch: [4][294/500]	Time 46.922 (46.922)	Loss 0.1777 (0.2525)	CeLoss 0.0236 (0.0371)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0024 (0.0026)	MaskLoss 0.0545 (0.0609)	MaskBCELoss 0.0334 (0.0156)	MaskDICELoss 0.0211 (0.0453)
Epoch: [4][295/500]	Time 46.583 (46.583)	Loss 0.3646 (0.3781)	CeLoss 0.0236 (0.0284)	SegCLSLoss 0.0023 (0.0026)	KLLoss 0.0041 (0.0039)	MaskLoss 0.1141 (0.1040)	MaskBCELoss 0.0603 (0.0357)	MaskDICELoss 0.0538 (0.0683)
Epoch: [4][296/500]	Time 44.736 (44.736)	Loss 0.0381 (0.2885)	CeLoss 0.0215 (0.0455)	SegCLSLoss 0.0012 (0.0015)	KLLoss 0.0028 (0.0030)	MaskLoss 0.0050 (0.0678)	MaskBCELoss 0.0033 (0.0160)	MaskDICELoss 0.0016 (0.0518)
Epoch: [4][297/500]	Time 44.689 (44.689)	Loss 0.4342 (0.4097)	CeLoss 0.0242 (0.0554)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0026 (0.0035)	MaskLoss 0.1059 (0.1005)	MaskBCELoss 0.0084 (0.0258)	MaskDICELoss 0.0975 (0.0746)
Epoch: [4][298/500]	Time 50.172 (50.172)	Loss 0.4577 (0.2989)	CeLoss 0.0388 (0.0436)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0036 (0.0033)	MaskLoss 0.1090 (0.0684)	MaskBCELoss 0.0106 (0.0110)	MaskDICELoss 0.0984 (0.0573)
Epoch: [4][299/500]	Time 48.236 (48.236)	Loss 0.3274 (0.3349)	CeLoss 0.0134 (0.0348)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0019 (0.0033)	MaskLoss 0.0908 (0.0901)	MaskBCELoss 0.0259 (0.0321)	MaskDICELoss 0.0650 (0.0580)
[2025-03-12 14:52:36,008] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[0.00027080722891566265], mom=[(0.9, 0.95)]
[2025-03-12 14:52:36,019] [INFO] [timer.py:215:stop] epoch=0/micro_step=2300/global_step=230, RunningAvgSamplesPerSec=0.6467737770727772, CurrSamplesPerSec=0.7928971545524329, MemAllocated=60.53GB, MaxMemAllocated=74.71GB
Epoch: [4][300/500]	Time 48.154 (48.154)	Loss 0.4266 (0.2911)	CeLoss 0.0219 (0.0354)	SegCLSLoss 0.0004 (0.0018)	KLLoss 0.0034 (0.0035)	MaskLoss 0.1017 (0.0718)	MaskBCELoss 0.0029 (0.0179)	MaskDICELoss 0.0989 (0.0539)
Epoch: [4][301/500]	Time 48.990 (48.990)	Loss 0.3565 (0.4074)	CeLoss 0.0172 (0.0494)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0033 (0.0031)	MaskLoss 0.0857 (0.1027)	MaskBCELoss 0.0035 (0.0281)	MaskDICELoss 0.0822 (0.0745)
Epoch: [4][302/500]	Time 49.301 (49.301)	Loss 0.4934 (0.2736)	CeLoss 0.0850 (0.0463)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0044 (0.0034)	MaskLoss 0.1018 (0.0691)	MaskBCELoss 0.0018 (0.0264)	MaskDICELoss 0.1000 (0.0427)
Epoch: [4][303/500]	Time 46.871 (46.871)	Loss 0.0367 (0.3243)	CeLoss 0.0222 (0.0422)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0025 (0.0031)	MaskLoss 0.0040 (0.0787)	MaskBCELoss 0.0023 (0.0181)	MaskDICELoss 0.0017 (0.0605)
Epoch: [4][304/500]	Time 49.091 (49.091)	Loss 0.5594 (0.3545)	CeLoss 0.0618 (0.0536)	SegCLSLoss 0.0009 (0.0007)	KLLoss 0.0043 (0.0037)	MaskLoss 0.1472 (0.0845)	MaskBCELoss 0.0480 (0.0205)	MaskDICELoss 0.0993 (0.0639)
Epoch: [4][305/500]	Time 47.214 (47.214)	Loss 0.0744 (0.3459)	CeLoss 0.0630 (0.0399)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0029 (0.0039)	MaskLoss 0.0027 (0.0807)	MaskBCELoss 0.0012 (0.0106)	MaskDICELoss 0.0015 (0.0701)
Epoch: [4][306/500]	Time 48.262 (48.262)	Loss 0.1637 (0.3902)	CeLoss 0.0850 (0.0548)	SegCLSLoss 0.0004 (0.0017)	KLLoss 0.0033 (0.0035)	MaskLoss 0.0201 (0.0945)	MaskBCELoss 0.0024 (0.0235)	MaskDICELoss 0.0177 (0.0710)
Epoch: [4][307/500]	Time 41.483 (41.483)	Loss 0.0330 (0.3451)	CeLoss 0.0330 (0.0493)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0803)	MaskBCELoss 0.0000 (0.0146)	MaskDICELoss 0.0000 (0.0657)
Epoch: [4][308/500]	Time 44.632 (44.632)	Loss 0.1800 (0.1989)	CeLoss 0.0175 (0.0432)	SegCLSLoss 0.0033 (0.0012)	KLLoss 0.0044 (0.0029)	MaskLoss 0.0427 (0.0455)	MaskBCELoss 0.0073 (0.0149)	MaskDICELoss 0.0355 (0.0306)
Epoch: [4][309/500]	Time 45.355 (45.355)	Loss 0.5275 (0.3410)	CeLoss 0.1079 (0.0486)	SegCLSLoss 0.0030 (0.0018)	KLLoss 0.0036 (0.0037)	MaskLoss 0.1072 (0.0825)	MaskBCELoss 0.0073 (0.0211)	MaskDICELoss 0.0999 (0.0614)
Epoch: [4][310/500]	Time 51.027 (51.027)	Loss 0.3727 (0.2349)	CeLoss 0.0500 (0.0378)	SegCLSLoss 0.0007 (0.0005)	KLLoss 0.0029 (0.0023)	MaskLoss 0.0854 (0.0553)	MaskBCELoss 0.0109 (0.0134)	MaskDICELoss 0.0744 (0.0419)
Epoch: [4][311/500]	Time 46.400 (46.400)	Loss 0.5385 (0.3751)	CeLoss 0.0264 (0.0519)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0036 (0.0035)	MaskLoss 0.1551 (0.0887)	MaskBCELoss 0.0562 (0.0178)	MaskDICELoss 0.0990 (0.0709)
Epoch: [4][312/500]	Time 47.969 (47.969)	Loss 0.0252 (0.2179)	CeLoss 0.0251 (0.0326)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0026)	MaskLoss 0.0000 (0.0506)	MaskBCELoss 0.0000 (0.0101)	MaskDICELoss 0.0000 (0.0405)
Epoch: [4][313/500]	Time 50.408 (50.408)	Loss 0.4294 (0.3573)	CeLoss 0.0205 (0.0386)	SegCLSLoss 0.0019 (0.0013)	KLLoss 0.0037 (0.0034)	MaskLoss 0.1021 (0.0924)	MaskBCELoss 0.0021 (0.0275)	MaskDICELoss 0.1000 (0.0649)
Epoch: [4][314/500]	Time 47.072 (47.072)	Loss 0.3848 (0.3210)	CeLoss 0.0219 (0.0446)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0025 (0.0030)	MaskLoss 0.0982 (0.0737)	MaskBCELoss 0.0166 (0.0110)	MaskDICELoss 0.0816 (0.0627)
Epoch: [4][315/500]	Time 45.494 (45.494)	Loss 0.3032 (0.3261)	CeLoss 0.0223 (0.0411)	SegCLSLoss 0.0049 (0.0022)	KLLoss 0.0026 (0.0029)	MaskLoss 0.0810 (0.0794)	MaskBCELoss 0.0240 (0.0182)	MaskDICELoss 0.0569 (0.0611)
Epoch: [4][316/500]	Time 50.434 (50.434)	Loss 0.5033 (0.3332)	CeLoss 0.0613 (0.0384)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0047 (0.0031)	MaskLoss 0.1243 (0.0777)	MaskBCELoss 0.0302 (0.0099)	MaskDICELoss 0.0941 (0.0678)
Epoch: [4][317/500]	Time 45.849 (45.849)	Loss 0.4762 (0.3212)	CeLoss 0.0232 (0.0380)	SegCLSLoss 0.0013 (0.0014)	KLLoss 0.0028 (0.0037)	MaskLoss 0.1343 (0.0856)	MaskBCELoss 0.0438 (0.0318)	MaskDICELoss 0.0905 (0.0538)
Epoch: [4][318/500]	Time 47.505 (47.505)	Loss 0.1662 (0.3090)	CeLoss 0.0208 (0.0356)	SegCLSLoss 0.0029 (0.0012)	KLLoss 0.0027 (0.0032)	MaskLoss 0.0453 (0.0810)	MaskBCELoss 0.0200 (0.0272)	MaskDICELoss 0.0254 (0.0538)
Epoch: [4][319/500]	Time 48.501 (48.501)	Loss 0.4803 (0.2887)	CeLoss 0.0659 (0.0561)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0056 (0.0035)	MaskLoss 0.1052 (0.0627)	MaskBCELoss 0.0063 (0.0110)	MaskDICELoss 0.0988 (0.0516)
Epoch: [4][320/500]	Time 49.557 (49.557)	Loss 0.4993 (0.4469)	CeLoss 0.0299 (0.0412)	SegCLSLoss 0.0008 (0.0019)	KLLoss 0.0088 (0.0038)	MaskLoss 0.1309 (0.1161)	MaskBCELoss 0.0316 (0.0317)	MaskDICELoss 0.0992 (0.0844)
Epoch: [4][321/500]	Time 41.635 (41.635)	Loss 0.4742 (0.2863)	CeLoss 0.0850 (0.0451)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0031 (0.0031)	MaskLoss 0.1073 (0.0687)	MaskBCELoss 0.0220 (0.0186)	MaskDICELoss 0.0853 (0.0501)
Epoch: [4][322/500]	Time 46.465 (46.465)	Loss 0.3242 (0.3194)	CeLoss 0.0232 (0.0400)	SegCLSLoss 0.0018 (0.0017)	KLLoss 0.0025 (0.0037)	MaskLoss 0.0777 (0.0752)	MaskBCELoss 0.0065 (0.0131)	MaskDICELoss 0.0712 (0.0621)
Epoch: [4][323/500]	Time 47.469 (47.469)	Loss 0.3787 (0.3177)	CeLoss 0.0234 (0.0401)	SegCLSLoss 0.0029 (0.0016)	KLLoss 0.0056 (0.0036)	MaskLoss 0.1046 (0.0790)	MaskBCELoss 0.0350 (0.0214)	MaskDICELoss 0.0696 (0.0576)
Epoch: [4][324/500]	Time 46.230 (46.230)	Loss 0.4545 (0.3098)	CeLoss 0.0889 (0.0558)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0029 (0.0033)	MaskLoss 0.0986 (0.0720)	MaskBCELoss 0.0159 (0.0190)	MaskDICELoss 0.0827 (0.0531)
Epoch: [4][325/500]	Time 44.484 (44.484)	Loss 0.6268 (0.3358)	CeLoss 0.0476 (0.0372)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0035 (0.0037)	MaskLoss 0.2082 (0.0875)	MaskBCELoss 0.1285 (0.0278)	MaskDICELoss 0.0796 (0.0597)
Epoch: [4][326/500]	Time 48.246 (48.246)	Loss 0.3527 (0.3123)	CeLoss 0.0237 (0.0389)	SegCLSLoss 0.0014 (0.0017)	KLLoss 0.0028 (0.0040)	MaskLoss 0.0850 (0.0758)	MaskBCELoss 0.0072 (0.0173)	MaskDICELoss 0.0778 (0.0585)
Epoch: [4][327/500]	Time 43.095 (43.095)	Loss 0.4684 (0.4120)	CeLoss 0.0586 (0.0556)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0039 (0.0036)	MaskLoss 0.1028 (0.0959)	MaskBCELoss 0.0028 (0.0158)	MaskDICELoss 0.1000 (0.0801)
Epoch: [4][328/500]	Time 47.683 (47.683)	Loss 0.2823 (0.3796)	CeLoss 0.0148 (0.0452)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0026 (0.0038)	MaskLoss 0.1013 (0.0932)	MaskBCELoss 0.0703 (0.0213)	MaskDICELoss 0.0310 (0.0719)
Epoch: [4][329/500]	Time 45.616 (45.616)	Loss 0.3987 (0.2664)	CeLoss 0.0698 (0.0426)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0034 (0.0022)	MaskLoss 0.1092 (0.0645)	MaskBCELoss 0.0559 (0.0185)	MaskDICELoss 0.0533 (0.0460)
Epoch: [4][330/500]	Time 51.006 (51.006)	Loss 0.0535 (0.2193)	CeLoss 0.0410 (0.0365)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0028 (0.0031)	MaskLoss 0.0027 (0.0515)	MaskBCELoss 0.0006 (0.0135)	MaskDICELoss 0.0021 (0.0380)
Epoch: [4][331/500]	Time 45.808 (45.808)	Loss 0.4770 (0.3443)	CeLoss 0.0574 (0.0354)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0030 (0.0041)	MaskLoss 0.1081 (0.0805)	MaskBCELoss 0.0081 (0.0089)	MaskDICELoss 0.1000 (0.0716)
Epoch: [4][332/500]	Time 49.305 (49.305)	Loss 0.3348 (0.3081)	CeLoss 0.0208 (0.0436)	SegCLSLoss 0.0018 (0.0007)	KLLoss 0.0033 (0.0029)	MaskLoss 0.0978 (0.0722)	MaskBCELoss 0.0407 (0.0138)	MaskDICELoss 0.0571 (0.0584)
Epoch: [4][333/500]	Time 45.105 (45.105)	Loss 0.2076 (0.3087)	CeLoss 0.0140 (0.0489)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0034 (0.0030)	MaskLoss 0.0486 (0.0712)	MaskBCELoss 0.0024 (0.0145)	MaskDICELoss 0.0462 (0.0568)
Epoch: [4][334/500]	Time 49.306 (49.306)	Loss 0.4228 (0.2942)	CeLoss 0.0113 (0.0280)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0033 (0.0033)	MaskLoss 0.1041 (0.0695)	MaskBCELoss 0.0042 (0.0078)	MaskDICELoss 0.0998 (0.0616)
Epoch: [4][335/500]	Time 49.372 (49.372)	Loss 0.3857 (0.3827)	CeLoss 0.0250 (0.0382)	SegCLSLoss 0.0027 (0.0017)	KLLoss 0.0034 (0.0037)	MaskLoss 0.1016 (0.0966)	MaskBCELoss 0.0251 (0.0231)	MaskDICELoss 0.0765 (0.0734)
Epoch: [4][336/500]	Time 46.987 (46.987)	Loss 0.4909 (0.3642)	CeLoss 0.0864 (0.0449)	SegCLSLoss 0.0033 (0.0022)	KLLoss 0.0027 (0.0031)	MaskLoss 0.1019 (0.0879)	MaskBCELoss 0.0037 (0.0182)	MaskDICELoss 0.0982 (0.0697)
Epoch: [4][337/500]	Time 43.998 (43.998)	Loss 0.0406 (0.3242)	CeLoss 0.0405 (0.0406)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0804)	MaskBCELoss 0.0000 (0.0212)	MaskDICELoss 0.0000 (0.0592)
Epoch: [4][338/500]	Time 50.283 (50.283)	Loss 0.4290 (0.2551)	CeLoss 0.0228 (0.0355)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0031 (0.0028)	MaskLoss 0.1010 (0.0641)	MaskBCELoss 0.0010 (0.0201)	MaskDICELoss 0.1000 (0.0440)
Epoch: [4][339/500]	Time 44.911 (44.911)	Loss 0.3239 (0.3178)	CeLoss 0.0206 (0.0480)	SegCLSLoss 0.0018 (0.0012)	KLLoss 0.0034 (0.0033)	MaskLoss 0.0792 (0.0740)	MaskBCELoss 0.0088 (0.0150)	MaskDICELoss 0.0703 (0.0590)
Epoch: [4][340/500]	Time 44.211 (44.211)	Loss 0.4582 (0.3634)	CeLoss 0.0825 (0.0609)	SegCLSLoss 0.0006 (0.0020)	KLLoss 0.0034 (0.0041)	MaskLoss 0.1128 (0.0867)	MaskBCELoss 0.0397 (0.0246)	MaskDICELoss 0.0731 (0.0620)
Epoch: [4][341/500]	Time 45.425 (45.425)	Loss 0.2174 (0.3017)	CeLoss 0.0208 (0.0400)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0046 (0.0034)	MaskLoss 0.0536 (0.0724)	MaskBCELoss 0.0116 (0.0161)	MaskDICELoss 0.0421 (0.0564)
Epoch: [4][342/500]	Time 45.093 (45.093)	Loss 0.6530 (0.4210)	CeLoss 0.0613 (0.0467)	SegCLSLoss 0.0008 (0.0016)	KLLoss 0.0046 (0.0036)	MaskLoss 0.1938 (0.1082)	MaskBCELoss 0.0944 (0.0314)	MaskDICELoss 0.0995 (0.0768)
Epoch: [4][343/500]	Time 49.365 (49.365)	Loss 0.2659 (0.3298)	CeLoss 0.0140 (0.0400)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0026 (0.0039)	MaskLoss 0.0648 (0.0772)	MaskBCELoss 0.0053 (0.0118)	MaskDICELoss 0.0596 (0.0654)
Epoch: [4][344/500]	Time 51.518 (51.518)	Loss 0.2038 (0.2914)	CeLoss 0.0242 (0.0357)	SegCLSLoss 0.0067 (0.0015)	KLLoss 0.0033 (0.0044)	MaskLoss 0.0506 (0.0676)	MaskBCELoss 0.0148 (0.0100)	MaskDICELoss 0.0358 (0.0577)
Epoch: [4][345/500]	Time 46.896 (46.896)	Loss 0.4480 (0.3327)	CeLoss 0.0222 (0.0410)	SegCLSLoss 0.0023 (0.0012)	KLLoss 0.0055 (0.0035)	MaskLoss 0.1228 (0.0826)	MaskBCELoss 0.0361 (0.0213)	MaskDICELoss 0.0867 (0.0613)
Epoch: [4][346/500]	Time 48.220 (48.220)	Loss 0.2871 (0.3244)	CeLoss 0.0571 (0.0439)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0037 (0.0030)	MaskLoss 0.0604 (0.0735)	MaskBCELoss 0.0079 (0.0085)	MaskDICELoss 0.0525 (0.0650)
Epoch: [4][347/500]	Time 46.083 (46.083)	Loss 0.0504 (0.3217)	CeLoss 0.0503 (0.0456)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0746)	MaskBCELoss 0.0000 (0.0129)	MaskDICELoss 0.0000 (0.0617)
Epoch: [4][348/500]	Time 50.470 (50.470)	Loss 0.3767 (0.4038)	CeLoss 0.0277 (0.0455)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0031 (0.0039)	MaskLoss 0.0925 (0.0986)	MaskBCELoss 0.0121 (0.0204)	MaskDICELoss 0.0803 (0.0782)
Epoch: [4][349/500]	Time 49.540 (49.540)	Loss 0.5010 (0.3990)	CeLoss 0.0767 (0.0327)	SegCLSLoss 0.0011 (0.0018)	KLLoss 0.0033 (0.0035)	MaskLoss 0.1108 (0.0978)	MaskBCELoss 0.0111 (0.0147)	MaskDICELoss 0.0997 (0.0831)
Epoch: [4][350/500]	Time 50.927 (50.927)	Loss 0.4593 (0.2042)	CeLoss 0.0231 (0.0385)	SegCLSLoss 0.0011 (0.0005)	KLLoss 0.0047 (0.0033)	MaskLoss 0.1161 (0.0479)	MaskBCELoss 0.0166 (0.0146)	MaskDICELoss 0.0994 (0.0332)
Epoch: [4][351/500]	Time 54.254 (54.254)	Loss 0.3003 (0.4011)	CeLoss 0.0232 (0.0324)	SegCLSLoss 0.0018 (0.0008)	KLLoss 0.0060 (0.0041)	MaskLoss 0.0739 (0.1051)	MaskBCELoss 0.0126 (0.0281)	MaskDICELoss 0.0612 (0.0770)
Epoch: [4][352/500]	Time 50.983 (50.983)	Loss 0.4482 (0.3992)	CeLoss 0.0396 (0.0364)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0019 (0.0030)	MaskLoss 0.1031 (0.0975)	MaskBCELoss 0.0031 (0.0154)	MaskDICELoss 0.1000 (0.0821)
Epoch: [4][353/500]	Time 55.191 (55.191)	Loss 0.3322 (0.2441)	CeLoss 0.0613 (0.0332)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0030 (0.0028)	MaskLoss 0.0877 (0.0679)	MaskBCELoss 0.0417 (0.0319)	MaskDICELoss 0.0460 (0.0360)
Epoch: [4][354/500]	Time 46.940 (46.940)	Loss 0.4775 (0.4062)	CeLoss 0.0581 (0.0438)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0032 (0.0039)	MaskLoss 0.1082 (0.0992)	MaskBCELoss 0.0086 (0.0194)	MaskDICELoss 0.0997 (0.0798)
Epoch: [4][355/500]	Time 45.497 (45.497)	Loss 0.3345 (0.3858)	CeLoss 0.0258 (0.0357)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0056 (0.0049)	MaskLoss 0.0837 (0.0980)	MaskBCELoss 0.0162 (0.0236)	MaskDICELoss 0.0675 (0.0743)
Epoch: [4][356/500]	Time 45.894 (45.894)	Loss 0.5147 (0.3199)	CeLoss 0.0369 (0.0433)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0035 (0.0039)	MaskLoss 0.1412 (0.0762)	MaskBCELoss 0.0454 (0.0163)	MaskDICELoss 0.0958 (0.0599)
Epoch: [4][357/500]	Time 51.874 (51.874)	Loss 0.0094 (0.2448)	CeLoss 0.0094 (0.0388)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0035)	MaskLoss 0.0000 (0.0556)	MaskBCELoss 0.0000 (0.0103)	MaskDICELoss 0.0000 (0.0454)
Epoch: [4][358/500]	Time 51.425 (51.425)	Loss 0.2140 (0.3011)	CeLoss 0.0205 (0.0296)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0032 (0.0031)	MaskLoss 0.0548 (0.0727)	MaskBCELoss 0.0149 (0.0115)	MaskDICELoss 0.0400 (0.0612)
Epoch: [4][359/500]	Time 43.600 (43.600)	Loss 0.5451 (0.3661)	CeLoss 0.0679 (0.0590)	SegCLSLoss 0.0005 (0.0008)	KLLoss 0.0034 (0.0040)	MaskLoss 0.1646 (0.0881)	MaskBCELoss 0.0926 (0.0249)	MaskDICELoss 0.0720 (0.0633)
Epoch: [4][360/500]	Time 48.202 (48.202)	Loss 0.4323 (0.2676)	CeLoss 0.0232 (0.0214)	SegCLSLoss 0.0016 (0.0007)	KLLoss 0.0023 (0.0035)	MaskLoss 0.1029 (0.0680)	MaskBCELoss 0.0029 (0.0149)	MaskDICELoss 0.1000 (0.0531)
Epoch: [4][361/500]	Time 47.246 (47.246)	Loss 0.3663 (0.3652)	CeLoss 0.0620 (0.0552)	SegCLSLoss 0.0020 (0.0009)	KLLoss 0.0040 (0.0037)	MaskLoss 0.0866 (0.0961)	MaskBCELoss 0.0236 (0.0393)	MaskDICELoss 0.0630 (0.0568)
Epoch: [4][362/500]	Time 50.284 (50.284)	Loss 0.1303 (0.3018)	CeLoss 0.0243 (0.0297)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0035 (0.0035)	MaskLoss 0.0352 (0.0727)	MaskBCELoss 0.0192 (0.0114)	MaskDICELoss 0.0159 (0.0613)
Epoch: [4][363/500]	Time 45.850 (45.850)	Loss 0.3641 (0.3545)	CeLoss 0.0204 (0.0491)	SegCLSLoss 0.0064 (0.0020)	KLLoss 0.0047 (0.0034)	MaskLoss 0.0907 (0.0847)	MaskBCELoss 0.0136 (0.0190)	MaskDICELoss 0.0772 (0.0658)
Epoch: [4][364/500]	Time 46.789 (46.789)	Loss 0.3007 (0.2245)	CeLoss 0.0195 (0.0373)	SegCLSLoss 0.0007 (0.0016)	KLLoss 0.0043 (0.0041)	MaskLoss 0.0764 (0.0539)	MaskBCELoss 0.0146 (0.0167)	MaskDICELoss 0.0618 (0.0373)
Epoch: [4][365/500]	Time 51.596 (51.596)	Loss 0.3782 (0.2938)	CeLoss 0.0610 (0.0564)	SegCLSLoss 0.0017 (0.0008)	KLLoss 0.0024 (0.0028)	MaskLoss 0.0930 (0.0670)	MaskBCELoss 0.0290 (0.0168)	MaskDICELoss 0.0641 (0.0502)
Epoch: [4][366/500]	Time 50.947 (50.947)	Loss 0.2531 (0.2301)	CeLoss 0.0466 (0.0436)	SegCLSLoss 0.0006 (0.0005)	KLLoss 0.0042 (0.0023)	MaskLoss 0.0629 (0.0501)	MaskBCELoss 0.0248 (0.0082)	MaskDICELoss 0.0381 (0.0419)
Epoch: [4][367/500]	Time 43.898 (43.898)	Loss 0.3306 (0.2605)	CeLoss 0.0459 (0.0436)	SegCLSLoss 0.0027 (0.0012)	KLLoss 0.0065 (0.0037)	MaskLoss 0.0938 (0.0590)	MaskBCELoss 0.0492 (0.0118)	MaskDICELoss 0.0446 (0.0473)
Epoch: [4][368/500]	Time 48.565 (48.565)	Loss 0.5005 (0.3506)	CeLoss 0.0830 (0.0537)	SegCLSLoss 0.0015 (0.0015)	KLLoss 0.0034 (0.0037)	MaskLoss 0.1068 (0.0818)	MaskBCELoss 0.0068 (0.0175)	MaskDICELoss 0.0999 (0.0644)
Epoch: [4][369/500]	Time 50.625 (50.625)	Loss 0.3280 (0.3639)	CeLoss 0.0145 (0.0400)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0023 (0.0042)	MaskLoss 0.0833 (0.0879)	MaskBCELoss 0.0113 (0.0164)	MaskDICELoss 0.0721 (0.0716)
Epoch: [4][370/500]	Time 43.706 (43.706)	Loss 0.0218 (0.3020)	CeLoss 0.0217 (0.0337)	SegCLSLoss 0.0000 (0.0022)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0707)	MaskBCELoss 0.0000 (0.0094)	MaskDICELoss 0.0000 (0.0612)
Epoch: [4][371/500]	Time 47.433 (47.433)	Loss 0.3627 (0.3106)	CeLoss 0.0208 (0.0394)	SegCLSLoss 0.0048 (0.0013)	KLLoss 0.0031 (0.0034)	MaskLoss 0.0872 (0.0739)	MaskBCELoss 0.0063 (0.0143)	MaskDICELoss 0.0809 (0.0596)
Epoch: [4][372/500]	Time 51.914 (51.914)	Loss 0.4304 (0.3612)	CeLoss 0.0238 (0.0447)	SegCLSLoss 0.0020 (0.0011)	KLLoss 0.0024 (0.0031)	MaskLoss 0.1041 (0.0896)	MaskBCELoss 0.0065 (0.0226)	MaskDICELoss 0.0975 (0.0669)
Epoch: [4][373/500]	Time 54.234 (54.234)	Loss 0.1677 (0.2040)	CeLoss 0.0125 (0.0299)	SegCLSLoss 0.0002 (0.0008)	KLLoss 0.0024 (0.0026)	MaskLoss 0.0496 (0.0495)	MaskBCELoss 0.0228 (0.0135)	MaskDICELoss 0.0268 (0.0360)
Epoch: [4][374/500]	Time 45.837 (45.837)	Loss 0.5433 (0.3859)	CeLoss 0.0383 (0.0620)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0033 (0.0049)	MaskLoss 0.1601 (0.0918)	MaskBCELoss 0.0695 (0.0245)	MaskDICELoss 0.0906 (0.0674)
Epoch: [4][375/500]	Time 43.070 (43.070)	Loss 0.4286 (0.3334)	CeLoss 0.0223 (0.0479)	SegCLSLoss 0.0032 (0.0018)	KLLoss 0.0036 (0.0034)	MaskLoss 0.1008 (0.0783)	MaskBCELoss 0.0011 (0.0161)	MaskDICELoss 0.0997 (0.0623)
Epoch: [4][376/500]	Time 46.805 (46.805)	Loss 0.3302 (0.2722)	CeLoss 0.0620 (0.0520)	SegCLSLoss 0.0043 (0.0012)	KLLoss 0.0028 (0.0025)	MaskLoss 0.0845 (0.0670)	MaskBCELoss 0.0375 (0.0255)	MaskDICELoss 0.0470 (0.0415)
Epoch: [4][377/500]	Time 48.870 (48.870)	Loss 0.4641 (0.2988)	CeLoss 0.0535 (0.0321)	SegCLSLoss 0.0007 (0.0015)	KLLoss 0.0045 (0.0035)	MaskLoss 0.1030 (0.0733)	MaskBCELoss 0.0030 (0.0154)	MaskDICELoss 0.1000 (0.0579)
Epoch: [4][378/500]	Time 45.476 (45.476)	Loss 0.4355 (0.3867)	CeLoss 0.0276 (0.0307)	SegCLSLoss 0.0005 (0.0025)	KLLoss 0.0033 (0.0038)	MaskLoss 0.1023 (0.0949)	MaskBCELoss 0.0023 (0.0143)	MaskDICELoss 0.1000 (0.0806)
Epoch: [4][379/500]	Time 51.168 (51.168)	Loss 0.4319 (0.3460)	CeLoss 0.0198 (0.0473)	SegCLSLoss 0.0037 (0.0010)	KLLoss 0.0039 (0.0037)	MaskLoss 0.1116 (0.0824)	MaskBCELoss 0.0198 (0.0175)	MaskDICELoss 0.0917 (0.0649)
Epoch: [4][380/500]	Time 50.583 (50.583)	Loss 0.3065 (0.3335)	CeLoss 0.0210 (0.0384)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0042 (0.0040)	MaskLoss 0.0777 (0.0862)	MaskBCELoss 0.0149 (0.0270)	MaskDICELoss 0.0627 (0.0592)
Epoch: [4][381/500]	Time 47.918 (47.918)	Loss 0.3247 (0.3715)	CeLoss 0.0310 (0.0422)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0043 (0.0033)	MaskLoss 0.0766 (0.0920)	MaskBCELoss 0.0087 (0.0213)	MaskDICELoss 0.0679 (0.0707)
Epoch: [4][382/500]	Time 46.501 (46.501)	Loss 0.0512 (0.3172)	CeLoss 0.0513 (0.0371)	SegCLSLoss 0.0000 (0.0015)	KLLoss 0.0000 (0.0037)	MaskLoss 0.0000 (0.0750)	MaskBCELoss 0.0000 (0.0122)	MaskDICELoss 0.0000 (0.0628)
Epoch: [4][383/500]	Time 41.629 (41.629)	Loss 0.4049 (0.2836)	CeLoss 0.0254 (0.0535)	SegCLSLoss 0.0016 (0.0014)	KLLoss 0.0028 (0.0027)	MaskLoss 0.0946 (0.0606)	MaskBCELoss 0.0013 (0.0079)	MaskDICELoss 0.0933 (0.0527)
Epoch: [4][384/500]	Time 47.063 (47.063)	Loss 0.4381 (0.3538)	CeLoss 0.0486 (0.0480)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0046 (0.0036)	MaskLoss 0.1087 (0.0824)	MaskBCELoss 0.0252 (0.0140)	MaskDICELoss 0.0834 (0.0684)
Epoch: [4][385/500]	Time 46.329 (46.329)	Loss 0.4688 (0.3903)	CeLoss 0.0601 (0.0367)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0033 (0.0036)	MaskLoss 0.1116 (0.0982)	MaskBCELoss 0.0209 (0.0218)	MaskDICELoss 0.0907 (0.0764)
Epoch: [4][386/500]	Time 51.766 (51.766)	Loss 0.1908 (0.3864)	CeLoss 0.0688 (0.0557)	SegCLSLoss 0.0023 (0.0010)	KLLoss 0.0027 (0.0038)	MaskLoss 0.0376 (0.0929)	MaskBCELoss 0.0162 (0.0226)	MaskDICELoss 0.0214 (0.0703)
Epoch: [4][387/500]	Time 44.861 (44.861)	Loss 0.3759 (0.3489)	CeLoss 0.0520 (0.0566)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0025 (0.0044)	MaskLoss 0.0885 (0.0785)	MaskBCELoss 0.0164 (0.0134)	MaskDICELoss 0.0721 (0.0651)
Epoch: [4][388/500]	Time 48.797 (48.797)	Loss 0.1432 (0.3715)	CeLoss 0.0256 (0.0453)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0024 (0.0036)	MaskLoss 0.0375 (0.0921)	MaskBCELoss 0.0177 (0.0232)	MaskDICELoss 0.0198 (0.0689)
Epoch: [4][389/500]	Time 43.316 (43.316)	Loss 0.0964 (0.2675)	CeLoss 0.0237 (0.0553)	SegCLSLoss 0.0012 (0.0013)	KLLoss 0.0039 (0.0028)	MaskLoss 0.0213 (0.0609)	MaskBCELoss 0.0085 (0.0175)	MaskDICELoss 0.0128 (0.0434)
Epoch: [4][390/500]	Time 41.873 (41.873)	Loss 0.2953 (0.4094)	CeLoss 0.0356 (0.0477)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0038 (0.0029)	MaskLoss 0.0775 (0.0969)	MaskBCELoss 0.0272 (0.0147)	MaskDICELoss 0.0503 (0.0822)
Epoch: [4][391/500]	Time 49.991 (49.991)	Loss 0.4410 (0.2660)	CeLoss 0.0393 (0.0471)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0031 (0.0029)	MaskLoss 0.1065 (0.0600)	MaskBCELoss 0.0137 (0.0122)	MaskDICELoss 0.0927 (0.0478)
Epoch: [4][392/500]	Time 46.549 (46.549)	Loss 0.4345 (0.2021)	CeLoss 0.0209 (0.0312)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0027 (0.0030)	MaskLoss 0.1062 (0.0459)	MaskBCELoss 0.0072 (0.0081)	MaskDICELoss 0.0990 (0.0378)
Epoch: [4][393/500]	Time 47.381 (47.381)	Loss 0.0898 (0.2671)	CeLoss 0.0251 (0.0370)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0028 (0.0038)	MaskLoss 0.0200 (0.0658)	MaskBCELoss 0.0093 (0.0187)	MaskDICELoss 0.0107 (0.0471)
Epoch: [4][394/500]	Time 52.580 (52.580)	Loss 0.4324 (0.2384)	CeLoss 0.0198 (0.0257)	SegCLSLoss 0.0036 (0.0014)	KLLoss 0.0038 (0.0034)	MaskLoss 0.1035 (0.0602)	MaskBCELoss 0.0035 (0.0161)	MaskDICELoss 0.1000 (0.0441)
Epoch: [4][395/500]	Time 42.408 (42.408)	Loss 0.3578 (0.4051)	CeLoss 0.0791 (0.0514)	SegCLSLoss 0.0009 (0.0014)	KLLoss 0.0050 (0.0040)	MaskLoss 0.0797 (0.1003)	MaskBCELoss 0.0230 (0.0262)	MaskDICELoss 0.0568 (0.0741)
Epoch: [4][396/500]	Time 49.898 (49.898)	Loss 0.4468 (0.3407)	CeLoss 0.0459 (0.0300)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0021 (0.0035)	MaskLoss 0.1014 (0.0889)	MaskBCELoss 0.0038 (0.0245)	MaskDICELoss 0.0976 (0.0644)
Epoch: [4][397/500]	Time 47.821 (47.821)	Loss 0.4379 (0.3011)	CeLoss 0.0457 (0.0483)	SegCLSLoss 0.0010 (0.0012)	KLLoss 0.0037 (0.0032)	MaskLoss 0.0975 (0.0685)	MaskBCELoss 0.0010 (0.0125)	MaskDICELoss 0.0965 (0.0560)
Epoch: [4][398/500]	Time 51.167 (51.167)	Loss 0.3626 (0.3270)	CeLoss 0.0176 (0.0365)	SegCLSLoss 0.0022 (0.0014)	KLLoss 0.0025 (0.0039)	MaskLoss 0.0914 (0.0826)	MaskBCELoss 0.0121 (0.0222)	MaskDICELoss 0.0793 (0.0604)
Epoch: [4][399/500]	Time 47.441 (47.441)	Loss 0.0301 (0.3062)	CeLoss 0.0300 (0.0340)	SegCLSLoss 0.0000 (0.0007)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0767)	MaskBCELoss 0.0000 (0.0190)	MaskDICELoss 0.0000 (0.0576)
[2025-03-12 16:12:04,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[0.0002694819277108434], mom=[(0.9, 0.95)]
[2025-03-12 16:12:04,672] [INFO] [timer.py:215:stop] epoch=0/micro_step=2400/global_step=240, RunningAvgSamplesPerSec=0.652924442444069, CurrSamplesPerSec=0.8546872140805728, MemAllocated=59.54GB, MaxMemAllocated=74.71GB
Epoch: [4][400/500]	Time 48.437 (48.437)	Loss 0.4083 (0.3460)	CeLoss 0.0217 (0.0394)	SegCLSLoss 0.0015 (0.0010)	KLLoss 0.0051 (0.0043)	MaskLoss 0.1116 (0.0851)	MaskBCELoss 0.0328 (0.0194)	MaskDICELoss 0.0787 (0.0657)
Epoch: [4][401/500]	Time 50.839 (50.839)	Loss 0.4114 (0.4006)	CeLoss 0.0250 (0.0561)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0031 (0.0037)	MaskLoss 0.0974 (0.0946)	MaskBCELoss 0.0031 (0.0190)	MaskDICELoss 0.0942 (0.0756)
Epoch: [4][402/500]	Time 45.505 (45.505)	Loss 0.0120 (0.2752)	CeLoss 0.0120 (0.0501)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0029)	MaskLoss 0.0000 (0.0625)	MaskBCELoss 0.0000 (0.0142)	MaskDICELoss 0.0000 (0.0484)
Epoch: [4][403/500]	Time 48.678 (48.678)	Loss 0.3993 (0.3226)	CeLoss 0.0203 (0.0413)	SegCLSLoss 0.0037 (0.0011)	KLLoss 0.0039 (0.0033)	MaskLoss 0.0938 (0.0737)	MaskBCELoss 0.0009 (0.0088)	MaskDICELoss 0.0929 (0.0649)
Epoch: [4][404/500]	Time 48.149 (48.149)	Loss 0.4661 (0.3889)	CeLoss 0.0574 (0.0597)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0029 (0.0039)	MaskLoss 0.1041 (0.0903)	MaskBCELoss 0.0055 (0.0181)	MaskDICELoss 0.0985 (0.0721)
Epoch: [4][405/500]	Time 48.163 (48.163)	Loss 0.0641 (0.2591)	CeLoss 0.0640 (0.0368)	SegCLSLoss 0.0000 (0.0017)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0601)	MaskBCELoss 0.0000 (0.0110)	MaskDICELoss 0.0000 (0.0491)
Epoch: [4][406/500]	Time 50.601 (50.601)	Loss 0.0119 (0.2926)	CeLoss 0.0118 (0.0314)	SegCLSLoss 0.0000 (0.0013)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0703)	MaskBCELoss 0.0000 (0.0116)	MaskDICELoss 0.0000 (0.0587)
Epoch: [4][407/500]	Time 46.975 (46.975)	Loss 0.3001 (0.3009)	CeLoss 0.0239 (0.0434)	SegCLSLoss 0.0022 (0.0016)	KLLoss 0.0037 (0.0045)	MaskLoss 0.0768 (0.0758)	MaskBCELoss 0.0178 (0.0255)	MaskDICELoss 0.0589 (0.0503)
Epoch: [4][408/500]	Time 46.654 (46.654)	Loss 0.4609 (0.3962)	CeLoss 0.0222 (0.0397)	SegCLSLoss 0.0012 (0.0016)	KLLoss 0.0044 (0.0046)	MaskLoss 0.1274 (0.1081)	MaskBCELoss 0.0380 (0.0407)	MaskDICELoss 0.0894 (0.0674)
Epoch: [4][409/500]	Time 49.533 (49.533)	Loss 0.4285 (0.3370)	CeLoss 0.0201 (0.0298)	SegCLSLoss 0.0014 (0.0015)	KLLoss 0.0042 (0.0033)	MaskLoss 0.1020 (0.0826)	MaskBCELoss 0.0022 (0.0137)	MaskDICELoss 0.0998 (0.0689)
Epoch: [4][410/500]	Time 47.380 (47.380)	Loss 0.4344 (0.3900)	CeLoss 0.0223 (0.0504)	SegCLSLoss 0.0013 (0.0015)	KLLoss 0.0028 (0.0036)	MaskLoss 0.1051 (0.0899)	MaskBCELoss 0.0060 (0.0121)	MaskDICELoss 0.0992 (0.0777)
Epoch: [4][411/500]	Time 52.852 (52.852)	Loss 0.4638 (0.2817)	CeLoss 0.0222 (0.0414)	SegCLSLoss 0.0036 (0.0009)	KLLoss 0.0033 (0.0031)	MaskLoss 0.1189 (0.0632)	MaskBCELoss 0.0195 (0.0081)	MaskDICELoss 0.0994 (0.0551)
Epoch: [4][412/500]	Time 50.025 (50.025)	Loss 0.4577 (0.3307)	CeLoss 0.0227 (0.0403)	SegCLSLoss 0.0035 (0.0012)	KLLoss 0.0070 (0.0038)	MaskLoss 0.1177 (0.0781)	MaskBCELoss 0.0223 (0.0132)	MaskDICELoss 0.0954 (0.0649)
Epoch: [4][413/500]	Time 50.734 (50.734)	Loss 0.3736 (0.3750)	CeLoss 0.0240 (0.0378)	SegCLSLoss 0.0013 (0.0016)	KLLoss 0.0023 (0.0039)	MaskLoss 0.0932 (0.0932)	MaskBCELoss 0.0130 (0.0202)	MaskDICELoss 0.0802 (0.0730)
Epoch: [4][414/500]	Time 46.985 (46.985)	Loss 0.3917 (0.3798)	CeLoss 0.0454 (0.0374)	SegCLSLoss 0.0004 (0.0014)	KLLoss 0.0033 (0.0042)	MaskLoss 0.0893 (0.0931)	MaskBCELoss 0.0072 (0.0174)	MaskDICELoss 0.0820 (0.0757)
Epoch: [4][415/500]	Time 49.776 (49.776)	Loss 0.4599 (0.3529)	CeLoss 0.0496 (0.0483)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0030 (0.0036)	MaskLoss 0.1048 (0.0811)	MaskBCELoss 0.0064 (0.0119)	MaskDICELoss 0.0984 (0.0691)
Epoch: [4][416/500]	Time 45.861 (45.861)	Loss 0.0379 (0.3445)	CeLoss 0.0378 (0.0437)	SegCLSLoss 0.0000 (0.0012)	KLLoss 0.0000 (0.0030)	MaskLoss 0.0000 (0.0837)	MaskBCELoss 0.0000 (0.0188)	MaskDICELoss 0.0000 (0.0649)
Epoch: [4][417/500]	Time 49.786 (49.786)	Loss 0.1621 (0.3123)	CeLoss 0.0239 (0.0518)	SegCLSLoss 0.0016 (0.0009)	KLLoss 0.0030 (0.0035)	MaskLoss 0.0445 (0.0741)	MaskBCELoss 0.0217 (0.0200)	MaskDICELoss 0.0227 (0.0542)
Epoch: [4][418/500]	Time 43.045 (43.045)	Loss 0.3126 (0.2586)	CeLoss 0.0713 (0.0596)	SegCLSLoss 0.0010 (0.0008)	KLLoss 0.0053 (0.0026)	MaskLoss 0.0608 (0.0554)	MaskBCELoss 0.0039 (0.0127)	MaskDICELoss 0.0569 (0.0427)
Epoch: [4][419/500]	Time 51.966 (51.966)	Loss 0.0892 (0.2643)	CeLoss 0.0192 (0.0355)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0045 (0.0035)	MaskLoss 0.0224 (0.0616)	MaskBCELoss 0.0124 (0.0108)	MaskDICELoss 0.0100 (0.0508)
Epoch: [4][420/500]	Time 43.482 (43.482)	Loss 0.3289 (0.3764)	CeLoss 0.0243 (0.0526)	SegCLSLoss 0.0017 (0.0013)	KLLoss 0.0040 (0.0041)	MaskLoss 0.0885 (0.0906)	MaskBCELoss 0.0273 (0.0216)	MaskDICELoss 0.0613 (0.0690)
Epoch: [4][421/500]	Time 50.403 (50.403)	Loss 0.4275 (0.4163)	CeLoss 0.0166 (0.0477)	SegCLSLoss 0.0010 (0.0011)	KLLoss 0.0019 (0.0043)	MaskLoss 0.1043 (0.1028)	MaskBCELoss 0.0044 (0.0237)	MaskDICELoss 0.1000 (0.0791)
Epoch: [4][422/500]	Time 47.096 (47.096)	Loss 0.1225 (0.3010)	CeLoss 0.0498 (0.0532)	SegCLSLoss 0.0003 (0.0011)	KLLoss 0.0042 (0.0038)	MaskLoss 0.0223 (0.0686)	MaskBCELoss 0.0104 (0.0154)	MaskDICELoss 0.0118 (0.0531)
Epoch: [4][423/500]	Time 43.587 (43.587)	Loss 0.3247 (0.3577)	CeLoss 0.0221 (0.0454)	SegCLSLoss 0.0022 (0.0016)	KLLoss 0.0030 (0.0042)	MaskLoss 0.0779 (0.0832)	MaskBCELoss 0.0066 (0.0127)	MaskDICELoss 0.0713 (0.0705)
Epoch: [4][424/500]	Time 51.507 (51.507)	Loss 0.3660 (0.3003)	CeLoss 0.0214 (0.0282)	SegCLSLoss 0.0018 (0.0014)	KLLoss 0.0030 (0.0031)	MaskLoss 0.0928 (0.0770)	MaskBCELoss 0.0151 (0.0198)	MaskDICELoss 0.0777 (0.0572)
Epoch: [4][425/500]	Time 48.958 (48.958)	Loss 0.3475 (0.2641)	CeLoss 0.0364 (0.0601)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0074 (0.0043)	MaskLoss 0.0907 (0.0549)	MaskBCELoss 0.0295 (0.0101)	MaskDICELoss 0.0611 (0.0448)
Epoch: [4][426/500]	Time 53.547 (53.547)	Loss 0.4852 (0.2625)	CeLoss 0.0791 (0.0422)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0029 (0.0038)	MaskLoss 0.1014 (0.0580)	MaskBCELoss 0.0014 (0.0081)	MaskDICELoss 0.1000 (0.0499)
Epoch: [4][427/500]	Time 44.350 (44.350)	Loss 0.4443 (0.3211)	CeLoss 0.0571 (0.0413)	SegCLSLoss 0.0004 (0.0016)	KLLoss 0.0037 (0.0036)	MaskLoss 0.0996 (0.0758)	MaskBCELoss 0.0076 (0.0138)	MaskDICELoss 0.0920 (0.0619)
Epoch: [4][428/500]	Time 51.087 (51.087)	Loss 0.2816 (0.2894)	CeLoss 0.0271 (0.0375)	SegCLSLoss 0.0009 (0.0007)	KLLoss 0.0031 (0.0038)	MaskLoss 0.0872 (0.0704)	MaskBCELoss 0.0489 (0.0169)	MaskDICELoss 0.0383 (0.0535)
Epoch: [4][429/500]	Time 43.286 (43.286)	Loss 0.0960 (0.2442)	CeLoss 0.0222 (0.0384)	SegCLSLoss 0.0015 (0.0019)	KLLoss 0.0030 (0.0050)	MaskLoss 0.0262 (0.0586)	MaskBCELoss 0.0173 (0.0173)	MaskDICELoss 0.0089 (0.0413)
Epoch: [4][430/500]	Time 46.274 (46.274)	Loss 0.3268 (0.3472)	CeLoss 0.0176 (0.0506)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0033 (0.0042)	MaskLoss 0.0834 (0.0830)	MaskBCELoss 0.0140 (0.0201)	MaskDICELoss 0.0694 (0.0629)
Epoch: [4][431/500]	Time 49.203 (49.203)	Loss 0.5224 (0.3805)	CeLoss 0.0791 (0.0492)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0028 (0.0035)	MaskLoss 0.1562 (0.0959)	MaskBCELoss 0.0923 (0.0282)	MaskDICELoss 0.0639 (0.0677)
Epoch: [4][432/500]	Time 44.831 (44.831)	Loss 0.4230 (0.4040)	CeLoss 0.0212 (0.0662)	SegCLSLoss 0.0017 (0.0015)	KLLoss 0.0045 (0.0041)	MaskLoss 0.0998 (0.0968)	MaskBCELoss 0.0013 (0.0271)	MaskDICELoss 0.0985 (0.0697)
Epoch: [4][433/500]	Time 42.365 (42.365)	Loss 0.0363 (0.2838)	CeLoss 0.0364 (0.0442)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0033)	MaskLoss 0.0000 (0.0649)	MaskBCELoss 0.0000 (0.0120)	MaskDICELoss 0.0000 (0.0529)
Epoch: [4][434/500]	Time 44.678 (44.678)	Loss 0.2681 (0.3130)	CeLoss 0.0203 (0.0487)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0029 (0.0039)	MaskLoss 0.0624 (0.0726)	MaskBCELoss 0.0026 (0.0151)	MaskDICELoss 0.0598 (0.0574)
Epoch: [4][435/500]	Time 47.183 (47.183)	Loss 0.1788 (0.3038)	CeLoss 0.0618 (0.0389)	SegCLSLoss 0.0014 (0.0010)	KLLoss 0.0032 (0.0036)	MaskLoss 0.0304 (0.0735)	MaskBCELoss 0.0042 (0.0166)	MaskDICELoss 0.0262 (0.0569)
Epoch: [4][436/500]	Time 50.929 (50.929)	Loss 0.4304 (0.3758)	CeLoss 0.0801 (0.0350)	SegCLSLoss 0.0015 (0.0007)	KLLoss 0.0034 (0.0035)	MaskLoss 0.0872 (0.0929)	MaskBCELoss 0.0013 (0.0174)	MaskDICELoss 0.0858 (0.0755)
Epoch: [4][437/500]	Time 51.398 (51.398)	Loss 0.2234 (0.2336)	CeLoss 0.0222 (0.0229)	SegCLSLoss 0.0046 (0.0020)	KLLoss 0.0035 (0.0028)	MaskLoss 0.0563 (0.0552)	MaskBCELoss 0.0150 (0.0069)	MaskDICELoss 0.0414 (0.0483)
Epoch: [4][438/500]	Time 46.458 (46.458)	Loss 0.3848 (0.2662)	CeLoss 0.0222 (0.0333)	SegCLSLoss 0.0025 (0.0010)	KLLoss 0.0041 (0.0031)	MaskLoss 0.1157 (0.0638)	MaskBCELoss 0.0527 (0.0128)	MaskDICELoss 0.0629 (0.0509)
Epoch: [4][439/500]	Time 47.897 (47.897)	Loss 0.4821 (0.3382)	CeLoss 0.0732 (0.0445)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0038 (0.0036)	MaskLoss 0.1130 (0.0792)	MaskBCELoss 0.0237 (0.0136)	MaskDICELoss 0.0894 (0.0656)
Epoch: [4][440/500]	Time 51.387 (51.387)	Loss 0.0774 (0.2582)	CeLoss 0.0221 (0.0348)	SegCLSLoss 0.0010 (0.0009)	KLLoss 0.0030 (0.0036)	MaskLoss 0.0179 (0.0615)	MaskBCELoss 0.0099 (0.0132)	MaskDICELoss 0.0080 (0.0482)
Epoch: [4][441/500]	Time 46.067 (46.067)	Loss 0.4215 (0.3344)	CeLoss 0.0214 (0.0412)	SegCLSLoss 0.0036 (0.0015)	KLLoss 0.0026 (0.0041)	MaskLoss 0.0993 (0.0793)	MaskBCELoss 0.0007 (0.0144)	MaskDICELoss 0.0986 (0.0649)
Epoch: [4][442/500]	Time 52.006 (52.006)	Loss 0.1635 (0.3019)	CeLoss 0.0226 (0.0532)	SegCLSLoss 0.0015 (0.0013)	KLLoss 0.0037 (0.0045)	MaskLoss 0.0424 (0.0730)	MaskBCELoss 0.0166 (0.0243)	MaskDICELoss 0.0258 (0.0487)
Epoch: [4][443/500]	Time 80.832 (80.832)	Loss 0.4229 (0.2765)	CeLoss 0.0140 (0.0386)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0043 (0.0031)	MaskLoss 0.1022 (0.0627)	MaskBCELoss 0.0023 (0.0082)	MaskDICELoss 0.0999 (0.0545)
Epoch: [4][444/500]	Time 78.748 (78.748)	Loss 0.7079 (0.3007)	CeLoss 0.0097 (0.0489)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0063 (0.0039)	MaskLoss 0.2515 (0.0737)	MaskBCELoss 0.1573 (0.0236)	MaskDICELoss 0.0943 (0.0500)
Epoch: [4][445/500]	Time 78.721 (78.721)	Loss 0.2537 (0.4229)	CeLoss 0.0767 (0.0491)	SegCLSLoss 0.0004 (0.0020)	KLLoss 0.0054 (0.0043)	MaskLoss 0.0472 (0.1063)	MaskBCELoss 0.0086 (0.0284)	MaskDICELoss 0.0386 (0.0779)
Epoch: [4][446/500]	Time 76.436 (76.436)	Loss 0.0115 (0.3993)	CeLoss 0.0115 (0.0455)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0034)	MaskLoss 0.0000 (0.0919)	MaskBCELoss 0.0000 (0.0090)	MaskDICELoss 0.0000 (0.0830)
Epoch: [4][447/500]	Time 74.165 (74.165)	Loss 0.2652 (0.3131)	CeLoss 0.0239 (0.0422)	SegCLSLoss 0.0033 (0.0012)	KLLoss 0.0053 (0.0037)	MaskLoss 0.0623 (0.0745)	MaskBCELoss 0.0075 (0.0159)	MaskDICELoss 0.0548 (0.0587)
Epoch: [4][448/500]	Time 82.648 (82.648)	Loss 0.0522 (0.2835)	CeLoss 0.0139 (0.0400)	SegCLSLoss 0.0002 (0.0009)	KLLoss 0.0021 (0.0037)	MaskLoss 0.0102 (0.0717)	MaskBCELoss 0.0023 (0.0238)	MaskDICELoss 0.0079 (0.0480)
Epoch: [4][449/500]	Time 72.443 (72.443)	Loss 0.2634 (0.2406)	CeLoss 0.0209 (0.0357)	SegCLSLoss 0.0024 (0.0010)	KLLoss 0.0056 (0.0038)	MaskLoss 0.0720 (0.0557)	MaskBCELoss 0.0263 (0.0111)	MaskDICELoss 0.0458 (0.0446)
Epoch: [4][450/500]	Time 78.605 (78.605)	Loss 0.2897 (0.2535)	CeLoss 0.0601 (0.0352)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0037 (0.0029)	MaskLoss 0.0675 (0.0617)	MaskBCELoss 0.0226 (0.0160)	MaskDICELoss 0.0449 (0.0457)
Epoch: [4][451/500]	Time 73.513 (73.513)	Loss 0.4698 (0.4116)	CeLoss 0.0664 (0.0447)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0031 (0.0036)	MaskLoss 0.1017 (0.0983)	MaskBCELoss 0.0034 (0.0152)	MaskDICELoss 0.0983 (0.0831)
Epoch: [4][452/500]	Time 85.366 (85.366)	Loss 0.4226 (0.2886)	CeLoss 0.0239 (0.0309)	SegCLSLoss 0.0008 (0.0012)	KLLoss 0.0056 (0.0039)	MaskLoss 0.1075 (0.0701)	MaskBCELoss 0.0186 (0.0137)	MaskDICELoss 0.0889 (0.0564)
Epoch: [4][453/500]	Time 78.038 (78.038)	Loss 0.0621 (0.2910)	CeLoss 0.0620 (0.0378)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0653)	MaskBCELoss 0.0000 (0.0059)	MaskDICELoss 0.0000 (0.0594)
Epoch: [4][454/500]	Time 74.871 (74.871)	Loss 0.4179 (0.3550)	CeLoss 0.0674 (0.0366)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0042 (0.0041)	MaskLoss 0.1301 (0.0907)	MaskBCELoss 0.0872 (0.0245)	MaskDICELoss 0.0429 (0.0662)
Epoch: [4][455/500]	Time 75.602 (75.602)	Loss 0.6631 (0.4357)	CeLoss 0.0193 (0.0457)	SegCLSLoss 0.0026 (0.0014)	KLLoss 0.0062 (0.0045)	MaskLoss 0.2209 (0.1203)	MaskBCELoss 0.1237 (0.0482)	MaskDICELoss 0.0972 (0.0721)
Epoch: [4][456/500]	Time 79.726 (79.726)	Loss 0.3159 (0.3365)	CeLoss 0.0198 (0.0362)	SegCLSLoss 0.0023 (0.0018)	KLLoss 0.0049 (0.0037)	MaskLoss 0.0798 (0.0798)	MaskBCELoss 0.0147 (0.0117)	MaskDICELoss 0.0651 (0.0681)
Epoch: [4][457/500]	Time 78.911 (78.911)	Loss 0.4145 (0.3288)	CeLoss 0.0126 (0.0432)	SegCLSLoss 0.0012 (0.0008)	KLLoss 0.0030 (0.0030)	MaskLoss 0.1003 (0.0750)	MaskBCELoss 0.0015 (0.0088)	MaskDICELoss 0.0988 (0.0661)
Epoch: [4][458/500]	Time 73.189 (73.189)	Loss 0.2284 (0.3482)	CeLoss 0.0251 (0.0466)	SegCLSLoss 0.0014 (0.0017)	KLLoss 0.0044 (0.0043)	MaskLoss 0.0539 (0.0794)	MaskBCELoss 0.0089 (0.0106)	MaskDICELoss 0.0450 (0.0688)
Epoch: [4][459/500]	Time 76.644 (76.644)	Loss 0.4039 (0.3898)	CeLoss 0.0457 (0.0394)	SegCLSLoss 0.0005 (0.0016)	KLLoss 0.0022 (0.0039)	MaskLoss 0.0904 (0.0925)	MaskBCELoss 0.0030 (0.0121)	MaskDICELoss 0.0875 (0.0804)
Epoch: [4][460/500]	Time 76.512 (76.512)	Loss 0.0393 (0.2811)	CeLoss 0.0393 (0.0451)	SegCLSLoss 0.0000 (0.0014)	KLLoss 0.0000 (0.0039)	MaskLoss 0.0000 (0.0659)	MaskBCELoss 0.0000 (0.0162)	MaskDICELoss 0.0000 (0.0497)
Epoch: [4][461/500]	Time 76.111 (76.111)	Loss 0.4933 (0.3716)	CeLoss 0.0491 (0.0380)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0057 (0.0048)	MaskLoss 0.1192 (0.0908)	MaskBCELoss 0.0193 (0.0176)	MaskDICELoss 0.0999 (0.0732)
Epoch: [4][462/500]	Time 75.276 (75.276)	Loss 0.0648 (0.2761)	CeLoss 0.0133 (0.0316)	SegCLSLoss 0.0003 (0.0027)	KLLoss 0.0043 (0.0039)	MaskLoss 0.0142 (0.0682)	MaskBCELoss 0.0050 (0.0167)	MaskDICELoss 0.0093 (0.0515)
Epoch: [4][463/500]	Time 72.418 (72.418)	Loss 0.3684 (0.3433)	CeLoss 0.0693 (0.0436)	SegCLSLoss 0.0010 (0.0014)	KLLoss 0.0046 (0.0043)	MaskLoss 0.0890 (0.0804)	MaskBCELoss 0.0311 (0.0134)	MaskDICELoss 0.0579 (0.0670)
Epoch: [4][464/500]	Time 79.323 (79.323)	Loss 0.3446 (0.3715)	CeLoss 0.0210 (0.0452)	SegCLSLoss 0.0025 (0.0011)	KLLoss 0.0055 (0.0042)	MaskLoss 0.0812 (0.0925)	MaskBCELoss 0.0039 (0.0242)	MaskDICELoss 0.0773 (0.0683)
Epoch: [4][465/500]	Time 76.166 (76.166)	Loss 0.4622 (0.2806)	CeLoss 0.0635 (0.0394)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0033 (0.0040)	MaskLoss 0.0993 (0.0664)	MaskBCELoss 0.0009 (0.0146)	MaskDICELoss 0.0984 (0.0518)
Epoch: [4][466/500]	Time 70.112 (70.112)	Loss 0.4030 (0.3872)	CeLoss 0.0579 (0.0613)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0033 (0.0054)	MaskLoss 0.0893 (0.0932)	MaskBCELoss 0.0081 (0.0265)	MaskDICELoss 0.0812 (0.0667)
Epoch: [4][467/500]	Time 76.437 (76.437)	Loss 0.4266 (0.3460)	CeLoss 0.0237 (0.0368)	SegCLSLoss 0.0030 (0.0012)	KLLoss 0.0036 (0.0040)	MaskLoss 0.1012 (0.0835)	MaskBCELoss 0.0036 (0.0147)	MaskDICELoss 0.0976 (0.0688)
Epoch: [4][468/500]	Time 73.790 (73.790)	Loss 0.2140 (0.2775)	CeLoss 0.0635 (0.0448)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0049 (0.0039)	MaskLoss 0.0425 (0.0619)	MaskBCELoss 0.0122 (0.0097)	MaskDICELoss 0.0303 (0.0522)
Epoch: [4][469/500]	Time 81.947 (81.947)	Loss 0.4324 (0.4038)	CeLoss 0.0245 (0.0414)	SegCLSLoss 0.0025 (0.0013)	KLLoss 0.0037 (0.0046)	MaskLoss 0.1017 (0.1123)	MaskBCELoss 0.0019 (0.0459)	MaskDICELoss 0.0998 (0.0663)
Epoch: [4][470/500]	Time 73.464 (73.464)	Loss 0.3285 (0.3534)	CeLoss 0.0415 (0.0300)	SegCLSLoss 0.0002 (0.0017)	KLLoss 0.0043 (0.0040)	MaskLoss 0.0839 (0.0881)	MaskBCELoss 0.0266 (0.0169)	MaskDICELoss 0.0573 (0.0712)
Epoch: [4][471/500]	Time 69.542 (69.542)	Loss 0.0151 (0.3163)	CeLoss 0.0151 (0.0391)	SegCLSLoss 0.0000 (0.0019)	KLLoss 0.0000 (0.0031)	MaskLoss 0.0000 (0.0732)	MaskBCELoss 0.0000 (0.0099)	MaskDICELoss 0.0000 (0.0634)
Epoch: [4][472/500]	Time 80.985 (80.985)	Loss 0.1850 (0.2672)	CeLoss 0.0471 (0.0328)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0036 (0.0041)	MaskLoss 0.0359 (0.0622)	MaskBCELoss 0.0049 (0.0095)	MaskDICELoss 0.0310 (0.0527)
Epoch: [4][473/500]	Time 78.257 (78.257)	Loss 0.4384 (0.3821)	CeLoss 0.0214 (0.0431)	SegCLSLoss 0.0029 (0.0014)	KLLoss 0.0083 (0.0051)	MaskLoss 0.1054 (0.0892)	MaskBCELoss 0.0072 (0.0118)	MaskDICELoss 0.0982 (0.0774)
Epoch: [4][474/500]	Time 78.050 (78.050)	Loss 0.0334 (0.3833)	CeLoss 0.0334 (0.0354)	SegCLSLoss 0.0000 (0.0017)	KLLoss 0.0000 (0.0047)	MaskLoss 0.0000 (0.1090)	MaskBCELoss 0.0000 (0.0469)	MaskDICELoss 0.0000 (0.0621)
Epoch: [4][475/500]	Time 75.379 (75.379)	Loss 0.3322 (0.3453)	CeLoss 0.0189 (0.0595)	SegCLSLoss 0.0017 (0.0012)	KLLoss 0.0051 (0.0041)	MaskLoss 0.0883 (0.0794)	MaskBCELoss 0.0230 (0.0182)	MaskDICELoss 0.0653 (0.0612)
Epoch: [4][476/500]	Time 76.239 (76.239)	Loss 0.3493 (0.3392)	CeLoss 0.0593 (0.0450)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0052 (0.0044)	MaskLoss 0.0933 (0.0834)	MaskBCELoss 0.0442 (0.0223)	MaskDICELoss 0.0491 (0.0612)
Epoch: [4][477/500]	Time 75.726 (75.726)	Loss 0.4361 (0.3500)	CeLoss 0.0693 (0.0474)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0067 (0.0038)	MaskLoss 0.1314 (0.0829)	MaskBCELoss 0.0828 (0.0166)	MaskDICELoss 0.0486 (0.0663)
Epoch: [4][478/500]	Time 78.307 (78.307)	Loss 0.0196 (0.3344)	CeLoss 0.0197 (0.0423)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0039)	MaskLoss 0.0000 (0.0764)	MaskBCELoss 0.0000 (0.0088)	MaskDICELoss 0.0000 (0.0675)
Epoch: [4][479/500]	Time 79.695 (79.695)	Loss 0.2792 (0.3324)	CeLoss 0.0435 (0.0344)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0059 (0.0048)	MaskLoss 0.0617 (0.0793)	MaskBCELoss 0.0086 (0.0122)	MaskDICELoss 0.0531 (0.0671)
Epoch: [4][480/500]	Time 78.163 (78.163)	Loss 0.4305 (0.3289)	CeLoss 0.0232 (0.0397)	SegCLSLoss 0.0026 (0.0013)	KLLoss 0.0034 (0.0038)	MaskLoss 0.1013 (0.0755)	MaskBCELoss 0.0013 (0.0087)	MaskDICELoss 0.1000 (0.0668)
Epoch: [4][481/500]	Time 78.195 (78.195)	Loss 0.3668 (0.3580)	CeLoss 0.0153 (0.0463)	SegCLSLoss 0.0010 (0.0010)	KLLoss 0.0036 (0.0038)	MaskLoss 0.0875 (0.0879)	MaskBCELoss 0.0012 (0.0222)	MaskDICELoss 0.0863 (0.0658)
Epoch: [4][482/500]	Time 88.555 (88.555)	Loss 0.3978 (0.3375)	CeLoss 0.0593 (0.0501)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0047 (0.0050)	MaskLoss 0.0984 (0.0774)	MaskBCELoss 0.0302 (0.0138)	MaskDICELoss 0.0683 (0.0636)
Epoch: [4][483/500]	Time 77.445 (77.445)	Loss 0.3089 (0.3261)	CeLoss 0.0228 (0.0345)	SegCLSLoss 0.0034 (0.0015)	KLLoss 0.0058 (0.0044)	MaskLoss 0.0792 (0.0803)	MaskBCELoss 0.0192 (0.0173)	MaskDICELoss 0.0600 (0.0629)
Epoch: [4][484/500]	Time 71.440 (71.440)	Loss 0.4824 (0.3669)	CeLoss 0.0713 (0.0550)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0049 (0.0033)	MaskLoss 0.1032 (0.0814)	MaskBCELoss 0.0034 (0.0088)	MaskDICELoss 0.0998 (0.0726)
Epoch: [4][485/500]	Time 75.919 (75.919)	Loss 0.4828 (0.2930)	CeLoss 0.0854 (0.0477)	SegCLSLoss 0.0003 (0.0012)	KLLoss 0.0042 (0.0037)	MaskLoss 0.1048 (0.0633)	MaskBCELoss 0.0132 (0.0061)	MaskDICELoss 0.0916 (0.0572)
Epoch: [4][486/500]	Time 86.211 (86.211)	Loss 0.4040 (0.3203)	CeLoss 0.0143 (0.0298)	SegCLSLoss 0.0004 (0.0010)	KLLoss 0.0034 (0.0032)	MaskLoss 0.0977 (0.0792)	MaskBCELoss 0.0022 (0.0150)	MaskDICELoss 0.0955 (0.0642)
Epoch: [4][487/500]	Time 71.616 (71.616)	Loss 0.4013 (0.3385)	CeLoss 0.0198 (0.0386)	SegCLSLoss 0.0012 (0.0011)	KLLoss 0.0041 (0.0047)	MaskLoss 0.0997 (0.0830)	MaskBCELoss 0.0109 (0.0187)	MaskDICELoss 0.0888 (0.0644)
Epoch: [4][488/500]	Time 75.412 (75.412)	Loss 0.0146 (0.2261)	CeLoss 0.0146 (0.0366)	SegCLSLoss 0.0000 (0.0006)	KLLoss 0.0000 (0.0032)	MaskLoss 0.0000 (0.0528)	MaskBCELoss 0.0000 (0.0126)	MaskDICELoss 0.0000 (0.0402)
Epoch: [4][489/500]	Time 81.384 (81.384)	Loss 0.0648 (0.3374)	CeLoss 0.0649 (0.0454)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0041)	MaskLoss 0.0000 (0.0900)	MaskBCELoss 0.0000 (0.0362)	MaskDICELoss 0.0000 (0.0537)
Epoch: [4][490/500]	Time 75.073 (75.073)	Loss 0.1994 (0.3560)	CeLoss 0.0547 (0.0426)	SegCLSLoss 0.0010 (0.0017)	KLLoss 0.0029 (0.0044)	MaskLoss 0.0421 (0.0846)	MaskBCELoss 0.0134 (0.0151)	MaskDICELoss 0.0287 (0.0695)
Epoch: [4][491/500]	Time 80.029 (80.029)	Loss 0.4792 (0.3540)	CeLoss 0.0693 (0.0439)	SegCLSLoss 0.0006 (0.0017)	KLLoss 0.0038 (0.0041)	MaskLoss 0.1028 (0.0838)	MaskBCELoss 0.0029 (0.0150)	MaskDICELoss 0.0999 (0.0688)
Epoch: [4][492/500]	Time 79.410 (79.410)	Loss 0.3951 (0.2980)	CeLoss 0.0708 (0.0529)	SegCLSLoss 0.0004 (0.0009)	KLLoss 0.0028 (0.0034)	MaskLoss 0.0945 (0.0654)	MaskBCELoss 0.0283 (0.0102)	MaskDICELoss 0.0661 (0.0552)
Epoch: [4][493/500]	Time 72.158 (72.158)	Loss 0.4563 (0.3635)	CeLoss 0.0713 (0.0464)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0031 (0.0038)	MaskLoss 0.0965 (0.0825)	MaskBCELoss 0.0021 (0.0089)	MaskDICELoss 0.0944 (0.0736)
Epoch: [4][494/500]	Time 71.257 (71.257)	Loss 0.3158 (0.3509)	CeLoss 0.0347 (0.0507)	SegCLSLoss 0.0016 (0.0007)	KLLoss 0.0043 (0.0036)	MaskLoss 0.0756 (0.0968)	MaskBCELoss 0.0132 (0.0454)	MaskDICELoss 0.0624 (0.0513)
Epoch: [4][495/500]	Time 72.649 (72.649)	Loss 0.4053 (0.3231)	CeLoss 0.1016 (0.0528)	SegCLSLoss 0.0005 (0.0014)	KLLoss 0.0049 (0.0038)	MaskLoss 0.0953 (0.0774)	MaskBCELoss 0.0410 (0.0218)	MaskDICELoss 0.0543 (0.0556)
Epoch: [4][496/500]	Time 71.412 (71.412)	Loss 0.4570 (0.4394)	CeLoss 0.0245 (0.0353)	SegCLSLoss 0.0022 (0.0016)	KLLoss 0.0026 (0.0045)	MaskLoss 0.1145 (0.1107)	MaskBCELoss 0.0146 (0.0220)	MaskDICELoss 0.0999 (0.0887)
Epoch: [4][497/500]	Time 76.341 (76.341)	Loss 0.4348 (0.2730)	CeLoss 0.0222 (0.0440)	SegCLSLoss 0.0024 (0.0012)	KLLoss 0.0029 (0.0039)	MaskLoss 0.1059 (0.0651)	MaskBCELoss 0.0075 (0.0179)	MaskDICELoss 0.0984 (0.0472)
Epoch: [4][498/500]	Time 77.262 (77.262)	Loss 0.4774 (0.3557)	CeLoss 0.0610 (0.0459)	SegCLSLoss 0.0008 (0.0011)	KLLoss 0.0044 (0.0044)	MaskLoss 0.1060 (0.0835)	MaskBCELoss 0.0062 (0.0146)	MaskDICELoss 0.0999 (0.0689)
Epoch: [4][499/500]	Time 86.526 (86.526)	Loss 0.0950 (0.3374)	CeLoss 0.0153 (0.0428)	SegCLSLoss 0.0007 (0.0012)	KLLoss 0.0033 (0.0041)	MaskLoss 0.0264 (0.0789)	MaskBCELoss 0.0147 (0.0128)	MaskDICELoss 0.0117 (0.0661)
[2025-03-12 18:00:19,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[0.00026815662650602406], mom=[(0.9, 0.95)]
[2025-03-12 18:00:19,267] [INFO] [timer.py:215:stop] epoch=0/micro_step=2500/global_step=250, RunningAvgSamplesPerSec=0.6505442909128202, CurrSamplesPerSec=0.4897146649746231, MemAllocated=59.79GB, MaxMemAllocated=74.71GB
Epoch: [4][500/500]	Time 84.452 (84.452)	Loss 0.4536 (0.4137)	CeLoss 0.0503 (0.0436)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0034 (0.0042)	MaskLoss 0.1022 (0.0974)	MaskBCELoss 0.0047 (0.0121)	MaskDICELoss 0.0975 (0.0853)
































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [02:37<00:00,  1.27it/s]
giou: 0.2707, ciou: 0.2085
[2025-03-12 18:02:58,170] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step250 is about to be saved!
[2025-03-12 18:03:25,863] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step250/mp_rank_00_model_states.pt
[2025-03-12 18:03:25,864] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step250/mp_rank_00_model_states.pt...
[2025-03-12 18:06:40,754] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step250/mp_rank_00_model_states.pt.
[2025-03-12 18:06:42,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-12 18:06:53,443] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-12 18:06:53,488] [INFO] [engine.py:3244:_save_zero_checkpoint] zero checkpoint saved ./runs/plum-13b_kld_1_dice_4/plum-13b_kld_1_dice_4_accum-10_maxlen512_epochs50_bsz4_kld_loss_1.0_dice_loss_4.0_1000.0_lr0.0003_teacher_ckpt_model/global_step250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-12 18:06:53,489] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step250 is ready now!
Epoch: [5][  1/500]	Time 85.461 (85.461)	Loss 0.1744 (0.3058)	CeLoss 0.0256 (0.0350)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0030 (0.0034)	MaskLoss 0.0485 (0.0754)	MaskBCELoss 0.0243 (0.0173)	MaskDICELoss 0.0242 (0.0581)
Epoch: [5][  2/500]	Time 74.498 (74.498)	Loss 0.1525 (0.2850)	CeLoss 0.0618 (0.0410)	SegCLSLoss 0.0014 (0.0018)	KLLoss 0.0047 (0.0042)	MaskLoss 0.0244 (0.0689)	MaskBCELoss 0.0061 (0.0184)	MaskDICELoss 0.0182 (0.0505)
Epoch: [5][  3/500]	Time 85.258 (85.258)	Loss 0.4686 (0.3143)	CeLoss 0.0542 (0.0496)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0042 (0.0041)	MaskLoss 0.1116 (0.0706)	MaskBCELoss 0.0184 (0.0111)	MaskDICELoss 0.0932 (0.0595)
Epoch: [5][  4/500]	Time 80.737 (80.737)	Loss 0.4735 (0.3004)	CeLoss 0.0522 (0.0350)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0037 (0.0037)	MaskLoss 0.1084 (0.0758)	MaskBCELoss 0.0084 (0.0211)	MaskDICELoss 0.1000 (0.0548)
Epoch: [5][  5/500]	Time 75.932 (75.932)	Loss 0.4311 (0.3174)	CeLoss 0.0210 (0.0239)	SegCLSLoss 0.0010 (0.0017)	KLLoss 0.0047 (0.0031)	MaskLoss 0.1025 (0.0823)	MaskBCELoss 0.0025 (0.0198)	MaskDICELoss 0.1000 (0.0625)
Epoch: [5][  6/500]	Time 79.480 (79.480)	Loss 0.0148 (0.3353)	CeLoss 0.0148 (0.0348)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0043)	MaskLoss 0.0000 (0.0845)	MaskBCELoss 0.0000 (0.0211)	MaskDICELoss 0.0000 (0.0634)
Epoch: [5][  7/500]	Time 78.956 (78.956)	Loss 0.1647 (0.3052)	CeLoss 0.0535 (0.0304)	SegCLSLoss 0.0004 (0.0012)	KLLoss 0.0041 (0.0039)	MaskLoss 0.0299 (0.0725)	MaskBCELoss 0.0062 (0.0099)	MaskDICELoss 0.0237 (0.0626)
Epoch: [5][  8/500]	Time 76.211 (76.211)	Loss 0.5746 (0.3670)	CeLoss 0.0942 (0.0482)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0020 (0.0037)	MaskLoss 0.1460 (0.0863)	MaskBCELoss 0.0528 (0.0154)	MaskDICELoss 0.0931 (0.0709)
Epoch: [5][  9/500]	Time 80.931 (80.931)	Loss 0.2739 (0.4114)	CeLoss 0.0645 (0.0557)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0031 (0.0040)	MaskLoss 0.0623 (0.0981)	MaskBCELoss 0.0216 (0.0207)	MaskDICELoss 0.0407 (0.0774)
Epoch: [5][ 10/500]	Time 72.524 (72.524)	Loss 0.1293 (0.2945)	CeLoss 0.0215 (0.0481)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0053 (0.0040)	MaskLoss 0.0269 (0.0670)	MaskBCELoss 0.0031 (0.0132)	MaskDICELoss 0.0239 (0.0538)
Epoch: [5][ 11/500]	Time 71.597 (71.597)	Loss 0.1191 (0.3596)	CeLoss 0.0786 (0.0653)	SegCLSLoss 0.0005 (0.0006)	KLLoss 0.0035 (0.0043)	MaskLoss 0.0110 (0.0836)	MaskBCELoss 0.0037 (0.0224)	MaskDICELoss 0.0073 (0.0612)
Epoch: [5][ 12/500]	Time 71.962 (71.962)	Loss 0.4775 (0.3447)	CeLoss 0.0227 (0.0382)	SegCLSLoss 0.0026 (0.0014)	KLLoss 0.0056 (0.0037)	MaskLoss 0.1249 (0.0837)	MaskBCELoss 0.0258 (0.0163)	MaskDICELoss 0.0991 (0.0673)
Epoch: [5][ 13/500]	Time 72.281 (72.281)	Loss 0.4358 (0.3669)	CeLoss 0.0486 (0.0433)	SegCLSLoss 0.0007 (0.0014)	KLLoss 0.0022 (0.0040)	MaskLoss 0.1043 (0.0876)	MaskBCELoss 0.0163 (0.0157)	MaskDICELoss 0.0880 (0.0718)
Epoch: [5][ 14/500]	Time 70.927 (70.927)	Loss 0.5437 (0.3132)	CeLoss 0.0277 (0.0403)	SegCLSLoss 0.0013 (0.0013)	KLLoss 0.0048 (0.0042)	MaskLoss 0.1984 (0.0799)	MaskBCELoss 0.1415 (0.0257)	MaskDICELoss 0.0569 (0.0542)
Epoch: [5][ 15/500]	Time 81.817 (81.817)	Loss 0.1911 (0.3138)	CeLoss 0.0112 (0.0340)	SegCLSLoss 0.0006 (0.0012)	KLLoss 0.0043 (0.0041)	MaskLoss 0.0519 (0.0742)	MaskBCELoss 0.0162 (0.0110)	MaskDICELoss 0.0357 (0.0633)
Epoch: [5][ 16/500]	Time 71.612 (71.612)	Loss 0.3452 (0.3631)	CeLoss 0.0223 (0.0374)	SegCLSLoss 0.0025 (0.0013)	KLLoss 0.0034 (0.0040)	MaskLoss 0.0818 (0.0894)	MaskBCELoss 0.0044 (0.0183)	MaskDICELoss 0.0773 (0.0711)
Epoch: [5][ 17/500]	Time 71.990 (71.990)	Loss 0.3678 (0.2952)	CeLoss 0.0217 (0.0376)	SegCLSLoss 0.0015 (0.0010)	KLLoss 0.0027 (0.0039)	MaskLoss 0.0860 (0.0699)	MaskBCELoss 0.0006 (0.0131)	MaskDICELoss 0.0853 (0.0568)
Epoch: [5][ 18/500]	Time 70.811 (70.811)	Loss 0.0209 (0.2166)	CeLoss 0.0209 (0.0485)	SegCLSLoss 0.0000 (0.0008)	KLLoss 0.0000 (0.0036)	MaskLoss 0.0000 (0.0456)	MaskBCELoss 0.0000 (0.0091)	MaskDICELoss 0.0000 (0.0365)
Epoch: [5][ 19/500]	Time 70.704 (70.704)	Loss 0.3014 (0.3370)	CeLoss 0.0613 (0.0568)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0064 (0.0042)	MaskLoss 0.0660 (0.0821)	MaskBCELoss 0.0153 (0.0265)	MaskDICELoss 0.0507 (0.0556)
Epoch: [5][ 20/500]	Time 74.016 (74.016)	Loss 0.4079 (0.3300)	CeLoss 0.0222 (0.0376)	SegCLSLoss 0.0022 (0.0015)	KLLoss 0.0072 (0.0043)	MaskLoss 0.1118 (0.0792)	MaskBCELoss 0.0348 (0.0147)	MaskDICELoss 0.0769 (0.0645)
Epoch: [5][ 21/500]	Time 62.614 (62.614)	Loss 0.4527 (0.3371)	CeLoss 0.0238 (0.0441)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0042 (0.0044)	MaskLoss 0.1159 (0.0799)	MaskBCELoss 0.0197 (0.0157)	MaskDICELoss 0.0962 (0.0641)
Epoch: [5][ 22/500]	Time 72.662 (72.662)	Loss 0.2141 (0.2960)	CeLoss 0.0371 (0.0387)	SegCLSLoss 0.0006 (0.0010)	KLLoss 0.0037 (0.0043)	MaskLoss 0.0470 (0.0694)	MaskBCELoss 0.0074 (0.0124)	MaskDICELoss 0.0396 (0.0569)
Epoch: [5][ 23/500]	Time 69.691 (69.691)	Loss 0.2431 (0.2709)	CeLoss 0.0693 (0.0430)	SegCLSLoss 0.0075 (0.0019)	KLLoss 0.0057 (0.0041)	MaskLoss 0.0526 (0.0611)	MaskBCELoss 0.0231 (0.0108)	MaskDICELoss 0.0295 (0.0503)
Epoch: [5][ 24/500]	Time 70.482 (70.482)	Loss 0.4541 (0.3537)	CeLoss 0.0474 (0.0409)	SegCLSLoss 0.0006 (0.0013)	KLLoss 0.0037 (0.0039)	MaskLoss 0.1035 (0.0832)	MaskBCELoss 0.0056 (0.0123)	MaskDICELoss 0.0978 (0.0709)
Epoch: [5][ 25/500]	Time 75.268 (75.268)	Loss 0.4619 (0.3628)	CeLoss 0.0757 (0.0414)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0042 (0.0034)	MaskLoss 0.1023 (0.0865)	MaskBCELoss 0.0140 (0.0142)	MaskDICELoss 0.0882 (0.0723)
Epoch: [5][ 26/500]	Time 68.387 (68.387)	Loss 0.4331 (0.3641)	CeLoss 0.0193 (0.0495)	SegCLSLoss 0.0019 (0.0011)	KLLoss 0.0044 (0.0037)	MaskLoss 0.1043 (0.0890)	MaskBCELoss 0.0043 (0.0229)	MaskDICELoss 0.0999 (0.0661)
Epoch: [5][ 27/500]	Time 62.769 (62.769)	Loss 0.4166 (0.2931)	CeLoss 0.0840 (0.0458)	SegCLSLoss 0.0003 (0.0009)	KLLoss 0.0031 (0.0031)	MaskLoss 0.0864 (0.0675)	MaskBCELoss 0.0080 (0.0131)	MaskDICELoss 0.0784 (0.0544)
Epoch: [5][ 28/500]	Time 76.272 (76.272)	Loss 0.2805 (0.3488)	CeLoss 0.0254 (0.0388)	SegCLSLoss 0.0019 (0.0007)	KLLoss 0.0036 (0.0035)	MaskLoss 0.0824 (0.0814)	MaskBCELoss 0.0396 (0.0099)	MaskDICELoss 0.0428 (0.0716)
Epoch: [5][ 29/500]	Time 81.843 (81.843)	Loss 0.4281 (0.3248)	CeLoss 0.0674 (0.0413)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0030 (0.0036)	MaskLoss 0.0928 (0.0798)	MaskBCELoss 0.0072 (0.0200)	MaskDICELoss 0.0855 (0.0598)
Epoch: [5][ 30/500]	Time 72.844 (72.844)	Loss 0.4540 (0.2340)	CeLoss 0.0376 (0.0290)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0082 (0.0032)	MaskLoss 0.1116 (0.0568)	MaskBCELoss 0.0191 (0.0130)	MaskDICELoss 0.0924 (0.0438)
Epoch: [5][ 31/500]	Time 73.947 (73.947)	Loss 0.4888 (0.2748)	CeLoss 0.0874 (0.0396)	SegCLSLoss 0.0027 (0.0012)	KLLoss 0.0041 (0.0037)	MaskLoss 0.0996 (0.0644)	MaskBCELoss 0.0011 (0.0134)	MaskDICELoss 0.0985 (0.0510)
Epoch: [5][ 32/500]	Time 81.201 (81.201)	Loss 0.4526 (0.2253)	CeLoss 0.0811 (0.0462)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0028 (0.0027)	MaskLoss 0.0947 (0.0498)	MaskBCELoss 0.0051 (0.0115)	MaskDICELoss 0.0896 (0.0383)
Epoch: [5][ 33/500]	Time 78.929 (78.929)	Loss 0.3819 (0.2967)	CeLoss 0.0105 (0.0364)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0045 (0.0033)	MaskLoss 0.0940 (0.0730)	MaskBCELoss 0.0047 (0.0177)	MaskDICELoss 0.0893 (0.0553)
Epoch: [5][ 34/500]	Time 71.391 (71.391)	Loss 0.4214 (0.4853)	CeLoss 0.0216 (0.0652)	SegCLSLoss 0.0026 (0.0010)	KLLoss 0.0030 (0.0040)	MaskLoss 0.0995 (0.1191)	MaskBCELoss 0.0012 (0.0305)	MaskDICELoss 0.0983 (0.0886)
Epoch: [5][ 35/500]	Time 70.237 (70.237)	Loss 0.3122 (0.3640)	CeLoss 0.0214 (0.0311)	SegCLSLoss 0.0014 (0.0020)	KLLoss 0.0046 (0.0043)	MaskLoss 0.0723 (0.0961)	MaskBCELoss 0.0017 (0.0283)	MaskDICELoss 0.0705 (0.0677)
Epoch: [5][ 36/500]	Time 73.008 (73.008)	Loss 0.3591 (0.4378)	CeLoss 0.0120 (0.0453)	SegCLSLoss 0.0016 (0.0011)	KLLoss 0.0068 (0.0039)	MaskLoss 0.0998 (0.1152)	MaskBCELoss 0.0297 (0.0363)	MaskDICELoss 0.0700 (0.0789)
Epoch: [5][ 37/500]	Time 73.940 (73.940)	Loss 0.4224 (0.2171)	CeLoss 0.0205 (0.0331)	SegCLSLoss 0.0023 (0.0009)	KLLoss 0.0036 (0.0029)	MaskLoss 0.1010 (0.0504)	MaskBCELoss 0.0034 (0.0105)	MaskDICELoss 0.0975 (0.0399)
Epoch: [5][ 38/500]	Time 71.965 (71.965)	Loss 0.0252 (0.3222)	CeLoss 0.0251 (0.0455)	SegCLSLoss 0.0000 (0.0006)	KLLoss 0.0000 (0.0028)	MaskLoss 0.0000 (0.0708)	MaskBCELoss 0.0000 (0.0048)	MaskDICELoss 0.0000 (0.0660)
Epoch: [5][ 39/500]	Time 57.896 (57.896)	Loss 0.0496 (0.3619)	CeLoss 0.0496 (0.0532)	SegCLSLoss 0.0000 (0.0010)	KLLoss 0.0000 (0.0042)	MaskLoss 0.0000 (0.0830)	MaskBCELoss 0.0000 (0.0140)	MaskDICELoss 0.0000 (0.0690)
Epoch: [5][ 40/500]	Time 68.341 (68.341)	Loss 0.4336 (0.3209)	CeLoss 0.0242 (0.0539)	SegCLSLoss 0.0018 (0.0022)	KLLoss 0.0027 (0.0045)	MaskLoss 0.1028 (0.0711)	MaskBCELoss 0.0028 (0.0116)	MaskDICELoss 0.1000 (0.0595)
Epoch: [5][ 41/500]	Time 83.643 (83.643)	Loss 0.1527 (0.2618)	CeLoss 0.0320 (0.0425)	SegCLSLoss 0.0004 (0.0008)	KLLoss 0.0029 (0.0034)	MaskLoss 0.0297 (0.0556)	MaskBCELoss 0.0007 (0.0034)	MaskDICELoss 0.0290 (0.0521)
Epoch: [5][ 42/500]	Time 67.598 (67.598)	Loss 1.5945 (0.4568)	CeLoss 0.0540 (0.0364)	SegCLSLoss 0.0010 (0.0013)	KLLoss 0.0053 (0.0045)	MaskLoss 0.6740 (0.1424)	MaskBCELoss 0.5806 (0.0771)	MaskDICELoss 0.0934 (0.0653)
Epoch: [5][ 43/500]	Time 69.003 (69.003)	Loss 0.1781 (0.3597)	CeLoss 0.0491 (0.0346)	SegCLSLoss 0.0004 (0.0022)	KLLoss 0.0022 (0.0036)	MaskLoss 0.0328 (0.0843)	MaskBCELoss 0.0023 (0.0084)	MaskDICELoss 0.0305 (0.0759)
Epoch: [5][ 44/500]	Time 76.372 (76.372)	Loss 0.4525 (0.3833)	CeLoss 0.0742 (0.0482)	SegCLSLoss 0.0026 (0.0009)	KLLoss 0.0053 (0.0038)	MaskLoss 0.0992 (0.0907)	MaskBCELoss 0.0127 (0.0159)	MaskDICELoss 0.0866 (0.0748)
Epoch: [5][ 45/500]	Time 68.664 (68.664)	Loss 0.4166 (0.3553)	CeLoss 0.0130 (0.0489)	SegCLSLoss 0.0017 (0.0018)	KLLoss 0.0036 (0.0045)	MaskLoss 0.1030 (0.0867)	MaskBCELoss 0.0063 (0.0229)	MaskDICELoss 0.0966 (0.0638)
Epoch: [5][ 46/500]	Time 76.086 (76.086)	Loss 0.4585 (0.3395)	CeLoss 0.0452 (0.0430)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0046 (0.0036)	MaskLoss 0.1044 (0.0818)	MaskBCELoss 0.0046 (0.0175)	MaskDICELoss 0.0997 (0.0643)
Epoch: [5][ 47/500]	Time 67.160 (67.160)	Loss 0.2877 (0.3238)	CeLoss 0.0186 (0.0434)	SegCLSLoss 0.0049 (0.0016)	KLLoss 0.0039 (0.0035)	MaskLoss 0.0820 (0.0823)	MaskBCELoss 0.0326 (0.0266)	MaskDICELoss 0.0494 (0.0557)
Epoch: [5][ 48/500]	Time 64.801 (64.801)	Loss 0.2909 (0.2753)	CeLoss 0.0238 (0.0528)	SegCLSLoss 0.0017 (0.0015)	KLLoss 0.0036 (0.0039)	MaskLoss 0.0735 (0.0616)	MaskBCELoss 0.0157 (0.0143)	MaskDICELoss 0.0578 (0.0473)
Epoch: [5][ 49/500]	Time 73.141 (73.141)	Loss 0.2947 (0.2717)	CeLoss 0.0266 (0.0442)	SegCLSLoss 0.0030 (0.0012)	KLLoss 0.0042 (0.0033)	MaskLoss 0.0728 (0.0628)	MaskBCELoss 0.0145 (0.0138)	MaskDICELoss 0.0583 (0.0490)
Epoch: [5][ 50/500]	Time 72.503 (72.503)	Loss 0.2860 (0.3150)	CeLoss 0.0654 (0.0453)	SegCLSLoss 0.0007 (0.0007)	KLLoss 0.0036 (0.0034)	MaskLoss 0.0681 (0.0719)	MaskBCELoss 0.0279 (0.0108)	MaskDICELoss 0.0402 (0.0611)
Epoch: [5][ 51/500]	Time 68.046 (68.046)	Loss 0.4244 (0.3450)	CeLoss 0.0227 (0.0634)	SegCLSLoss 0.0011 (0.0011)	KLLoss 0.0033 (0.0040)	MaskLoss 0.1049 (0.0765)	MaskBCELoss 0.0108 (0.0145)	MaskDICELoss 0.0941 (0.0620)
Epoch: [5][ 52/500]	Time 71.241 (71.241)	Loss 0.1491 (0.3495)	CeLoss 0.0552 (0.0440)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0044 (0.0036)	MaskLoss 0.0297 (0.0837)	MaskBCELoss 0.0147 (0.0167)	MaskDICELoss 0.0150 (0.0670)
Epoch: [5][ 53/500]	Time 69.259 (69.259)	Loss 0.4134 (0.2596)	CeLoss 0.0223 (0.0327)	SegCLSLoss 0.0019 (0.0015)	KLLoss 0.0060 (0.0034)	MaskLoss 0.0966 (0.0612)	MaskBCELoss 0.0011 (0.0111)	MaskDICELoss 0.0955 (0.0501)
Epoch: [5][ 54/500]	Time 70.192 (70.192)	Loss 0.3974 (0.3365)	CeLoss 0.0469 (0.0382)	SegCLSLoss 0.0006 (0.0011)	KLLoss 0.0042 (0.0031)	MaskLoss 0.0893 (0.0803)	MaskBCELoss 0.0058 (0.0133)	MaskDICELoss 0.0836 (0.0670)
Epoch: [5][ 55/500]	Time 77.923 (77.923)	Loss 0.3530 (0.2419)	CeLoss 0.0422 (0.0352)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0034 (0.0030)	MaskLoss 0.1082 (0.0570)	MaskBCELoss 0.0627 (0.0124)	MaskDICELoss 0.0455 (0.0446)
Epoch: [5][ 56/500]	Time 71.286 (71.286)	Loss 0.2901 (0.3171)	CeLoss 0.0209 (0.0412)	SegCLSLoss 0.0020 (0.0007)	KLLoss 0.0042 (0.0031)	MaskLoss 0.0720 (0.0725)	MaskBCELoss 0.0121 (0.0088)	MaskDICELoss 0.0599 (0.0637)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py", line 671, in <module>
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py", line 404, in main
[rank0]:     train_iter = train(
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py", line 500, in train
[rank0]:     input_dict["images"] = input_dict["images"].half()
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1735, in forward
[rank0]:     loss = self.module(*inputs, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/peft/peft_model.py", line 922, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/PLUM.py", line 216, in forward
[rank0]:     self.token_to_mask_fcs.train()
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/PLUM.py", line 234, in model_forward
[rank0]:     self.config.tune_mm_mlp_adapter = False
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/PLUM.py", line 205, in get_visual_embs
[rank0]:     for param in self.text_hidden_fcs.parameters():
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/segment_anything/modeling/image_encoder.py", line 116, in forward
[rank0]:     x = blk(x)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/segment_anything/modeling/image_encoder.py", line 185, in forward
[rank0]:     x = self.attn(x)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/segment_anything/modeling/image_encoder.py", line 247, in forward
[rank0]:     attn = add_decomposed_rel_pos(
[rank0]:   File "/shared/nas2/jk100/partonomy_private/src/models/PLUM/model/segment_anything/modeling/image_encoder.py", line 378, in add_decomposed_rel_pos
[rank0]:     Rh = get_rel_pos(q_h, k_h, rel_pos_h)
[rank0]: KeyboardInterrupt