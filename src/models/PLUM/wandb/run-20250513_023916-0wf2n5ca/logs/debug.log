2025-05-13 02:39:16,808 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Current SDK version is 0.16.0
2025-05-13 02:39:16,808 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Configure stats pid to 3681105
2025-05-13 02:39:16,808 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Loading settings from /home/jk100/.config/wandb/settings
2025-05-13 02:39:16,808 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Loading settings from /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/settings
2025-05-13 02:39:16,808 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'src/models/PLUM/plum_train_ds.py', 'program_abspath': '/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py', 'program': '/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py'}
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_init.py:_log_setup():524] Logging user logs to /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/run-20250513_023916-0wf2n5ca/logs/debug.log
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_init.py:_log_setup():525] Logging internal logs to /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/run-20250513_023916-0wf2n5ca/logs/debug-internal.log
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_init.py:init():564] calling init triggers
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'local_rank': 0, 'version': 'liuhaotian/llava-llama-2-13b-chat-lightning-preview', 'zero_shot_ckpt_path': 'runs/plum-13b_kld_0.1_focal_tversky_8_v1_0shot/plum-13b_kld_0.1_focal_tversky_8_v1_0shot_bidirbio_2048_accum_10_maxlen512_epochs25_segloss_2_bce_loss_2_kld_loss_0_dice_loss_8_bidir_bio_train_prompt_enc_ckpt_model', 'eval_ckpt_path': '', 'vis_save_path': './vis_output', 'precision': 'bf16', 'image_size': 1024, 'model_max_length': 512, 'lora_r': 8, 'vision_tower': 'openai/clip-vit-large-patch14', 'load_in_8bit': False, 'load_in_4bit': False, 'dataset': 'explanatory_seg', 'sample_rates': '1', 'sem_seg_data': 'ade20k||cocostuff||pascal_part||paco_lvis||mapillary', 'refer_seg_data': 'refclef||refcoco||refcoco+||refcocog', 'explanatory_seg_data': True, 'wandb': False, 'wandb_project_name': 'plum-training', 'vqa_data': 'llava_instruct_150k', 'reason_seg_data': 'ReasonSeg|train', 'val_dataset': 'ReasonSeg|val', 'dataset_dir': '/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset', 'partonomy_train_dataset_path': '/shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/{dataset_split}/{dataset_split}_qa_pairs_train.json', 'partonomy_val_dataset_path': '/shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/{dataset_split}/{dataset_split}_qa_pairs_val.json', 'partonomy_dataset_split': 'partimagenet', 'partonomy_question_type': 'identification_with_label', 'sample_one_question_per_image': True, 'random_seed': 42, 'metrics_macro_giou_evaluator_config': {'matching_strategy': 'PAIRED', 'reduction': 'MACRO'}, 'metrics_micro_giou_evaluator_config': {'matching_strategy': 'PAIRED', 'reduction': 'MICRO'}, 'metrics_part_text_evaluator_config': {'match_method': 'EXACT', 'embedding_model': 'google-bert/bert-base-uncased', 'cosine_threshold': 0.75, 'embedding_device': 'cuda', 'embedding_matching_algorithm': 'hungarian', 'llm_model': 'microsoft/Phi-4-mini-instruct', 'llm_temperature': 0, 'max_tokens': 100, 'vllm_gpu_memory_utilization': 1.0}, 'log_base_dir': './runs', 'exp_name': 'plum-13b_kld_0.1_focal_tversky_8_v1_partonomy_ft', 'epochs': 5, 'steps_per_epoch': 500, 'batch_size': 8, 'grad_accumulation_steps': 10, 'val_batch_size': 1, 'workers': 4, 'lr': 0.0003, 'ce_loss_weight': 1.0, 'dice_type': 'focal_tversky', 'dice_loss_weight': 8.0, 'dice_scale_factor': 1000.0, 'bce_loss_weight': 2.0, 'kld_loss_weight': 0.1, 'kld_sigma': 1.0, 'seg_cls_loss_weight': 2.0, 'seg_cls_loss_per_cls_weight': [0.1, 1.0, 1.0], 'use_teacher_ref': False, 'use_bidir_bio': True, 'use_cross_attn_bio': False, 'use_hinge_loss': False, 'use_crf_bio': False, 'pred_binary_span': False, 'focal_tversky_alpha': 0.7, 'focal_tversky_beta': 0.3, 'limit_batches': None, 'use_feedback_loop': True, 'bidir_nhead': 8, 'bidir_dim_feedforward': 2048, 'lora_alpha': 16, 'lora_dropout': 0.05, 'lora_target_modules': 'q_proj,v_proj', 'explanatory': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'num_classes_per_sample': 5, 'exclude_val': False, 'no_eval': False, 'eval_only': False, 'vision_pretrained': '/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/weights/sam_vit_h_4b8939.pth', 'out_dim': 256, 'resume': '', 'print_freq': 1, 'start_epoch': 0, 'gradient_checkpointing': True, 'train_mask_decoder': True, 'train_mask_prompt_encoder': True, 'use_mm_start_end': True, 'auto_resume': True, 'conv_type': 'llava_v1', 'log_dir': './runs/plum-13b_kld_0.1_focal_tversky_8_v1_partonomy_ft'}
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_init.py:init():614] starting backend
2025-05-13 02:39:16,809 INFO    MainThread:3681105 [wandb_init.py:init():618] setting up manager
2025-05-13 02:39:16,810 INFO    MainThread:3681105 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-13 02:39:16,811 INFO    MainThread:3681105 [wandb_init.py:init():624] backend started and connected
2025-05-13 02:39:16,813 INFO    MainThread:3681105 [wandb_init.py:init():716] updated telemetry
2025-05-13 02:39:16,822 INFO    MainThread:3681105 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2025-05-13 02:39:17,158 INFO    MainThread:3681105 [wandb_run.py:_on_init():2254] communicating current version
2025-05-13 02:39:17,248 INFO    MainThread:3681105 [wandb_run.py:_on_init():2263] got version response upgrade_message: "wandb version 0.19.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-05-13 02:39:17,248 INFO    MainThread:3681105 [wandb_init.py:init():800] starting run threads in backend
2025-05-13 02:39:22,825 INFO    MainThread:3681105 [wandb_run.py:_console_start():2233] atexit reg
2025-05-13 02:39:22,826 INFO    MainThread:3681105 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2025-05-13 02:39:22,826 INFO    MainThread:3681105 [wandb_run.py:_redirect():2153] Wrapping output streams.
2025-05-13 02:39:22,826 INFO    MainThread:3681105 [wandb_run.py:_redirect():2178] Redirects installed.
2025-05-13 02:39:22,826 INFO    MainThread:3681105 [wandb_init.py:init():841] run started, returning control to user process
2025-05-13 02:44:36,569 WARNING MsgRouterThr:3681105 [router.py:message_loop():77] message_loop has been closed
