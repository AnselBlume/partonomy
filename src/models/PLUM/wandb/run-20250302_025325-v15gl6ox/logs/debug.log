2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Current SDK version is 0.16.0
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Configure stats pid to 4044286
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Loading settings from /home/jk100/.config/wandb/settings
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Loading settings from /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/settings
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'src/models/PLUM/plum_train_ds.py', 'program_abspath': '/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py', 'program': '/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py'}
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_init.py:_log_setup():524] Logging user logs to /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/run-20250302_025325-v15gl6ox/logs/debug.log
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_init.py:_log_setup():525] Logging internal logs to /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/run-20250302_025325-v15gl6ox/logs/debug-internal.log
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_init.py:init():564] calling init triggers
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'local_rank': 0, 'version': 'liuhaotian/llava-llama-2-13b-chat-lightning-preview', 'vis_save_path': './vis_output', 'precision': 'bf16', 'image_size': 1024, 'model_max_length': 1536, 'lora_r': 8, 'vision_tower': 'openai/clip-vit-large-patch14', 'load_in_8bit': False, 'load_in_4bit': False, 'dataset': 'sem_seg||refer_seg||vqa||reason_seg', 'sample_rates': '9,3,3,1', 'sem_seg_data': 'ade20k||cocostuff||pascal_part||paco_lvis||mapillary', 'refer_seg_data': 'refclef||refcoco||refcoco+||refcocog', 'wandb': False, 'wandb_project_name': 'plum-training', 'vqa_data': 'llava_instruct_150k', 'reason_seg_data': 'ReasonSeg|train', 'val_dataset': 'ReasonSeg|val', 'dataset_dir': '/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset', 'log_base_dir': './runs', 'exp_name': 'plum-13b', 'epochs': 50, 'steps_per_epoch': 500, 'batch_size': 1, 'grad_accumulation_steps': 10, 'val_batch_size': 1, 'workers': 4, 'lr': 0.0003, 'ce_loss_weight': 1.0, 'dice_loss_weight': 0.5, 'bce_loss_weight': 2.0, 'kld_loss_weight': 0.5, 'kld_sigma': 1.0, 'seg_cls_loss_weight': 0.5, 'use_teacher_ref': True, 'lora_alpha': 16, 'lora_dropout': 0.05, 'lora_target_modules': 'q_proj,v_proj', 'explanatory': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'num_classes_per_sample': 5, 'exclude_val': False, 'no_eval': False, 'eval_only': False, 'vision_pretrained': '/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/weights/sam_vit_h_4b8939.pth', 'out_dim': 256, 'resume': '', 'print_freq': 1, 'start_epoch': 0, 'gradient_checkpointing': True, 'train_mask_decoder': True, 'use_mm_start_end': True, 'auto_resume': False, 'conv_type': 'llava_v1', 'log_dir': './runs/plum-13b'}
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_init.py:init():614] starting backend
2025-03-02 02:53:25,476 INFO    MainThread:4044286 [wandb_init.py:init():618] setting up manager
2025-03-02 02:53:25,477 INFO    MainThread:4044286 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-03-02 02:53:25,478 INFO    MainThread:4044286 [wandb_init.py:init():624] backend started and connected
2025-03-02 02:53:25,480 INFO    MainThread:4044286 [wandb_init.py:init():716] updated telemetry
2025-03-02 02:53:25,489 INFO    MainThread:4044286 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2025-03-02 02:53:25,677 INFO    MainThread:4044286 [wandb_run.py:_on_init():2254] communicating current version
2025-03-02 02:53:25,750 INFO    MainThread:4044286 [wandb_run.py:_on_init():2263] got version response upgrade_message: "wandb version 0.19.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-03-02 02:53:25,750 INFO    MainThread:4044286 [wandb_init.py:init():800] starting run threads in backend
2025-03-02 02:53:29,980 INFO    MainThread:4044286 [wandb_run.py:_console_start():2233] atexit reg
2025-03-02 02:53:29,980 INFO    MainThread:4044286 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2025-03-02 02:53:29,981 INFO    MainThread:4044286 [wandb_run.py:_redirect():2153] Wrapping output streams.
2025-03-02 02:53:29,981 INFO    MainThread:4044286 [wandb_run.py:_redirect():2178] Redirects installed.
2025-03-02 02:53:29,981 INFO    MainThread:4044286 [wandb_init.py:init():841] run started, returning control to user process
2025-03-02 03:00:55,701 WARNING MsgRouterThr:4044286 [router.py:message_loop():77] message_loop has been closed
