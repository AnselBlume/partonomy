You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")


Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:23<00:00, 47.80s/it]
Some weights of PLUMForCausalLM were not initialized from the model checkpoint at liuhaotian/llava-llama-2-13b-chat-lightning-preview and are newly initialized: ['bio_encoder.encoder.layers.0.self_attn.in_proj_bias', 'bio_encoder.encoder.layers.0.norm2.weight', 'bio_encoder.encoder.layers.0.norm2.bias', 'bio_encoder.encoder.layers.0.linear2.weight', 'bio_encoder.encoder.layers.0.self_attn.out_proj.bias', 'bio_encoder.encoder.layers.0.norm1.weight', 'bio_encoder.encoder.layers.0.self_attn.out_proj.weight', 'bio_encoder.encoder.layers.0.linear1.bias', 'bio_encoder.encoder.layers.0.norm1.bias', 'bio_encoder.encoder.layers.0.linear2.bias', 'bio_encoder.encoder.layers.0.linear1.weight', 'bio_encoder.encoder.layers.0.self_attn.in_proj_weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
trainable params: 6,553,600 || all params: 14,151,578,931 || trainable%: 0.0463100268313092
>> model.config.train_mask_prompt_encoder:  True
n:  base_model.model.model.embed_tokens.weight p.shape:  torch.Size([32002, 5120])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.0.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.1.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.2.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.3.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.not_a_point_embed.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.0.weight p.shape:  torch.Size([4, 1, 2, 2])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.0.bias p.shape:  torch.Size([4])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.1.weight p.shape:  torch.Size([4])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.1.bias p.shape:  torch.Size([4])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.3.weight p.shape:  torch.Size([16, 4, 2, 2])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.3.bias p.shape:  torch.Size([16])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.4.weight p.shape:  torch.Size([16])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.4.bias p.shape:  torch.Size([16])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.6.weight p.shape:  torch.Size([256, 16, 1, 1])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.6.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.prompt_encoder.no_mask_embed.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.q_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.q_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.k_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.k_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.v_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.v_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.out_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm1.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm2.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin1.weight p.shape:  torch.Size([2048, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin1.bias p.shape:  torch.Size([2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin2.weight p.shape:  torch.Size([256, 2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm3.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm3.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm4.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm4.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.q_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.q_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.k_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.k_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.v_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.v_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.out_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm1.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm2.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin1.weight p.shape:  torch.Size([2048, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin1.bias p.shape:  torch.Size([2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin2.weight p.shape:  torch.Size([256, 2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm3.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm3.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm4.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm4.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.norm_final_attn.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.norm_final_attn.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_token.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.mask_decoder.mask_tokens.weight p.shape:  torch.Size([4, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.0.weight p.shape:  torch.Size([256, 64, 2, 2])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.0.bias p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.1.weight p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.1.bias p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.3.weight p.shape:  torch.Size([64, 32, 2, 2])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.3.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.2.weight p.shape:  torch.Size([4, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.2.bias p.shape:  torch.Size([4])
n:  base_model.model.model.text_hidden_fcs.0.0.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.model.text_hidden_fcs.0.0.bias p.shape:  torch.Size([5120])
n:  base_model.model.model.text_hidden_fcs.0.2.weight p.shape:  torch.Size([256, 5120])
n:  base_model.model.model.text_hidden_fcs.0.2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.token_to_mask_fcs.0.0.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.model.token_to_mask_fcs.0.0.bias p.shape:  torch.Size([5120])
n:  base_model.model.model.token_to_mask_fcs.0.2.weight p.shape:  torch.Size([3, 5120])
n:  base_model.model.model.token_to_mask_fcs.0.2.bias p.shape:  torch.Size([3])
n:  base_model.model.lm_head.weight p.shape:  torch.Size([32002, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.in_proj_weight p.shape:  torch.Size([15360, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.in_proj_bias p.shape:  torch.Size([15360])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.out_proj.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.out_proj.bias p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.linear1.weight p.shape:  torch.Size([2048, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.linear1.bias p.shape:  torch.Size([2048])
n:  base_model.model.bio_encoder.encoder.layers.0.linear2.weight p.shape:  torch.Size([5120, 2048])
n:  base_model.model.bio_encoder.encoder.layers.0.linear2.bias p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm1.weight p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm1.bias p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm2.weight p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm2.bias p.shape:  torch.Size([5120])
>> (plum_train_ds) loading ExplanatorySegDataset...
>> (plum_train_ds) question_types:  QuestionType.POSITIVE
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.POSITIVE_WITH_LABEL
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.NEGATIVE
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.NEGATIVE_WITH_LABEL
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.DIFFERENCE
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.DIFFERENCE_WITH_LABEL
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
ade20k:  20210
cocostuff:  118287
loading annotations into memory...
Done (t=0.33s)
creating index...
index created!
pascal_part:  4366
loading annotations into memory...
Done (t=12.42s)
creating index...
index created!
paco_lvis:  45790
mapillary:  18000
loading dataset refclef into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refclef/refs(unc).p
creating index...
index created.
DONE (t=9.98s)
dataset refclef (refs unc) (train split) has 17978 images and 99523 annotations.
loading dataset refcoco into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcoco/refs(unc).p
creating index...
index created.
DONE (t=4.50s)
dataset refcoco (refs unc) (train split) has 16994 images and 196771 annotations.
loading dataset refcoco+ into memory...

ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcoco+/refs(unc).p
creating index...
index created.
DONE (t=5.56s)
dataset refcoco+ (refs unc) (train split) has 16992 images and 196737 annotations.
loading dataset refcocog into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcocog/refs(umd).p
creating index...
index created.
DONE (t=13.36s)
dataset refcocog (refs umd) (train split) has 21899 images and 208960 annotations.
vqa_data:  157712
number of reason_seg samples:  239
len(self.img_to_explanation):  239
Training with 20000 examples and validating with 200 examples.
[2025-04-16 22:41:16,703] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5, git-hash=unknown, git-branch=unknown
[2025-04-16 22:41:16,703] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-04-16 22:41:16,703] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-04-16 22:41:16,704] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-04-16 22:41:45,386] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /shared/nas/data/m1/jk100/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /shared/nas/data/m1/jk100/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Time to load fused_adam op: 69.92099022865295 seconds
[2025-04-16 22:42:56,038] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/tensor/python_tensor.cpp:78.)
  self._dummy_overflow_buf = get_accelerator().IntTensor([0])
[2025-04-16 22:42:56,564] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-04-16 22:42:56,572] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2025-04-16 22:42:56,581] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-04-16 22:42:56,590] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500000000
[2025-04-16 22:42:56,593] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[2025-04-16 22:42:56,596] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2025-04-16 22:42:56,600] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Rank: 0 partition count [1] and sizes[(517961268, False)]
[2025-04-16 22:44:32,013] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2025-04-16 22:44:32,014] [INFO] [utils.py:786:see_memory_usage] MA 28.49 GB         Max_MA 29.45 GB         CA 29.59 GB         Max_CA 30 GB
[2025-04-16 22:44:32,015] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 54.32 GB, percent = 5.4%
[2025-04-16 22:44:41,742] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2025-04-16 22:44:41,744] [INFO] [utils.py:786:see_memory_usage] MA 32.35 GB         Max_MA 34.28 GB         CA 35.38 GB         Max_CA 35 GB
[2025-04-16 22:44:41,744] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 56.05 GB, percent = 5.6%
[2025-04-16 22:44:41,744] [INFO] [stage_1_and_2.py:488:__init__] optimizer state initialized
[2025-04-16 22:44:51,707] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2025-04-16 22:44:51,708] [INFO] [utils.py:786:see_memory_usage] MA 32.35 GB         Max_MA 32.35 GB         CA 35.38 GB         Max_CA 35 GB
[2025-04-16 22:44:51,708] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 58.78 GB, percent = 5.8%
[2025-04-16 22:44:51,719] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-04-16 22:44:51,719] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR
[2025-04-16 22:44:51,719] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x7f5321b58f10>
[2025-04-16 22:44:51,719] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[(0.9, 0.95)]
[2025-04-16 22:44:51,723] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2025-04-16 22:44:51,723] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2025-04-16 22:44:51,723] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-04-16 22:44:51,723] [INFO] [config.py:964:print]   amp_enabled .................. False
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   amp_params ................... False
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   bfloat16_enabled ............. True
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5321b593f0>
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   communication_data_type ...... None
[2025-04-16 22:44:51,724] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   disable_allgather ............ False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   dump_state ................... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2025-04-16 22:44:51,725] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   fp16_auto_cast ............... None
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   fp16_enabled ................. False
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   global_rank .................. 0
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 10
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0
[2025-04-16 22:44:51,726] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 1
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   loss_scale ................... 1.0
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2025-04-16 22:44:51,743] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   optimizer_name ............... adamw
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   optimizer_params ............. {'lr': 0.0003, 'weight_decay': 0.0, 'betas': (0.9, 0.95)}
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   pld_enabled .................. False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   pld_params ................... False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   scheduler_name ............... WarmupDecayLR
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   scheduler_params ............. {'total_num_steps': 25000, 'warmup_min_lr': 0, 'warmup_max_lr': 0.0003, 'warmup_num_steps': 100, 'warmup_type': 'linear'}
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   sparse_attention ............. None
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   train_batch_size ............. 40
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  4
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2025-04-16 22:44:51,744] [INFO] [config.py:964:print]   world_size ................... 1
[2025-04-16 22:44:51,745] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[2025-04-16 22:44:51,745] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2025-04-16 22:44:51,745] [INFO] [config.py:964:print]   zero_enabled ................. True
[2025-04-16 22:44:51,745] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-16 22:44:51,745] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[2025-04-16 22:44:51,745] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4,
    "gradient_accumulation_steps": 10,
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 0.0003,
            "weight_decay": 0.0,
            "betas": [0.9, 0.95]
        }
    },
    "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "total_num_steps": 2.500000e+04,
            "warmup_min_lr": 0,
            "warmup_max_lr": 0.0003,
            "warmup_num_steps": 100,
            "warmup_type": "linear"
        }
    },
    "fp16": {
        "enabled": false
    },
    "bf16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "zero_optimization": {
        "stage": 2,
        "contiguous_gradients": true,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 5.000000e+08,
        "allgather_bucket_size": 5.000000e+08
    }
}
(train) >> AFTER DEEPSPEED
>> (train) Auto-resume from:  ./runs/plum-13b_kld_0_dice_6_v1_partonomy/plum-13b_kld_0_dice_6_v1_partonomy_bidirbio_768_accum_10_maxlen512_epochs50_segloss_2_bce_loss_2_kld_loss_0_dice_loss_6_bidir_bio_exp_seg_train_prompt_enc_ckpt_model
>> (train) resume exists:  False
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)
  return F.conv2d(input, weight, bias, self.stride,
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a CuDNNError: cuDNN error: CUDNN_STATUS_BAD_PARAM
Exception raised from run_conv_plan at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:374 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f5dfd178897 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe1640b (0x7f5d9c5fb40b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x108f133 (0x7f5d9c874133 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x1091043 (0x7f5d9c876043 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x109176b (0x7f5d9c87676b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x1075c7d (0x7f5d9c85ac7d in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x107656a (0x7f5d9c85b56a in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #7: at::native::cudnn_convolution_transpose(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool) + 0xa4 (0x7f5d9c85b714 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #8: <unknown function> + 0x32f2cc2 (0x7f5d9ead7cc2 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0x32ff147 (0x7f5d9eae4147 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #10: at::_ops::cudnn_convolution_transpose::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool) + 0x2fb (0x7f5df143c2fb in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool) + 0x166d (0x7f5df0b6348d in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #12: <unknown function> + 0x2a8d27f (0x7f5df1cf127f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #13: <unknown function> + 0x2a93bdc (0x7f5df1cf7bdc in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool) + 0x344 (0x7f5df143a0d4 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long) + 0x3b8 (0x7f5df0b56868 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x2a8cb1c (0x7f5df1cf0b1c in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2a93a48 (0x7f5df1cf7a48 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt) + 0x17b (0x7f5df13f7d6b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x41902e1 (0x7f5df33f42e1 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0x4191259 (0x7f5df33f5259 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #21: at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt) + 0x2d4 (0x7f5df1438ed4 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x164a2e0 (0x7f5df08ae2e0 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::native::conv_transpose2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>) + 0x125 (0x7f5df0b5bb05 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2c879c9 (0x7f5df1eeb9c9 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x2c87b03 (0x7f5df1eebb03 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_ops::conv_transpose2d_input::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>) + 0x2cb (0x7f5df179509b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #27: <unknown function> + 0x61476f (0x7f5dfc21c76f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #28: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x4fc697]
frame #29: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x53d6 (0x4f2376 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #31: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #32: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #33: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #34: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #35: _PyObject_FastCallDictTstate + 0xcd (0x4f561d in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #36: _PyObject_Call_Prepend + 0x66 (0x506596 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #37: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x5cc323]
frame #38: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #39: _PyEval_EvalFrameDefault + 0x4dde (0x4f1d7e in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #40: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #41: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #42: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #43: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #44: _PyObject_FastCallDictTstate + 0xcd (0x4f561d in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #45: _PyObject_Call_Prepend + 0x66 (0x506596 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #46: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x5cc323]
frame #47: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #48: _PyEval_EvalFrameDefault + 0x53d6 (0x4f2376 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #49: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
frame #50: _PyEval_EvalFrameDefault + 0x13b3 (0x4ee353 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #51: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
frame #52: PyObject_Call + 0xb8 (0x508858 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #54: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
frame #55: PyObject_Call + 0xb8 (0x508858 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #56: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #57: _PyFunction_Vectorcall + 0x6f (0x4fcadf in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #58: _PyObject_FastCallDictTstate + 0x17d (0x4f56cd in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #59: _PyObject_Call_Prepend + 0x66 (0x506596 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #60: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x5cc323]
frame #61: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #62: _PyEval_EvalFrameDefault + 0x5757 (0x4f26f7 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #63: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
 (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:921.)
  return F.conv_transpose2d(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv_transpose2d(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a CuDNNError: cuDNN error: CUDNN_STATUS_BAD_PARAM
Exception raised from run_conv_plan at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:374 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f5dfd178897 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe1640b (0x7f5d9c5fb40b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x108f133 (0x7f5d9c874133 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x1091043 (0x7f5d9c876043 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x10915bb (0x7f5d9c8765bb in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x1074062 (0x7f5d9c859062 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x107527f (0x7f5d9c85a27f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x1078184 (0x7f5d9c85d184 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>) + 0x1872 (0x7f5df0b661e2 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #9: <unknown function> + 0x32f8375 (0x7f5d9eadd375 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0x3300422 (0x7f5d9eae5422 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>) + 0x26b (0x7f5df1a3510b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #12: <unknown function> + 0x45578f3 (0x7f5df37bb8f3 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #13: <unknown function> + 0x45594a3 (0x7f5df37bd4a3 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>) + 0x3a3 (0x7f5df1a5b7c3 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x164a4b1 (0x7f5df08ae4b1 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x300 (0x7f5df32cd290 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x4dcc3ab (0x7f5df40303ab in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1526 (0x7f5df402a4a6 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x698 (0x7f5df402b108 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x13f (0x7f5df402203f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x5c (0x7f5dfc430e1c in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xdbbf4 (0x7f5e106cabf4 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/../../libstdc++.so.6)
frame #23: <unknown function> + 0x94ac3 (0x7f5e11c33ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #24: <unknown function> + 0x126850 (0x7f5e11cc5850 in /lib/x86_64-linux-gnu/libc.so.6)
 (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:921.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch: [0][  1/500]	Time 49.294 (49.294)	Loss 1.0434 (1.1321)	CeLoss 0.1865 (0.2250)	SegCLSLoss 0.1133 (0.1208)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1441 (0.1451)	MaskBCELoss 0.0585 (0.0514)	MaskDICELoss 0.0857 (0.0937)
Epoch: [0][  2/500]	Time 41.124 (41.124)	Loss 1.1966 (1.1696)	CeLoss 0.2539 (0.2573)	SegCLSLoss 0.1211 (0.1211)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1602 (0.1473)	MaskBCELoss 0.0646 (0.0534)	MaskDICELoss 0.0956 (0.0940)
Epoch: [0][  3/500]	Time 41.279 (41.279)	Loss 1.3736 (1.2025)	CeLoss 0.2988 (0.2387)	SegCLSLoss 0.1221 (0.1210)	KLLoss 0.0000 (0.0000)	MaskLoss 0.2184 (0.1733)	MaskBCELoss 0.1201 (0.0794)	MaskDICELoss 0.0983 (0.0939)
Epoch: [0][  4/500]	Time 34.001 (34.001)	Loss 1.0824 (1.2372)	CeLoss 0.1543 (0.2465)	SegCLSLoss 0.1211 (0.1202)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1501 (0.1853)	MaskBCELoss 0.0538 (0.0904)	MaskDICELoss 0.0963 (0.0949)
Epoch: [0][  5/500]	Time 36.696 (36.696)	Loss 1.1589 (1.2362)	CeLoss 0.2969 (0.3013)	SegCLSLoss 0.1182 (0.1205)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1380 (0.1602)	MaskBCELoss 0.0501 (0.0668)	MaskDICELoss 0.0879 (0.0934)
Epoch: [0][  6/500]	Time 40.868 (40.868)	Loss 1.1796 (1.1301)	CeLoss 0.2891 (0.2188)	SegCLSLoss 0.1211 (0.1201)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1277 (0.1470)	MaskBCELoss 0.0295 (0.0527)	MaskDICELoss 0.0982 (0.0943)
Epoch: [0][  7/500]	Time 36.110 (36.110)	Loss 1.2654 (1.1557)	CeLoss 0.3242 (0.2440)	SegCLSLoss 0.1211 (0.1187)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1579 (0.1480)	MaskBCELoss 0.0619 (0.0532)	MaskDICELoss 0.0960 (0.0947)
Epoch: [0][  8/500]	Time 35.822 (35.822)	Loss 1.0411 (1.1230)	CeLoss 0.1875 (0.2155)	SegCLSLoss 0.1172 (0.1186)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1312 (0.1480)	MaskBCELoss 0.0420 (0.0546)	MaskDICELoss 0.0892 (0.0935)
Epoch: [0][  9/500]	Time 34.938 (34.938)	Loss 1.2307 (1.1628)	CeLoss 0.3086 (0.2400)	SegCLSLoss 0.1196 (0.1207)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1453 (0.1520)	MaskBCELoss 0.0478 (0.0578)	MaskDICELoss 0.0975 (0.0943)
Epoch: [0][ 10/500]	Time 38.448 (38.448)	Loss 1.0486 (1.1936)	CeLoss 0.1523 (0.2773)	SegCLSLoss 0.1172 (0.1214)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1426 (0.1508)	MaskBCELoss 0.0486 (0.0579)	MaskDICELoss 0.0940 (0.0929)
Epoch: [0][ 11/500]	Time 36.296 (36.296)	Loss 1.0832 (1.0504)	CeLoss 0.3398 (0.2479)	SegCLSLoss 0.0679 (0.0730)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1158 (0.1350)	MaskBCELoss 0.0217 (0.0384)	MaskDICELoss 0.0941 (0.0966)
Epoch: [0][ 12/500]	Time 41.249 (41.249)	Loss 0.9312 (1.0319)	CeLoss 0.1157 (0.2535)	SegCLSLoss 0.0820 (0.0717)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1334 (0.1291)	MaskBCELoss 0.0373 (0.0350)	MaskDICELoss 0.0962 (0.0941)
Epoch: [0][ 13/500]	Time 39.995 (39.995)	Loss 1.1011 (1.0248)	CeLoss 0.3164 (0.2501)	SegCLSLoss 0.0732 (0.0691)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1243 (0.1282)	MaskBCELoss 0.0268 (0.0332)	MaskDICELoss 0.0975 (0.0950)
Epoch: [0][ 14/500]	Time 38.823 (38.823)	Loss 1.0135 (1.0491)	CeLoss 0.1729 (0.2483)	SegCLSLoss 0.0625 (0.0705)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1611 (0.1356)	MaskBCELoss 0.0626 (0.0385)	MaskDICELoss 0.0986 (0.0970)
Epoch: [0][ 15/500]	Time 40.891 (40.891)	Loss 1.0255 (1.0269)	CeLoss 0.2051 (0.2437)	SegCLSLoss 0.0664 (0.0664)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1464 (0.1297)	MaskBCELoss 0.0475 (0.0319)	MaskDICELoss 0.0988 (0.0978)
Epoch: [0][ 16/500]	Time 43.759 (43.759)	Loss 1.1120 (1.0032)	CeLoss 0.3105 (0.2315)	SegCLSLoss 0.0693 (0.0687)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1403 (0.1273)	MaskBCELoss 0.0450 (0.0324)	MaskDICELoss 0.0953 (0.0949)
Epoch: [0][ 17/500]	Time 40.214 (40.214)	Loss 0.9976 (1.0516)	CeLoss 0.1992 (0.2498)	SegCLSLoss 0.0674 (0.0697)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1338 (0.1381)	MaskBCELoss 0.0349 (0.0415)	MaskDICELoss 0.0989 (0.0966)
Epoch: [0][ 18/500]	Time 45.216 (45.216)	Loss 0.9465 (1.0308)	CeLoss 0.1943 (0.2316)	SegCLSLoss 0.0640 (0.0655)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1147 (0.1400)	MaskBCELoss 0.0159 (0.0430)	MaskDICELoss 0.0988 (0.0970)
Epoch: [0][ 19/500]	Time 40.706 (40.706)	Loss 1.0473 (1.0268)	CeLoss 0.2852 (0.2474)	SegCLSLoss 0.0693 (0.0657)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1304 (0.1337)	MaskBCELoss 0.0392 (0.0385)	MaskDICELoss 0.0912 (0.0952)
Epoch: [0][ 20/500]	Time 37.400 (37.400)	Loss 1.1191 (1.0686)	CeLoss 0.3281 (0.2438)	SegCLSLoss 0.0693 (0.0706)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1386 (0.1462)	MaskBCELoss 0.0445 (0.0483)	MaskDICELoss 0.0941 (0.0979)
Epoch: [0][ 21/500]	Time 38.623 (38.623)	Loss 1.0143 (0.9569)	CeLoss 0.2734 (0.2177)	SegCLSLoss 0.0513 (0.0460)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1208 (0.1280)	MaskBCELoss 0.0214 (0.0301)	MaskDICELoss 0.0994 (0.0979)
Epoch: [0][ 22/500]	Time 35.028 (35.028)	Loss 0.8266 (0.9215)	CeLoss 0.1621 (0.2104)	SegCLSLoss 0.0206 (0.0374)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1136 (0.1238)	MaskBCELoss 0.0145 (0.0267)	MaskDICELoss 0.0991 (0.0972)
Epoch: [0][ 23/500]	Time 43.319 (43.319)	Loss 0.9591 (0.9434)	CeLoss 0.2314 (0.2285)	SegCLSLoss 0.0513 (0.0376)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1144 (0.1267)	MaskBCELoss 0.0154 (0.0301)	MaskDICELoss 0.0990 (0.0966)
Epoch: [0][ 24/500]	Time 38.766 (38.766)	Loss 0.9391 (0.9629)	CeLoss 0.3008 (0.2188)	SegCLSLoss 0.0225 (0.0453)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1178 (0.1367)	MaskBCELoss 0.0287 (0.0418)	MaskDICELoss 0.0892 (0.0950)
Epoch: [0][ 25/500]	Time 35.646 (35.646)	Loss 0.8491 (0.9978)	CeLoss 0.1621 (0.2443)	SegCLSLoss 0.0178 (0.0436)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1399 (0.1379)	MaskBCELoss 0.0472 (0.0403)	MaskDICELoss 0.0927 (0.0976)
Epoch: [0][ 26/500]	Time 47.511 (47.511)	Loss 0.9215 (0.9276)	CeLoss 0.1777 (0.1936)	SegCLSLoss 0.0306 (0.0430)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1434 (0.1283)	MaskBCELoss 0.0445 (0.0304)	MaskDICELoss 0.0989 (0.0979)
Epoch: [0][ 27/500]	Time 38.281 (38.281)	Loss 0.8388 (0.9205)	CeLoss 0.1738 (0.1969)	SegCLSLoss 0.0289 (0.0399)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1049 (0.1292)	MaskBCELoss 0.0054 (0.0328)	MaskDICELoss 0.0994 (0.0964)
Epoch: [0][ 28/500]	Time 42.148 (42.148)	Loss 0.9882 (0.9722)	CeLoss 0.2637 (0.2510)	SegCLSLoss 0.0432 (0.0356)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1214 (0.1309)	MaskBCELoss 0.0226 (0.0339)	MaskDICELoss 0.0988 (0.0970)
Epoch: [0][ 29/500]	Time 38.720 (38.720)	Loss 1.0424 (0.9424)	CeLoss 0.2393 (0.2130)	SegCLSLoss 0.0591 (0.0476)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1456 (0.1214)	MaskBCELoss 0.0469 (0.0237)	MaskDICELoss 0.0987 (0.0978)
Epoch: [0][ 30/500]	Time 40.721 (40.721)	Loss 1.0612 (1.0033)	CeLoss 0.0879 (0.1822)	SegCLSLoss 0.1187 (0.0737)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1710 (0.1429)	MaskBCELoss 0.0725 (0.0459)	MaskDICELoss 0.0985 (0.0970)
Epoch: [0][ 31/500]	Time 34.981 (34.981)	Loss 1.0013 (0.9802)	CeLoss 0.2451 (0.2342)	SegCLSLoss 0.0674 (0.0660)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1147 (0.1225)	MaskBCELoss 0.0170 (0.0302)	MaskDICELoss 0.0977 (0.0923)
Epoch: [0][ 32/500]	Time 31.545 (31.545)	Loss 0.9717 (0.9539)	CeLoss 0.2236 (0.2361)	SegCLSLoss 0.0713 (0.0512)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1057 (0.1190)	MaskBCELoss 0.0070 (0.0246)	MaskDICELoss 0.0987 (0.0944)
Epoch: [0][ 33/500]	Time 39.836 (39.836)	Loss 0.9392 (0.9380)	CeLoss 0.1543 (0.1942)	SegCLSLoss 0.0674 (0.0628)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1381 (0.1231)	MaskBCELoss 0.0442 (0.0301)	MaskDICELoss 0.0939 (0.0930)
Epoch: [0][ 34/500]	Time 39.895 (39.895)	Loss 0.9875 (1.0179)	CeLoss 0.1396 (0.2178)	SegCLSLoss 0.1201 (0.0866)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1206 (0.1273)	MaskBCELoss 0.0294 (0.0343)	MaskDICELoss 0.0913 (0.0930)
Epoch: [0][ 35/500]	Time 37.397 (37.397)	Loss 1.0212 (0.9524)	CeLoss 0.2695 (0.2002)	SegCLSLoss 0.0613 (0.0623)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1197 (0.1273)	MaskBCELoss 0.0226 (0.0341)	MaskDICELoss 0.0970 (0.0932)
Epoch: [0][ 36/500]	Time 42.673 (42.673)	Loss 1.0500 (1.0058)	CeLoss 0.1904 (0.2048)	SegCLSLoss 0.1123 (0.0926)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1271 (0.1247)	MaskBCELoss 0.0321 (0.0330)	MaskDICELoss 0.0950 (0.0917)
Epoch: [0][ 37/500]	Time 34.197 (34.197)	Loss 0.9887 (0.9842)	CeLoss 0.2656 (0.1917)	SegCLSLoss 0.0503 (0.0886)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1234 (0.1226)	MaskBCELoss 0.0294 (0.0301)	MaskDICELoss 0.0941 (0.0925)
Epoch: [0][ 38/500]	Time 40.922 (40.922)	Loss 1.0035 (0.9534)	CeLoss 0.2441 (0.1927)	SegCLSLoss 0.0796 (0.0685)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1253 (0.1287)	MaskBCELoss 0.0378 (0.0371)	MaskDICELoss 0.0875 (0.0916)
Epoch: [0][ 39/500]	Time 40.323 (40.323)	Loss 0.9522 (0.9651)	CeLoss 0.2617 (0.2357)	SegCLSLoss 0.0449 (0.0520)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1215 (0.1271)	MaskBCELoss 0.0317 (0.0342)	MaskDICELoss 0.0898 (0.0929)
Epoch: [0][ 40/500]	Time 39.864 (39.864)	Loss 0.8506 (0.9588)	CeLoss 0.1836 (0.2128)	SegCLSLoss 0.0315 (0.0649)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1044 (0.1238)	MaskBCELoss 0.0057 (0.0317)	MaskDICELoss 0.0987 (0.0921)
Epoch: [0][ 41/500]	Time 36.176 (36.176)	Loss 0.8346 (0.9289)	CeLoss 0.1504 (0.2362)	SegCLSLoss 0.0261 (0.0398)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1399 (0.1284)	MaskBCELoss 0.0519 (0.0394)	MaskDICELoss 0.0879 (0.0890)
Epoch: [0][ 42/500]	Time 40.243 (40.243)	Loss 0.9353 (0.9111)	CeLoss 0.2441 (0.2116)	SegCLSLoss 0.0417 (0.0419)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1322 (0.1315)	MaskBCELoss 0.0464 (0.0433)	MaskDICELoss 0.0857 (0.0882)
Epoch: [0][ 43/500]	Time 40.834 (40.834)	Loss 0.9874 (0.9049)	CeLoss 0.2637 (0.1920)	SegCLSLoss 0.0483 (0.0498)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1268 (0.1263)	MaskBCELoss 0.0336 (0.0361)	MaskDICELoss 0.0932 (0.0902)
Epoch: [0][ 44/500]	Time 43.469 (43.469)	Loss 0.8208 (0.8958)	CeLoss 0.1514 (0.1977)	SegCLSLoss 0.0208 (0.0382)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1385 (0.1305)	MaskBCELoss 0.0509 (0.0404)	MaskDICELoss 0.0877 (0.0901)
Epoch: [0][ 45/500]	Time 36.450 (36.450)	Loss 0.9333 (0.8779)	CeLoss 0.2061 (0.1812)	SegCLSLoss 0.0386 (0.0412)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1316 (0.1254)	MaskBCELoss 0.0352 (0.0346)	MaskDICELoss 0.0964 (0.0908)
Epoch: [0][ 46/500]	Time 39.073 (39.073)	Loss 0.9117 (0.9023)	CeLoss 0.2324 (0.2076)	SegCLSLoss 0.0322 (0.0398)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1334 (0.1272)	MaskBCELoss 0.0464 (0.0369)	MaskDICELoss 0.0870 (0.0903)
Epoch: [0][ 47/500]	Time 31.296 (31.296)	Loss 1.0334 (0.9136)	CeLoss 0.3340 (0.1869)	SegCLSLoss 0.0610 (0.0707)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1062 (0.1248)	MaskBCELoss 0.0150 (0.0408)	MaskDICELoss 0.0912 (0.0839)
Epoch: [0][ 48/500]	Time 36.094 (36.094)	Loss 0.9225 (0.9059)	CeLoss 0.1934 (0.2005)	SegCLSLoss 0.0554 (0.0434)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1377 (0.1264)	MaskBCELoss 0.0520 (0.0350)	MaskDICELoss 0.0856 (0.0914)
Epoch: [0][ 49/500]	Time 45.807 (45.807)	Loss 0.8586 (0.9004)	CeLoss 0.1172 (0.1692)	SegCLSLoss 0.0762 (0.0553)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1295 (0.1307)	MaskBCELoss 0.0467 (0.0410)	MaskDICELoss 0.0827 (0.0897)
Epoch: [0][ 50/500]	Time 36.076 (36.076)	Loss 0.8455 (0.8744)	CeLoss 0.1738 (0.1909)	SegCLSLoss 0.0267 (0.0372)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1331 (0.1268)	MaskBCELoss 0.0449 (0.0379)	MaskDICELoss 0.0882 (0.0889)
Epoch: [0][ 51/500]	Time 32.546 (32.546)	Loss 0.7802 (0.8623)	CeLoss 0.1201 (0.1500)	SegCLSLoss 0.0630 (0.0677)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1082 (0.1151)	MaskBCELoss 0.0290 (0.0286)	MaskDICELoss 0.0792 (0.0866)
Epoch: [0][ 52/500]	Time 39.816 (39.816)	Loss 0.9035 (0.8609)	CeLoss 0.1543 (0.1359)	SegCLSLoss 0.0679 (0.0651)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1184 (0.1177)	MaskBCELoss 0.0244 (0.0279)	MaskDICELoss 0.0940 (0.0898)
Epoch: [0][ 53/500]	Time 38.581 (38.581)	Loss 0.9188 (0.8836)	CeLoss 0.1592 (0.1580)	SegCLSLoss 0.0732 (0.0671)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1327 (0.1190)	MaskBCELoss 0.0459 (0.0305)	MaskDICELoss 0.0868 (0.0885)
Epoch: [0][ 54/500]	Time 47.027 (47.027)	Loss 0.7963 (0.8603)	CeLoss 0.1006 (0.1407)	SegCLSLoss 0.0593 (0.0657)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1190 (0.1176)	MaskBCELoss 0.0341 (0.0292)	MaskDICELoss 0.0849 (0.0883)
Epoch: [0][ 55/500]	Time 40.150 (40.150)	Loss 0.9083 (0.8942)	CeLoss 0.1455 (0.1501)	SegCLSLoss 0.0776 (0.0685)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1176 (0.1183)	MaskBCELoss 0.0244 (0.0257)	MaskDICELoss 0.0933 (0.0926)
Epoch: [0][ 56/500]	Time 39.292 (39.292)	Loss 0.9393 (0.8885)	CeLoss 0.1836 (0.1539)	SegCLSLoss 0.0801 (0.0702)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1268 (0.1177)	MaskBCELoss 0.0412 (0.0279)	MaskDICELoss 0.0855 (0.0897)
Epoch: [0][ 57/500]	Time 37.631 (37.631)	Loss 0.8488 (0.8887)	CeLoss 0.1318 (0.1524)	SegCLSLoss 0.0586 (0.0690)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1166 (0.1177)	MaskBCELoss 0.0252 (0.0270)	MaskDICELoss 0.0914 (0.0907)
Epoch: [0][ 58/500]	Time 42.506 (42.506)	Loss 0.8406 (0.8625)	CeLoss 0.1133 (0.1416)	SegCLSLoss 0.0649 (0.0633)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1214 (0.1156)	MaskBCELoss 0.0330 (0.0248)	MaskDICELoss 0.0885 (0.0908)
Epoch: [0][ 59/500]	Time 41.602 (41.602)	Loss 0.9362 (0.8931)	CeLoss 0.1709 (0.1542)	SegCLSLoss 0.0791 (0.0706)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1257 (0.1186)	MaskBCELoss 0.0369 (0.0285)	MaskDICELoss 0.0888 (0.0901)
Epoch: [0][ 60/500]	Time 38.298 (38.298)	Loss 0.9096 (0.8917)	CeLoss 0.1553 (0.1486)	SegCLSLoss 0.0688 (0.0706)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1233 (0.1197)	MaskBCELoss 0.0309 (0.0291)	MaskDICELoss 0.0923 (0.0906)
Epoch: [0][ 61/500]	Time 38.030 (38.030)	Loss 0.7258 (0.7589)	CeLoss 0.1465 (0.1133)	SegCLSLoss 0.0187 (0.0383)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1017 (0.1099)	MaskBCELoss 0.0170 (0.0226)	MaskDICELoss 0.0847 (0.0873)
Epoch: [0][ 62/500]	Time 30.837 (30.837)	Loss 0.7462 (0.7407)	CeLoss 0.1973 (0.1255)	SegCLSLoss 0.0388 (0.0320)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0842 (0.1072)	MaskBCELoss 0.0085 (0.0230)	MaskDICELoss 0.0757 (0.0842)
Epoch: [0][ 63/500]	Time 44.468 (44.468)	Loss 0.7217 (0.7637)	CeLoss 0.1084 (0.1063)	SegCLSLoss 0.0300 (0.0366)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1013 (0.1150)	MaskBCELoss 0.0136 (0.0263)	MaskDICELoss 0.0876 (0.0886)
Epoch: [0][ 64/500]	Time 42.274 (42.274)	Loss 0.7085 (0.7814)	CeLoss 0.0874 (0.1023)	SegCLSLoss 0.0145 (0.0436)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1195 (0.1199)	MaskBCELoss 0.0313 (0.0319)	MaskDICELoss 0.0883 (0.0881)
Epoch: [0][ 65/500]	Time 42.124 (42.124)	Loss 0.7054 (0.7477)	CeLoss 0.1162 (0.1023)	SegCLSLoss 0.0264 (0.0372)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1022 (0.1115)	MaskBCELoss 0.0192 (0.0244)	MaskDICELoss 0.0831 (0.0871)
Epoch: [0][ 66/500]	Time 45.542 (45.542)	Loss 0.7574 (0.7728)	CeLoss 0.1094 (0.1104)	SegCLSLoss 0.0286 (0.0434)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1168 (0.1103)	MaskBCELoss 0.0275 (0.0215)	MaskDICELoss 0.0893 (0.0887)
Epoch: [0][ 67/500]	Time 39.635 (39.635)	Loss 0.7316 (0.7652)	CeLoss 0.0996 (0.0971)	SegCLSLoss 0.0620 (0.0465)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0930 (0.1100)	MaskBCELoss 0.0125 (0.0212)	MaskDICELoss 0.0805 (0.0888)
Epoch: [0][ 68/500]	Time 36.898 (36.898)	Loss 0.7494 (0.7692)	CeLoss 0.1973 (0.1149)	SegCLSLoss 0.0405 (0.0485)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0842 (0.1075)	MaskBCELoss 0.0084 (0.0218)	MaskDICELoss 0.0757 (0.0856)
Epoch: [0][ 69/500]	Time 45.554 (45.554)	Loss 0.6530 (0.7883)	CeLoss 0.1226 (0.1030)	SegCLSLoss 0.0291 (0.0585)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0842 (0.1126)	MaskBCELoss 0.0084 (0.0268)	MaskDICELoss 0.0758 (0.0858)
Epoch: [0][ 70/500]	Time 43.441 (43.441)	Loss 0.8802 (0.7691)	CeLoss 0.0894 (0.1027)	SegCLSLoss 0.1016 (0.0435)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1075 (0.1155)	MaskBCELoss 0.0142 (0.0285)	MaskDICELoss 0.0933 (0.0870)
Epoch: [0][ 71/500]	Time 36.712 (36.712)	Loss 0.6092 (0.6539)	CeLoss 0.0713 (0.0731)	SegCLSLoss 0.0060 (0.0166)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1049 (0.1085)	MaskBCELoss 0.0260 (0.0258)	MaskDICELoss 0.0789 (0.0827)
Epoch: [0][ 72/500]	Time 39.889 (39.889)	Loss 0.8135 (0.7170)	CeLoss 0.0864 (0.0858)	SegCLSLoss 0.0471 (0.0160)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1406 (0.1276)	MaskBCELoss 0.0527 (0.0416)	MaskDICELoss 0.0879 (0.0860)
Epoch: [0][ 73/500]	Time 36.376 (36.376)	Loss 0.6608 (0.6686)	CeLoss 0.0889 (0.0731)	SegCLSLoss 0.0103 (0.0163)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1104 (0.1108)	MaskBCELoss 0.0277 (0.0255)	MaskDICELoss 0.0827 (0.0853)
Epoch: [0][ 74/500]	Time 41.588 (41.588)	Loss 0.7395 (0.6975)	CeLoss 0.0825 (0.0785)	SegCLSLoss 0.0172 (0.0219)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1261 (0.1134)	MaskBCELoss 0.0335 (0.0263)	MaskDICELoss 0.0925 (0.0871)
Epoch: [0][ 75/500]	Time 39.572 (39.572)	Loss 0.6005 (0.6610)	CeLoss 0.0820 (0.0748)	SegCLSLoss 0.0176 (0.0113)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1009 (0.1138)	MaskBCELoss 0.0306 (0.0298)	MaskDICELoss 0.0704 (0.0840)
Epoch: [0][ 76/500]	Time 36.288 (36.288)	Loss 0.7671 (0.6767)	CeLoss 0.0713 (0.0757)	SegCLSLoss 0.0232 (0.0123)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1569 (0.1190)	MaskBCELoss 0.0729 (0.0344)	MaskDICELoss 0.0840 (0.0846)
Epoch: [0][ 77/500]	Time 33.545 (33.545)	Loss 0.7079 (0.6617)	CeLoss 0.0659 (0.0806)	SegCLSLoss 0.0166 (0.0141)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1334 (0.1119)	MaskBCELoss 0.0480 (0.0297)	MaskDICELoss 0.0855 (0.0823)
Epoch: [0][ 78/500]	Time 42.619 (42.619)	Loss 0.6464 (0.6783)	CeLoss 0.0698 (0.0749)	SegCLSLoss 0.0104 (0.0158)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1151 (0.1174)	MaskBCELoss 0.0338 (0.0332)	MaskDICELoss 0.0814 (0.0843)
Epoch: [0][ 79/500]	Time 33.988 (33.988)	Loss 0.7236 (0.6902)	CeLoss 0.0732 (0.0899)	SegCLSLoss 0.0155 (0.0239)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1448 (0.1140)	MaskBCELoss 0.0625 (0.0329)	MaskDICELoss 0.0823 (0.0811)
Epoch: [0][ 80/500]	Time 37.338 (37.338)	Loss 0.7315 (0.6615)	CeLoss 0.1143 (0.0821)	SegCLSLoss 0.0079 (0.0105)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1475 (0.1137)	MaskBCELoss 0.0707 (0.0310)	MaskDICELoss 0.0767 (0.0827)
Epoch: [0][ 81/500]	Time 31.153 (31.153)	Loss 0.7796 (0.7424)	CeLoss 0.0408 (0.0605)	SegCLSLoss 0.0781 (0.0735)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1226 (0.1129)	MaskBCELoss 0.0383 (0.0355)	MaskDICELoss 0.0844 (0.0774)
Epoch: [0][ 82/500]	Time 38.413 (38.413)	Loss 0.7829 (0.8108)	CeLoss 0.1094 (0.0592)	SegCLSLoss 0.0659 (0.0905)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1108 (0.1199)	MaskBCELoss 0.0306 (0.0373)	MaskDICELoss 0.0802 (0.0827)
Epoch: [0][ 83/500]	Time 36.545 (36.545)	Loss 0.7483 (0.7823)	CeLoss 0.0408 (0.0554)	SegCLSLoss 0.0728 (0.0813)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1248 (0.1217)	MaskBCELoss 0.0466 (0.0415)	MaskDICELoss 0.0782 (0.0803)
Epoch: [0][ 84/500]	Time 45.748 (45.748)	Loss 0.7900 (0.8013)	CeLoss 0.0349 (0.0518)	SegCLSLoss 0.0732 (0.0819)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1340 (0.1247)	MaskBCELoss 0.0491 (0.0407)	MaskDICELoss 0.0850 (0.0841)
Epoch: [0][ 85/500]	Time 39.931 (39.931)	Loss 0.7926 (0.7904)	CeLoss 0.0306 (0.0566)	SegCLSLoss 0.0889 (0.0805)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1237 (0.1248)	MaskBCELoss 0.0398 (0.0440)	MaskDICELoss 0.0839 (0.0808)
Epoch: [0][ 86/500]	Time 36.366 (36.366)	Loss 0.9640 (0.8124)	CeLoss 0.0713 (0.0560)	SegCLSLoss 0.1387 (0.0857)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1271 (0.1230)	MaskBCELoss 0.0371 (0.0383)	MaskDICELoss 0.0900 (0.0847)
Epoch: [0][ 87/500]	Time 41.320 (41.320)	Loss 0.7782 (0.7924)	CeLoss 0.0347 (0.0450)	SegCLSLoss 0.0796 (0.0830)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1249 (0.1247)	MaskBCELoss 0.0412 (0.0415)	MaskDICELoss 0.0837 (0.0831)
Epoch: [0][ 88/500]	Time 40.082 (40.082)	Loss 0.8595 (0.7989)	CeLoss 0.0840 (0.0525)	SegCLSLoss 0.0889 (0.0813)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1228 (0.1247)	MaskBCELoss 0.0345 (0.0411)	MaskDICELoss 0.0883 (0.0836)
Epoch: [0][ 89/500]	Time 38.489 (38.489)	Loss 0.7707 (0.7719)	CeLoss 0.0371 (0.0565)	SegCLSLoss 0.0684 (0.0768)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1319 (0.1221)	MaskBCELoss 0.0485 (0.0427)	MaskDICELoss 0.0834 (0.0795)
Epoch: [0][ 90/500]	Time 46.415 (46.415)	Loss 0.7606 (0.7715)	CeLoss 0.0287 (0.0462)	SegCLSLoss 0.0811 (0.0782)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1174 (0.1212)	MaskBCELoss 0.0338 (0.0396)	MaskDICELoss 0.0836 (0.0816)
Epoch: [0][ 91/500]	Time 38.489 (38.489)	Loss 0.7322 (0.8687)	CeLoss 0.0503 (0.0554)	SegCLSLoss 0.0439 (0.1429)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1192 (0.1024)	MaskBCELoss 0.0303 (0.0218)	MaskDICELoss 0.0889 (0.0806)
Epoch: [0][ 92/500]	Time 39.597 (39.597)	Loss 0.7210 (0.7445)	CeLoss 0.0500 (0.0384)	SegCLSLoss 0.0410 (0.0630)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1080 (0.1146)	MaskBCELoss 0.0147 (0.0269)	MaskDICELoss 0.0933 (0.0877)
Epoch: [0][ 93/500]	Time 45.306 (45.306)	Loss 0.8023 (0.7896)	CeLoss 0.0317 (0.0526)	SegCLSLoss 0.0747 (0.0695)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1294 (0.1208)	MaskBCELoss 0.0388 (0.0317)	MaskDICELoss 0.0906 (0.0891)
Epoch: [0][ 94/500]	Time 36.901 (36.901)	Loss 0.9109 (0.7466)	CeLoss 0.1006 (0.0567)	SegCLSLoss 0.0674 (0.0592)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1414 (0.1142)	MaskBCELoss 0.0430 (0.0285)	MaskDICELoss 0.0984 (0.0857)
Epoch: [0][ 95/500]	Time 41.737 (41.737)	Loss 0.7684 (0.7939)	CeLoss 0.1201 (0.0387)	SegCLSLoss 0.0635 (0.0866)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0943 (0.1154)	MaskBCELoss 0.0111 (0.0277)	MaskDICELoss 0.0832 (0.0877)
Epoch: [0][ 96/500]	Time 33.132 (33.132)	Loss 1.0754 (0.7758)	CeLoss 0.0811 (0.0628)	SegCLSLoss 0.2168 (0.0781)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0999 (0.1137)	MaskBCELoss 0.0099 (0.0314)	MaskDICELoss 0.0900 (0.0824)
Epoch: [0][ 97/500]	Time 39.445 (39.445)	Loss 0.7152 (0.8029)	CeLoss 0.0869 (0.0491)	SegCLSLoss 0.0364 (0.0908)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1064 (0.1123)	MaskBCELoss 0.0206 (0.0253)	MaskDICELoss 0.0858 (0.0870)
Epoch: [0][ 98/500]	Time 42.663 (42.663)	Loss 1.0595 (0.8104)	CeLoss 0.0635 (0.0401)	SegCLSLoss 0.2061 (0.1076)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1299 (0.1088)	MaskBCELoss 0.0487 (0.0245)	MaskDICELoss 0.0812 (0.0843)
Epoch: [0][ 99/500]	Time 35.216 (35.216)	Loss 0.6647 (0.7405)	CeLoss 0.0320 (0.0396)	SegCLSLoss 0.0801 (0.0732)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0942 (0.1086)	MaskBCELoss 0.0231 (0.0242)	MaskDICELoss 0.0711 (0.0844)
[2025-04-16 23:50:17,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.00029991566265060235], mom=[(0.9, 0.95)]
[2025-04-16 23:50:17,186] [INFO] [timer.py:215:stop] epoch=0/micro_step=100/global_step=10, RunningAvgSamplesPerSec=1.0379993181121507, CurrSamplesPerSec=0.9469779282138335, MemAllocated=35.72GB, MaxMemAllocated=45.5GB
Epoch: [0][100/500]	Time 34.798 (34.798)	Loss 0.8137 (0.7420)	CeLoss 0.0522 (0.0655)	SegCLSLoss 0.0625 (0.0693)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1369 (0.1088)	MaskBCELoss 0.0462 (0.0288)	MaskDICELoss 0.0906 (0.0800)
Epoch: [0][101/500]	Time 32.350 (32.350)	Loss 0.6028 (0.7432)	CeLoss 0.0187 (0.0528)	SegCLSLoss 0.0767 (0.0829)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0821 (0.1049)	MaskBCELoss 0.0155 (0.0262)	MaskDICELoss 0.0667 (0.0787)
Epoch: [0][102/500]	Time 42.347 (42.347)	Loss 0.7846 (0.7439)	CeLoss 0.1055 (0.0495)	SegCLSLoss 0.0320 (0.0639)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1150 (0.1121)	MaskBCELoss 0.0188 (0.0266)	MaskDICELoss 0.0962 (0.0856)
Epoch: [0][103/500]	Time 38.979 (38.979)	Loss 0.7892 (0.7379)	CeLoss 0.0669 (0.0480)	SegCLSLoss 0.0762 (0.0556)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1145 (0.1186)	MaskBCELoss 0.0292 (0.0332)	MaskDICELoss 0.0854 (0.0854)
Epoch: [0][104/500]	Time 39.420 (39.420)	Loss 0.6864 (0.8088)	CeLoss 0.0060 (0.0431)	SegCLSLoss 0.0386 (0.0882)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1332 (0.1257)	MaskBCELoss 0.0489 (0.0412)	MaskDICELoss 0.0843 (0.0845)
Epoch: [0][105/500]	Time 41.308 (41.308)	Loss 0.6683 (0.7352)	CeLoss 0.0114 (0.0257)	SegCLSLoss 0.0854 (0.0732)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0938 (0.1099)	MaskBCELoss 0.0194 (0.0242)	MaskDICELoss 0.0745 (0.0857)
Epoch: [0][106/500]	Time 48.812 (48.812)	Loss 0.9928 (0.8036)	CeLoss 0.0295 (0.0387)	SegCLSLoss 0.1445 (0.0868)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1536 (0.1178)	MaskBCELoss 0.0619 (0.0289)	MaskDICELoss 0.0917 (0.0889)
Epoch: [0][107/500]	Time 40.549 (40.549)	Loss 0.6970 (0.7147)	CeLoss 0.0376 (0.0305)	SegCLSLoss 0.0289 (0.0487)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1172 (0.1183)	MaskBCELoss 0.0254 (0.0308)	MaskDICELoss 0.0918 (0.0876)
Epoch: [0][108/500]	Time 42.393 (42.393)	Loss 0.6117 (0.7754)	CeLoss 0.0732 (0.0400)	SegCLSLoss 0.0535 (0.0781)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0822 (0.1225)	MaskBCELoss 0.0155 (0.0389)	MaskDICELoss 0.0667 (0.0836)
Epoch: [0][109/500]	Time 36.779 (36.779)	Loss 0.6992 (0.7239)	CeLoss 0.0605 (0.0315)	SegCLSLoss 0.0317 (0.0645)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1247 (0.1161)	MaskBCELoss 0.0432 (0.0333)	MaskDICELoss 0.0814 (0.0828)
Epoch: [0][110/500]	Time 35.804 (35.804)	Loss 0.6965 (0.7943)	CeLoss 0.0215 (0.0485)	SegCLSLoss 0.0850 (0.0953)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1006 (0.1206)	MaskBCELoss 0.0248 (0.0422)	MaskDICELoss 0.0758 (0.0784)
Epoch: [0][111/500]	Time 45.636 (45.636)	Loss 0.7015 (0.6699)	CeLoss 0.0159 (0.0562)	SegCLSLoss 0.0344 (0.0314)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1337 (0.1141)	MaskBCELoss 0.0464 (0.0335)	MaskDICELoss 0.0873 (0.0806)
Epoch: [0][112/500]	Time 36.856 (36.856)	Loss 0.6195 (0.6611)	CeLoss 0.0044 (0.0338)	SegCLSLoss 0.0354 (0.0323)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1140 (0.1171)	MaskBCELoss 0.0349 (0.0350)	MaskDICELoss 0.0791 (0.0821)
Epoch: [0][113/500]	Time 33.519 (33.519)	Loss 0.6416 (0.6555)	CeLoss 0.0071 (0.0225)	SegCLSLoss 0.0352 (0.0324)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1241 (0.1192)	MaskBCELoss 0.0450 (0.0367)	MaskDICELoss 0.0790 (0.0825)
Epoch: [0][114/500]	Time 41.089 (41.089)	Loss 0.6625 (0.6686)	CeLoss 0.0183 (0.0453)	SegCLSLoss 0.0361 (0.0328)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1074 (0.1127)	MaskBCELoss 0.0181 (0.0296)	MaskDICELoss 0.0893 (0.0831)
Epoch: [0][115/500]	Time 45.797 (45.797)	Loss 0.6449 (0.6904)	CeLoss 0.0193 (0.0484)	SegCLSLoss 0.0361 (0.0334)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1079 (0.1157)	MaskBCELoss 0.0235 (0.0298)	MaskDICELoss 0.0844 (0.0859)
Epoch: [0][116/500]	Time 40.966 (40.966)	Loss 0.6367 (0.6631)	CeLoss 0.0178 (0.0382)	SegCLSLoss 0.0386 (0.0330)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1080 (0.1121)	MaskBCELoss 0.0267 (0.0284)	MaskDICELoss 0.0813 (0.0837)
Epoch: [0][117/500]	Time 37.640 (37.640)	Loss 0.7325 (0.6544)	CeLoss 0.0864 (0.0351)	SegCLSLoss 0.0342 (0.0323)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1187 (0.1103)	MaskBCELoss 0.0336 (0.0268)	MaskDICELoss 0.0851 (0.0835)
Epoch: [0][118/500]	Time 36.972 (36.972)	Loss 0.6536 (0.6534)	CeLoss 0.0041 (0.0256)	SegCLSLoss 0.0337 (0.0314)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1254 (0.1158)	MaskBCELoss 0.0425 (0.0325)	MaskDICELoss 0.0829 (0.0833)
Epoch: [0][119/500]	Time 43.815 (43.815)	Loss 0.6815 (0.6691)	CeLoss 0.0693 (0.0456)	SegCLSLoss 0.0243 (0.0305)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1097 (0.1146)	MaskBCELoss 0.0237 (0.0313)	MaskDICELoss 0.0860 (0.0833)
Epoch: [0][120/500]	Time 34.579 (34.579)	Loss 0.6295 (0.6480)	CeLoss 0.1357 (0.0493)	SegCLSLoss 0.0299 (0.0330)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0810 (0.1036)	MaskBCELoss 0.0129 (0.0222)	MaskDICELoss 0.0680 (0.0814)
Epoch: [0][121/500]	Time 37.376 (37.376)	Loss 0.6610 (0.6565)	CeLoss 0.0168 (0.0304)	SegCLSLoss 0.0337 (0.0284)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1127 (0.1170)	MaskBCELoss 0.0247 (0.0332)	MaskDICELoss 0.0879 (0.0838)
Epoch: [0][122/500]	Time 39.996 (39.996)	Loss 0.6078 (0.6605)	CeLoss 0.0977 (0.0655)	SegCLSLoss 0.0238 (0.0303)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0873 (0.1092)	MaskBCELoss 0.0153 (0.0303)	MaskDICELoss 0.0720 (0.0790)
Epoch: [0][123/500]	Time 40.405 (40.405)	Loss 0.7217 (0.6595)	CeLoss 0.0713 (0.0320)	SegCLSLoss 0.0251 (0.0287)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1234 (0.1159)	MaskBCELoss 0.0351 (0.0313)	MaskDICELoss 0.0883 (0.0845)
Epoch: [0][124/500]	Time 34.371 (34.371)	Loss 0.6646 (0.6390)	CeLoss 0.0131 (0.0362)	SegCLSLoss 0.0320 (0.0318)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1162 (0.1115)	MaskBCELoss 0.0275 (0.0324)	MaskDICELoss 0.0887 (0.0790)
Epoch: [0][125/500]	Time 42.059 (42.059)	Loss 0.6844 (0.6513)	CeLoss 0.0620 (0.0428)	SegCLSLoss 0.0198 (0.0287)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1250 (0.1126)	MaskBCELoss 0.0417 (0.0311)	MaskDICELoss 0.0832 (0.0815)
Epoch: [0][126/500]	Time 38.408 (38.408)	Loss 0.6282 (0.6466)	CeLoss 0.0037 (0.0398)	SegCLSLoss 0.0327 (0.0296)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1178 (0.1108)	MaskBCELoss 0.0368 (0.0293)	MaskDICELoss 0.0810 (0.0815)
Epoch: [0][127/500]	Time 46.168 (46.168)	Loss 0.6723 (0.6905)	CeLoss 0.0145 (0.0439)	SegCLSLoss 0.0291 (0.0290)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1249 (0.1225)	MaskBCELoss 0.0374 (0.0365)	MaskDICELoss 0.0875 (0.0859)
Epoch: [0][128/500]	Time 43.220 (43.220)	Loss 0.7246 (0.6842)	CeLoss 0.0542 (0.0562)	SegCLSLoss 0.0243 (0.0263)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1158 (0.1180)	MaskBCELoss 0.0183 (0.0333)	MaskDICELoss 0.0975 (0.0848)
Epoch: [0][129/500]	Time 40.209 (40.209)	Loss 0.6929 (0.6724)	CeLoss 0.0306 (0.0391)	SegCLSLoss 0.0281 (0.0280)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1286 (0.1201)	MaskBCELoss 0.0413 (0.0359)	MaskDICELoss 0.0873 (0.0842)
Epoch: [0][130/500]	Time 36.577 (36.577)	Loss 0.5980 (0.6605)	CeLoss 0.0229 (0.0432)	SegCLSLoss 0.0352 (0.0287)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1026 (0.1150)	MaskBCELoss 0.0278 (0.0325)	MaskDICELoss 0.0749 (0.0825)
Epoch: [0][131/500]	Time 41.786 (41.786)	Loss 0.5445 (0.6233)	CeLoss 0.0021 (0.0314)	SegCLSLoss 0.0077 (0.0110)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1051 (0.1164)	MaskBCELoss 0.0258 (0.0322)	MaskDICELoss 0.0792 (0.0842)
Epoch: [0][132/500]	Time 44.524 (44.524)	Loss 0.6484 (0.6078)	CeLoss 0.0713 (0.0377)	SegCLSLoss 0.0074 (0.0147)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1246 (0.1115)	MaskBCELoss 0.0464 (0.0320)	MaskDICELoss 0.0783 (0.0795)
Epoch: [0][133/500]	Time 33.940 (33.940)	Loss 0.6107 (0.5935)	CeLoss 0.0598 (0.0287)	SegCLSLoss 0.0112 (0.0107)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1084 (0.1095)	MaskBCELoss 0.0305 (0.0284)	MaskDICELoss 0.0780 (0.0811)
Epoch: [0][134/500]	Time 36.568 (36.568)	Loss 0.6061 (0.5940)	CeLoss 0.0231 (0.0272)	SegCLSLoss 0.0112 (0.0148)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1142 (0.1090)	MaskBCELoss 0.0312 (0.0292)	MaskDICELoss 0.0831 (0.0798)
Epoch: [0][135/500]	Time 33.282 (33.282)	Loss 0.6270 (0.6083)	CeLoss 0.0103 (0.0324)	SegCLSLoss 0.0092 (0.0139)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1273 (0.1122)	MaskBCELoss 0.0414 (0.0312)	MaskDICELoss 0.0859 (0.0810)
Epoch: [0][136/500]	Time 41.251 (41.251)	Loss 0.6158 (0.5921)	CeLoss 0.0198 (0.0510)	SegCLSLoss 0.0165 (0.0141)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1100 (0.1037)	MaskBCELoss 0.0242 (0.0273)	MaskDICELoss 0.0858 (0.0764)
Epoch: [0][137/500]	Time 33.899 (33.899)	Loss 0.5646 (0.5846)	CeLoss 0.1108 (0.0388)	SegCLSLoss 0.0070 (0.0107)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0805 (0.1040)	MaskBCELoss 0.0108 (0.0248)	MaskDICELoss 0.0697 (0.0791)
Epoch: [0][138/500]	Time 38.426 (38.426)	Loss 0.6785 (0.6298)	CeLoss 0.0688 (0.0408)	SegCLSLoss 0.0053 (0.0121)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1311 (0.1119)	MaskBCELoss 0.0469 (0.0267)	MaskDICELoss 0.0842 (0.0852)
Epoch: [0][139/500]	Time 37.806 (37.806)	Loss 0.6860 (0.6170)	CeLoss 0.1025 (0.0439)	SegCLSLoss 0.0312 (0.0147)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1173 (0.1100)	MaskBCELoss 0.0456 (0.0290)	MaskDICELoss 0.0717 (0.0810)
Epoch: [0][140/500]	Time 41.493 (41.493)	Loss 0.5905 (0.6475)	CeLoss 0.0024 (0.0597)	SegCLSLoss 0.0107 (0.0167)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1128 (0.1107)	MaskBCELoss 0.0275 (0.0275)	MaskDICELoss 0.0853 (0.0833)
Epoch: [0][141/500]	Time 39.512 (39.512)	Loss 0.5352 (0.6111)	CeLoss 0.0074 (0.0370)	SegCLSLoss 0.0286 (0.0148)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0962 (0.1103)	MaskBCELoss 0.0267 (0.0293)	MaskDICELoss 0.0696 (0.0810)
Epoch: [0][142/500]	Time 32.750 (32.750)	Loss 0.6043 (0.5903)	CeLoss 0.0069 (0.0299)	SegCLSLoss 0.0159 (0.0141)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1080 (0.1064)	MaskBCELoss 0.0205 (0.0265)	MaskDICELoss 0.0875 (0.0799)
Epoch: [0][143/500]	Time 45.293 (45.293)	Loss 0.7265 (0.6364)	CeLoss 0.0547 (0.0426)	SegCLSLoss 0.0447 (0.0217)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1161 (0.1105)	MaskBCELoss 0.0285 (0.0281)	MaskDICELoss 0.0876 (0.0824)
Epoch: [0][144/500]	Time 47.529 (47.529)	Loss 0.7047 (0.6971)	CeLoss 0.0554 (0.0593)	SegCLSLoss 0.0081 (0.0346)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1265 (0.1133)	MaskBCELoss 0.0315 (0.0278)	MaskDICELoss 0.0950 (0.0855)
Epoch: [0][145/500]	Time 34.926 (34.926)	Loss 0.4609 (0.5939)	CeLoss 0.0447 (0.0308)	SegCLSLoss 0.0104 (0.0158)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0700 (0.1050)	MaskBCELoss 0.0062 (0.0246)	MaskDICELoss 0.0638 (0.0804)
Epoch: [0][146/500]	Time 44.009 (44.009)	Loss 0.6370 (0.6326)	CeLoss 0.0135 (0.0383)	SegCLSLoss 0.0157 (0.0234)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1150 (0.1123)	MaskBCELoss 0.0245 (0.0316)	MaskDICELoss 0.0905 (0.0807)
Epoch: [0][147/500]	Time 35.087 (35.087)	Loss 0.6270 (0.5980)	CeLoss 0.0178 (0.0268)	SegCLSLoss 0.0232 (0.0198)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1143 (0.1046)	MaskBCELoss 0.0306 (0.0240)	MaskDICELoss 0.0836 (0.0806)
Epoch: [0][148/500]	Time 35.664 (35.664)	Loss 0.6051 (0.5690)	CeLoss 0.0138 (0.0289)	SegCLSLoss 0.0273 (0.0129)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1021 (0.1027)	MaskBCELoss 0.0190 (0.0255)	MaskDICELoss 0.0831 (0.0772)
Epoch: [0][149/500]	Time 44.415 (44.415)	Loss 0.5351 (0.6193)	CeLoss 0.0127 (0.0294)	SegCLSLoss 0.0280 (0.0210)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0943 (0.1102)	MaskBCELoss 0.0249 (0.0283)	MaskDICELoss 0.0694 (0.0819)
Epoch: [0][150/500]	Time 34.343 (34.343)	Loss 0.6194 (0.5852)	CeLoss 0.0227 (0.0189)	SegCLSLoss 0.0140 (0.0168)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1137 (0.1064)	MaskBCELoss 0.0284 (0.0264)	MaskDICELoss 0.0853 (0.0800)
Epoch: [0][151/500]	Time 40.426 (40.426)	Loss 0.6031 (0.5952)	CeLoss 0.0109 (0.0288)	SegCLSLoss 0.0116 (0.0117)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1055 (0.1102)	MaskBCELoss 0.0160 (0.0296)	MaskDICELoss 0.0895 (0.0806)
Epoch: [0][152/500]	Time 36.762 (36.762)	Loss 0.6302 (0.5969)	CeLoss 0.0193 (0.0411)	SegCLSLoss 0.0233 (0.0108)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1054 (0.1044)	MaskBCELoss 0.0171 (0.0230)	MaskDICELoss 0.0883 (0.0814)
Epoch: [0][153/500]	Time 42.155 (42.155)	Loss 0.5910 (0.6220)	CeLoss 0.0063 (0.0257)	SegCLSLoss 0.0098 (0.0181)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1210 (0.1128)	MaskBCELoss 0.0402 (0.0292)	MaskDICELoss 0.0808 (0.0837)
Epoch: [0][154/500]	Time 38.318 (38.318)	Loss 0.7350 (0.6216)	CeLoss 0.0889 (0.0531)	SegCLSLoss 0.0117 (0.0140)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1188 (0.1055)	MaskBCELoss 0.0225 (0.0232)	MaskDICELoss 0.0962 (0.0823)
Epoch: [0][155/500]	Time 40.035 (40.035)	Loss 0.6234 (0.6221)	CeLoss 0.0117 (0.0452)	SegCLSLoss 0.0212 (0.0154)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1127 (0.1079)	MaskBCELoss 0.0268 (0.0253)	MaskDICELoss 0.0859 (0.0826)
Epoch: [0][156/500]	Time 36.341 (36.341)	Loss 0.5265 (0.5737)	CeLoss 0.0009 (0.0288)	SegCLSLoss 0.0116 (0.0136)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0973 (0.1011)	MaskBCELoss 0.0203 (0.0222)	MaskDICELoss 0.0770 (0.0789)
Epoch: [0][157/500]	Time 31.784 (31.784)	Loss 0.5165 (0.5788)	CeLoss 0.1045 (0.0415)	SegCLSLoss 0.0091 (0.0096)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0703 (0.1015)	MaskBCELoss 0.0069 (0.0228)	MaskDICELoss 0.0633 (0.0788)
Epoch: [0][158/500]	Time 41.997 (41.997)	Loss 0.5275 (0.6236)	CeLoss 0.0112 (0.0435)	SegCLSLoss 0.0164 (0.0144)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0869 (0.1086)	MaskBCELoss 0.0096 (0.0251)	MaskDICELoss 0.0774 (0.0835)
Epoch: [0][159/500]	Time 41.086 (41.086)	Loss 0.6203 (0.6267)	CeLoss 0.0071 (0.0364)	SegCLSLoss 0.0354 (0.0233)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1032 (0.1060)	MaskBCELoss 0.0192 (0.0230)	MaskDICELoss 0.0840 (0.0830)
Epoch: [0][160/500]	Time 34.667 (34.667)	Loss 0.6541 (0.5936)	CeLoss 0.1309 (0.0381)	SegCLSLoss 0.0151 (0.0143)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1027 (0.1055)	MaskBCELoss 0.0308 (0.0265)	MaskDICELoss 0.0719 (0.0790)
Epoch: [0][161/500]	Time 39.242 (39.242)	Loss 0.5302 (0.6037)	CeLoss 0.0009 (0.0176)	SegCLSLoss 0.0091 (0.0113)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1030 (0.1176)	MaskBCELoss 0.0268 (0.0356)	MaskDICELoss 0.0763 (0.0821)
Epoch: [0][162/500]	Time 36.996 (36.996)	Loss 0.5270 (0.5994)	CeLoss 0.0825 (0.0478)	SegCLSLoss 0.0064 (0.0178)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0870 (0.1035)	MaskBCELoss 0.0225 (0.0262)	MaskDICELoss 0.0644 (0.0773)
Epoch: [0][163/500]	Time 45.305 (45.305)	Loss 0.4853 (0.6282)	CeLoss 0.0195 (0.0494)	SegCLSLoss 0.0115 (0.0139)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0832 (0.1127)	MaskBCELoss 0.0141 (0.0313)	MaskDICELoss 0.0691 (0.0814)
Epoch: [0][164/500]	Time 39.074 (39.074)	Loss 0.5089 (0.5748)	CeLoss 0.0010 (0.0267)	SegCLSLoss 0.0073 (0.0137)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0954 (0.1028)	MaskBCELoss 0.0197 (0.0241)	MaskDICELoss 0.0757 (0.0787)
Epoch: [0][165/500]	Time 34.853 (34.853)	Loss 0.6078 (0.5558)	CeLoss 0.0027 (0.0388)	SegCLSLoss 0.0072 (0.0083)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1249 (0.0989)	MaskBCELoss 0.0396 (0.0232)	MaskDICELoss 0.0852 (0.0757)
Epoch: [0][166/500]	Time 38.138 (38.138)	Loss 0.5514 (0.5810)	CeLoss 0.0073 (0.0391)	SegCLSLoss 0.0153 (0.0092)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0932 (0.1011)	MaskBCELoss 0.0113 (0.0208)	MaskDICELoss 0.0818 (0.0803)
Epoch: [0][167/500]	Time 39.857 (39.857)	Loss 0.5549 (0.6115)	CeLoss 0.0007 (0.0514)	SegCLSLoss 0.0071 (0.0084)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1041 (0.1072)	MaskBCELoss 0.0211 (0.0249)	MaskDICELoss 0.0830 (0.0823)
Epoch: [0][168/500]	Time 36.958 (36.958)	Loss 0.5519 (0.5762)	CeLoss 0.0082 (0.0419)	SegCLSLoss 0.0121 (0.0141)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0996 (0.0990)	MaskBCELoss 0.0196 (0.0220)	MaskDICELoss 0.0800 (0.0770)
Epoch: [0][169/500]	Time 43.920 (43.920)	Loss 0.6143 (0.6248)	CeLoss 0.0103 (0.0332)	SegCLSLoss 0.0127 (0.0101)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1081 (0.1100)	MaskBCELoss 0.0175 (0.0221)	MaskDICELoss 0.0906 (0.0878)
Epoch: [0][170/500]	Time 43.654 (43.654)	Loss 0.6697 (0.6202)	CeLoss 0.0508 (0.0497)	SegCLSLoss 0.0073 (0.0167)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1264 (0.1067)	MaskBCELoss 0.0386 (0.0258)	MaskDICELoss 0.0878 (0.0809)
Epoch: [0][171/500]	Time 45.661 (45.661)	Loss 0.6672 (0.6065)	CeLoss 0.0522 (0.0480)	SegCLSLoss 0.0051 (0.0096)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1282 (0.1085)	MaskBCELoss 0.0411 (0.0279)	MaskDICELoss 0.0871 (0.0806)
Epoch: [0][172/500]	Time 49.608 (49.608)	Loss 0.5775 (0.6100)	CeLoss 0.0078 (0.0323)	SegCLSLoss 0.0099 (0.0093)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0987 (0.1098)	MaskBCELoss 0.0105 (0.0249)	MaskDICELoss 0.0881 (0.0849)
Epoch: [0][173/500]	Time 48.243 (48.243)	Loss 0.5863 (0.6063)	CeLoss 0.0097 (0.0400)	SegCLSLoss 0.0103 (0.0087)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1119 (0.1117)	MaskBCELoss 0.0289 (0.0303)	MaskDICELoss 0.0830 (0.0814)
Epoch: [0][174/500]	Time 33.845 (33.845)	Loss 0.6121 (0.5762)	CeLoss 0.0034 (0.0576)	SegCLSLoss 0.0104 (0.0096)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1121 (0.0986)	MaskBCELoss 0.0212 (0.0231)	MaskDICELoss 0.0909 (0.0755)
Epoch: [0][175/500]	Time 42.517 (42.517)	Loss 0.6303 (0.6136)	CeLoss 0.0640 (0.0478)	SegCLSLoss 0.0052 (0.0096)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1262 (0.1080)	MaskBCELoss 0.0504 (0.0254)	MaskDICELoss 0.0758 (0.0826)
Epoch: [0][176/500]	Time 37.540 (37.540)	Loss 0.5341 (0.5720)	CeLoss 0.0300 (0.0199)	SegCLSLoss 0.0205 (0.0126)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0874 (0.1020)	MaskBCELoss 0.0153 (0.0212)	MaskDICELoss 0.0721 (0.0808)
Epoch: [0][177/500]	Time 42.881 (42.881)	Loss 0.6063 (0.6199)	CeLoss 0.0115 (0.0471)	SegCLSLoss 0.0125 (0.0085)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1139 (0.1171)	MaskBCELoss 0.0284 (0.0367)	MaskDICELoss 0.0855 (0.0804)
Epoch: [0][178/500]	Time 41.743 (41.743)	Loss 0.4975 (0.5700)	CeLoss 0.0011 (0.0394)	SegCLSLoss 0.0084 (0.0110)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0944 (0.0993)	MaskBCELoss 0.0218 (0.0217)	MaskDICELoss 0.0727 (0.0776)
Epoch: [0][179/500]	Time 35.097 (35.097)	Loss 0.5451 (0.5640)	CeLoss 0.0150 (0.0429)	SegCLSLoss 0.0162 (0.0106)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0949 (0.0995)	MaskBCELoss 0.0179 (0.0244)	MaskDICELoss 0.0770 (0.0752)
Epoch: [0][180/500]	Time 41.132 (41.132)	Loss 0.5635 (0.5614)	CeLoss 0.0009 (0.0089)	SegCLSLoss 0.0087 (0.0094)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1279 (0.1085)	MaskBCELoss 0.0555 (0.0293)	MaskDICELoss 0.0724 (0.0792)
Epoch: [0][181/500]	Time 35.579 (35.579)	Loss 0.5046 (0.5613)	CeLoss 0.0026 (0.0320)	SegCLSLoss 0.0095 (0.0094)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0935 (0.1043)	MaskBCELoss 0.0194 (0.0288)	MaskDICELoss 0.0741 (0.0755)
Epoch: [0][182/500]	Time 40.668 (40.668)	Loss 0.5834 (0.5895)	CeLoss 0.0547 (0.0590)	SegCLSLoss 0.0203 (0.0104)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1004 (0.1011)	MaskBCELoss 0.0286 (0.0242)	MaskDICELoss 0.0718 (0.0769)
Epoch: [0][183/500]	Time 34.383 (34.383)	Loss 0.5358 (0.5491)	CeLoss 0.0056 (0.0239)	SegCLSLoss 0.0093 (0.0084)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1063 (0.1020)	MaskBCELoss 0.0315 (0.0260)	MaskDICELoss 0.0748 (0.0761)
Epoch: [0][184/500]	Time 36.913 (36.913)	Loss 0.6529 (0.5475)	CeLoss 0.0522 (0.0218)	SegCLSLoss 0.0056 (0.0087)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1153 (0.1002)	MaskBCELoss 0.0257 (0.0232)	MaskDICELoss 0.0896 (0.0770)
Epoch: [0][185/500]	Time 38.387 (38.387)	Loss 0.5556 (0.5632)	CeLoss 0.0035 (0.0248)	SegCLSLoss 0.0099 (0.0096)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1066 (0.1029)	MaskBCELoss 0.0268 (0.0245)	MaskDICELoss 0.0798 (0.0784)
Epoch: [0][186/500]	Time 37.631 (37.631)	Loss 0.6890 (0.5784)	CeLoss 0.1001 (0.0456)	SegCLSLoss 0.0150 (0.0100)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1047 (0.1054)	MaskBCELoss 0.0173 (0.0299)	MaskDICELoss 0.0875 (0.0755)
Epoch: [0][187/500]	Time 50.216 (50.216)	Loss 0.5929 (0.6422)	CeLoss 0.0025 (0.0487)	SegCLSLoss 0.0093 (0.0084)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1165 (0.1182)	MaskBCELoss 0.0319 (0.0331)	MaskDICELoss 0.0847 (0.0851)
Epoch: [0][188/500]	Time 42.748 (42.748)	Loss 0.6469 (0.5970)	CeLoss 0.0771 (0.0354)	SegCLSLoss 0.0072 (0.0083)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1146 (0.1122)	MaskBCELoss 0.0331 (0.0320)	MaskDICELoss 0.0815 (0.0802)
Epoch: [0][189/500]	Time 39.749 (39.749)	Loss 0.6777 (0.5749)	CeLoss 0.0464 (0.0292)	SegCLSLoss 0.0060 (0.0110)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1188 (0.1030)	MaskBCELoss 0.0234 (0.0235)	MaskDICELoss 0.0954 (0.0795)
Epoch: [0][190/500]	Time 38.967 (38.967)	Loss 0.5761 (0.5568)	CeLoss 0.0176 (0.0318)	SegCLSLoss 0.0103 (0.0092)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1143 (0.1017)	MaskBCELoss 0.0370 (0.0259)	MaskDICELoss 0.0773 (0.0758)
Epoch: [0][191/500]	Time 41.715 (41.715)	Loss 0.4908 (0.6056)	CeLoss 0.1631 (0.0544)	SegCLSLoss 0.0065 (0.0066)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0575 (0.1073)	MaskBCELoss 0.0078 (0.0265)	MaskDICELoss 0.0498 (0.0808)
Epoch: [0][192/500]	Time 36.821 (36.821)	Loss 0.5611 (0.5642)	CeLoss 0.0025 (0.0284)	SegCLSLoss 0.0074 (0.0073)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1175 (0.1035)	MaskBCELoss 0.0404 (0.0250)	MaskDICELoss 0.0772 (0.0785)
Epoch: [0][193/500]	Time 44.303 (44.303)	Loss 0.6754 (0.5915)	CeLoss 0.0791 (0.0416)	SegCLSLoss 0.0103 (0.0073)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1256 (0.1083)	MaskBCELoss 0.0444 (0.0287)	MaskDICELoss 0.0812 (0.0797)
Epoch: [0][194/500]	Time 36.777 (36.777)	Loss 0.5441 (0.5469)	CeLoss 0.0014 (0.0311)	SegCLSLoss 0.0071 (0.0066)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1187 (0.1037)	MaskBCELoss 0.0460 (0.0299)	MaskDICELoss 0.0727 (0.0738)
Epoch: [0][195/500]	Time 40.259 (40.259)	Loss 0.5613 (0.5448)	CeLoss 0.0040 (0.0299)	SegCLSLoss 0.0087 (0.0071)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1003 (0.1000)	MaskBCELoss 0.0154 (0.0248)	MaskDICELoss 0.0849 (0.0752)
Epoch: [0][196/500]	Time 37.927 (37.927)	Loss 0.3892 (0.5023)	CeLoss 0.0625 (0.0166)	SegCLSLoss 0.0065 (0.0073)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0575 (0.0962)	MaskBCELoss 0.0077 (0.0265)	MaskDICELoss 0.0497 (0.0697)
Epoch: [0][197/500]	Time 39.038 (39.038)	Loss 0.5729 (0.5889)	CeLoss 0.0015 (0.0522)	SegCLSLoss 0.0068 (0.0068)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1164 (0.1085)	MaskBCELoss 0.0352 (0.0320)	MaskDICELoss 0.0812 (0.0765)
Epoch: [0][198/500]	Time 32.960 (32.960)	Loss 0.4605 (0.5335)	CeLoss 0.0014 (0.0406)	SegCLSLoss 0.0082 (0.0068)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0854 (0.0974)	MaskBCELoss 0.0174 (0.0262)	MaskDICELoss 0.0680 (0.0712)
Epoch: [0][199/500]	Time 42.765 (42.765)	Loss 0.6370 (0.5844)	CeLoss 0.0649 (0.0253)	SegCLSLoss 0.0051 (0.0070)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1060 (0.1108)	MaskBCELoss 0.0186 (0.0299)	MaskDICELoss 0.0875 (0.0809)
[2025-04-17 00:56:11,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0002985903614457831], mom=[(0.9, 0.95)]
[2025-04-17 00:56:11,066] [INFO] [timer.py:215:stop] epoch=0/micro_step=200/global_step=20, RunningAvgSamplesPerSec=1.070058300960594, CurrSamplesPerSec=1.2806629017275284, MemAllocated=33.85GB, MaxMemAllocated=45.53GB
Epoch: [0][200/500]	Time 35.334 (35.334)	Loss 0.5017 (0.5143)	CeLoss 0.0029 (0.0230)	SegCLSLoss 0.0096 (0.0077)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0954 (0.0947)	MaskBCELoss 0.0232 (0.0231)	MaskDICELoss 0.0722 (0.0716)
Epoch: [0][201/500]	Time 37.940 (37.940)	Loss 0.5965 (0.5341)	CeLoss 0.0020 (0.0288)	SegCLSLoss 0.0068 (0.0062)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1157 (0.0998)	MaskBCELoss 0.0282 (0.0265)	MaskDICELoss 0.0874 (0.0733)
Epoch: [0][202/500]	Time 46.152 (46.152)	Loss 0.6312 (0.5649)	CeLoss 0.0640 (0.0432)	SegCLSLoss 0.0044 (0.0082)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1123 (0.1001)	MaskBCELoss 0.0288 (0.0239)	MaskDICELoss 0.0835 (0.0762)
Epoch: [0][203/500]	Time 41.768 (41.768)	Loss 0.4784 (0.5664)	CeLoss 0.0033 (0.0387)	SegCLSLoss 0.0057 (0.0065)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0890 (0.1045)	MaskBCELoss 0.0175 (0.0281)	MaskDICELoss 0.0715 (0.0764)
Epoch: [0][204/500]	Time 33.865 (33.865)	Loss 0.6033 (0.5192)	CeLoss 0.0011 (0.0398)	SegCLSLoss 0.0051 (0.0057)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1297 (0.0974)	MaskBCELoss 0.0465 (0.0290)	MaskDICELoss 0.0832 (0.0683)
Epoch: [0][205/500]	Time 40.420 (40.420)	Loss 0.4196 (0.5347)	CeLoss 0.1348 (0.0571)	SegCLSLoss 0.0064 (0.0067)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0493 (0.0939)	MaskBCELoss 0.0060 (0.0249)	MaskDICELoss 0.0433 (0.0691)
Epoch: [0][206/500]	Time 33.334 (33.334)	Loss 0.4405 (0.5038)	CeLoss 0.0030 (0.0381)	SegCLSLoss 0.0068 (0.0060)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0871 (0.0916)	MaskBCELoss 0.0246 (0.0240)	MaskDICELoss 0.0624 (0.0676)
Epoch: [0][207/500]	Time 36.596 (36.596)	Loss 0.5334 (0.5329)	CeLoss 0.0056 (0.0085)	SegCLSLoss 0.0063 (0.0073)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1044 (0.1020)	MaskBCELoss 0.0279 (0.0256)	MaskDICELoss 0.0766 (0.0764)
Epoch: [0][208/500]	Time 39.992 (39.992)	Loss 0.5831 (0.5766)	CeLoss 0.0042 (0.0416)	SegCLSLoss 0.0085 (0.0070)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1193 (0.1050)	MaskBCELoss 0.0384 (0.0272)	MaskDICELoss 0.0809 (0.0778)
Epoch: [0][209/500]	Time 34.024 (34.024)	Loss 0.5280 (0.4646)	CeLoss 0.0028 (0.0412)	SegCLSLoss 0.0071 (0.0063)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1076 (0.0818)	MaskBCELoss 0.0337 (0.0199)	MaskDICELoss 0.0740 (0.0618)
Epoch: [0][210/500]	Time 35.046 (35.046)	Loss 0.4526 (0.4918)	CeLoss 0.0057 (0.0245)	SegCLSLoss 0.0071 (0.0063)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0848 (0.0908)	MaskBCELoss 0.0190 (0.0225)	MaskDICELoss 0.0658 (0.0683)
Epoch: [0][211/500]	Time 38.267 (38.267)	Loss 0.4826 (0.5396)	CeLoss 0.0005 (0.0390)	SegCLSLoss 0.0071 (0.0061)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0912 (0.1011)	MaskBCELoss 0.0198 (0.0296)	MaskDICELoss 0.0714 (0.0715)
Epoch: [0][212/500]	Time 46.920 (46.920)	Loss 0.5763 (0.5757)	CeLoss 0.0601 (0.0303)	SegCLSLoss 0.0041 (0.0053)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1047 (0.1159)	MaskBCELoss 0.0300 (0.0401)	MaskDICELoss 0.0747 (0.0757)
Epoch: [0][213/500]	Time 34.631 (34.631)	Loss 0.4921 (0.5032)	CeLoss 0.0018 (0.0033)	SegCLSLoss 0.0081 (0.0077)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0973 (0.0970)	MaskBCELoss 0.0273 (0.0244)	MaskDICELoss 0.0699 (0.0726)
Epoch: [0][214/500]	Time 33.117 (33.117)	Loss 0.6700 (0.5283)	CeLoss 0.0732 (0.0506)	SegCLSLoss 0.0063 (0.0052)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1079 (0.0925)	MaskBCELoss 0.0159 (0.0219)	MaskDICELoss 0.0921 (0.0706)
Epoch: [0][215/500]	Time 39.760 (39.760)	Loss 0.4260 (0.5551)	CeLoss 0.0020 (0.0192)	SegCLSLoss 0.0058 (0.0071)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0790 (0.1061)	MaskBCELoss 0.0153 (0.0287)	MaskDICELoss 0.0637 (0.0774)
Epoch: [0][216/500]	Time 32.518 (32.518)	Loss 0.3464 (0.5035)	CeLoss 0.0004 (0.0225)	SegCLSLoss 0.0082 (0.0057)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0626 (0.0924)	MaskBCELoss 0.0115 (0.0212)	MaskDICELoss 0.0511 (0.0712)
Epoch: [0][217/500]	Time 36.669 (36.669)	Loss 0.5579 (0.5302)	CeLoss 0.0762 (0.0326)	SegCLSLoss 0.0036 (0.0054)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0905 (0.0962)	MaskBCELoss 0.0171 (0.0227)	MaskDICELoss 0.0734 (0.0735)
Epoch: [0][218/500]	Time 36.823 (36.823)	Loss 0.6035 (0.5360)	CeLoss 0.0496 (0.0104)	SegCLSLoss 0.0042 (0.0068)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1093 (0.1022)	MaskBCELoss 0.0275 (0.0254)	MaskDICELoss 0.0818 (0.0769)
Epoch: [0][219/500]	Time 38.968 (38.968)	Loss 0.5441 (0.5666)	CeLoss 0.0023 (0.0167)	SegCLSLoss 0.0055 (0.0073)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1101 (0.1104)	MaskBCELoss 0.0325 (0.0318)	MaskDICELoss 0.0776 (0.0786)
Epoch: [0][220/500]	Time 39.765 (39.765)	Loss 0.5210 (0.5874)	CeLoss 0.0009 (0.0397)	SegCLSLoss 0.0053 (0.0084)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0993 (0.1129)	MaskBCELoss 0.0215 (0.0367)	MaskDICELoss 0.0778 (0.0763)
Epoch: [0][221/500]	Time 37.857 (37.857)	Loss 0.5965 (0.5683)	CeLoss 0.1016 (0.0358)	SegCLSLoss 0.0059 (0.0074)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1071 (0.1078)	MaskBCELoss 0.0398 (0.0323)	MaskDICELoss 0.0673 (0.0756)
Epoch: [0][222/500]	Time 41.599 (41.599)	Loss 0.4257 (0.5146)	CeLoss 0.0062 (0.0534)	SegCLSLoss 0.0066 (0.0063)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0883 (0.0951)	MaskBCELoss 0.0309 (0.0305)	MaskDICELoss 0.0574 (0.0646)
Epoch: [0][223/500]	Time 40.732 (40.732)	Loss 0.6221 (0.5733)	CeLoss 0.0703 (0.0369)	SegCLSLoss 0.0073 (0.0069)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1026 (0.1107)	MaskBCELoss 0.0195 (0.0353)	MaskDICELoss 0.0830 (0.0753)
Epoch: [0][224/500]	Time 41.361 (41.361)	Loss 0.5265 (0.5494)	CeLoss 0.0046 (0.0284)	SegCLSLoss 0.0059 (0.0063)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1138 (0.1059)	MaskBCELoss 0.0431 (0.0317)	MaskDICELoss 0.0706 (0.0742)
Epoch: [0][225/500]	Time 40.961 (40.961)	Loss 0.4708 (0.5513)	CeLoss 0.0005 (0.0445)	SegCLSLoss 0.0063 (0.0071)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0876 (0.1000)	MaskBCELoss 0.0170 (0.0269)	MaskDICELoss 0.0706 (0.0731)
Epoch: [0][226/500]	Time 41.829 (41.829)	Loss 0.5129 (0.5263)	CeLoss 0.0620 (0.0460)	SegCLSLoss 0.0065 (0.0063)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0830 (0.0935)	MaskBCELoss 0.0151 (0.0234)	MaskDICELoss 0.0680 (0.0702)
Epoch: [0][227/500]	Time 37.293 (37.293)	Loss 0.6124 (0.5141)	CeLoss 0.0015 (0.0226)	SegCLSLoss 0.0068 (0.0073)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1195 (0.0987)	MaskBCELoss 0.0299 (0.0288)	MaskDICELoss 0.0896 (0.0699)
Epoch: [0][228/500]	Time 36.161 (36.161)	Loss 0.5666 (0.5349)	CeLoss 0.0049 (0.0521)	SegCLSLoss 0.0201 (0.0079)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1052 (0.0970)	MaskBCELoss 0.0274 (0.0288)	MaskDICELoss 0.0778 (0.0682)
Epoch: [0][229/500]	Time 40.066 (40.066)	Loss 0.3447 (0.5071)	CeLoss 0.1045 (0.0367)	SegCLSLoss 0.0050 (0.0071)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0437 (0.0913)	MaskBCELoss 0.0081 (0.0230)	MaskDICELoss 0.0356 (0.0684)
Epoch: [0][230/500]	Time 40.669 (40.669)	Loss 0.4969 (0.5182)	CeLoss 0.0159 (0.0356)	SegCLSLoss 0.0209 (0.0086)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0825 (0.0963)	MaskBCELoss 0.0140 (0.0281)	MaskDICELoss 0.0685 (0.0682)
Epoch: [0][231/500]	Time 33.338 (33.338)	Loss 0.3346 (0.4734)	CeLoss 0.0007 (0.0172)	SegCLSLoss 0.0063 (0.0062)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0709 (0.0895)	MaskBCELoss 0.0260 (0.0233)	MaskDICELoss 0.0449 (0.0662)
Epoch: [0][232/500]	Time 40.794 (40.794)	Loss 0.6463 (0.4729)	CeLoss 0.0664 (0.0359)	SegCLSLoss 0.0091 (0.0062)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1187 (0.0926)	MaskBCELoss 0.0376 (0.0328)	MaskDICELoss 0.0811 (0.0598)
Epoch: [0][233/500]	Time 34.821 (34.821)	Loss 0.5676 (0.5085)	CeLoss 0.0498 (0.0514)	SegCLSLoss 0.0037 (0.0051)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0958 (0.0888)	MaskBCELoss 0.0161 (0.0215)	MaskDICELoss 0.0797 (0.0673)
Epoch: [0][234/500]	Time 45.453 (45.453)	Loss 0.6468 (0.5408)	CeLoss 0.0540 (0.0264)	SegCLSLoss 0.0043 (0.0063)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1211 (0.1052)	MaskBCELoss 0.0356 (0.0324)	MaskDICELoss 0.0855 (0.0728)
Epoch: [0][235/500]	Time 30.645 (30.645)	Loss 0.4801 (0.4634)	CeLoss 0.0020 (0.0282)	SegCLSLoss 0.0056 (0.0053)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1013 (0.0867)	MaskBCELoss 0.0352 (0.0240)	MaskDICELoss 0.0661 (0.0628)
Epoch: [0][236/500]	Time 33.351 (33.351)	Loss 0.5952 (0.4978)	CeLoss 0.1226 (0.0657)	SegCLSLoss 0.0041 (0.0053)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1020 (0.0864)	MaskBCELoss 0.0370 (0.0243)	MaskDICELoss 0.0650 (0.0621)
Epoch: [0][237/500]	Time 41.644 (41.644)	Loss 0.5609 (0.5372)	CeLoss 0.0708 (0.0384)	SegCLSLoss 0.0043 (0.0051)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0977 (0.1017)	MaskBCELoss 0.0261 (0.0303)	MaskDICELoss 0.0716 (0.0713)
Epoch: [0][238/500]	Time 34.595 (34.595)	Loss 0.5653 (0.5004)	CeLoss 0.0017 (0.0484)	SegCLSLoss 0.0042 (0.0049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1210 (0.0933)	MaskBCELoss 0.0427 (0.0295)	MaskDICELoss 0.0783 (0.0639)
Epoch: [0][239/500]	Time 42.249 (42.249)	Loss 0.5707 (0.5188)	CeLoss 0.0698 (0.0315)	SegCLSLoss 0.0058 (0.0058)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1139 (0.0968)	MaskBCELoss 0.0485 (0.0263)	MaskDICELoss 0.0653 (0.0705)
Epoch: [0][240/500]	Time 33.642 (33.642)	Loss 0.5515 (0.4350)	CeLoss 0.0014 (0.0328)	SegCLSLoss 0.0051 (0.0067)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1129 (0.0789)	MaskBCELoss 0.0344 (0.0212)	MaskDICELoss 0.0785 (0.0577)
Epoch: [0][241/500]	Time 35.681 (35.681)	Loss 0.4457 (0.4649)	CeLoss 0.0026 (0.0206)	SegCLSLoss 0.0072 (0.0061)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0899 (0.0895)	MaskBCELoss 0.0277 (0.0262)	MaskDICELoss 0.0622 (0.0633)
Epoch: [0][242/500]	Time 36.936 (36.936)	Loss 0.2471 (0.4659)	CeLoss 0.0009 (0.0377)	SegCLSLoss 0.0071 (0.0069)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0448 (0.0836)	MaskBCELoss 0.0092 (0.0218)	MaskDICELoss 0.0356 (0.0618)
Epoch: [0][243/500]	Time 37.953 (37.953)	Loss 0.3729 (0.5147)	CeLoss 0.0005 (0.0243)	SegCLSLoss 0.0063 (0.0060)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0743 (0.0945)	MaskBCELoss 0.0216 (0.0222)	MaskDICELoss 0.0527 (0.0723)
Epoch: [0][244/500]	Time 43.561 (43.561)	Loss 0.5645 (0.5217)	CeLoss 0.0309 (0.0236)	SegCLSLoss 0.0038 (0.0054)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1144 (0.0993)	MaskBCELoss 0.0401 (0.0271)	MaskDICELoss 0.0743 (0.0722)
Epoch: [0][245/500]	Time 37.791 (37.791)	Loss 0.4805 (0.5208)	CeLoss 0.0021 (0.0240)	SegCLSLoss 0.0069 (0.0058)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0977 (0.0960)	MaskBCELoss 0.0304 (0.0228)	MaskDICELoss 0.0673 (0.0733)
Epoch: [0][246/500]	Time 36.945 (36.945)	Loss 0.5184 (0.4942)	CeLoss 0.0005 (0.0168)	SegCLSLoss 0.0066 (0.0067)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0977 (0.0924)	MaskBCELoss 0.0204 (0.0226)	MaskDICELoss 0.0773 (0.0698)
Epoch: [0][247/500]	Time 37.700 (37.700)	Loss 0.4674 (0.4773)	CeLoss 0.0474 (0.0488)	SegCLSLoss 0.0044 (0.0052)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0821 (0.0847)	MaskBCELoss 0.0204 (0.0225)	MaskDICELoss 0.0617 (0.0622)
Epoch: [0][248/500]	Time 30.893 (30.893)	Loss 0.2862 (0.4543)	CeLoss 0.0962 (0.0543)	SegCLSLoss 0.0050 (0.0059)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0343 (0.0762)	MaskBCELoss 0.0065 (0.0172)	MaskDICELoss 0.0278 (0.0590)
Epoch: [0][249/500]	Time 41.342 (41.342)	Loss 0.5298 (0.4904)	CeLoss 0.0037 (0.0149)	SegCLSLoss 0.0063 (0.0061)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1067 (0.0929)	MaskBCELoss 0.0318 (0.0235)	MaskDICELoss 0.0750 (0.0694)
Epoch: [0][250/500]	Time 36.207 (36.207)	Loss 0.6280 (0.5444)	CeLoss 0.0679 (0.0347)	SegCLSLoss 0.0044 (0.0056)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1085 (0.1019)	MaskBCELoss 0.0250 (0.0282)	MaskDICELoss 0.0835 (0.0737)
Epoch: [0][251/500]	Time 42.113 (42.113)	Loss 0.6119 (0.4978)	CeLoss 0.0522 (0.0371)	SegCLSLoss 0.0043 (0.0049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1100 (0.0926)	MaskBCELoss 0.0273 (0.0262)	MaskDICELoss 0.0827 (0.0664)
Epoch: [0][252/500]	Time 40.555 (40.555)	Loss 0.2410 (0.5331)	CeLoss 0.0002 (0.0234)	SegCLSLoss 0.0052 (0.0054)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0431 (0.0985)	MaskBCELoss 0.0070 (0.0230)	MaskDICELoss 0.0360 (0.0755)
Epoch: [0][253/500]	Time 36.846 (36.846)	Loss 0.5524 (0.4759)	CeLoss 0.0012 (0.0303)	SegCLSLoss 0.0056 (0.0056)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1042 (0.0873)	MaskBCELoss 0.0213 (0.0224)	MaskDICELoss 0.0829 (0.0649)
Epoch: [0][254/500]	Time 44.084 (44.084)	Loss 0.5027 (0.5156)	CeLoss 0.0005 (0.0167)	SegCLSLoss 0.0050 (0.0054)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1045 (0.0986)	MaskBCELoss 0.0337 (0.0259)	MaskDICELoss 0.0708 (0.0727)
Epoch: [0][255/500]	Time 34.504 (34.504)	Loss 0.5921 (0.4970)	CeLoss 0.0454 (0.0328)	SegCLSLoss 0.0034 (0.0052)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1036 (0.0869)	MaskBCELoss 0.0204 (0.0170)	MaskDICELoss 0.0832 (0.0700)
Epoch: [0][256/500]	Time 38.028 (38.028)	Loss 0.5382 (0.5224)	CeLoss 0.0010 (0.0373)	SegCLSLoss 0.0060 (0.0051)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1022 (0.0987)	MaskBCELoss 0.0220 (0.0293)	MaskDICELoss 0.0802 (0.0694)
Epoch: [0][257/500]	Time 37.992 (37.992)	Loss 0.4852 (0.4844)	CeLoss 0.0004 (0.0402)	SegCLSLoss 0.0060 (0.0057)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1015 (0.0872)	MaskBCELoss 0.0340 (0.0226)	MaskDICELoss 0.0675 (0.0646)
Epoch: [0][258/500]	Time 36.887 (36.887)	Loss 0.7061 (0.5210)	CeLoss 0.0625 (0.0467)	SegCLSLoss 0.0035 (0.0048)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1222 (0.0941)	MaskBCELoss 0.0242 (0.0250)	MaskDICELoss 0.0980 (0.0691)
Epoch: [0][259/500]	Time 42.574 (42.574)	Loss 0.5617 (0.5039)	CeLoss 0.0023 (0.0314)	SegCLSLoss 0.0056 (0.0049)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1168 (0.0906)	MaskBCELoss 0.0381 (0.0202)	MaskDICELoss 0.0787 (0.0704)
Epoch: [0][260/500]	Time 33.722 (33.722)	Loss 0.5356 (0.4809)	CeLoss 0.0645 (0.0283)	SegCLSLoss 0.0038 (0.0051)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0800 (0.0869)	MaskBCELoss 0.0040 (0.0197)	MaskDICELoss 0.0759 (0.0671)
Epoch: [0][261/500]	Time 36.114 (36.114)	Loss 0.5992 (0.4282)	CeLoss 0.1108 (0.0268)	SegCLSLoss 0.0022 (0.0041)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1206 (0.0795)	MaskBCELoss 0.0601 (0.0209)	MaskDICELoss 0.0606 (0.0586)
Epoch: [0][262/500]	Time 38.663 (38.663)	Loss 0.6764 (0.4856)	CeLoss 0.0864 (0.0435)	SegCLSLoss 0.0027 (0.0041)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1074 (0.0845)	MaskBCELoss 0.0149 (0.0183)	MaskDICELoss 0.0925 (0.0662)
Epoch: [0][263/500]	Time 39.503 (39.503)	Loss 0.3714 (0.5124)	CeLoss 0.0003 (0.0172)	SegCLSLoss 0.0038 (0.0041)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0727 (0.0957)	MaskBCELoss 0.0182 (0.0218)	MaskDICELoss 0.0545 (0.0739)
Epoch: [0][264/500]	Time 40.956 (40.956)	Loss 0.5355 (0.5455)	CeLoss 0.0067 (0.0365)	SegCLSLoss 0.0035 (0.0048)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1080 (0.0981)	MaskBCELoss 0.0315 (0.0222)	MaskDICELoss 0.0765 (0.0758)
Epoch: [0][265/500]	Time 38.268 (38.268)	Loss 0.4835 (0.4836)	CeLoss 0.0013 (0.0208)	SegCLSLoss 0.0049 (0.0046)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0850 (0.0901)	MaskBCELoss 0.0094 (0.0217)	MaskDICELoss 0.0756 (0.0684)
Epoch: [0][266/500]	Time 42.638 (42.638)	Loss 0.4940 (0.4920)	CeLoss 0.0004 (0.0256)	SegCLSLoss 0.0035 (0.0044)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0946 (0.0900)	MaskBCELoss 0.0203 (0.0206)	MaskDICELoss 0.0743 (0.0694)
Epoch: [0][267/500]	Time 40.024 (40.024)	Loss 0.5522 (0.5130)	CeLoss 0.0732 (0.0271)	SegCLSLoss 0.0033 (0.0038)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1056 (0.0994)	MaskBCELoss 0.0403 (0.0295)	MaskDICELoss 0.0652 (0.0699)
Epoch: [0][268/500]	Time 34.957 (34.957)	Loss 0.5211 (0.4370)	CeLoss 0.0005 (0.0305)	SegCLSLoss 0.0028 (0.0037)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1056 (0.0820)	MaskBCELoss 0.0297 (0.0233)	MaskDICELoss 0.0759 (0.0587)
Epoch: [0][269/500]	Time 41.012 (41.012)	Loss 0.5331 (0.5479)	CeLoss 0.0013 (0.0418)	SegCLSLoss 0.0033 (0.0046)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1024 (0.0990)	MaskBCELoss 0.0222 (0.0242)	MaskDICELoss 0.0801 (0.0747)
Epoch: [0][270/500]	Time 40.193 (40.193)	Loss 0.5250 (0.4864)	CeLoss 0.0010 (0.0016)	SegCLSLoss 0.0037 (0.0046)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1094 (0.0939)	MaskBCELoss 0.0350 (0.0220)	MaskDICELoss 0.0744 (0.0719)
Epoch: [0][271/500]	Time 37.445 (37.445)	Loss 0.2330 (0.4992)	CeLoss 0.0938 (0.0391)	SegCLSLoss 0.0036 (0.0045)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0255 (0.0909)	MaskBCELoss 0.0051 (0.0236)	MaskDICELoss 0.0203 (0.0673)
Epoch: [0][272/500]	Time 42.409 (42.409)	Loss 0.3129 (0.5106)	CeLoss 0.0003 (0.0421)	SegCLSLoss 0.0074 (0.0051)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0558 (0.0912)	MaskBCELoss 0.0092 (0.0222)	MaskDICELoss 0.0466 (0.0690)
Epoch: [0][273/500]	Time 30.905 (30.905)	Loss 0.5482 (0.4038)	CeLoss 0.0493 (0.0440)	SegCLSLoss 0.0028 (0.0045)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0943 (0.0719)	MaskBCELoss 0.0182 (0.0201)	MaskDICELoss 0.0761 (0.0518)
Epoch: [0][274/500]	Time 40.787 (40.787)	Loss 0.3352 (0.4955)	CeLoss 0.0003 (0.0109)	SegCLSLoss 0.0029 (0.0037)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0664 (0.0954)	MaskBCELoss 0.0173 (0.0238)	MaskDICELoss 0.0491 (0.0716)
Epoch: [0][275/500]	Time 46.108 (46.108)	Loss 0.4939 (0.5313)	CeLoss 0.0014 (0.0246)	SegCLSLoss 0.0037 (0.0037)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1010 (0.1023)	MaskBCELoss 0.0303 (0.0287)	MaskDICELoss 0.0708 (0.0737)
Epoch: [0][276/500]	Time 37.271 (37.271)	Loss 0.4721 (0.5238)	CeLoss 0.0074 (0.0296)	SegCLSLoss 0.0045 (0.0055)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0959 (0.0962)	MaskBCELoss 0.0299 (0.0235)	MaskDICELoss 0.0660 (0.0727)
Epoch: [0][277/500]	Time 39.068 (39.068)	Loss 0.5568 (0.5012)	CeLoss 0.0762 (0.0521)	SegCLSLoss 0.0022 (0.0040)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0968 (0.0954)	MaskBCELoss 0.0261 (0.0328)	MaskDICELoss 0.0707 (0.0626)
Epoch: [0][278/500]	Time 31.900 (31.900)	Loss 0.5177 (0.4475)	CeLoss 0.0016 (0.0266)	SegCLSLoss 0.0034 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1143 (0.0853)	MaskBCELoss 0.0441 (0.0246)	MaskDICELoss 0.0702 (0.0608)
Epoch: [0][279/500]	Time 37.577 (37.577)	Loss 0.3512 (0.4885)	CeLoss 0.0002 (0.0369)	SegCLSLoss 0.0021 (0.0041)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0774 (0.0903)	MaskBCELoss 0.0295 (0.0246)	MaskDICELoss 0.0480 (0.0657)
Epoch: [0][280/500]	Time 35.135 (35.135)	Loss 0.4329 (0.5106)	CeLoss 0.0007 (0.0314)	SegCLSLoss 0.0047 (0.0047)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0781 (0.0926)	MaskBCELoss 0.0114 (0.0214)	MaskDICELoss 0.0667 (0.0712)
Epoch: [0][281/500]	Time 40.134 (40.134)	Loss 0.5282 (0.4445)	CeLoss 0.0016 (0.0274)	SegCLSLoss 0.0040 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0977 (0.0804)	MaskBCELoss 0.0169 (0.0180)	MaskDICELoss 0.0808 (0.0624)
Epoch: [0][282/500]	Time 35.547 (35.547)	Loss 0.4554 (0.4226)	CeLoss 0.0004 (0.0191)	SegCLSLoss 0.0034 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0941 (0.0767)	MaskBCELoss 0.0290 (0.0160)	MaskDICELoss 0.0650 (0.0608)
Epoch: [0][283/500]	Time 40.493 (40.493)	Loss 0.4816 (0.4679)	CeLoss 0.0007 (0.0192)	SegCLSLoss 0.0033 (0.0043)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1017 (0.0896)	MaskBCELoss 0.0339 (0.0244)	MaskDICELoss 0.0677 (0.0652)
Epoch: [0][284/500]	Time 41.856 (41.856)	Loss 0.5566 (0.5027)	CeLoss 0.0012 (0.0216)	SegCLSLoss 0.0043 (0.0033)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1191 (0.0973)	MaskBCELoss 0.0420 (0.0274)	MaskDICELoss 0.0771 (0.0700)
Epoch: [0][285/500]	Time 35.504 (35.504)	Loss 0.4630 (0.4847)	CeLoss 0.0012 (0.0428)	SegCLSLoss 0.0052 (0.0039)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0921 (0.0875)	MaskBCELoss 0.0253 (0.0226)	MaskDICELoss 0.0668 (0.0648)
Epoch: [0][286/500]	Time 37.729 (37.729)	Loss 0.4255 (0.4478)	CeLoss 0.0198 (0.0451)	SegCLSLoss 0.0024 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0723 (0.0776)	MaskBCELoss 0.0083 (0.0175)	MaskDICELoss 0.0641 (0.0601)
Epoch: [0][287/500]	Time 38.065 (38.065)	Loss 0.5471 (0.4574)	CeLoss 0.0366 (0.0441)	SegCLSLoss 0.0036 (0.0050)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0958 (0.0844)	MaskBCELoss 0.0179 (0.0257)	MaskDICELoss 0.0779 (0.0586)
Epoch: [0][288/500]	Time 37.951 (37.951)	Loss 0.5232 (0.4214)	CeLoss 0.0022 (0.0268)	SegCLSLoss 0.0046 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1024 (0.0784)	MaskBCELoss 0.0257 (0.0208)	MaskDICELoss 0.0767 (0.0577)
Epoch: [0][289/500]	Time 40.684 (40.684)	Loss 0.6008 (0.5252)	CeLoss 0.0513 (0.0383)	SegCLSLoss 0.0025 (0.0036)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1029 (0.0980)	MaskBCELoss 0.0183 (0.0270)	MaskDICELoss 0.0847 (0.0709)
Epoch: [0][290/500]	Time 37.634 (37.634)	Loss 0.4703 (0.5088)	CeLoss 0.0011 (0.0412)	SegCLSLoss 0.0031 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0904 (0.0954)	MaskBCELoss 0.0199 (0.0279)	MaskDICELoss 0.0706 (0.0675)
Epoch: [0][291/500]	Time 35.333 (35.333)	Loss 0.3482 (0.4372)	CeLoss 0.0286 (0.0096)	SegCLSLoss 0.0052 (0.0034)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0656 (0.0864)	MaskBCELoss 0.0211 (0.0244)	MaskDICELoss 0.0445 (0.0620)
Epoch: [0][292/500]	Time 32.615 (32.615)	Loss 0.6129 (0.4339)	CeLoss 0.0006 (0.0258)	SegCLSLoss 0.0042 (0.0027)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1198 (0.0811)	MaskBCELoss 0.0287 (0.0210)	MaskDICELoss 0.0911 (0.0601)
Epoch: [0][293/500]	Time 37.572 (37.572)	Loss 0.3128 (0.4817)	CeLoss 0.0012 (0.0351)	SegCLSLoss 0.0021 (0.0029)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0677 (0.0920)	MaskBCELoss 0.0247 (0.0278)	MaskDICELoss 0.0430 (0.0642)
Epoch: [0][294/500]	Time 43.539 (43.539)	Loss 0.5989 (0.5411)	CeLoss 0.0009 (0.0321)	SegCLSLoss 0.0020 (0.0033)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1195 (0.1010)	MaskBCELoss 0.0308 (0.0260)	MaskDICELoss 0.0887 (0.0751)
Epoch: [0][295/500]	Time 33.500 (33.500)	Loss 0.4431 (0.4840)	CeLoss 0.0009 (0.0206)	SegCLSLoss 0.0057 (0.0032)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0939 (0.0922)	MaskBCELoss 0.0332 (0.0240)	MaskDICELoss 0.0607 (0.0682)
Epoch: [0][296/500]	Time 43.197 (43.197)	Loss 0.4727 (0.5053)	CeLoss 0.0017 (0.0381)	SegCLSLoss 0.0047 (0.0032)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0989 (0.0933)	MaskBCELoss 0.0329 (0.0248)	MaskDICELoss 0.0660 (0.0685)
Epoch: [0][297/500]	Time 46.312 (46.312)	Loss 0.5810 (0.5245)	CeLoss 0.0981 (0.0322)	SegCLSLoss 0.0014 (0.0036)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0876 (0.1002)	MaskBCELoss 0.0113 (0.0290)	MaskDICELoss 0.0763 (0.0712)
Epoch: [0][298/500]	Time 31.266 (31.266)	Loss 0.5141 (0.4735)	CeLoss 0.0674 (0.0404)	SegCLSLoss 0.0025 (0.0037)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0819 (0.0873)	MaskBCELoss 0.0125 (0.0245)	MaskDICELoss 0.0695 (0.0628)
Epoch: [0][299/500]	Time 40.864 (40.864)	Loss 0.3116 (0.4685)	CeLoss 0.0483 (0.0368)	SegCLSLoss 0.0030 (0.0030)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0487 (0.0868)	MaskBCELoss 0.0087 (0.0238)	MaskDICELoss 0.0400 (0.0631)
[2025-04-17 01:59:59,154] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.0002972650602409638], mom=[(0.9, 0.95)]
[2025-04-17 01:59:59,171] [INFO] [timer.py:215:stop] epoch=0/micro_step=300/global_step=30, RunningAvgSamplesPerSec=1.0528562309586282, CurrSamplesPerSec=1.0183371467121356, MemAllocated=37.17GB, MaxMemAllocated=46.26GB
Epoch: [0][300/500]	Time 39.425 (39.425)	Loss 0.6149 (0.4904)	CeLoss 0.0310 (0.0531)	SegCLSLoss 0.0041 (0.0035)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1242 (0.0902)	MaskBCELoss 0.0424 (0.0278)	MaskDICELoss 0.0818 (0.0624)
Epoch: [0][301/500]	Time 38.660 (38.660)	Loss 0.4313 (0.4509)	CeLoss 0.0571 (0.0190)	SegCLSLoss 0.0053 (0.0028)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0773 (0.0877)	MaskBCELoss 0.0250 (0.0250)	MaskDICELoss 0.0523 (0.0627)
Epoch: [0][302/500]	Time 32.919 (32.919)	Loss 0.5898 (0.4314)	CeLoss 0.0532 (0.0193)	SegCLSLoss 0.0027 (0.0023)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1259 (0.0867)	MaskBCELoss 0.0561 (0.0281)	MaskDICELoss 0.0698 (0.0585)
Epoch: [0][303/500]	Time 41.989 (41.989)	Loss 0.5855 (0.5148)	CeLoss 0.0016 (0.0063)	SegCLSLoss 0.0043 (0.0034)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1192 (0.1041)	MaskBCELoss 0.0350 (0.0307)	MaskDICELoss 0.0842 (0.0734)
Epoch: [0][304/500]	Time 38.843 (38.843)	Loss 0.2167 (0.4617)	CeLoss 0.0835 (0.0377)	SegCLSLoss 0.0003 (0.0032)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0259 (0.0824)	MaskBCELoss 0.0058 (0.0192)	MaskDICELoss 0.0201 (0.0632)
Epoch: [0][305/500]	Time 38.512 (38.512)	Loss 0.5831 (0.5130)	CeLoss 0.0339 (0.0217)	SegCLSLoss 0.0043 (0.0028)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1165 (0.0990)	MaskBCELoss 0.0395 (0.0271)	MaskDICELoss 0.0769 (0.0719)
Epoch: [0][306/500]	Time 42.595 (42.595)	Loss 0.5284 (0.4748)	CeLoss 0.0012 (0.0359)	SegCLSLoss 0.0033 (0.0023)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1001 (0.0890)	MaskBCELoss 0.0200 (0.0250)	MaskDICELoss 0.0801 (0.0640)
Epoch: [0][307/500]	Time 40.622 (40.622)	Loss 0.4758 (0.4339)	CeLoss 0.0300 (0.0231)	SegCLSLoss 0.0032 (0.0027)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0979 (0.0857)	MaskBCELoss 0.0369 (0.0272)	MaskDICELoss 0.0609 (0.0585)
Epoch: [0][308/500]	Time 35.667 (35.667)	Loss 0.3918 (0.4243)	CeLoss 0.0017 (0.0304)	SegCLSLoss 0.0036 (0.0027)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0782 (0.0782)	MaskBCELoss 0.0216 (0.0202)	MaskDICELoss 0.0566 (0.0580)
Epoch: [0][309/500]	Time 35.396 (35.396)	Loss 0.4697 (0.4362)	CeLoss 0.0698 (0.0412)	SegCLSLoss 0.0049 (0.0023)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0850 (0.0801)	MaskBCELoss 0.0301 (0.0225)	MaskDICELoss 0.0550 (0.0576)
Epoch: [0][310/500]	Time 40.141 (40.141)	Loss 0.4454 (0.4277)	CeLoss 0.0635 (0.0215)	SegCLSLoss 0.0057 (0.0032)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0685 (0.0813)	MaskBCELoss 0.0100 (0.0220)	MaskDICELoss 0.0584 (0.0593)
Epoch: [0][311/500]	Time 35.759 (35.759)	Loss 0.5920 (0.4505)	CeLoss 0.0016 (0.0141)	SegCLSLoss 0.0039 (0.0021)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1145 (0.0895)	MaskBCELoss 0.0261 (0.0262)	MaskDICELoss 0.0884 (0.0633)
Epoch: [0][312/500]	Time 39.548 (39.548)	Loss 0.3452 (0.4673)	CeLoss 0.0002 (0.0172)	SegCLSLoss 0.0005 (0.0024)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0740 (0.0903)	MaskBCELoss 0.0250 (0.0241)	MaskDICELoss 0.0490 (0.0662)
Epoch: [0][313/500]	Time 38.540 (38.540)	Loss 0.4305 (0.4984)	CeLoss 0.0005 (0.0349)	SegCLSLoss 0.0031 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0820 (0.0932)	MaskBCELoss 0.0170 (0.0248)	MaskDICELoss 0.0650 (0.0685)
Epoch: [0][314/500]	Time 42.838 (42.838)	Loss 0.5967 (0.5085)	CeLoss 0.0009 (0.0090)	SegCLSLoss 0.0007 (0.0025)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1121 (0.0996)	MaskBCELoss 0.0196 (0.0258)	MaskDICELoss 0.0926 (0.0738)
Epoch: [0][315/500]	Time 37.266 (37.266)	Loss 0.2047 (0.5044)	CeLoss 0.0002 (0.0364)	SegCLSLoss 0.0016 (0.0019)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0437 (0.0936)	MaskBCELoss 0.0152 (0.0243)	MaskDICELoss 0.0285 (0.0693)
Epoch: [0][316/500]	Time 33.457 (33.457)	Loss 0.2982 (0.4523)	CeLoss 0.0009 (0.0335)	SegCLSLoss 0.0038 (0.0026)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0597 (0.0817)	MaskBCELoss 0.0171 (0.0191)	MaskDICELoss 0.0426 (0.0626)
Epoch: [0][317/500]	Time 40.162 (40.162)	Loss 0.4121 (0.4261)	CeLoss 0.0003 (0.0121)	SegCLSLoss 0.0020 (0.0029)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0866 (0.0851)	MaskBCELoss 0.0280 (0.0255)	MaskDICELoss 0.0587 (0.0595)
Epoch: [0][318/500]	Time 41.152 (41.152)	Loss 0.4854 (0.4651)	CeLoss 0.0008 (0.0084)	SegCLSLoss 0.0030 (0.0027)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1035 (0.0903)	MaskBCELoss 0.0356 (0.0226)	MaskDICELoss 0.0679 (0.0677)
Epoch: [0][319/500]	Time 35.958 (35.958)	Loss 0.1220 (0.4088)	CeLoss 0.0002 (0.0255)	SegCLSLoss 0.0003 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0242 (0.0766)	MaskBCELoss 0.0060 (0.0199)	MaskDICELoss 0.0182 (0.0567)
Epoch: [0][320/500]	Time 41.886 (41.886)	Loss 0.5558 (0.5015)	CeLoss 0.0586 (0.0370)	SegCLSLoss 0.0019 (0.0022)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1004 (0.0935)	MaskBCELoss 0.0272 (0.0253)	MaskDICELoss 0.0731 (0.0682)
Epoch: [0][321/500]	Time 37.219 (37.219)	Loss 0.4654 (0.5166)	CeLoss 0.0004 (0.0395)	SegCLSLoss 0.0018 (0.0022)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0972 (0.0952)	MaskBCELoss 0.0305 (0.0246)	MaskDICELoss 0.0667 (0.0706)
Epoch: [0][322/500]	Time 40.750 (40.750)	Loss 0.5748 (0.4589)	CeLoss 0.0581 (0.0161)	SegCLSLoss 0.0013 (0.0018)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0939 (0.0856)	MaskBCELoss 0.0123 (0.0187)	MaskDICELoss 0.0816 (0.0670)
Epoch: [0][323/500]	Time 38.255 (38.255)	Loss 0.6490 (0.4409)	CeLoss 0.0437 (0.0309)	SegCLSLoss 0.0014 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1119 (0.0812)	MaskBCELoss 0.0171 (0.0198)	MaskDICELoss 0.0947 (0.0614)
Epoch: [0][324/500]	Time 47.888 (47.888)	Loss 0.4490 (0.5009)	CeLoss 0.0513 (0.0291)	SegCLSLoss 0.0016 (0.0019)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0705 (0.0979)	MaskBCELoss 0.0070 (0.0298)	MaskDICELoss 0.0634 (0.0681)
Epoch: [0][325/500]	Time 42.082 (42.082)	Loss 0.5908 (0.4566)	CeLoss 0.0008 (0.0244)	SegCLSLoss 0.0039 (0.0017)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1131 (0.0873)	MaskBCELoss 0.0242 (0.0238)	MaskDICELoss 0.0890 (0.0636)
Epoch: [0][326/500]	Time 37.488 (37.488)	Loss 0.4673 (0.4509)	CeLoss 0.0009 (0.0168)	SegCLSLoss 0.0024 (0.0021)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0967 (0.0887)	MaskBCELoss 0.0297 (0.0256)	MaskDICELoss 0.0670 (0.0631)
Epoch: [0][327/500]	Time 41.774 (41.774)	Loss 0.5406 (0.4925)	CeLoss 0.0422 (0.0236)	SegCLSLoss 0.0024 (0.0018)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1060 (0.0957)	MaskBCELoss 0.0356 (0.0271)	MaskDICELoss 0.0704 (0.0685)
Epoch: [0][328/500]	Time 38.696 (38.696)	Loss 0.5055 (0.4735)	CeLoss 0.0019 (0.0257)	SegCLSLoss 0.0022 (0.0015)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0968 (0.0916)	MaskBCELoss 0.0204 (0.0262)	MaskDICELoss 0.0764 (0.0654)
Epoch: [0][329/500]	Time 37.255 (37.255)	Loss 0.5544 (0.4594)	CeLoss 0.0006 (0.0489)	SegCLSLoss 0.0011 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1158 (0.0833)	MaskBCELoss 0.0358 (0.0231)	MaskDICELoss 0.0800 (0.0602)
Epoch: [0][330/500]	Time 36.409 (36.409)	Loss 0.5756 (0.4439)	CeLoss 0.0015 (0.0352)	SegCLSLoss 0.0016 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1119 (0.0822)	MaskBCELoss 0.0251 (0.0218)	MaskDICELoss 0.0868 (0.0604)
Epoch: [0][331/500]	Time 39.363 (39.363)	Loss 0.5588 (0.4484)	CeLoss 0.0016 (0.0228)	SegCLSLoss 0.0046 (0.0026)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1100 (0.0876)	MaskBCELoss 0.0280 (0.0263)	MaskDICELoss 0.0820 (0.0613)
Epoch: [0][332/500]	Time 39.011 (39.011)	Loss 0.4190 (0.4792)	CeLoss 0.0344 (0.0340)	SegCLSLoss 0.0015 (0.0033)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0684 (0.0903)	MaskBCELoss 0.0072 (0.0258)	MaskDICELoss 0.0612 (0.0645)
Epoch: [0][333/500]	Time 43.443 (43.443)	Loss 0.1162 (0.5214)	CeLoss 0.0002 (0.0381)	SegCLSLoss 0.0003 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0231 (0.1002)	MaskBCELoss 0.0058 (0.0303)	MaskDICELoss 0.0173 (0.0699)
Epoch: [0][334/500]	Time 36.731 (36.731)	Loss 0.4418 (0.4819)	CeLoss 0.0051 (0.0243)	SegCLSLoss 0.0018 (0.0028)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0844 (0.0911)	MaskBCELoss 0.0184 (0.0236)	MaskDICELoss 0.0661 (0.0675)
Epoch: [0][335/500]	Time 41.826 (41.826)	Loss 0.6016 (0.5136)	CeLoss 0.0542 (0.0372)	SegCLSLoss 0.0018 (0.0020)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1110 (0.0998)	MaskBCELoss 0.0306 (0.0316)	MaskDICELoss 0.0804 (0.0682)
Epoch: [0][336/500]	Time 41.040 (41.040)	Loss 0.4839 (0.5330)	CeLoss 0.0474 (0.0308)	SegCLSLoss 0.0009 (0.0022)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0880 (0.1030)	MaskBCELoss 0.0233 (0.0300)	MaskDICELoss 0.0647 (0.0730)
Epoch: [0][337/500]	Time 34.028 (34.028)	Loss 0.5899 (0.4056)	CeLoss 0.0454 (0.0186)	SegCLSLoss 0.0020 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1201 (0.0829)	MaskBCELoss 0.0450 (0.0283)	MaskDICELoss 0.0751 (0.0546)
Epoch: [0][338/500]	Time 42.080 (42.080)	Loss 0.5628 (0.5307)	CeLoss 0.0015 (0.0265)	SegCLSLoss 0.0044 (0.0024)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1220 (0.1028)	MaskBCELoss 0.0448 (0.0293)	MaskDICELoss 0.0772 (0.0735)
Epoch: [0][339/500]	Time 37.886 (37.886)	Loss 0.4601 (0.4550)	CeLoss 0.0801 (0.0287)	SegCLSLoss 0.0004 (0.0019)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0885 (0.0870)	MaskBCELoss 0.0379 (0.0248)	MaskDICELoss 0.0506 (0.0621)
Epoch: [0][340/500]	Time 42.228 (42.228)	Loss 0.4488 (0.4653)	CeLoss 0.0693 (0.0330)	SegCLSLoss 0.0014 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0778 (0.0875)	MaskBCELoss 0.0225 (0.0239)	MaskDICELoss 0.0553 (0.0636)
Epoch: [0][341/500]	Time 38.573 (38.573)	Loss 0.4406 (0.5047)	CeLoss 0.0464 (0.0337)	SegCLSLoss 0.0002 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0754 (0.0944)	MaskBCELoss 0.0147 (0.0246)	MaskDICELoss 0.0607 (0.0698)
Epoch: [0][342/500]	Time 38.521 (38.521)	Loss 0.2853 (0.4097)	CeLoss 0.0023 (0.0272)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0713 (0.0796)	MaskBCELoss 0.0367 (0.0243)	MaskDICELoss 0.0346 (0.0552)
Epoch: [0][343/500]	Time 43.517 (43.517)	Loss 0.3539 (0.4973)	CeLoss 0.0002 (0.0303)	SegCLSLoss 0.0005 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0741 (0.0933)	MaskBCELoss 0.0230 (0.0238)	MaskDICELoss 0.0511 (0.0696)
Epoch: [0][344/500]	Time 40.628 (40.628)	Loss 0.5842 (0.4976)	CeLoss 0.0566 (0.0235)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0978 (0.0948)	MaskBCELoss 0.0156 (0.0241)	MaskDICELoss 0.0822 (0.0707)
Epoch: [0][345/500]	Time 44.944 (44.944)	Loss 0.4598 (0.4588)	CeLoss 0.0747 (0.0404)	SegCLSLoss 0.0021 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0770 (0.0825)	MaskBCELoss 0.0202 (0.0197)	MaskDICELoss 0.0568 (0.0628)
Epoch: [0][346/500]	Time 37.547 (37.547)	Loss 0.1139 (0.4155)	CeLoss 0.0002 (0.0226)	SegCLSLoss 0.0002 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0230 (0.0840)	MaskBCELoss 0.0062 (0.0286)	MaskDICELoss 0.0168 (0.0554)
Epoch: [0][347/500]	Time 37.522 (37.522)	Loss 0.5106 (0.4734)	CeLoss 0.0004 (0.0302)	SegCLSLoss 0.0032 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1016 (0.0926)	MaskBCELoss 0.0264 (0.0288)	MaskDICELoss 0.0751 (0.0638)
Epoch: [0][348/500]	Time 39.546 (39.546)	Loss 0.5875 (0.4599)	CeLoss 0.0771 (0.0206)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0969 (0.0851)	MaskBCELoss 0.0178 (0.0184)	MaskDICELoss 0.0790 (0.0667)
Epoch: [0][349/500]	Time 44.051 (44.051)	Loss 0.4660 (0.5427)	CeLoss 0.0002 (0.0249)	SegCLSLoss 0.0018 (0.0015)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0890 (0.1007)	MaskBCELoss 0.0179 (0.0223)	MaskDICELoss 0.0711 (0.0784)
Epoch: [0][350/500]	Time 37.783 (37.783)	Loss 0.4643 (0.4315)	CeLoss 0.0011 (0.0213)	SegCLSLoss 0.0011 (0.0009)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0944 (0.0836)	MaskBCELoss 0.0263 (0.0234)	MaskDICELoss 0.0681 (0.0603)
Epoch: [0][351/500]	Time 40.476 (40.476)	Loss 0.3563 (0.4937)	CeLoss 0.0004 (0.0224)	SegCLSLoss 0.0031 (0.0017)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0751 (0.0914)	MaskBCELoss 0.0253 (0.0202)	MaskDICELoss 0.0498 (0.0712)
Epoch: [0][352/500]	Time 37.508 (37.508)	Loss 0.4876 (0.4689)	CeLoss 0.0432 (0.0153)	SegCLSLoss 0.0013 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0941 (0.0906)	MaskBCELoss 0.0307 (0.0233)	MaskDICELoss 0.0634 (0.0674)
Epoch: [0][353/500]	Time 37.680 (37.680)	Loss 0.4019 (0.4439)	CeLoss 0.0001 (0.0341)	SegCLSLoss 0.0012 (0.0012)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0877 (0.0811)	MaskBCELoss 0.0318 (0.0198)	MaskDICELoss 0.0560 (0.0613)
Epoch: [0][354/500]	Time 38.265 (38.265)	Loss 0.6801 (0.4366)	CeLoss 0.0703 (0.0318)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1065 (0.0787)	MaskBCELoss 0.0076 (0.0176)	MaskDICELoss 0.0989 (0.0611)
Epoch: [0][355/500]	Time 38.936 (38.936)	Loss 0.4643 (0.4298)	CeLoss 0.0004 (0.0154)	SegCLSLoss 0.0009 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0938 (0.0806)	MaskBCELoss 0.0251 (0.0178)	MaskDICELoss 0.0687 (0.0628)
Epoch: [0][356/500]	Time 37.447 (37.447)	Loss 0.2470 (0.4100)	CeLoss 0.0003 (0.0074)	SegCLSLoss 0.0022 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0506 (0.0799)	MaskBCELoss 0.0153 (0.0200)	MaskDICELoss 0.0353 (0.0599)
Epoch: [0][357/500]	Time 36.148 (36.148)	Loss 0.1726 (0.4628)	CeLoss 0.0620 (0.0334)	SegCLSLoss 0.0001 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0222 (0.0836)	MaskBCELoss 0.0057 (0.0188)	MaskDICELoss 0.0165 (0.0649)
Epoch: [0][358/500]	Time 41.194 (41.194)	Loss 0.4713 (0.4200)	CeLoss 0.0276 (0.0330)	SegCLSLoss 0.0023 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0900 (0.0779)	MaskBCELoss 0.0253 (0.0206)	MaskDICELoss 0.0648 (0.0573)
Epoch: [0][359/500]	Time 42.540 (42.540)	Loss 0.5060 (0.5103)	CeLoss 0.0007 (0.0461)	SegCLSLoss 0.0017 (0.0017)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0978 (0.0944)	MaskBCELoss 0.0213 (0.0264)	MaskDICELoss 0.0766 (0.0680)
Epoch: [0][360/500]	Time 39.989 (39.989)	Loss 0.5152 (0.4799)	CeLoss 0.0001 (0.0137)	SegCLSLoss 0.0009 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1085 (0.0979)	MaskBCELoss 0.0345 (0.0309)	MaskDICELoss 0.0741 (0.0669)
Epoch: [0][361/500]	Time 42.628 (42.628)	Loss 0.4063 (0.5055)	CeLoss 0.0002 (0.0353)	SegCLSLoss 0.0027 (0.0018)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0864 (0.0936)	MaskBCELoss 0.0294 (0.0237)	MaskDICELoss 0.0570 (0.0699)
Epoch: [0][362/500]	Time 34.831 (34.831)	Loss 0.3869 (0.4460)	CeLoss 0.0547 (0.0360)	SegCLSLoss 0.0019 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0726 (0.0779)	MaskBCELoss 0.0269 (0.0151)	MaskDICELoss 0.0458 (0.0628)
Epoch: [0][363/500]	Time 35.860 (35.860)	Loss 0.3996 (0.4180)	CeLoss 0.0003 (0.0328)	SegCLSLoss 0.0014 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0792 (0.0811)	MaskBCELoss 0.0197 (0.0260)	MaskDICELoss 0.0595 (0.0551)
Epoch: [0][364/500]	Time 38.399 (38.399)	Loss 0.4520 (0.4723)	CeLoss 0.0483 (0.0314)	SegCLSLoss 0.0006 (0.0015)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0767 (0.0899)	MaskBCELoss 0.0145 (0.0253)	MaskDICELoss 0.0622 (0.0645)
Epoch: [0][365/500]	Time 35.487 (35.487)	Loss 0.4226 (0.4544)	CeLoss 0.0688 (0.0447)	SegCLSLoss 0.0017 (0.0024)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0736 (0.0783)	MaskBCELoss 0.0227 (0.0163)	MaskDICELoss 0.0509 (0.0621)
Epoch: [0][366/500]	Time 42.083 (42.083)	Loss 0.4045 (0.4936)	CeLoss 0.0055 (0.0144)	SegCLSLoss 0.0021 (0.0017)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0858 (0.0944)	MaskBCELoss 0.0300 (0.0227)	MaskDICELoss 0.0558 (0.0717)
Epoch: [0][367/500]	Time 35.881 (35.881)	Loss 0.3423 (0.4063)	CeLoss 0.0001 (0.0352)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0636 (0.0752)	MaskBCELoss 0.0100 (0.0207)	MaskDICELoss 0.0536 (0.0545)
Epoch: [0][368/500]	Time 37.567 (37.567)	Loss 0.3104 (0.4568)	CeLoss 0.0957 (0.0398)	SegCLSLoss 0.0016 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0467 (0.0858)	MaskBCELoss 0.0171 (0.0252)	MaskDICELoss 0.0296 (0.0606)
Epoch: [0][369/500]	Time 37.889 (37.889)	Loss 0.3631 (0.4593)	CeLoss 0.0908 (0.0500)	SegCLSLoss 0.0021 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0525 (0.0858)	MaskBCELoss 0.0118 (0.0270)	MaskDICELoss 0.0407 (0.0588)
Epoch: [0][370/500]	Time 33.760 (33.760)	Loss 0.5404 (0.3862)	CeLoss 0.0001 (0.0205)	SegCLSLoss 0.0023 (0.0019)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1054 (0.0731)	MaskBCELoss 0.0242 (0.0192)	MaskDICELoss 0.0812 (0.0539)
Epoch: [0][371/500]	Time 37.835 (37.835)	Loss 0.5362 (0.3683)	CeLoss 0.0571 (0.0376)	SegCLSLoss 0.0013 (0.0009)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0987 (0.0655)	MaskBCELoss 0.0288 (0.0160)	MaskDICELoss 0.0699 (0.0495)
Epoch: [0][372/500]	Time 35.528 (35.528)	Loss 0.4730 (0.4839)	CeLoss 0.0850 (0.0282)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0740 (0.0927)	MaskBCELoss 0.0146 (0.0257)	MaskDICELoss 0.0595 (0.0670)
Epoch: [0][373/500]	Time 35.682 (35.682)	Loss 0.6474 (0.4347)	CeLoss 0.0449 (0.0241)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1110 (0.0814)	MaskBCELoss 0.0166 (0.0201)	MaskDICELoss 0.0944 (0.0613)
Epoch: [0][374/500]	Time 33.656 (33.656)	Loss 0.5631 (0.3936)	CeLoss 0.0002 (0.0035)	SegCLSLoss 0.0013 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1158 (0.0781)	MaskBCELoss 0.0337 (0.0202)	MaskDICELoss 0.0822 (0.0579)
Epoch: [0][375/500]	Time 43.943 (43.943)	Loss 0.6295 (0.4426)	CeLoss 0.0500 (0.0135)	SegCLSLoss 0.0021 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1131 (0.0877)	MaskBCELoss 0.0258 (0.0249)	MaskDICELoss 0.0873 (0.0628)
Epoch: [0][376/500]	Time 39.589 (39.589)	Loss 0.5592 (0.4429)	CeLoss 0.0006 (0.0101)	SegCLSLoss 0.0013 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1105 (0.0854)	MaskBCELoss 0.0267 (0.0205)	MaskDICELoss 0.0838 (0.0648)
Epoch: [0][377/500]	Time 34.898 (34.898)	Loss 0.3212 (0.4116)	CeLoss 0.0003 (0.0055)	SegCLSLoss 0.0017 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0700 (0.0838)	MaskBCELoss 0.0256 (0.0249)	MaskDICELoss 0.0444 (0.0589)
Epoch: [0][378/500]	Time 39.068 (39.068)	Loss 0.5750 (0.4597)	CeLoss 0.0752 (0.0453)	SegCLSLoss 0.0020 (0.0018)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1007 (0.0823)	MaskBCELoss 0.0271 (0.0207)	MaskDICELoss 0.0737 (0.0616)
Epoch: [0][379/500]	Time 32.072 (32.072)	Loss 0.4985 (0.4049)	CeLoss 0.0001 (0.0106)	SegCLSLoss 0.0016 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0933 (0.0770)	MaskBCELoss 0.0162 (0.0174)	MaskDICELoss 0.0771 (0.0596)
Epoch: [0][380/500]	Time 46.417 (46.417)	Loss 0.5958 (0.4804)	CeLoss 0.0001 (0.0309)	SegCLSLoss 0.0023 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1134 (0.0903)	MaskBCELoss 0.0224 (0.0237)	MaskDICELoss 0.0910 (0.0666)
Epoch: [0][381/500]	Time 35.275 (35.275)	Loss 0.4764 (0.4081)	CeLoss 0.0001 (0.0214)	SegCLSLoss 0.0011 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0954 (0.0765)	MaskBCELoss 0.0245 (0.0186)	MaskDICELoss 0.0709 (0.0579)
Epoch: [0][382/500]	Time 45.481 (45.481)	Loss 0.5535 (0.4625)	CeLoss 0.0381 (0.0228)	SegCLSLoss 0.0002 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1179 (0.0885)	MaskBCELoss 0.0481 (0.0232)	MaskDICELoss 0.0698 (0.0653)
Epoch: [0][383/500]	Time 37.667 (37.667)	Loss 0.5367 (0.4589)	CeLoss 0.0781 (0.0218)	SegCLSLoss 0.0005 (0.0012)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0976 (0.0891)	MaskBCELoss 0.0320 (0.0250)	MaskDICELoss 0.0656 (0.0641)
Epoch: [0][384/500]	Time 42.377 (42.377)	Loss 0.3236 (0.4630)	CeLoss 0.0003 (0.0259)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0615 (0.0846)	MaskBCELoss 0.0117 (0.0180)	MaskDICELoss 0.0498 (0.0666)
Epoch: [0][385/500]	Time 36.233 (36.233)	Loss 0.5017 (0.4538)	CeLoss 0.0002 (0.0276)	SegCLSLoss 0.0009 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0984 (0.0867)	MaskBCELoss 0.0227 (0.0240)	MaskDICELoss 0.0757 (0.0627)
Epoch: [0][386/500]	Time 39.601 (39.601)	Loss 0.2821 (0.3935)	CeLoss 0.0688 (0.0147)	SegCLSLoss 0.0001 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0487 (0.0776)	MaskBCELoss 0.0198 (0.0222)	MaskDICELoss 0.0289 (0.0554)
Epoch: [0][387/500]	Time 37.399 (37.399)	Loss 0.5693 (0.4995)	CeLoss 0.0221 (0.0377)	SegCLSLoss 0.0013 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1087 (0.0891)	MaskBCELoss 0.0269 (0.0186)	MaskDICELoss 0.0818 (0.0705)
Epoch: [0][388/500]	Time 46.577 (46.577)	Loss 0.5416 (0.4431)	CeLoss 0.0297 (0.0073)	SegCLSLoss 0.0014 (0.0009)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0970 (0.0851)	MaskBCELoss 0.0182 (0.0191)	MaskDICELoss 0.0788 (0.0660)
Epoch: [0][389/500]	Time 39.921 (39.921)	Loss 0.5023 (0.4123)	CeLoss 0.0654 (0.0110)	SegCLSLoss 0.0005 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0817 (0.0783)	MaskBCELoss 0.0137 (0.0176)	MaskDICELoss 0.0680 (0.0607)
Epoch: [0][390/500]	Time 36.082 (36.082)	Loss 0.3058 (0.4462)	CeLoss 0.0003 (0.0089)	SegCLSLoss 0.0004 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0613 (0.0881)	MaskBCELoss 0.0157 (0.0234)	MaskDICELoss 0.0455 (0.0647)
Epoch: [0][391/500]	Time 48.917 (48.917)	Loss 0.3479 (0.4613)	CeLoss 0.0001 (0.0358)	SegCLSLoss 0.0028 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0798 (0.0868)	MaskBCELoss 0.0342 (0.0244)	MaskDICELoss 0.0457 (0.0623)
Epoch: [0][392/500]	Time 45.612 (45.612)	Loss 0.4210 (0.4694)	CeLoss 0.0001 (0.0446)	SegCLSLoss 0.0008 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0847 (0.0888)	MaskBCELoss 0.0222 (0.0275)	MaskDICELoss 0.0625 (0.0613)
Epoch: [0][393/500]	Time 31.648 (31.648)	Loss 0.4950 (0.3797)	CeLoss 0.0001 (0.0040)	SegCLSLoss 0.0008 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1002 (0.0758)	MaskBCELoss 0.0269 (0.0205)	MaskDICELoss 0.0733 (0.0553)
Epoch: [0][394/500]	Time 38.149 (38.149)	Loss 0.5073 (0.4566)	CeLoss 0.0003 (0.0345)	SegCLSLoss 0.0014 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1090 (0.0847)	MaskBCELoss 0.0375 (0.0219)	MaskDICELoss 0.0715 (0.0628)
Epoch: [0][395/500]	Time 44.092 (44.092)	Loss 0.5980 (0.5119)	CeLoss 0.0713 (0.0342)	SegCLSLoss 0.0005 (0.0009)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1192 (0.0975)	MaskBCELoss 0.0474 (0.0273)	MaskDICELoss 0.0718 (0.0702)
Epoch: [0][396/500]	Time 40.054 (40.054)	Loss 0.6208 (0.4513)	CeLoss 0.0295 (0.0140)	SegCLSLoss 0.0005 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1039 (0.0845)	MaskBCELoss 0.0082 (0.0181)	MaskDICELoss 0.0956 (0.0664)
Epoch: [0][397/500]	Time 40.082 (40.082)	Loss 0.2977 (0.4516)	CeLoss 0.0439 (0.0307)	SegCLSLoss 0.0033 (0.0012)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0602 (0.0860)	MaskBCELoss 0.0285 (0.0244)	MaskDICELoss 0.0317 (0.0616)
Epoch: [0][398/500]	Time 42.429 (42.429)	Loss 0.4699 (0.4532)	CeLoss 0.0464 (0.0203)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0880 (0.0869)	MaskBCELoss 0.0265 (0.0225)	MaskDICELoss 0.0616 (0.0644)
Epoch: [0][399/500]	Time 40.850 (40.850)	Loss 0.4492 (0.4852)	CeLoss 0.0002 (0.0329)	SegCLSLoss 0.0004 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0878 (0.0911)	MaskBCELoss 0.0196 (0.0242)	MaskDICELoss 0.0682 (0.0669)
[2025-04-17 03:05:22,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.00029593975903614454], mom=[(0.9, 0.95)]
[2025-04-17 03:05:22,933] [INFO] [timer.py:215:stop] epoch=0/micro_step=400/global_step=40, RunningAvgSamplesPerSec=1.034868586521696, CurrSamplesPerSec=1.0121620897503827, MemAllocated=35.7GB, MaxMemAllocated=46.26GB
Epoch: [0][400/500]	Time 42.065 (42.065)	Loss 0.4626 (0.4590)	CeLoss 0.0025 (0.0360)	SegCLSLoss 0.0014 (0.0009)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0889 (0.0814)	MaskBCELoss 0.0191 (0.0168)	MaskDICELoss 0.0699 (0.0646)
Epoch: [0][401/500]	Time 34.232 (34.232)	Loss 0.4459 (0.4152)	CeLoss 0.0002 (0.0360)	SegCLSLoss 0.0009 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0802 (0.0730)	MaskBCELoss 0.0093 (0.0151)	MaskDICELoss 0.0709 (0.0579)
Epoch: [0][402/500]	Time 42.312 (42.312)	Loss 0.4104 (0.4464)	CeLoss 0.0212 (0.0159)	SegCLSLoss 0.0011 (0.0015)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0837 (0.0826)	MaskBCELoss 0.0288 (0.0169)	MaskDICELoss 0.0549 (0.0656)
Epoch: [0][403/500]	Time 37.849 (37.849)	Loss 0.4377 (0.4606)	CeLoss 0.0178 (0.0115)	SegCLSLoss 0.0008 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0809 (0.0876)	MaskBCELoss 0.0168 (0.0198)	MaskDICELoss 0.0641 (0.0678)
Epoch: [0][404/500]	Time 37.463 (37.463)	Loss 0.2188 (0.4288)	CeLoss 0.1338 (0.0571)	SegCLSLoss 0.0002 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0162 (0.0735)	MaskBCELoss 0.0031 (0.0178)	MaskDICELoss 0.0130 (0.0556)
Epoch: [0][405/500]	Time 33.786 (33.786)	Loss 0.5423 (0.3758)	CeLoss 0.0019 (0.0139)	SegCLSLoss 0.0020 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1053 (0.0720)	MaskBCELoss 0.0238 (0.0183)	MaskDICELoss 0.0815 (0.0537)
Epoch: [0][406/500]	Time 37.643 (37.643)	Loss 0.2777 (0.4650)	CeLoss 0.0020 (0.0177)	SegCLSLoss 0.0003 (0.0015)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0529 (0.0902)	MaskBCELoss 0.0106 (0.0243)	MaskDICELoss 0.0423 (0.0660)
Epoch: [0][407/500]	Time 31.368 (31.368)	Loss 0.1778 (0.3689)	CeLoss 0.0933 (0.0583)	SegCLSLoss 0.0000 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0161 (0.0601)	MaskBCELoss 0.0031 (0.0130)	MaskDICELoss 0.0130 (0.0471)
Epoch: [0][408/500]	Time 42.934 (42.934)	Loss 0.3144 (0.5057)	CeLoss 0.0356 (0.0275)	SegCLSLoss 0.0003 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0575 (0.0918)	MaskBCELoss 0.0167 (0.0188)	MaskDICELoss 0.0408 (0.0730)
Epoch: [0][409/500]	Time 41.301 (41.301)	Loss 0.5205 (0.4250)	CeLoss 0.0571 (0.0097)	SegCLSLoss 0.0017 (0.0013)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0837 (0.0824)	MaskBCELoss 0.0105 (0.0204)	MaskDICELoss 0.0732 (0.0620)
Epoch: [0][410/500]	Time 41.608 (41.608)	Loss 0.4035 (0.4997)	CeLoss 0.0003 (0.0132)	SegCLSLoss 0.0010 (0.0016)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0884 (0.0952)	MaskBCELoss 0.0323 (0.0220)	MaskDICELoss 0.0561 (0.0732)
Epoch: [0][411/500]	Time 39.762 (39.762)	Loss 0.3676 (0.4137)	CeLoss 0.0605 (0.0172)	SegCLSLoss 0.0015 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0642 (0.0799)	MaskBCELoss 0.0203 (0.0213)	MaskDICELoss 0.0439 (0.0586)
Epoch: [0][412/500]	Time 45.132 (45.132)	Loss 0.4219 (0.4509)	CeLoss 0.0630 (0.0338)	SegCLSLoss 0.0002 (0.0012)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0961 (0.0888)	MaskBCELoss 0.0544 (0.0295)	MaskDICELoss 0.0416 (0.0593)
Epoch: [0][413/500]	Time 34.340 (34.340)	Loss 0.0808 (0.4048)	CeLoss 0.0003 (0.0224)	SegCLSLoss 0.0001 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0155 (0.0751)	MaskBCELoss 0.0032 (0.0174)	MaskDICELoss 0.0123 (0.0577)
Epoch: [0][414/500]	Time 40.816 (40.816)	Loss 0.4524 (0.4566)	CeLoss 0.0002 (0.0194)	SegCLSLoss 0.0007 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0888 (0.0888)	MaskBCELoss 0.0205 (0.0245)	MaskDICELoss 0.0683 (0.0644)
Epoch: [0][415/500]	Time 31.899 (31.899)	Loss 0.4034 (0.3368)	CeLoss 0.0381 (0.0098)	SegCLSLoss 0.0000 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0849 (0.0665)	MaskBCELoss 0.0360 (0.0183)	MaskDICELoss 0.0489 (0.0482)
Epoch: [0][416/500]	Time 36.937 (36.937)	Loss 0.2853 (0.4140)	CeLoss 0.0022 (0.0099)	SegCLSLoss 0.0003 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0616 (0.0798)	MaskBCELoss 0.0217 (0.0190)	MaskDICELoss 0.0398 (0.0609)
Epoch: [0][417/500]	Time 45.308 (45.308)	Loss 0.5575 (0.4993)	CeLoss 0.0728 (0.0335)	SegCLSLoss 0.0017 (0.0014)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1067 (0.0998)	MaskBCELoss 0.0398 (0.0339)	MaskDICELoss 0.0670 (0.0659)
Epoch: [0][418/500]	Time 34.664 (34.664)	Loss 0.4307 (0.3937)	CeLoss 0.0002 (0.0378)	SegCLSLoss 0.0002 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0807 (0.0699)	MaskBCELoss 0.0135 (0.0163)	MaskDICELoss 0.0672 (0.0536)
Epoch: [0][419/500]	Time 38.664 (38.664)	Loss 0.3802 (0.4086)	CeLoss 0.0515 (0.0379)	SegCLSLoss 0.0001 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0695 (0.0740)	MaskBCELoss 0.0222 (0.0186)	MaskDICELoss 0.0473 (0.0554)
Epoch: [0][420/500]	Time 37.027 (37.027)	Loss 0.6397 (0.4871)	CeLoss 0.0811 (0.0329)	SegCLSLoss 0.0007 (0.0011)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1048 (0.0891)	MaskBCELoss 0.0180 (0.0207)	MaskDICELoss 0.0868 (0.0685)
Epoch: [0][421/500]	Time 35.963 (35.963)	Loss 0.5229 (0.4147)	CeLoss 0.0310 (0.0165)	SegCLSLoss 0.0014 (0.0012)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0963 (0.0748)	MaskBCELoss 0.0222 (0.0133)	MaskDICELoss 0.0741 (0.0615)
Epoch: [0][422/500]	Time 41.613 (41.613)	Loss 0.5397 (0.4551)	CeLoss 0.0471 (0.0279)	SegCLSLoss 0.0002 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0898 (0.0858)	MaskBCELoss 0.0117 (0.0222)	MaskDICELoss 0.0781 (0.0636)
Epoch: [0][423/500]	Time 32.862 (32.862)	Loss 0.2179 (0.3921)	CeLoss 0.0002 (0.0287)	SegCLSLoss 0.0009 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0404 (0.0727)	MaskBCELoss 0.0067 (0.0186)	MaskDICELoss 0.0338 (0.0542)
Epoch: [0][424/500]	Time 43.468 (43.468)	Loss 0.1733 (0.4941)	CeLoss 0.0967 (0.0141)	SegCLSLoss 0.0000 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0148 (0.0916)	MaskBCELoss 0.0030 (0.0176)	MaskDICELoss 0.0118 (0.0740)
Epoch: [0][425/500]	Time 40.187 (40.187)	Loss 0.6423 (0.4880)	CeLoss 0.0403 (0.0405)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1099 (0.0883)	MaskBCELoss 0.0146 (0.0210)	MaskDICELoss 0.0953 (0.0674)
Epoch: [0][426/500]	Time 41.239 (41.239)	Loss 0.5351 (0.4112)	CeLoss 0.0003 (0.0223)	SegCLSLoss 0.0014 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1069 (0.0792)	MaskBCELoss 0.0274 (0.0219)	MaskDICELoss 0.0795 (0.0573)
Epoch: [0][427/500]	Time 40.052 (40.052)	Loss 0.3821 (0.4351)	CeLoss 0.0449 (0.0240)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0775 (0.0815)	MaskBCELoss 0.0322 (0.0198)	MaskDICELoss 0.0453 (0.0617)
Epoch: [0][428/500]	Time 37.436 (37.436)	Loss 0.2332 (0.3900)	CeLoss 0.0017 (0.0206)	SegCLSLoss 0.0005 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0517 (0.0778)	MaskBCELoss 0.0199 (0.0247)	MaskDICELoss 0.0318 (0.0531)
Epoch: [0][429/500]	Time 42.063 (42.063)	Loss 0.4817 (0.4484)	CeLoss 0.0002 (0.0553)	SegCLSLoss 0.0016 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1042 (0.0767)	MaskBCELoss 0.0367 (0.0170)	MaskDICELoss 0.0675 (0.0596)
Epoch: [0][430/500]	Time 38.163 (38.163)	Loss 0.5846 (0.4372)	CeLoss 0.0532 (0.0196)	SegCLSLoss 0.0009 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1280 (0.0873)	MaskBCELoss 0.0597 (0.0269)	MaskDICELoss 0.0683 (0.0604)
Epoch: [0][431/500]	Time 31.776 (31.776)	Loss 0.2788 (0.3329)	CeLoss 0.0007 (0.0175)	SegCLSLoss 0.0007 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0572 (0.0655)	MaskBCELoss 0.0166 (0.0196)	MaskDICELoss 0.0406 (0.0459)
Epoch: [0][432/500]	Time 42.857 (42.857)	Loss 0.5001 (0.4998)	CeLoss 0.0001 (0.0208)	SegCLSLoss 0.0010 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0956 (0.0959)	MaskBCELoss 0.0189 (0.0244)	MaskDICELoss 0.0767 (0.0715)
Epoch: [0][433/500]	Time 34.032 (34.032)	Loss 0.3981 (0.4235)	CeLoss 0.0003 (0.0314)	SegCLSLoss 0.0002 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0779 (0.0771)	MaskBCELoss 0.0175 (0.0179)	MaskDICELoss 0.0604 (0.0592)
Epoch: [0][434/500]	Time 37.863 (37.863)	Loss 0.3038 (0.3611)	CeLoss 0.0713 (0.0393)	SegCLSLoss 0.0001 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0534 (0.0606)	MaskBCELoss 0.0221 (0.0108)	MaskDICELoss 0.0313 (0.0498)
Epoch: [0][435/500]	Time 44.962 (44.962)	Loss 0.4503 (0.4493)	CeLoss 0.0003 (0.0292)	SegCLSLoss 0.0004 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0898 (0.0816)	MaskBCELoss 0.0223 (0.0176)	MaskDICELoss 0.0674 (0.0640)
Epoch: [0][436/500]	Time 33.314 (33.314)	Loss 0.4501 (0.3758)	CeLoss 0.0791 (0.0205)	SegCLSLoss 0.0001 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0648 (0.0695)	MaskBCELoss 0.0045 (0.0156)	MaskDICELoss 0.0604 (0.0539)
Epoch: [0][437/500]	Time 47.596 (47.596)	Loss 0.4561 (0.4571)	CeLoss 0.0007 (0.0242)	SegCLSLoss 0.0005 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0829 (0.0830)	MaskBCELoss 0.0107 (0.0166)	MaskDICELoss 0.0722 (0.0664)
Epoch: [0][438/500]	Time 35.530 (35.530)	Loss 0.2705 (0.4100)	CeLoss 0.0010 (0.0178)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0594 (0.0789)	MaskBCELoss 0.0219 (0.0207)	MaskDICELoss 0.0375 (0.0582)
Epoch: [0][439/500]	Time 40.063 (40.063)	Loss 0.2406 (0.4670)	CeLoss 0.0009 (0.0112)	SegCLSLoss 0.0002 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0556 (0.0920)	MaskBCELoss 0.0236 (0.0244)	MaskDICELoss 0.0320 (0.0676)
Epoch: [0][440/500]	Time 38.618 (38.618)	Loss 0.5507 (0.4352)	CeLoss 0.0635 (0.0234)	SegCLSLoss 0.0005 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0833 (0.0801)	MaskBCELoss 0.0034 (0.0174)	MaskDICELoss 0.0799 (0.0627)
Epoch: [0][441/500]	Time 35.350 (35.350)	Loss 0.5086 (0.4043)	CeLoss 0.0001 (0.0151)	SegCLSLoss 0.0006 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1014 (0.0812)	MaskBCELoss 0.0253 (0.0249)	MaskDICELoss 0.0761 (0.0563)
Epoch: [0][442/500]	Time 35.668 (35.668)	Loss 0.4166 (0.3711)	CeLoss 0.0001 (0.0187)	SegCLSLoss 0.0006 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0775 (0.0760)	MaskBCELoss 0.0124 (0.0263)	MaskDICELoss 0.0651 (0.0497)
Epoch: [0][443/500]	Time 35.550 (35.550)	Loss 0.6526 (0.4019)	CeLoss 0.0635 (0.0309)	SegCLSLoss 0.0009 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1170 (0.0755)	MaskBCELoss 0.0287 (0.0207)	MaskDICELoss 0.0882 (0.0548)
Epoch: [0][444/500]	Time 39.839 (39.839)	Loss 0.2421 (0.3926)	CeLoss 0.0003 (0.0231)	SegCLSLoss 0.0011 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0559 (0.0730)	MaskBCELoss 0.0239 (0.0175)	MaskDICELoss 0.0320 (0.0555)
Epoch: [0][445/500]	Time 42.481 (42.481)	Loss 0.5041 (0.4552)	CeLoss 0.0547 (0.0268)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0971 (0.0846)	MaskBCELoss 0.0341 (0.0202)	MaskDICELoss 0.0630 (0.0644)
Epoch: [0][446/500]	Time 33.868 (33.868)	Loss 0.9309 (0.4641)	CeLoss 0.0439 (0.0167)	SegCLSLoss 0.0004 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.2985 (0.1021)	MaskBCELoss 0.2263 (0.0417)	MaskDICELoss 0.0722 (0.0604)
Epoch: [0][447/500]	Time 37.407 (37.407)	Loss 0.4497 (0.3721)	CeLoss 0.0503 (0.0269)	SegCLSLoss 0.0003 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0804 (0.0712)	MaskBCELoss 0.0208 (0.0209)	MaskDICELoss 0.0596 (0.0503)
Epoch: [0][448/500]	Time 37.934 (37.934)	Loss 0.4852 (0.4312)	CeLoss 0.0002 (0.0251)	SegCLSLoss 0.0016 (0.0008)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0951 (0.0836)	MaskBCELoss 0.0223 (0.0243)	MaskDICELoss 0.0728 (0.0593)
Epoch: [0][449/500]	Time 36.599 (36.599)	Loss 0.3397 (0.3625)	CeLoss 0.0952 (0.0144)	SegCLSLoss 0.0005 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0580 (0.0729)	MaskBCELoss 0.0262 (0.0226)	MaskDICELoss 0.0318 (0.0503)
Epoch: [0][450/500]	Time 35.300 (35.300)	Loss 0.3420 (0.3893)	CeLoss 0.0001 (0.0311)	SegCLSLoss 0.0005 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0757 (0.0687)	MaskBCELoss 0.0283 (0.0137)	MaskDICELoss 0.0474 (0.0550)
Epoch: [0][451/500]	Time 41.897 (41.897)	Loss 0.4232 (0.4035)	CeLoss 0.0591 (0.0324)	SegCLSLoss 0.0001 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0745 (0.0734)	MaskBCELoss 0.0207 (0.0177)	MaskDICELoss 0.0538 (0.0558)
Epoch: [0][452/500]	Time 37.841 (37.841)	Loss 0.2462 (0.4361)	CeLoss 0.0010 (0.0351)	SegCLSLoss 0.0003 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0483 (0.0781)	MaskBCELoss 0.0113 (0.0171)	MaskDICELoss 0.0370 (0.0610)
Epoch: [0][453/500]	Time 34.007 (34.007)	Loss 0.4387 (0.3545)	CeLoss 0.0003 (0.0177)	SegCLSLoss 0.0002 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0893 (0.0683)	MaskBCELoss 0.0245 (0.0184)	MaskDICELoss 0.0649 (0.0499)
Epoch: [0][454/500]	Time 44.631 (44.631)	Loss 0.5241 (0.4607)	CeLoss 0.0254 (0.0136)	SegCLSLoss 0.0003 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0945 (0.0898)	MaskBCELoss 0.0172 (0.0233)	MaskDICELoss 0.0773 (0.0665)
Epoch: [0][455/500]	Time 33.770 (33.770)	Loss 0.5608 (0.3456)	CeLoss 0.0002 (0.0305)	SegCLSLoss 0.0003 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1047 (0.0648)	MaskBCELoss 0.0171 (0.0187)	MaskDICELoss 0.0876 (0.0461)
Epoch: [0][456/500]	Time 41.441 (41.441)	Loss 0.3376 (0.3753)	CeLoss 0.0012 (0.0247)	SegCLSLoss 0.0013 (0.0010)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0783 (0.0715)	MaskBCELoss 0.0341 (0.0201)	MaskDICELoss 0.0443 (0.0514)
Epoch: [0][457/500]	Time 38.961 (38.961)	Loss 0.2569 (0.4827)	CeLoss 0.0010 (0.0453)	SegCLSLoss 0.0014 (0.0009)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0520 (0.0888)	MaskBCELoss 0.0148 (0.0243)	MaskDICELoss 0.0372 (0.0645)
Epoch: [0][458/500]	Time 41.444 (41.444)	Loss 0.3784 (0.4273)	CeLoss 0.0447 (0.0260)	SegCLSLoss 0.0002 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0677 (0.0814)	MaskBCELoss 0.0182 (0.0221)	MaskDICELoss 0.0495 (0.0593)
Epoch: [0][459/500]	Time 40.887 (40.887)	Loss 0.4401 (0.4366)	CeLoss 0.0574 (0.0232)	SegCLSLoss 0.0024 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0741 (0.0786)	MaskBCELoss 0.0166 (0.0150)	MaskDICELoss 0.0575 (0.0637)
Epoch: [0][460/500]	Time 38.114 (38.114)	Loss 0.3623 (0.4242)	CeLoss 0.0437 (0.0251)	SegCLSLoss 0.0019 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0769 (0.0805)	MaskBCELoss 0.0366 (0.0213)	MaskDICELoss 0.0403 (0.0592)
Epoch: [0][461/500]	Time 39.920 (39.920)	Loss 0.2999 (0.4271)	CeLoss 0.0752 (0.0391)	SegCLSLoss 0.0003 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0469 (0.0786)	MaskBCELoss 0.0144 (0.0211)	MaskDICELoss 0.0325 (0.0575)
Epoch: [0][462/500]	Time 35.392 (35.392)	Loss 0.3110 (0.4187)	CeLoss 0.0003 (0.0257)	SegCLSLoss 0.0002 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0564 (0.0800)	MaskBCELoss 0.0070 (0.0218)	MaskDICELoss 0.0494 (0.0582)
Epoch: [0][463/500]	Time 37.238 (37.238)	Loss 0.3635 (0.4152)	CeLoss 0.0474 (0.0207)	SegCLSLoss 0.0002 (0.0007)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0638 (0.0760)	MaskBCELoss 0.0168 (0.0158)	MaskDICELoss 0.0470 (0.0603)
Epoch: [0][464/500]	Time 41.056 (41.056)	Loss 0.5113 (0.4393)	CeLoss 0.0002 (0.0188)	SegCLSLoss 0.0006 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1091 (0.0839)	MaskBCELoss 0.0361 (0.0208)	MaskDICELoss 0.0730 (0.0630)
Epoch: [0][465/500]	Time 38.425 (38.425)	Loss 0.3049 (0.4039)	CeLoss 0.0006 (0.0193)	SegCLSLoss 0.0008 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0653 (0.0778)	MaskBCELoss 0.0223 (0.0209)	MaskDICELoss 0.0430 (0.0570)
Epoch: [0][466/500]	Time 41.045 (41.045)	Loss 0.4405 (0.4219)	CeLoss 0.0337 (0.0257)	SegCLSLoss 0.0014 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0723 (0.0803)	MaskBCELoss 0.0074 (0.0216)	MaskDICELoss 0.0649 (0.0587)
Epoch: [0][467/500]	Time 37.364 (37.364)	Loss 0.3539 (0.3943)	CeLoss 0.0391 (0.0259)	SegCLSLoss 0.0001 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0761 (0.0753)	MaskBCELoss 0.0355 (0.0210)	MaskDICELoss 0.0406 (0.0543)
Epoch: [0][468/500]	Time 35.324 (35.324)	Loss 0.3833 (0.4146)	CeLoss 0.0009 (0.0362)	SegCLSLoss 0.0001 (0.0001)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0810 (0.0746)	MaskBCELoss 0.0259 (0.0173)	MaskDICELoss 0.0550 (0.0573)
Epoch: [0][469/500]	Time 40.205 (40.205)	Loss 0.3511 (0.3545)	CeLoss 0.0001 (0.0228)	SegCLSLoss 0.0003 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0696 (0.0639)	MaskBCELoss 0.0168 (0.0130)	MaskDICELoss 0.0528 (0.0509)
Epoch: [0][470/500]	Time 44.360 (44.360)	Loss 0.5226 (0.4443)	CeLoss 0.0535 (0.0239)	SegCLSLoss 0.0002 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1172 (0.0864)	MaskBCELoss 0.0587 (0.0248)	MaskDICELoss 0.0586 (0.0616)
Epoch: [0][471/500]	Time 41.130 (41.130)	Loss 0.2948 (0.4211)	CeLoss 0.0413 (0.0302)	SegCLSLoss 0.0003 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0544 (0.0769)	MaskBCELoss 0.0183 (0.0177)	MaskDICELoss 0.0361 (0.0591)
Epoch: [0][472/500]	Time 37.657 (37.657)	Loss 0.3481 (0.3990)	CeLoss 0.0019 (0.0124)	SegCLSLoss 0.0004 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0697 (0.0760)	MaskBCELoss 0.0182 (0.0176)	MaskDICELoss 0.0515 (0.0584)
Epoch: [0][473/500]	Time 42.693 (42.693)	Loss 0.4440 (0.4470)	CeLoss 0.0002 (0.0205)	SegCLSLoss 0.0007 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0881 (0.0859)	MaskBCELoss 0.0216 (0.0224)	MaskDICELoss 0.0665 (0.0635)
Epoch: [0][474/500]	Time 39.221 (39.221)	Loss 0.1579 (0.4016)	CeLoss 0.0991 (0.0222)	SegCLSLoss 0.0000 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0110 (0.0754)	MaskBCELoss 0.0018 (0.0184)	MaskDICELoss 0.0092 (0.0570)
Epoch: [0][475/500]	Time 38.526 (38.526)	Loss 0.3150 (0.4089)	CeLoss 0.0002 (0.0246)	SegCLSLoss 0.0000 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0589 (0.0752)	MaskBCELoss 0.0096 (0.0168)	MaskDICELoss 0.0493 (0.0583)
Epoch: [0][476/500]	Time 40.946 (40.946)	Loss 0.4274 (0.4336)	CeLoss 0.0454 (0.0292)	SegCLSLoss 0.0000 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0750 (0.0762)	MaskBCELoss 0.0170 (0.0133)	MaskDICELoss 0.0580 (0.0629)
Epoch: [0][477/500]	Time 41.217 (41.217)	Loss 0.1838 (0.3851)	CeLoss 0.0047 (0.0237)	SegCLSLoss 0.0018 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0445 (0.0740)	MaskBCELoss 0.0229 (0.0210)	MaskDICELoss 0.0216 (0.0530)
Epoch: [0][478/500]	Time 38.511 (38.511)	Loss 0.3750 (0.4129)	CeLoss 0.0889 (0.0360)	SegCLSLoss 0.0000 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0485 (0.0743)	MaskBCELoss 0.0012 (0.0175)	MaskDICELoss 0.0473 (0.0568)
Epoch: [0][479/500]	Time 33.482 (33.482)	Loss 0.3630 (0.3596)	CeLoss 0.0918 (0.0460)	SegCLSLoss 0.0001 (0.0001)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0567 (0.0646)	MaskBCELoss 0.0173 (0.0186)	MaskDICELoss 0.0394 (0.0460)
Epoch: [0][480/500]	Time 37.280 (37.280)	Loss 0.4767 (0.3857)	CeLoss 0.0005 (0.0249)	SegCLSLoss 0.0008 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0895 (0.0693)	MaskBCELoss 0.0156 (0.0140)	MaskDICELoss 0.0739 (0.0554)
Epoch: [0][481/500]	Time 53.924 (53.924)	Loss 0.3012 (0.4554)	CeLoss 0.0003 (0.0281)	SegCLSLoss 0.0000 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0597 (0.0864)	MaskBCELoss 0.0144 (0.0229)	MaskDICELoss 0.0454 (0.0635)
Epoch: [0][482/500]	Time 34.189 (34.189)	Loss 0.4690 (0.3509)	CeLoss 0.0354 (0.0277)	SegCLSLoss 0.0003 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0744 (0.0659)	MaskBCELoss 0.0034 (0.0181)	MaskDICELoss 0.0710 (0.0478)
Epoch: [0][483/500]	Time 37.820 (37.820)	Loss 0.5171 (0.4033)	CeLoss 0.0850 (0.0548)	SegCLSLoss 0.0007 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0845 (0.0688)	MaskBCELoss 0.0191 (0.0163)	MaskDICELoss 0.0654 (0.0525)
Epoch: [0][484/500]	Time 38.452 (38.452)	Loss 0.3622 (0.4618)	CeLoss 0.0005 (0.0372)	SegCLSLoss 0.0001 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0765 (0.0817)	MaskBCELoss 0.0244 (0.0165)	MaskDICELoss 0.0521 (0.0652)
Epoch: [0][485/500]	Time 46.897 (46.897)	Loss 0.4963 (0.4328)	CeLoss 0.0016 (0.0311)	SegCLSLoss 0.0001 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0961 (0.0794)	MaskBCELoss 0.0205 (0.0188)	MaskDICELoss 0.0756 (0.0606)
Epoch: [0][486/500]	Time 34.194 (34.194)	Loss 0.2370 (0.3098)	CeLoss 0.0002 (0.0093)	SegCLSLoss 0.0000 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0488 (0.0606)	MaskBCELoss 0.0140 (0.0158)	MaskDICELoss 0.0348 (0.0447)
Epoch: [0][487/500]	Time 38.406 (38.406)	Loss 0.4493 (0.4193)	CeLoss 0.0002 (0.0210)	SegCLSLoss 0.0001 (0.0001)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0800 (0.0783)	MaskBCELoss 0.0078 (0.0179)	MaskDICELoss 0.0722 (0.0604)
Epoch: [0][488/500]	Time 37.676 (37.676)	Loss 0.3525 (0.3671)	CeLoss 0.0003 (0.0149)	SegCLSLoss 0.0001 (0.0001)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0709 (0.0697)	MaskBCELoss 0.0184 (0.0166)	MaskDICELoss 0.0525 (0.0531)
Epoch: [0][489/500]	Time 42.720 (42.720)	Loss 0.5668 (0.4743)	CeLoss 0.0005 (0.0130)	SegCLSLoss 0.0001 (0.0005)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1051 (0.0874)	MaskBCELoss 0.0161 (0.0160)	MaskDICELoss 0.0890 (0.0714)
Epoch: [0][490/500]	Time 37.917 (37.917)	Loss 0.3264 (0.3621)	CeLoss 0.0014 (0.0165)	SegCLSLoss 0.0010 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0628 (0.0671)	MaskBCELoss 0.0134 (0.0143)	MaskDICELoss 0.0494 (0.0528)
Epoch: [0][491/500]	Time 47.748 (47.748)	Loss 0.4345 (0.4438)	CeLoss 0.0376 (0.0226)	SegCLSLoss 0.0002 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0767 (0.0826)	MaskBCELoss 0.0160 (0.0187)	MaskDICELoss 0.0608 (0.0639)
Epoch: [0][492/500]	Time 35.216 (35.216)	Loss 0.3617 (0.4096)	CeLoss 0.0023 (0.0116)	SegCLSLoss 0.0000 (0.0003)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0745 (0.0777)	MaskBCELoss 0.0219 (0.0172)	MaskDICELoss 0.0526 (0.0605)
Epoch: [0][493/500]	Time 37.673 (37.673)	Loss 0.5350 (0.3912)	CeLoss 0.0864 (0.0285)	SegCLSLoss 0.0000 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0798 (0.0693)	MaskBCELoss 0.0075 (0.0133)	MaskDICELoss 0.0723 (0.0559)
Epoch: [0][494/500]	Time 38.568 (38.568)	Loss 0.4361 (0.3711)	CeLoss 0.0723 (0.0216)	SegCLSLoss 0.0001 (0.0001)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0673 (0.0662)	MaskBCELoss 0.0099 (0.0120)	MaskDICELoss 0.0573 (0.0542)
Epoch: [0][495/500]	Time 37.079 (37.079)	Loss 0.3733 (0.3861)	CeLoss 0.0003 (0.0188)	SegCLSLoss 0.0000 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0705 (0.0688)	MaskBCELoss 0.0125 (0.0114)	MaskDICELoss 0.0580 (0.0573)
Epoch: [0][496/500]	Time 38.812 (38.812)	Loss 0.3697 (0.4215)	CeLoss 0.0001 (0.0125)	SegCLSLoss 0.0002 (0.0004)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0655 (0.0768)	MaskBCELoss 0.0059 (0.0132)	MaskDICELoss 0.0596 (0.0636)
Epoch: [0][497/500]	Time 43.863 (43.863)	Loss 0.5091 (0.4468)	CeLoss 0.0014 (0.0198)	SegCLSLoss 0.0003 (0.0001)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0993 (0.0843)	MaskBCELoss 0.0221 (0.0197)	MaskDICELoss 0.0771 (0.0645)
Epoch: [0][498/500]	Time 42.351 (42.351)	Loss 0.2123 (0.4269)	CeLoss 0.0554 (0.0405)	SegCLSLoss 0.0002 (0.0006)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0337 (0.0736)	MaskBCELoss 0.0115 (0.0141)	MaskDICELoss 0.0222 (0.0595)
Epoch: [0][499/500]	Time 41.917 (41.917)	Loss 0.4269 (0.3862)	CeLoss 0.0001 (0.0329)	SegCLSLoss 0.0002 (0.0002)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0849 (0.0708)	MaskBCELoss 0.0207 (0.0180)	MaskDICELoss 0.0642 (0.0528)
  0%|                                                                                                                      | 0/200 [00:00<?, ?it/s]
[2025-04-17 04:10:12,753] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.00029461445783132527], mom=[(0.9, 0.95)]
[2025-04-17 04:10:12,769] [INFO] [timer.py:215:stop] epoch=0/micro_step=500/global_step=50, RunningAvgSamplesPerSec=1.0285484256731225, CurrSamplesPerSec=0.9451753736608676, MemAllocated=35.74GB, MaxMemAllocated=46.26GB






























100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:01<00:00,  3.25it/s]
