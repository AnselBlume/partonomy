You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")


Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:32<00:00, 50.73s/it]
Some weights of PLUMForCausalLM were not initialized from the model checkpoint at liuhaotian/llava-llama-2-13b-chat-lightning-preview and are newly initialized: ['bio_encoder.encoder.layers.0.linear1.weight', 'bio_encoder.encoder.layers.0.linear2.weight', 'bio_encoder.encoder.layers.0.linear2.bias', 'bio_encoder.encoder.layers.0.norm2.bias', 'bio_encoder.encoder.layers.0.self_attn.in_proj_bias', 'bio_encoder.encoder.layers.0.norm2.weight', 'bio_encoder.encoder.layers.0.norm1.bias', 'bio_encoder.encoder.layers.0.self_attn.out_proj.weight', 'bio_encoder.encoder.layers.0.linear1.bias', 'bio_encoder.encoder.layers.0.self_attn.out_proj.bias', 'bio_encoder.encoder.layers.0.norm1.weight', 'bio_encoder.encoder.layers.0.self_attn.in_proj_weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
trainable params: 6,553,600 || all params: 14,151,578,931 || trainable%: 0.0463100268313092
>> model.config.train_mask_prompt_encoder:  True
n:  base_model.model.model.embed_tokens.weight p.shape:  torch.Size([32002, 5120])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.0.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.1.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.2.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.point_embeddings.3.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.not_a_point_embed.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.0.weight p.shape:  torch.Size([4, 1, 2, 2])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.0.bias p.shape:  torch.Size([4])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.1.weight p.shape:  torch.Size([4])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.1.bias p.shape:  torch.Size([4])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.3.weight p.shape:  torch.Size([16, 4, 2, 2])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.3.bias p.shape:  torch.Size([16])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.4.weight p.shape:  torch.Size([16])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.4.bias p.shape:  torch.Size([16])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.6.weight p.shape:  torch.Size([256, 16, 1, 1])
n:  base_model.model.model.visual_model.prompt_encoder.mask_downscaling.6.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.prompt_encoder.no_mask_embed.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.q_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.q_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.k_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.k_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.v_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.v_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.out_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.self_attn.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm1.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm2.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin1.weight p.shape:  torch.Size([2048, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin1.bias p.shape:  torch.Size([2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin2.weight p.shape:  torch.Size([256, 2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.mlp.lin2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm3.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm3.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm4.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.norm4.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.q_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.q_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.k_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.k_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.v_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.v_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.out_proj.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.self_attn.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm1.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm2.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin1.weight p.shape:  torch.Size([2048, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin1.bias p.shape:  torch.Size([2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin2.weight p.shape:  torch.Size([256, 2048])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.mlp.lin2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm3.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm3.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm4.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.norm4.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.q_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.q_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.k_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.k_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.v_proj.weight p.shape:  torch.Size([128, 256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.v_proj.bias p.shape:  torch.Size([128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.out_proj.weight p.shape:  torch.Size([256, 128])
n:  base_model.model.model.visual_model.mask_decoder.transformer.final_attn_token_to_image.out_proj.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.norm_final_attn.weight p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.transformer.norm_final_attn.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_token.weight p.shape:  torch.Size([1, 256])
n:  base_model.model.model.visual_model.mask_decoder.mask_tokens.weight p.shape:  torch.Size([4, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.0.weight p.shape:  torch.Size([256, 64, 2, 2])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.0.bias p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.1.weight p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.1.bias p.shape:  torch.Size([64])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.3.weight p.shape:  torch.Size([64, 32, 2, 2])
n:  base_model.model.model.visual_model.mask_decoder.output_upscaling.3.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.0.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.1.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.2.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.2.weight p.shape:  torch.Size([32, 256])
n:  base_model.model.model.visual_model.mask_decoder.output_hypernetworks_mlps.3.layers.2.bias p.shape:  torch.Size([32])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.0.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.0.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.1.weight p.shape:  torch.Size([256, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.1.bias p.shape:  torch.Size([256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.2.weight p.shape:  torch.Size([4, 256])
n:  base_model.model.model.visual_model.mask_decoder.iou_prediction_head.layers.2.bias p.shape:  torch.Size([4])
n:  base_model.model.model.text_hidden_fcs.0.0.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.model.text_hidden_fcs.0.0.bias p.shape:  torch.Size([5120])
n:  base_model.model.model.text_hidden_fcs.0.2.weight p.shape:  torch.Size([256, 5120])
n:  base_model.model.model.text_hidden_fcs.0.2.bias p.shape:  torch.Size([256])
n:  base_model.model.model.token_to_mask_fcs.0.0.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.model.token_to_mask_fcs.0.0.bias p.shape:  torch.Size([5120])
n:  base_model.model.model.token_to_mask_fcs.0.2.weight p.shape:  torch.Size([3, 5120])
n:  base_model.model.model.token_to_mask_fcs.0.2.bias p.shape:  torch.Size([3])
n:  base_model.model.lm_head.weight p.shape:  torch.Size([32002, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.in_proj_weight p.shape:  torch.Size([15360, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.in_proj_bias p.shape:  torch.Size([15360])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.out_proj.weight p.shape:  torch.Size([5120, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.self_attn.out_proj.bias p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.linear1.weight p.shape:  torch.Size([2048, 5120])
n:  base_model.model.bio_encoder.encoder.layers.0.linear1.bias p.shape:  torch.Size([2048])
n:  base_model.model.bio_encoder.encoder.layers.0.linear2.weight p.shape:  torch.Size([5120, 2048])
n:  base_model.model.bio_encoder.encoder.layers.0.linear2.bias p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm1.weight p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm1.bias p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm2.weight p.shape:  torch.Size([5120])
n:  base_model.model.bio_encoder.encoder.layers.0.norm2.bias p.shape:  torch.Size([5120])
>> (plum_train_ds) loading ExplanatorySegDataset...
>> (plum_train_ds) question_types:  QuestionType.POSITIVE
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.POSITIVE_WITH_LABEL
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.NEGATIVE
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.NEGATIVE_WITH_LABEL
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.DIFFERENCE
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
>> (plum_train_ds) question_types:  QuestionType.DIFFERENCE_WITH_LABEL
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partonomy/partonomy_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/pascal_part/pascal_part_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/partimagenet/partimagenet_qa_pairs.json
(explanatory_seg_dataset.py) >>> Loading dataset from: /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json /shared/nas2/blume5/sp25/partonomy/partonomy_private/data/partonomy_descriptors/paco_lvis/paco_lvis_qa_pairs.json
ade20k:  20210
cocostuff:  118287
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
pascal_part:  4366
loading annotations into memory...
Done (t=10.73s)
creating index...
index created!
paco_lvis:  45790
mapillary:  18000
loading dataset refclef into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refclef/refs(unc).p
creating index...
index created.
DONE (t=7.93s)
dataset refclef (refs unc) (train split) has 17978 images and 99523 annotations.
loading dataset refcoco into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcoco/refs(unc).p
creating index...
index created.
DONE (t=3.83s)
dataset refcoco (refs unc) (train split) has 16994 images and 196771 annotations.
loading dataset refcoco+ into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcoco+/refs(unc).p
creating index...
index created.
DONE (t=4.02s)
dataset refcoco+ (refs unc) (train split) has 16992 images and 196737 annotations.
loading dataset refcocog into memory...
ref_file:  /shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset/refer_seg/refcocog/refs(umd).p
creating index...
index created.
DONE (t=12.04s)
dataset refcocog (refs umd) (train split) has 21899 images and 208960 annotations.
vqa_data:  157712
number of reason_seg samples:  239
len(self.img_to_explanation):  239
Training with 40000 examples and validating with 200 examples.
[2025-04-16 20:21:55,325] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5, git-hash=unknown, git-branch=unknown
[2025-04-16 20:21:55,325] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-04-16 20:21:55,325] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-04-16 20:21:55,325] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-04-16 20:22:27,168] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /shared/nas/data/m1/jk100/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /shared/nas/data/m1/jk100/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Time to load fused_adam op: 26.811658143997192 seconds
[2025-04-16 20:22:54,341] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
Loading extension module fused_adam...
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/tensor/python_tensor.cpp:78.)
  self._dummy_overflow_buf = get_accelerator().IntTensor([0])
[2025-04-16 20:22:54,536] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-04-16 20:22:54,536] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2025-04-16 20:22:54,536] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-04-16 20:22:54,537] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500000000
[2025-04-16 20:22:54,537] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[2025-04-16 20:22:54,537] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2025-04-16 20:22:54,537] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Rank: 0 partition count [1] and sizes[(517961268, False)]
[2025-04-16 20:23:05,638] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2025-04-16 20:23:05,639] [INFO] [utils.py:786:see_memory_usage] MA 28.49 GB         Max_MA 29.45 GB         CA 29.59 GB         Max_CA 30 GB
[2025-04-16 20:23:05,639] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 287.8 GB, percent = 28.6%
[2025-04-16 20:23:13,570] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2025-04-16 20:23:13,572] [INFO] [utils.py:786:see_memory_usage] MA 32.35 GB         Max_MA 34.28 GB         CA 35.38 GB         Max_CA 35 GB
[2025-04-16 20:23:13,572] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 288.11 GB, percent = 28.6%
[2025-04-16 20:23:13,572] [INFO] [stage_1_and_2.py:488:__init__] optimizer state initialized
[2025-04-16 20:23:21,483] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2025-04-16 20:23:21,483] [INFO] [utils.py:786:see_memory_usage] MA 32.35 GB         Max_MA 32.35 GB         CA 35.38 GB         Max_CA 35 GB
[2025-04-16 20:23:21,484] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 288.5 GB, percent = 28.6%
[2025-04-16 20:23:21,490] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-04-16 20:23:21,490] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR
[2025-04-16 20:23:21,491] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x7f117c4db550>
[2025-04-16 20:23:21,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[(0.9, 0.95)]
[2025-04-16 20:23:21,494] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2025-04-16 20:23:21,494] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2025-04-16 20:23:21,494] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-04-16 20:23:21,494] [INFO] [config.py:964:print]   amp_enabled .................. False
[2025-04-16 20:23:21,494] [INFO] [config.py:964:print]   amp_params ................... False
[2025-04-16 20:23:21,494] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   bfloat16_enabled ............. True
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f117c4db2e0>
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   communication_data_type ...... None
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   disable_allgather ............ False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   dump_state ................... False
[2025-04-16 20:23:21,495] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   fp16_auto_cast ............... None
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   fp16_enabled ................. False
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   global_rank .................. 0
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 10
[2025-04-16 20:23:21,496] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 1
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   loss_scale ................... 1.0
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   optimizer_name ............... adamw
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   optimizer_params ............. {'lr': 0.0003, 'weight_decay': 0.0, 'betas': (0.9, 0.95)}
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2025-04-16 20:23:21,497] [INFO] [config.py:964:print]   pld_enabled .................. False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   pld_params ................... False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   scheduler_name ............... WarmupDecayLR
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   scheduler_params ............. {'total_num_steps': 25000, 'warmup_min_lr': 0, 'warmup_max_lr': 0.0003, 'warmup_num_steps': 100, 'warmup_type': 'linear'}
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   sparse_attention ............. None
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   train_batch_size ............. 80
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  8
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   world_size ................... 1
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   zero_enabled ................. True
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-16 20:23:21,498] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[2025-04-16 20:23:21,499] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 8,
    "gradient_accumulation_steps": 10,
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 0.0003,
            "weight_decay": 0.0,
            "betas": [0.9, 0.95]
        }
    },
    "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "total_num_steps": 2.500000e+04,
            "warmup_min_lr": 0,
            "warmup_max_lr": 0.0003,
            "warmup_num_steps": 100,
            "warmup_type": "linear"
        }
    },
    "fp16": {
        "enabled": false
    },
    "bf16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "zero_optimization": {
        "stage": 2,
        "contiguous_gradients": true,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 5.000000e+08,
        "allgather_bucket_size": 5.000000e+08
    }
}
(train) >> AFTER DEEPSPEED
>> (train) Auto-resume from:  ./runs/plum-13b_kld_0.1_focal_tversky_6_v1_partonomy/plum-13b_kld_0.1_focal_tversky_6_v1_partonomy_bidirbio_2048_accum_10_maxlen512_epochs50_segloss_2_bce_loss_2_kld_loss_0_focal_tversky_loss_6_bidir_bio_exp_seg_train_prompt_enc_ckpt_model
>> (train) resume exists:  False
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)
  return F.conv2d(input, weight, bias, self.stride,
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a CuDNNError: cuDNN error: CUDNN_STATUS_BAD_PARAM
Exception raised from run_conv_plan at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:374 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f1e80d78897 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe1640b (0x7f1e201fb40b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x108f133 (0x7f1e20474133 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x1091043 (0x7f1e20476043 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x109176b (0x7f1e2047676b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x1075c7d (0x7f1e2045ac7d in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x107656a (0x7f1e2045b56a in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #7: at::native::cudnn_convolution_transpose(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool) + 0xa4 (0x7f1e2045b714 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #8: <unknown function> + 0x32f2cc2 (0x7f1e226d7cc2 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0x32ff147 (0x7f1e226e4147 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #10: at::_ops::cudnn_convolution_transpose::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool) + 0x2fb (0x7f1e7503c2fb in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool) + 0x166d (0x7f1e7476348d in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #12: <unknown function> + 0x2a8d27f (0x7f1e758f127f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #13: <unknown function> + 0x2a93bdc (0x7f1e758f7bdc in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool) + 0x344 (0x7f1e7503a0d4 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long) + 0x3b8 (0x7f1e74756868 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x2a8cb1c (0x7f1e758f0b1c in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2a93a48 (0x7f1e758f7a48 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt) + 0x17b (0x7f1e74ff7d6b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x41902e1 (0x7f1e76ff42e1 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0x4191259 (0x7f1e76ff5259 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #21: at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt) + 0x2d4 (0x7f1e75038ed4 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x164a2e0 (0x7f1e744ae2e0 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::native::conv_transpose2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>) + 0x125 (0x7f1e7475bb05 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2c879c9 (0x7f1e75aeb9c9 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x2c87b03 (0x7f1e75aebb03 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_ops::conv_transpose2d_input::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>) + 0x2cb (0x7f1e7539509b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #27: <unknown function> + 0x61476f (0x7f1e7fe1c76f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #28: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x4fc697]
frame #29: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x53d6 (0x4f2376 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #31: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #32: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #33: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #34: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #35: _PyObject_FastCallDictTstate + 0xcd (0x4f561d in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #36: _PyObject_Call_Prepend + 0x66 (0x506596 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #37: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x5cc323]
frame #38: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #39: _PyEval_EvalFrameDefault + 0x4dde (0x4f1d7e in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #40: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #41: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #42: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x508006]
frame #43: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #44: _PyObject_FastCallDictTstate + 0xcd (0x4f561d in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #45: _PyObject_Call_Prepend + 0x66 (0x506596 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #46: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x5cc323]
frame #47: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #48: _PyEval_EvalFrameDefault + 0x53d6 (0x4f2376 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #49: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
frame #50: _PyEval_EvalFrameDefault + 0x13b3 (0x4ee353 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #51: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
frame #52: PyObject_Call + 0xb8 (0x508858 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #54: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
frame #55: PyObject_Call + 0xb8 (0x508858 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #56: _PyEval_EvalFrameDefault + 0x2b79 (0x4efb19 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #57: _PyFunction_Vectorcall + 0x6f (0x4fcadf in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #58: _PyObject_FastCallDictTstate + 0x17d (0x4f56cd in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #59: _PyObject_Call_Prepend + 0x66 (0x506596 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #60: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x5cc323]
frame #61: _PyObject_MakeTpCall + 0x25b (0x4f614b in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #62: _PyEval_EvalFrameDefault + 0x5757 (0x4f26f7 in /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python)
frame #63: /shared/nas/data/m1/jk100/.conda/envs/llava/bin/python() [0x507eae]
 (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:921.)
  return F.conv_transpose2d(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv_transpose2d(
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a CuDNNError: cuDNN error: CUDNN_STATUS_BAD_PARAM
Exception raised from run_conv_plan at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:374 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f1e80d78897 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe1640b (0x7f1e201fb40b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x108f133 (0x7f1e20474133 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x1091043 (0x7f1e20476043 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x10915bb (0x7f1e204765bb in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x1074062 (0x7f1e20459062 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x107527f (0x7f1e2045a27f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x1078184 (0x7f1e2045d184 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>) + 0x1872 (0x7f1e747661e2 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #9: <unknown function> + 0x32f8375 (0x7f1e226dd375 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0x3300422 (0x7f1e226e5422 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>) + 0x26b (0x7f1e7563510b in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #12: <unknown function> + 0x45578f3 (0x7f1e773bb8f3 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #13: <unknown function> + 0x45594a3 (0x7f1e773bd4a3 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>) + 0x3a3 (0x7f1e7565b7c3 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x164a4b1 (0x7f1e744ae4b1 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x300 (0x7f1e76ecd290 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x4dcc3ab (0x7f1e77c303ab in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1526 (0x7f1e77c2a4a6 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x698 (0x7f1e77c2b108 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x13f (0x7f1e77c2203f in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x5c (0x7f1e80030e1c in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xdbbf4 (0x7f1e943a2bf4 in /shared/nas/data/m1/jk100/.conda/envs/llava/lib/python3.10/site-packages/../../libstdc++.so.6)
frame #23: <unknown function> + 0x94ac3 (0x7f1e9590bac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #24: <unknown function> + 0x126850 (0x7f1e9599d850 in /lib/x86_64-linux-gnu/libc.so.6)
 (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:921.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch: [0][  1/500]	Time 60.067 (60.067)	Loss 1.0526 (1.1276)	CeLoss 0.2373 (0.2985)	SegCLSLoss 0.0835 (0.0822)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1391 (0.1469)	MaskBCELoss 0.0471 (0.0542)	MaskDICELoss 0.0920 (0.0927)
Epoch: [0][  2/500]	Time 49.647 (49.647)	Loss 1.1722 (1.1646)	CeLoss 0.3262 (0.3074)	SegCLSLoss 0.0806 (0.0826)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1565 (0.1567)	MaskBCELoss 0.0636 (0.0621)	MaskDICELoss 0.0929 (0.0946)
Epoch: [0][  3/500]	Time 50.259 (50.259)	Loss 1.0723 (1.1620)	CeLoss 0.2637 (0.3028)	SegCLSLoss 0.0830 (0.0824)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1567 (0.1597)	MaskBCELoss 0.0748 (0.0661)	MaskDICELoss 0.0819 (0.0936)
Epoch: [0][  4/500]	Time 52.067 (52.067)	Loss 1.1661 (1.1233)	CeLoss 0.3203 (0.2699)	SegCLSLoss 0.0845 (0.0832)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1455 (0.1587)	MaskBCELoss 0.0485 (0.0664)	MaskDICELoss 0.0969 (0.0922)
Epoch: [0][  5/500]	Time 55.369 (55.369)	Loss 1.1327 (1.1127)	CeLoss 0.3145 (0.2806)	SegCLSLoss 0.0825 (0.0835)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1486 (0.1470)	MaskBCELoss 0.0593 (0.0542)	MaskDICELoss 0.0893 (0.0928)
Epoch: [0][  6/500]	Time 52.991 (52.991)	Loss 1.2405 (1.1339)	CeLoss 0.3301 (0.2934)	SegCLSLoss 0.0840 (0.0830)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1759 (0.1506)	MaskBCELoss 0.0779 (0.0572)	MaskDICELoss 0.0980 (0.0934)
Epoch: [0][  7/500]	Time 53.349 (53.349)	Loss 1.1383 (1.1311)	CeLoss 0.2656 (0.2832)	SegCLSLoss 0.0835 (0.0838)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1685 (0.1556)	MaskBCELoss 0.0759 (0.0632)	MaskDICELoss 0.0925 (0.0924)
Epoch: [0][  8/500]	Time 56.640 (56.640)	Loss 1.1436 (1.1234)	CeLoss 0.3086 (0.2875)	SegCLSLoss 0.0811 (0.0819)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1525 (0.1521)	MaskBCELoss 0.0600 (0.0600)	MaskDICELoss 0.0925 (0.0921)
Epoch: [0][  9/500]	Time 50.910 (50.910)	Loss 1.1063 (1.1471)	CeLoss 0.2695 (0.3041)	SegCLSLoss 0.0825 (0.0822)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1454 (0.1516)	MaskBCELoss 0.0501 (0.0578)	MaskDICELoss 0.0953 (0.0938)
Epoch: [0][ 10/500]	Time 55.016 (55.016)	Loss 1.1468 (1.1466)	CeLoss 0.2695 (0.2857)	SegCLSLoss 0.0830 (0.0836)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1635 (0.1602)	MaskBCELoss 0.0671 (0.0668)	MaskDICELoss 0.0964 (0.0934)
Epoch: [0][ 11/500]	Time 57.096 (57.096)	Loss 0.9874 (1.0240)	CeLoss 0.2559 (0.2783)	SegCLSLoss 0.0552 (0.0550)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1328 (0.1346)	MaskBCELoss 0.0437 (0.0430)	MaskDICELoss 0.0891 (0.0917)
Epoch: [0][ 12/500]	Time 60.817 (60.817)	Loss 0.9853 (1.0336)	CeLoss 0.2832 (0.2912)	SegCLSLoss 0.0535 (0.0527)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1291 (0.1359)	MaskBCELoss 0.0450 (0.0445)	MaskDICELoss 0.0841 (0.0914)
Epoch: [0][ 13/500]	Time 57.911 (57.911)	Loss 1.0228 (1.0095)	CeLoss 0.2773 (0.2707)	SegCLSLoss 0.0605 (0.0545)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1215 (0.1332)	MaskBCELoss 0.0266 (0.0424)	MaskDICELoss 0.0949 (0.0908)
Epoch: [0][ 14/500]	Time 50.317 (50.317)	Loss 1.0279 (1.0521)	CeLoss 0.3086 (0.2998)	SegCLSLoss 0.0500 (0.0554)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1283 (0.1323)	MaskBCELoss 0.0378 (0.0381)	MaskDICELoss 0.0905 (0.0942)
Epoch: [0][ 15/500]	Time 57.210 (57.210)	Loss 1.0865 (1.0344)	CeLoss 0.3164 (0.2908)	SegCLSLoss 0.0491 (0.0524)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1465 (0.1367)	MaskBCELoss 0.0520 (0.0452)	MaskDICELoss 0.0945 (0.0915)
Epoch: [0][ 16/500]	Time 54.409 (54.409)	Loss 1.0217 (1.0382)	CeLoss 0.2559 (0.2893)	SegCLSLoss 0.0562 (0.0527)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1353 (0.1354)	MaskBCELoss 0.0398 (0.0421)	MaskDICELoss 0.0956 (0.0932)
Epoch: [0][ 17/500]	Time 55.069 (55.069)	Loss 1.0293 (1.0414)	CeLoss 0.2773 (0.2966)	SegCLSLoss 0.0554 (0.0530)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1388 (0.1389)	MaskBCELoss 0.0477 (0.0486)	MaskDICELoss 0.0911 (0.0903)
Epoch: [0][ 18/500]	Time 53.186 (53.186)	Loss 1.0394 (1.0369)	CeLoss 0.3086 (0.2870)	SegCLSLoss 0.0520 (0.0543)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1289 (0.1358)	MaskBCELoss 0.0366 (0.0434)	MaskDICELoss 0.0923 (0.0924)
Epoch: [0][ 19/500]	Time 59.373 (59.373)	Loss 0.9895 (1.0302)	CeLoss 0.2451 (0.2734)	SegCLSLoss 0.0581 (0.0557)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1247 (0.1380)	MaskBCELoss 0.0303 (0.0456)	MaskDICELoss 0.0944 (0.0924)
Epoch: [0][ 20/500]	Time 51.098 (51.098)	Loss 0.9831 (1.0303)	CeLoss 0.2617 (0.2898)	SegCLSLoss 0.0591 (0.0531)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1261 (0.1340)	MaskBCELoss 0.0379 (0.0424)	MaskDICELoss 0.0882 (0.0917)
Epoch: [0][ 21/500]	Time 55.488 (55.488)	Loss 0.9756 (1.0158)	CeLoss 0.2471 (0.2536)	SegCLSLoss 0.0476 (0.0582)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1456 (0.1398)	MaskBCELoss 0.0600 (0.0483)	MaskDICELoss 0.0856 (0.0916)
Epoch: [0][ 22/500]	Time 53.978 (53.978)	Loss 1.0310 (1.0189)	CeLoss 0.2812 (0.2510)	SegCLSLoss 0.0493 (0.0620)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1410 (0.1386)	MaskBCELoss 0.0487 (0.0469)	MaskDICELoss 0.0923 (0.0917)
Epoch: [0][ 23/500]	Time 53.825 (53.825)	Loss 1.0202 (1.0414)	CeLoss 0.2656 (0.2804)	SegCLSLoss 0.0442 (0.0529)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1529 (0.1413)	MaskBCELoss 0.0626 (0.0480)	MaskDICELoss 0.0903 (0.0932)
Epoch: [0][ 24/500]	Time 51.876 (51.876)	Loss 1.0036 (1.0266)	CeLoss 0.2080 (0.2741)	SegCLSLoss 0.0771 (0.0555)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1400 (0.1392)	MaskBCELoss 0.0497 (0.0485)	MaskDICELoss 0.0903 (0.0907)
Epoch: [0][ 25/500]	Time 56.677 (56.677)	Loss 1.0776 (1.0255)	CeLoss 0.3340 (0.2695)	SegCLSLoss 0.0403 (0.0581)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1411 (0.1368)	MaskBCELoss 0.0461 (0.0452)	MaskDICELoss 0.0950 (0.0916)
Epoch: [0][ 26/500]	Time 59.835 (59.835)	Loss 1.0161 (1.0228)	CeLoss 0.2773 (0.2642)	SegCLSLoss 0.0535 (0.0557)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1407 (0.1409)	MaskBCELoss 0.0531 (0.0495)	MaskDICELoss 0.0876 (0.0914)
Epoch: [0][ 27/500]	Time 56.150 (56.150)	Loss 0.9358 (1.0254)	CeLoss 0.2188 (0.2726)	SegCLSLoss 0.0601 (0.0566)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1260 (0.1369)	MaskBCELoss 0.0399 (0.0454)	MaskDICELoss 0.0862 (0.0915)
Epoch: [0][ 28/500]	Time 54.170 (54.170)	Loss 1.0243 (1.0187)	CeLoss 0.2891 (0.2753)	SegCLSLoss 0.0496 (0.0524)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1375 (0.1377)	MaskBCELoss 0.0470 (0.0469)	MaskDICELoss 0.0905 (0.0908)
Epoch: [0][ 29/500]	Time 57.760 (57.760)	Loss 1.0103 (1.0211)	CeLoss 0.2441 (0.2663)	SegCLSLoss 0.0586 (0.0543)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1385 (0.1379)	MaskBCELoss 0.0454 (0.0454)	MaskDICELoss 0.0931 (0.0925)
Epoch: [0][ 30/500]	Time 55.174 (55.174)	Loss 0.9902 (1.0068)	CeLoss 0.2422 (0.2583)	SegCLSLoss 0.0625 (0.0556)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1314 (0.1365)	MaskBCELoss 0.0413 (0.0454)	MaskDICELoss 0.0901 (0.0910)
Epoch: [0][ 31/500]	Time 54.364 (54.364)	Loss 0.9475 (0.9840)	CeLoss 0.2314 (0.2459)	SegCLSLoss 0.0747 (0.0663)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1133 (0.1244)	MaskBCELoss 0.0284 (0.0353)	MaskDICELoss 0.0849 (0.0891)
Epoch: [0][ 32/500]	Time 60.404 (60.404)	Loss 0.9672 (0.9668)	CeLoss 0.1992 (0.2352)	SegCLSLoss 0.0737 (0.0601)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1308 (0.1292)	MaskBCELoss 0.0411 (0.0411)	MaskDICELoss 0.0897 (0.0881)
Epoch: [0][ 33/500]	Time 52.726 (52.726)	Loss 0.9496 (0.9944)	CeLoss 0.2637 (0.2634)	SegCLSLoss 0.0559 (0.0630)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1151 (0.1228)	MaskBCELoss 0.0289 (0.0329)	MaskDICELoss 0.0861 (0.0900)
Epoch: [0][ 34/500]	Time 54.968 (54.968)	Loss 1.0459 (0.9725)	CeLoss 0.2754 (0.2478)	SegCLSLoss 0.0728 (0.0641)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1195 (0.1213)	MaskBCELoss 0.0224 (0.0327)	MaskDICELoss 0.0971 (0.0886)
Epoch: [0][ 35/500]	Time 51.527 (51.527)	Loss 1.0103 (0.9897)	CeLoss 0.2441 (0.2300)	SegCLSLoss 0.0718 (0.0744)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1195 (0.1247)	MaskBCELoss 0.0235 (0.0343)	MaskDICELoss 0.0960 (0.0904)
Epoch: [0][ 36/500]	Time 58.826 (58.826)	Loss 0.9463 (0.9720)	CeLoss 0.2441 (0.2346)	SegCLSLoss 0.0435 (0.0661)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1276 (0.1260)	MaskBCELoss 0.0377 (0.0378)	MaskDICELoss 0.0900 (0.0882)
Epoch: [0][ 37/500]	Time 53.407 (53.407)	Loss 1.0158 (0.9792)	CeLoss 0.2656 (0.2301)	SegCLSLoss 0.0654 (0.0687)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1229 (0.1270)	MaskBCELoss 0.0296 (0.0376)	MaskDICELoss 0.0933 (0.0895)
Epoch: [0][ 38/500]	Time 48.191 (48.191)	Loss 0.9226 (0.9759)	CeLoss 0.2207 (0.2436)	SegCLSLoss 0.0664 (0.0686)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1181 (0.1203)	MaskBCELoss 0.0347 (0.0317)	MaskDICELoss 0.0833 (0.0886)
Epoch: [0][ 39/500]	Time 51.085 (51.085)	Loss 0.9770 (0.9828)	CeLoss 0.2520 (0.2426)	SegCLSLoss 0.0566 (0.0645)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1266 (0.1240)	MaskBCELoss 0.0371 (0.0332)	MaskDICELoss 0.0895 (0.0908)
Epoch: [0][ 40/500]	Time 53.356 (53.356)	Loss 1.0193 (0.9855)	CeLoss 0.2246 (0.2357)	SegCLSLoss 0.0845 (0.0717)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1235 (0.1247)	MaskBCELoss 0.0289 (0.0355)	MaskDICELoss 0.0946 (0.0892)
Epoch: [0][ 41/500]	Time 58.400 (58.400)	Loss 0.8188 (0.8407)	CeLoss 0.1953 (0.1971)	SegCLSLoss 0.0286 (0.0298)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1136 (0.1180)	MaskBCELoss 0.0290 (0.0311)	MaskDICELoss 0.0846 (0.0870)
Epoch: [0][ 42/500]	Time 56.323 (56.323)	Loss 0.8089 (0.8186)	CeLoss 0.1924 (0.1884)	SegCLSLoss 0.0299 (0.0296)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1101 (0.1168)	MaskBCELoss 0.0258 (0.0324)	MaskDICELoss 0.0843 (0.0844)
Epoch: [0][ 43/500]	Time 53.261 (53.261)	Loss 0.8373 (0.8514)	CeLoss 0.2031 (0.2191)	SegCLSLoss 0.0286 (0.0281)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1162 (0.1151)	MaskBCELoss 0.0298 (0.0286)	MaskDICELoss 0.0864 (0.0865)
Epoch: [0][ 44/500]	Time 54.320 (54.320)	Loss 0.9028 (0.8591)	CeLoss 0.2363 (0.2128)	SegCLSLoss 0.0303 (0.0282)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1167 (0.1193)	MaskBCELoss 0.0235 (0.0316)	MaskDICELoss 0.0931 (0.0878)
Epoch: [0][ 45/500]	Time 60.331 (60.331)	Loss 0.8321 (0.8472)	CeLoss 0.1807 (0.1992)	SegCLSLoss 0.0293 (0.0278)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1158 (0.1233)	MaskBCELoss 0.0254 (0.0368)	MaskDICELoss 0.0904 (0.0865)
Epoch: [0][ 46/500]	Time 51.674 (51.674)	Loss 0.8024 (0.8484)	CeLoss 0.1992 (0.2050)	SegCLSLoss 0.0283 (0.0286)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1110 (0.1195)	MaskBCELoss 0.0299 (0.0327)	MaskDICELoss 0.0811 (0.0868)
Epoch: [0][ 47/500]	Time 57.998 (57.998)	Loss 0.8583 (0.8451)	CeLoss 0.2002 (0.2084)	SegCLSLoss 0.0293 (0.0283)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1203 (0.1171)	MaskBCELoss 0.0307 (0.0306)	MaskDICELoss 0.0896 (0.0865)
Epoch: [0][ 48/500]	Time 54.528 (54.528)	Loss 0.8548 (0.8654)	CeLoss 0.2061 (0.2149)	SegCLSLoss 0.0264 (0.0283)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1270 (0.1212)	MaskBCELoss 0.0417 (0.0334)	MaskDICELoss 0.0853 (0.0879)
Epoch: [0][ 49/500]	Time 55.766 (55.766)	Loss 0.8363 (0.8433)	CeLoss 0.2139 (0.2013)	SegCLSLoss 0.0310 (0.0289)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1094 (0.1193)	MaskBCELoss 0.0241 (0.0329)	MaskDICELoss 0.0852 (0.0864)
Epoch: [0][ 50/500]	Time 56.194 (56.194)	Loss 0.8596 (0.8465)	CeLoss 0.2158 (0.2062)	SegCLSLoss 0.0286 (0.0284)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1130 (0.1164)	MaskBCELoss 0.0225 (0.0287)	MaskDICELoss 0.0905 (0.0877)
Epoch: [0][ 51/500]	Time 54.659 (54.659)	Loss 0.7925 (0.7958)	CeLoss 0.1514 (0.1577)	SegCLSLoss 0.0376 (0.0383)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1146 (0.1119)	MaskBCELoss 0.0304 (0.0275)	MaskDICELoss 0.0842 (0.0844)
Epoch: [0][ 52/500]	Time 50.374 (50.374)	Loss 0.8548 (0.8156)	CeLoss 0.1641 (0.1655)	SegCLSLoss 0.0347 (0.0363)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1277 (0.1141)	MaskBCELoss 0.0365 (0.0268)	MaskDICELoss 0.0912 (0.0873)
Epoch: [0][ 53/500]	Time 55.912 (55.912)	Loss 0.8504 (0.8267)	CeLoss 0.1621 (0.1565)	SegCLSLoss 0.0386 (0.0389)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1252 (0.1228)	MaskBCELoss 0.0349 (0.0361)	MaskDICELoss 0.0903 (0.0867)
Epoch: [0][ 54/500]	Time 58.225 (58.225)	Loss 0.8529 (0.7996)	CeLoss 0.1436 (0.1515)	SegCLSLoss 0.0393 (0.0390)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1383 (0.1161)	MaskBCELoss 0.0497 (0.0316)	MaskDICELoss 0.0886 (0.0844)
Epoch: [0][ 55/500]	Time 50.280 (50.280)	Loss 0.8107 (0.8147)	CeLoss 0.1777 (0.1652)	SegCLSLoss 0.0366 (0.0393)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1058 (0.1162)	MaskBCELoss 0.0185 (0.0316)	MaskDICELoss 0.0873 (0.0846)
Epoch: [0][ 56/500]	Time 50.869 (50.869)	Loss 0.7929 (0.7938)	CeLoss 0.1357 (0.1500)	SegCLSLoss 0.0398 (0.0390)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1222 (0.1150)	MaskBCELoss 0.0390 (0.0311)	MaskDICELoss 0.0832 (0.0839)
Epoch: [0][ 57/500]	Time 44.464 (44.464)	Loss 0.7573 (0.8012)	CeLoss 0.1279 (0.1688)	SegCLSLoss 0.0356 (0.0361)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1120 (0.1096)	MaskBCELoss 0.0285 (0.0242)	MaskDICELoss 0.0835 (0.0854)
Epoch: [0][ 58/500]	Time 58.825 (58.825)	Loss 0.7916 (0.7909)	CeLoss 0.1562 (0.1455)	SegCLSLoss 0.0425 (0.0390)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1122 (0.1151)	MaskBCELoss 0.0305 (0.0308)	MaskDICELoss 0.0817 (0.0843)
Epoch: [0][ 59/500]	Time 56.817 (56.817)	Loss 0.8453 (0.8196)	CeLoss 0.1543 (0.1521)	SegCLSLoss 0.0383 (0.0388)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1358 (0.1211)	MaskBCELoss 0.0502 (0.0342)	MaskDICELoss 0.0856 (0.0869)
Epoch: [0][ 60/500]	Time 58.067 (58.067)	Loss 0.8284 (0.7887)	CeLoss 0.1592 (0.1530)	SegCLSLoss 0.0413 (0.0381)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1277 (0.1141)	MaskBCELoss 0.0449 (0.0313)	MaskDICELoss 0.0827 (0.0828)
Epoch: [0][ 61/500]	Time 49.456 (49.456)	Loss 0.8008 (0.7901)	CeLoss 0.0933 (0.1087)	SegCLSLoss 0.1030 (0.0750)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1038 (0.1054)	MaskBCELoss 0.0305 (0.0253)	MaskDICELoss 0.0733 (0.0801)
Epoch: [0][ 62/500]	Time 55.375 (55.375)	Loss 0.8056 (0.8125)	CeLoss 0.1055 (0.1137)	SegCLSLoss 0.0732 (0.0678)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1047 (0.1148)	MaskBCELoss 0.0189 (0.0314)	MaskDICELoss 0.0858 (0.0834)
Epoch: [0][ 63/500]	Time 56.682 (56.682)	Loss 0.7551 (0.8115)	CeLoss 0.0986 (0.1027)	SegCLSLoss 0.0559 (0.0761)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1091 (0.1150)	MaskBCELoss 0.0271 (0.0334)	MaskDICELoss 0.0819 (0.0817)
Epoch: [0][ 64/500]	Time 56.222 (56.222)	Loss 0.7596 (0.8084)	CeLoss 0.0967 (0.1060)	SegCLSLoss 0.0757 (0.0764)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0975 (0.1095)	MaskBCELoss 0.0185 (0.0269)	MaskDICELoss 0.0790 (0.0826)
Epoch: [0][ 65/500]	Time 56.514 (56.514)	Loss 0.8751 (0.8150)	CeLoss 0.0771 (0.1032)	SegCLSLoss 0.1260 (0.0927)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1167 (0.1053)	MaskBCELoss 0.0383 (0.0263)	MaskDICELoss 0.0784 (0.0790)
Epoch: [0][ 66/500]	Time 55.426 (55.426)	Loss 0.8176 (0.7958)	CeLoss 0.0908 (0.1063)	SegCLSLoss 0.0850 (0.0706)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1225 (0.1147)	MaskBCELoss 0.0446 (0.0348)	MaskDICELoss 0.0779 (0.0798)
Epoch: [0][ 67/500]	Time 53.171 (53.171)	Loss 0.7857 (0.8093)	CeLoss 0.1006 (0.0999)	SegCLSLoss 0.0747 (0.0851)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1109 (0.1085)	MaskBCELoss 0.0324 (0.0279)	MaskDICELoss 0.0785 (0.0806)
Epoch: [0][ 68/500]	Time 53.161 (53.161)	Loss 0.8190 (0.8089)	CeLoss 0.1001 (0.1052)	SegCLSLoss 0.0874 (0.0785)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1149 (0.1124)	MaskBCELoss 0.0364 (0.0319)	MaskDICELoss 0.0785 (0.0805)
Epoch: [0][ 69/500]	Time 53.760 (53.760)	Loss 0.8132 (0.8006)	CeLoss 0.1309 (0.1097)	SegCLSLoss 0.0593 (0.0714)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1144 (0.1120)	MaskBCELoss 0.0308 (0.0310)	MaskDICELoss 0.0836 (0.0810)
Epoch: [0][ 70/500]	Time 53.236 (53.236)	Loss 0.8768 (0.8144)	CeLoss 0.1162 (0.1163)	SegCLSLoss 0.0850 (0.0823)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1197 (0.1047)	MaskBCELoss 0.0323 (0.0237)	MaskDICELoss 0.0875 (0.0810)
Epoch: [0][ 71/500]	Time 55.341 (55.341)	Loss 0.7499 (0.7175)	CeLoss 0.0664 (0.0632)	SegCLSLoss 0.0840 (0.0698)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1057 (0.1037)	MaskBCELoss 0.0297 (0.0269)	MaskDICELoss 0.0760 (0.0768)
Epoch: [0][ 72/500]	Time 62.328 (62.328)	Loss 0.7535 (0.7481)	CeLoss 0.0618 (0.0638)	SegCLSLoss 0.0620 (0.0655)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1217 (0.1159)	MaskBCELoss 0.0407 (0.0355)	MaskDICELoss 0.0810 (0.0804)
Epoch: [0][ 73/500]	Time 51.040 (51.040)	Loss 0.7420 (0.7274)	CeLoss 0.0547 (0.0673)	SegCLSLoss 0.0674 (0.0639)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1144 (0.1081)	MaskBCELoss 0.0333 (0.0291)	MaskDICELoss 0.0811 (0.0790)
Epoch: [0][ 74/500]	Time 51.744 (51.744)	Loss 0.7715 (0.7431)	CeLoss 0.0630 (0.0607)	SegCLSLoss 0.0659 (0.0690)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1275 (0.1120)	MaskBCELoss 0.0471 (0.0319)	MaskDICELoss 0.0803 (0.0801)
Epoch: [0][ 75/500]	Time 50.159 (50.159)	Loss 0.7390 (0.7421)	CeLoss 0.0562 (0.0630)	SegCLSLoss 0.0825 (0.0683)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0989 (0.1108)	MaskBCELoss 0.0191 (0.0306)	MaskDICELoss 0.0798 (0.0802)
Epoch: [0][ 76/500]	Time 51.026 (51.026)	Loss 0.7912 (0.7271)	CeLoss 0.0820 (0.0668)	SegCLSLoss 0.0610 (0.0648)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1193 (0.1059)	MaskBCELoss 0.0320 (0.0261)	MaskDICELoss 0.0874 (0.0798)
Epoch: [0][ 77/500]	Time 56.180 (56.180)	Loss 0.6971 (0.7257)	CeLoss 0.0598 (0.0644)	SegCLSLoss 0.0540 (0.0632)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1103 (0.1110)	MaskBCELoss 0.0330 (0.0329)	MaskDICELoss 0.0773 (0.0782)
Epoch: [0][ 78/500]	Time 56.545 (56.545)	Loss 0.7696 (0.7230)	CeLoss 0.0732 (0.0610)	SegCLSLoss 0.0688 (0.0618)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1172 (0.1105)	MaskBCELoss 0.0362 (0.0311)	MaskDICELoss 0.0811 (0.0794)
Epoch: [0][ 79/500]	Time 51.667 (51.667)	Loss 0.7301 (0.7368)	CeLoss 0.0610 (0.0680)	SegCLSLoss 0.0581 (0.0663)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1118 (0.1108)	MaskBCELoss 0.0295 (0.0321)	MaskDICELoss 0.0823 (0.0786)
Epoch: [0][ 80/500]	Time 57.587 (57.587)	Loss 0.7674 (0.7403)	CeLoss 0.0535 (0.0630)	SegCLSLoss 0.0630 (0.0651)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1250 (0.1129)	MaskBCELoss 0.0405 (0.0326)	MaskDICELoss 0.0844 (0.0803)
Epoch: [0][ 81/500]	Time 61.499 (61.499)	Loss 0.6305 (0.6586)	CeLoss 0.0347 (0.0363)	SegCLSLoss 0.0481 (0.0513)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1015 (0.1063)	MaskBCELoss 0.0274 (0.0296)	MaskDICELoss 0.0741 (0.0767)
Epoch: [0][ 82/500]	Time 57.248 (57.248)	Loss 0.6831 (0.6607)	CeLoss 0.0393 (0.0377)	SegCLSLoss 0.0466 (0.0534)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1201 (0.1072)	MaskBCELoss 0.0425 (0.0318)	MaskDICELoss 0.0776 (0.0754)
Epoch: [0][ 83/500]	Time 60.240 (60.240)	Loss 0.7243 (0.6744)	CeLoss 0.0299 (0.0367)	SegCLSLoss 0.0527 (0.0517)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1292 (0.1124)	MaskBCELoss 0.0466 (0.0350)	MaskDICELoss 0.0827 (0.0774)
Epoch: [0][ 84/500]	Time 51.408 (51.408)	Loss 0.6180 (0.6610)	CeLoss 0.0461 (0.0436)	SegCLSLoss 0.0437 (0.0573)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0900 (0.1005)	MaskBCELoss 0.0139 (0.0251)	MaskDICELoss 0.0761 (0.0755)
Epoch: [0][ 85/500]	Time 52.076 (52.076)	Loss 0.6319 (0.6792)	CeLoss 0.0366 (0.0410)	SegCLSLoss 0.0413 (0.0562)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1085 (0.1090)	MaskBCELoss 0.0345 (0.0320)	MaskDICELoss 0.0740 (0.0770)
Epoch: [0][ 86/500]	Time 54.624 (54.624)	Loss 0.6651 (0.6620)	CeLoss 0.0425 (0.0400)	SegCLSLoss 0.0449 (0.0492)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1129 (0.1073)	MaskBCELoss 0.0361 (0.0301)	MaskDICELoss 0.0768 (0.0772)
Epoch: [0][ 87/500]	Time 54.899 (54.899)	Loss 0.6738 (0.6784)	CeLoss 0.0415 (0.0391)	SegCLSLoss 0.0693 (0.0555)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0954 (0.1091)	MaskBCELoss 0.0195 (0.0315)	MaskDICELoss 0.0759 (0.0776)
Epoch: [0][ 88/500]	Time 56.669 (56.669)	Loss 0.7178 (0.6828)	CeLoss 0.0393 (0.0366)	SegCLSLoss 0.0811 (0.0577)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1123 (0.1104)	MaskBCELoss 0.0393 (0.0329)	MaskDICELoss 0.0729 (0.0775)
Epoch: [0][ 89/500]	Time 53.743 (53.743)	Loss 0.7040 (0.6729)	CeLoss 0.0354 (0.0396)	SegCLSLoss 0.0422 (0.0487)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1336 (0.1136)	MaskBCELoss 0.0543 (0.0365)	MaskDICELoss 0.0793 (0.0772)
Epoch: [0][ 90/500]	Time 58.862 (58.862)	Loss 0.6697 (0.6673)	CeLoss 0.0388 (0.0366)	SegCLSLoss 0.0654 (0.0601)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1054 (0.1049)	MaskBCELoss 0.0332 (0.0298)	MaskDICELoss 0.0722 (0.0752)
Epoch: [0][ 91/500]	Time 46.419 (46.419)	Loss 0.6382 (0.6353)	CeLoss 0.0327 (0.0276)	SegCLSLoss 0.0513 (0.0495)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0966 (0.1027)	MaskBCELoss 0.0191 (0.0268)	MaskDICELoss 0.0775 (0.0758)
Epoch: [0][ 92/500]	Time 50.684 (50.684)	Loss 0.6811 (0.6551)	CeLoss 0.0270 (0.0265)	SegCLSLoss 0.0486 (0.0490)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1199 (0.1081)	MaskBCELoss 0.0407 (0.0295)	MaskDICELoss 0.0793 (0.0786)
Epoch: [0][ 93/500]	Time 55.303 (55.303)	Loss 0.6830 (0.6505)	CeLoss 0.0303 (0.0299)	SegCLSLoss 0.0496 (0.0476)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1157 (0.1084)	MaskBCELoss 0.0352 (0.0313)	MaskDICELoss 0.0805 (0.0771)
Epoch: [0][ 94/500]	Time 54.375 (54.375)	Loss 0.6191 (0.6503)	CeLoss 0.0256 (0.0294)	SegCLSLoss 0.0430 (0.0473)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1012 (0.1073)	MaskBCELoss 0.0250 (0.0294)	MaskDICELoss 0.0762 (0.0779)
Epoch: [0][ 95/500]	Time 55.911 (55.911)	Loss 0.6534 (0.6210)	CeLoss 0.0206 (0.0275)	SegCLSLoss 0.0474 (0.0470)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1167 (0.1031)	MaskBCELoss 0.0406 (0.0298)	MaskDICELoss 0.0761 (0.0733)
Epoch: [0][ 96/500]	Time 53.523 (53.523)	Loss 0.6457 (0.6476)	CeLoss 0.0242 (0.0256)	SegCLSLoss 0.0435 (0.0486)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1127 (0.1083)	MaskBCELoss 0.0354 (0.0312)	MaskDICELoss 0.0773 (0.0771)
Epoch: [0][ 97/500]	Time 57.888 (57.888)	Loss 0.6770 (0.6592)	CeLoss 0.0337 (0.0285)	SegCLSLoss 0.0464 (0.0485)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1125 (0.1069)	MaskBCELoss 0.0311 (0.0270)	MaskDICELoss 0.0814 (0.0800)
Epoch: [0][ 98/500]	Time 54.485 (54.485)	Loss 0.7400 (0.6478)	CeLoss 0.0222 (0.0271)	SegCLSLoss 0.0471 (0.0480)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1397 (0.1081)	MaskBCELoss 0.0537 (0.0310)	MaskDICELoss 0.0860 (0.0771)
Epoch: [0][ 99/500]	Time 50.365 (50.365)	Loss 0.6179 (0.6342)	CeLoss 0.0245 (0.0247)	SegCLSLoss 0.0540 (0.0489)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0956 (0.1039)	MaskBCELoss 0.0219 (0.0279)	MaskDICELoss 0.0737 (0.0760)
[2025-04-16 21:54:31,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.00029991566265060235], mom=[(0.9, 0.95)]
[2025-04-16 21:54:31,022] [INFO] [timer.py:215:stop] epoch=0/micro_step=100/global_step=10, RunningAvgSamplesPerSec=1.446696772305205, CurrSamplesPerSec=1.4684478282660953, MemAllocated=37.17GB, MaxMemAllocated=48.41GB
Epoch: [0][100/500]	Time 58.459 (58.459)	Loss 0.6862 (0.6450)	CeLoss 0.0164 (0.0253)	SegCLSLoss 0.0466 (0.0489)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1243 (0.1064)	MaskBCELoss 0.0422 (0.0292)	MaskDICELoss 0.0821 (0.0773)
Epoch: [0][101/500]	Time 52.390 (52.390)	Loss 0.5190 (0.5406)	CeLoss 0.0237 (0.0207)	SegCLSLoss 0.0312 (0.0305)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0838 (0.0939)	MaskBCELoss 0.0175 (0.0261)	MaskDICELoss 0.0663 (0.0678)
Epoch: [0][102/500]	Time 52.884 (52.884)	Loss 0.5894 (0.5539)	CeLoss 0.0223 (0.0200)	SegCLSLoss 0.0286 (0.0302)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1027 (0.1004)	MaskBCELoss 0.0265 (0.0322)	MaskDICELoss 0.0762 (0.0682)
Epoch: [0][103/500]	Time 54.944 (54.944)	Loss 0.5913 (0.5376)	CeLoss 0.0231 (0.0209)	SegCLSLoss 0.0299 (0.0307)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1066 (0.0917)	MaskBCELoss 0.0328 (0.0237)	MaskDICELoss 0.0738 (0.0680)
Epoch: [0][104/500]	Time 54.699 (54.699)	Loss 0.5105 (0.5420)	CeLoss 0.0181 (0.0193)	SegCLSLoss 0.0310 (0.0302)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0885 (0.0933)	MaskBCELoss 0.0251 (0.0245)	MaskDICELoss 0.0634 (0.0689)
Epoch: [0][105/500]	Time 56.544 (56.544)	Loss 0.5064 (0.5419)	CeLoss 0.0179 (0.0203)	SegCLSLoss 0.0286 (0.0292)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0929 (0.0949)	MaskBCELoss 0.0316 (0.0266)	MaskDICELoss 0.0614 (0.0683)
Epoch: [0][106/500]	Time 53.515 (53.515)	Loss 0.4716 (0.5241)	CeLoss 0.0148 (0.0202)	SegCLSLoss 0.0312 (0.0305)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0763 (0.0889)	MaskBCELoss 0.0158 (0.0226)	MaskDICELoss 0.0604 (0.0663)
Epoch: [0][107/500]	Time 59.084 (59.084)	Loss 0.5995 (0.5597)	CeLoss 0.0270 (0.0210)	SegCLSLoss 0.0327 (0.0292)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1041 (0.0977)	MaskBCELoss 0.0294 (0.0265)	MaskDICELoss 0.0747 (0.0712)
Epoch: [0][108/500]	Time 53.639 (53.639)	Loss 0.5240 (0.5427)	CeLoss 0.0108 (0.0198)	SegCLSLoss 0.0271 (0.0294)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0997 (0.0959)	MaskBCELoss 0.0349 (0.0278)	MaskDICELoss 0.0648 (0.0681)
Epoch: [0][109/500]	Time 49.291 (49.291)	Loss 0.6323 (0.5459)	CeLoss 0.0239 (0.0206)	SegCLSLoss 0.0271 (0.0294)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1174 (0.0984)	MaskBCELoss 0.0376 (0.0310)	MaskDICELoss 0.0798 (0.0674)
Epoch: [0][110/500]	Time 52.605 (52.605)	Loss 0.6071 (0.5507)	CeLoss 0.0203 (0.0248)	SegCLSLoss 0.0280 (0.0293)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1116 (0.0947)	MaskBCELoss 0.0347 (0.0252)	MaskDICELoss 0.0769 (0.0695)
Epoch: [0][111/500]	Time 53.109 (53.109)	Loss 0.5950 (0.5414)	CeLoss 0.0222 (0.0146)	SegCLSLoss 0.0393 (0.0268)	KLLoss 0.0000 (0.0000)	MaskLoss 0.0988 (0.0979)	MaskBCELoss 0.0246 (0.0286)	MaskDICELoss 0.0742 (0.0693)
Epoch: [0][112/500]	Time 58.631 (58.631)	Loss 0.6015 (0.5529)	CeLoss 0.0168 (0.0176)	SegCLSLoss 0.0227 (0.0241)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1136 (0.1010)	MaskBCELoss 0.0357 (0.0298)	MaskDICELoss 0.0779 (0.0713)
Epoch: [0][113/500]	Time 59.894 (59.894)	Loss 0.5882 (0.5474)	CeLoss 0.0193 (0.0151)	SegCLSLoss 0.0303 (0.0255)	KLLoss 0.0000 (0.0000)	MaskLoss 0.1043 (0.0986)	MaskBCELoss 0.0293 (0.0276)	MaskDICELoss 0.0750 (0.0710)
