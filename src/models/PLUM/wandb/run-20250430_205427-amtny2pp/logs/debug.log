2025-04-30 20:54:27,534 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Current SDK version is 0.16.0
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Configure stats pid to 2280013
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Loading settings from /home/jk100/.config/wandb/settings
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Loading settings from /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/settings
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'src/models/PLUM/plum_train_ds.py', 'program_abspath': '/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py', 'program': '/shared/nas2/jk100/partonomy_private/src/models/PLUM/plum_train_ds.py'}
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_init.py:_log_setup():524] Logging user logs to /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/run-20250430_205427-amtny2pp/logs/debug.log
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_init.py:_log_setup():525] Logging internal logs to /shared/nas2/jk100/partonomy_private/src/models/PLUM/wandb/run-20250430_205427-amtny2pp/logs/debug-internal.log
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_init.py:init():564] calling init triggers
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'local_rank': 0, 'version': 'liuhaotian/llava-llama-2-13b-chat-lightning-preview', 'zero_shot_ckpt_path': 'runs/plum-13b_kld_0.1_focal_tversky_8_v1_0shot/plum-13b_kld_0.1_focal_tversky_8_v1_0shot_bidirbio_2048_accum_10_maxlen512_epochs25_segloss_2_bce_loss_2_kld_loss_0_dice_loss_8_bidir_bio_train_prompt_enc_ckpt_model', 'vis_save_path': './vis_output', 'precision': 'bf16', 'image_size': 1024, 'model_max_length': 512, 'lora_r': 8, 'vision_tower': 'openai/clip-vit-large-patch14', 'load_in_8bit': False, 'load_in_4bit': False, 'dataset': 'explanatory_seg', 'sample_rates': '10', 'sem_seg_data': 'ade20k||cocostuff||pascal_part||paco_lvis||mapillary', 'refer_seg_data': 'refclef||refcoco||refcoco+||refcocog', 'explanatory_seg_data': True, 'wandb': False, 'wandb_project_name': 'plum-training', 'vqa_data': 'llava_instruct_150k', 'reason_seg_data': 'ReasonSeg|train', 'val_dataset': 'ReasonSeg|val', 'dataset_dir': '/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/dataset', 'log_base_dir': './runs', 'exp_name': 'plum-13b_kld_0.1_focal_tversky_8_v1_partonomy_ft', 'epochs': 4, 'steps_per_epoch': 500, 'batch_size': 6, 'grad_accumulation_steps': 10, 'val_batch_size': 1, 'workers': 4, 'lr': 0.0003, 'ce_loss_weight': 1.0, 'dice_type': 'focal_tversky', 'dice_loss_weight': 8.0, 'dice_scale_factor': 1000.0, 'bce_loss_weight': 2.0, 'kld_loss_weight': 0.1, 'kld_sigma': 1.0, 'seg_cls_loss_weight': 2.0, 'seg_cls_loss_per_cls_weight': [0.1, 1.0, 1.0], 'use_teacher_ref': False, 'use_bidir_bio': True, 'use_cross_attn_bio': False, 'use_crf_bio': False, 'pred_binary_span': False, 'focal_tversky_alpha': 0.4, 'focal_tversky_beta': 0.6, 'bidir_nhead': 8, 'bidir_dim_feedforward': 2048, 'lora_alpha': 16, 'lora_dropout': 0.05, 'lora_target_modules': 'q_proj,v_proj', 'explanatory': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'num_classes_per_sample': 5, 'exclude_val': False, 'no_eval': False, 'eval_only': False, 'vision_pretrained': '/shared/nas/data/m1/jk100/code/OpenAttrLibrary/LISA/weights/sam_vit_h_4b8939.pth', 'out_dim': 256, 'resume': '', 'print_freq': 1, 'start_epoch': 0, 'gradient_checkpointing': True, 'train_mask_decoder': True, 'train_mask_prompt_encoder': True, 'use_mm_start_end': True, 'auto_resume': True, 'conv_type': 'llava_v1', 'log_dir': './runs/plum-13b_kld_0.1_focal_tversky_8_v1_partonomy_ft'}
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_init.py:init():614] starting backend
2025-04-30 20:54:27,535 INFO    MainThread:2280013 [wandb_init.py:init():618] setting up manager
2025-04-30 20:54:27,536 INFO    MainThread:2280013 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-30 20:54:27,537 INFO    MainThread:2280013 [wandb_init.py:init():624] backend started and connected
2025-04-30 20:54:27,539 INFO    MainThread:2280013 [wandb_init.py:init():716] updated telemetry
2025-04-30 20:54:27,547 INFO    MainThread:2280013 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2025-04-30 20:54:27,762 INFO    MainThread:2280013 [wandb_run.py:_on_init():2254] communicating current version
2025-04-30 20:54:27,833 INFO    MainThread:2280013 [wandb_run.py:_on_init():2263] got version response upgrade_message: "wandb version 0.19.10 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-04-30 20:54:27,833 INFO    MainThread:2280013 [wandb_init.py:init():800] starting run threads in backend
2025-04-30 20:54:32,258 INFO    MainThread:2280013 [wandb_run.py:_console_start():2233] atexit reg
2025-04-30 20:54:32,258 INFO    MainThread:2280013 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2025-04-30 20:54:32,258 INFO    MainThread:2280013 [wandb_run.py:_redirect():2153] Wrapping output streams.
2025-04-30 20:54:32,258 INFO    MainThread:2280013 [wandb_run.py:_redirect():2178] Redirects installed.
2025-04-30 20:54:32,258 INFO    MainThread:2280013 [wandb_init.py:init():841] run started, returning control to user process
